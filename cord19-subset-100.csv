paper_id,title,body_text,journal
PMC7789912,Evaluation of two rapid ultrafiltration-based methods for SARS-CoV-2 concentration from wastewater,"There is increasing evidence that untreated wastewater is a promising unbiased indicator of the presence of SARS-CoV-2 virus in the population as it has been reported by different research groups as a possible way to monitor trends and the approximate overall prevalence of COVID-19 in the population (Kitajima et al., 2020; Medema et al., 2020a).
Given the coronavirus pandemic impacts, the method to detect SARS-CoV-2 RNA in wastewater had, by necessity, to be developed and implemented at warp-speed. One of the major challenges in SARS-CoV-2 research in wastewater has been the lack of standardized protocols for its detection. The way the virus is concentrated seems to be crucial in order to avoid false negative results or inaccurate reported concentrations.
On the lack of much data regarding coronavirus recovery efficiency when using common methods for viral concentration, we should rely on what it is known for other enveloped viruses considering that every single virus will have a different behaviour during viral concentration. Alone or combined, electropositive and electronegative filtration, centrifugal ultrafiltration, organic flocculation and PEG/Al(OH)3 precipitation methods have been used in different studies targeting enveloped viruses' in environmental waters as recently reviewed (Rusiñol et al., 2020).
Preliminary data obtained by our research group in a study evaluating different concentration methods for the detection of SARS-CoV-2 in wastewater showed no significant differences between skimmed milk organic flocculation and Centricon® Plus-70 and CP-Select™ ultrafiltration devices (Rusiñol et al., 2020). Centricon® Plus-70 ultrafilters have been described as a useful method for SARS-CoV-2 concentration from wastewater. Ultrafiltration is an interesting method since: i) samples do not need preacidification, ii) nor a long time of precipitation, which could not favour the stability of enveloped viruses, and iii) their concentration relies mainly on their size. However, and due to COVID-19 pandemic, there has been a shortage of these ultrafiltration devices. For this reason, this study was focused on the evaluation of two ultrafiltration methods described as useful for SARS-CoV-2 concentration from wastewater. Centricon® Plus-70 30 kDa devices and the Concentrator Pipette CP-Select™ from Innovaprep were tested to concentrate raw wastewater samples artificially spiked with MS2 bacteriophage and Murine Hepatitis Coronavirus (MHV) and presenting also naturally occurring SARS-CoV-2, Human adenoviruses (HAdV) and JC polyomaviruses (JCPyV). Centricon® of different cut-off size (10, 30 and 100 kDa) have been applied to concentrate SARS-CoV-2 (Medema et al., 2020a; Rusiñol et al., 2020). In this issue 30 kDa were the filters of election, trying to favour viral retention while avoiding the retention of smaller molecules that could act as enzymatic inhibitors. Regarding filter tips to be coupled to CP-Select™, the smallest available pore size tips (150 kDa) were used. The novelty of this method resides in the use of a pressurized eluent in the form of wet foam.
Bacteriophage MS2 (ATCC 23631), a model for non-enveloped RNA viruses and Murine Hepatitis Virus-A59 (MHV-A59), a model for enveloped betacoronaviruses (like SARS-CoV-2), were propagated using the following protocols. Bacteriophage MS2 was cultured in Salmonella typhimurium strain WG49 (NCTC 12484) following ISO 10705-1 indications. MHV-A59 and DBT murine cell line were kindly provided by Wigginton Group Research, Michigan University, Michigan. MHV were propagated by infecting confluent monolayers of DBT cells following previously described instructions (Leibowitz et al., 2011). Viruses were clarified from the supernatant by centrifugation at 3,000 ×g for 15 min and the supernatants were kept at −80 °C.
A total of 22 24-h-composite raw wastewater samples (500 ml) were collected between March and September 2020 from 6 WWTPs, located in Catalonia (Spain) (Table 1
). The selected WWTPs treat urban and industrial wastewater from approximately 20% of the Catalan population. Samples were either shipped to the laboratory under cool conditions or alternatively stored after collection at −20 °C.
Additionally, to determine the relation between the viral recovery and wastewater physicochemical characteristics, the turbidity was measured using a turbidimeter HI98703 (Hanna Instruments Inc.), the pH was measured using a pHmeter 902/4 (Nahita Inc.) and the BOD5 values were provided by WWTP managers.
An aliquot of 200 ml of each wastewater sample was seeded with 107 GC/ml of MS2 and MHV (1:100, v/v). Samples were centrifuged at 4,750 ×g for 30 min in order to remove suspended solids that may interfere with the ultrafiltration. The resulting supernatant was divided into two aliquots of 100 ml and subjected to two different viral concentration methods:
1) Concentration Pipette CP-Select™ using Hollow Fiber Polysulfone PVP high-flow pipette ultrafilter tips (CPT) with a cut-off of 150 KDa (InnovaPrep) and 2) Centricon® Plus-70 centrifugal ultrafiltration (CeUF) devices, with a cut-off of 30 KDa (Millipore). CP-Select™ method began with filtration of 80 ml of supernatant through single-use CPT. Viral particles were eluted with 0.075% Tween-20/Tris using Wet Foam Elution™ cans (Innovaprep) into a final volume of between 240 μl and 600 μl.
The CeUF devices were pre-rinsed before use, following manufacturer instructions, and then 70 ml of supernatant was centrifuged at 3,000 ×g for 30 min. Viruses were eluted inverting the CeUF device and centrifuged at 1,000 ×g for 3 min to obtain the final concentrate of approximately 280–900 μl.
Viral nucleic acids (NA) were extracted using the QIAmp Viral RNA Mini kit (Qiagen, Inc., Valencia, CA) according to the manufacturer's protocol in an automated QIAcube platform (Qiagen, Inc., Valencia, CA). The volume of the concentrates used for the extraction were 140 μl and the elution volumes were 60–80 μl. A negative control of the viral nucleic acid extraction was added per batch of samples.
Specific real-time qPCR and RT-qPCR assays previously described were used to quantify SARS-CoV-2 N1 and N2 (probes, primers and cycling conditions described in the CDC-006-00019 CDC/DDID/NCIRD/ Division of Viral Diseases protocol), MS2 bacteriophage (Pecson et al., 2009), MHV (Ahmed et al., 2020), HAdV (Hernroth et al., 2002) and JCPyV (Pal et al., 2006) by using TaqMan™ Environmental Master Mix 2.0 and RNA UltraSense™ One-Step RT-qPCR System (Invitrogen) for DNA and RNA viruses respectively. Quantification was performed in a StepOne plus Real-Time PCR System (Applied Biosystems, USA). Undiluted and 10-fold dilutions of the nucleic acid extracts were analyzed in duplicate. All the qPCR and RT-qPCR assays included non-template controls to demonstrate that the mix did not produce fluorescence and bovine serum albumina (BSA) (1 mg/ml), was added to RT-qPCR assays to reduce PCR inhibitors. The standards for viruses were prepared using synthetic gBlocks® Gene Fragments (IDT) and quantified with a Qubit® fluorometer (Thermo Fisher Scientific) except for SARS-CoV-2 standard which was constructed using the EURM-019 single stranded RNA fragments of SARS-CoV-2, provided by the European Commission Joint Research Centre. For all the standards, ten-fold dilutions were prepared from 100 to 107 copies per reaction.
As for enzymatic inhibition we performed previous tests, when setting up qPCR for N1 and N2 assays for SARS-CoV-2 detection, by adding known amounts of target RNA into wastewater. Inhibition was reduced when including BSA to the qPCR master mix. Every tested sample was previously spiked with MS2 bacteriophages that were used as a process control as well as for controlling inhibition by analysing tenfold dilutions of every nucleic acid extraction.
The limit of detection (LoD) of the whole method (including ultrafiltration, extraction and RT-qPCR detection) was calculated by running six replicate tenfold dilutions of target DNA/RNA suspensions around the detection end point (2.5, 5, 25 and 50 GC/reaction), for each analyzed virus. The concentration that produced at least 95% positive replicates was assumed to be the LoD of the qPCR assay, which was transformed to LoD of the entire method using the sample volume tested in each of the methodologies. The limit of quantification (LoQ) was estimated using the procedure described by Foorotan and colleagues (Forootan et al., 2017).
Viral recovery percentage was calculated according to experimental values obtained by spiking samples with MS2 and MHV viral stocks, shaking for 10 min and using as input viral concentration the direct quantification of the viral stock added:Virus recovery%=Concentrate TiterGC/mlXSample VolumemlInoculum TiterGC/mlXSample Volumeml/100X100

To shed some light into the role that the matrix into which viral stock is embedded may play when calculating viral recoveries, four different quantification strategies were conducted: 1) direct quantification of the viral stocks; 2) quantification of raw wastewater spiked with known concentrations of the viral stocks; 3) same as 2 but after debris removal, and 4) quantification of the viral stocks in a concentrated wastewater sample. All these quantifications were assayed in triplicate.
To investigate the percentage of coronaviruses which could remain attached to suspended material and not be properly quantified using ultrafiltration methods, viruses present in pellets obtained after centrifugation of 9 raw wastewater samples were further eluted in 3.5 ml of glycine buffer pH 9.5 for 30 min and after the addition of 3.5 ml of 2xPBS centrifuged at 3000 ×g for 20 min. The resulting supernatant (6.5–7.5 ml) was filtered using Amicon® Ultra-15 Centrifuge Filters Ultracell® 50KDa (Merck Millipore) and eluted for further viral quantification. Simultaneously supernatants obtained after first centrifugation were further concentrated as described in section 2.3 using Centricon® Plus-70 devices.
CP-Select™ manufacturer recommends the addition of Tween-20 before ultrafiltration in order to increase viral recovery. The appropriateness of including this step to the CP-Select™ concentration protocol step was evaluated in 3 selected wastewater samples (100 ml). Prior to ultrafiltration, 5% Tween 20 (1:100, v/v) was added to raw wastewater and processed as described above.
Data visualization, plotting and statistical test was done using R version 4.0.2. For each virus, Wilcoxon signed rank tests for paired data were used to evaluate whether there were statistically significant differences between both ultrafiltration methods. To evaluate potential associations between viral recovery and raw wastewater turbidity we run Pearson's correlation coefficient tests.
The MS2 phage, a non-enveloped RNA virus frequently used as a process control in environmental studies (Coulliette et al., 2014; Ikner et al., 2011; Ye et al., 2016) and the MHV, an enveloped RNA surrogate for human coronavirus (Ahmed et al., 2020; Casanova et al., 2009; Ye et al., 2016), were seeded to calculate viral concentration methods recovery efficiencies.
Mean recovery values for MS2 and MHV in wastewater are represented in Fig. 1
. No statistically significant differences were observed between concentration methods regarding MS2 recovery (p-value = 0.75) but CeUF provided significant highest mean recoveries for MHV (p-value = 0.004). However, no statistical differences were observed between the two methods when naturally occurring viruses were quantified (Fig. 2
): SARS-CoV-2 (p-value of 0.27 and 0.73 for N1 and N2, respectively), HAdV, JCPyV (p-values >0.05). CeUF provided higher mean recovery percentages for MHV whereas CP-Select™ provided higher recovery rates for MS2.

Table 2
summarizes equivalent sample volumes analyzed and the resulting concentration factors by using CP-Select™ or CeUF methods as well as the limits of detection and quantification (LoD95% and LoQ), calculated mean recoveries, standard deviations and coefficients of variation of the compared concentration methods based on MS2 and MHV quantifications. By using the concentrating pipette, a higher concentration factor was obtained, and a larger sample volume was analyzed in each RT-qPCR reaction.
After addition of Tween-20 into wastewater previously to concentration with CP-Select™, no statistical differences were observed when adding Tween-20 (p-value = 0.105), obtaining mean values of 50.7 and 20.9 GC/ml SARS-CoV-2 with and without Tween-20 addition respectively. However, the ultrafiltration time when adding Tween-20 was reduced.
When evaluating if calculation of viral recoveries could be biased by the effect of the matrix in which viral stocks were embedded, no significant differences were observed when quantifying MS2 stocks directly or within different wastewater matrices (p-values >0.05) (Fig. 3
). On the other hand, MHV stock quantification showed a matrix effect suggesting that the way the viral stock, used for spiking recovery assays, is quantified may influence recovery values obtained. In this study, the recoveries represented in Fig. 1 were calculated according to the direct quantification of the MHV used for spiking whereas MHV stock quantification in wastewater matrices would have showed higher viral recoveries (data not shown).
Seeded MS2 and naturally occurring SARS-CoV-2 (N1 gene) were quantified from sample concentrates and in the generated pellets at the debris removal step (Fig. 4
). For MS2, similar fractions were measured from the pellet (49%) and the supernatant (51%). For the naturally occurring SARS-CoV-2 (N1 assay), those samples that could be quantified showed more variability. In samples 1–9, most of the detectable SARS-CoV-2 fraction (mean values of 77%) was measured in the supernatant whereas the remaining 23% was detected in the pellets.
The turbidity of the wastewater samples was highly variable, ranging from 106 to 830 NTU (Nephelometric Turbidity Units). Weak correlations were observed between sample turbidity and viral quantifications obtained by using the CP-Select™ method (Pearson's correlation coefficients of 0.2 and 0.4 for MS2 and MHV, respectively) and inverse relation with sample turbidity was observed when using CeUF (Pearson's correlation coefficients of 0.2 and 0.1 for MS2 and MHV, respectively). No correlations between viral concentrations and pH and BOD5 were observed (<0.3).
In the actual pandemic scenario, viral concentration methods showing acceptable performance for both enveloped and non-enveloped viruses have received increased attention. As recently reviewed, a wide variety of strategies are being used to study viral presence in wastewater (Corpuz et al., 2020) but few of those concentration methodologies has been implemented for SARS-CoV-2 surveillance (Rusiñol et al., 2020). When comparing methodologies, ultrafiltration achieves higher MHV recoveries (25%) than PEG precipitation (5%), but the ultrafiltration devices are less used than flocculation/precipitation methods (Ye et al., 2016). This has been mainly caused by the shortage of supplies and the lack of readily material in many countries during lockdowns. Nevertheless, the one-step centrifugal ultrafiltration techniques enable the detection of viruses from relatively small sample volumes (70–80 ml).
Three ultrafiltration devices: the Centricon® Plus-70 (Medema et al., 2020b), the Amicon® Ultra-15 (Ahmed et al., 2020) and the new automatic Concentrating Pipette (CP-Select™) from Innovaprep (Gonzalez et al., 2020; Rusiñol et al., 2020) have been successfully used to detect SARS-CoV-2 from wastewater. The first two devices have also been used to concentrate other human enteric viruses from water (Qiu et al., 2016; Sidhu et al., 2018). Viruses are retained based on size exclusion and backwashed from the ultrafilters. Both CeUF devices (Centricon® and Amicon®) contain an Ultracell® regenerated cellulose membrane that results in 19 cm2 and 7.6 cm2 respectively, whereas the CP-Select™ with Hollow Fiber Polysulfone ultrafiltration tips has a surface are of 98 cm2, which is 5 to 13 times larger than those of the other CeUF devices. To our knowledge this is the first study that compares the performance of the CP-Select™ with Centricon® Plus-70 to concentrate SARS-CoV-2 and other viruses from wastewater samples. It should be noticed that this system includes a wet foam elution step which according to the manufacturer's improves viral elution from filter cells.
When applying ultrafiltration to wastewater, samples need to be pre-centrifuged to remove larger particles and avoid clogging. The resulting supernatant (70 - 80 ml) is then passed in a single-step through the ultrafilter. Viruses have been reported to adsorb to the solid fraction of wastewater (Ye et al., 2016). According to our results, 23% of total detected SARS-CoV-2 would be discarded during the debris removal step while higher percentage of the detectable MS2 (49%) would be retained in the pellet. Ye et al. (2016) reported MHV to adsorb to the solid fraction of wastewater samples in higher percentages (26%) than MS2 (6%) while Ahmed et al., reported similar loss for seeded MHV (30%) at the pre-filtration step (Ahmed et al., 2020). According to our results and considering the need of easy and fast method for SARS-CoV-2 detection in wastewater as an early warning tool, a straightforward and routinely adopted method shouldn't consider including viruses attached to the debris. This would imply an extra elution step, from the debris, and addition to the wastewater sample, which would suppose an addition of only a percentage of viruses attached to solid material. Thus, in our opinion, this step is not worth doing for routine testing and only when very high sensitivities and accurate quantifications are needed. Regarding the two ultrafiltration methods evaluated in this study, significant differences were only observed for MHV for which CeUF devices performed better than CP-Select™. In contrast, for naturally occurring SARS-CoV-2 both methods provided similar results showing that, as expected, each single virus behave differently under the same concentration procedure. Despite MHV is also a member of the Genus Betacoronavirus (as SARS-CoV-2), it did not show equivalent recovery rates to CeUF. Interestingly, however, the concentration of naturally occurring SARS-CoV-2 from wastewater using both concentration methods resulted in equivalent outcomes. This suggest that the best way to compare concentration methods for SARS-CoV-2 could be testing real environmental samples since, as observed for other viruses and other concentration methods, each virus has a particular behaviour for each of the methodologies applied. The way the MHV stock was quantified seemed to affect the recovery value obtained thus pointing at a clear effect of the matrix into which the viral stock is suspended. This could be probably due to different RNA protection/degradation phenomena or to the presence/absence of enzymatic inhibition in the different matrices assayed. This is another reason to consider when evaluating viral concentration methods and another argument in favour of using naturally occurring virus to complement concentration methods comparison studies, although this strategy does not allow the estimation of recovery rates.
Overall, CeUF devices were confirmed as an efficient ultrafiltration procedure for SARS-CoV-2 as it has been previously reported by others (Ahmed et al., 2020; Medema et al., 2020b). Moreover, CP-Select™ with Hollow Fiber Polysulfone tips showed to be useful for SARS-CoV-2 concentration from wastewater as well as for the concentration of other wastewater occurring viruses independently of the turbidity of the samples. It is worth mentioning that equipment fits into a BSL-2 cabinet which makes this procedure strongly recommended for viruses requiring biosafety containment. In turn, CeUF devices should be used in a superspeed centrifuge that is difficult to fit into BSL-2 facility especially in routine laboratories that require extreme security measures to avoid spill overs.
Also, CP-Select™ provides with good concentration factor and equivalent LoD, LoQ and variance than CeUF devices. The use of Tween-20, as it has been recommended by manufacturers, has not proven to increase SARS-CoV-2 recovery although it has been observed it may help to filtrate samples reducing the time required for ultrafiltration.
CP-Select™ is a handy equipment that can be applied without previous debris elimination or by only using syringe filters or vacuum filtration devices. This device allows concentration at the point-of-use by simply connecting the CP-Select™ equipment to a power supply. The number of methods available for SARS-CoV-2 concentration from wastewater is increasing, as well as data on their performance, which will be relevant for researchers and routine laboratories in order to make a good election on their SARS-CoV-2 testing strategies. Detection of other potential pandemic enveloped viruses, that could emerge soon, would require optimized and well characterized viral concentration methods.

•Ultrafiltration devices (Centricon® and CP-Select™) performed equally for different naturally occurring viruses, including SARS-CoV-2, whereas for the spiked MHV, used as a model of enveloped viruses of the genus betacoronavirus, the CeUF achieved higher recoveries.•The way the viral stock is quantified may influence recovery values calculations.•Up to 23% of detected SARS-CoV-2 adsorb to the solid fraction and is not considered in the further detection by quantitative PCR.•The CP-Select™ fits into a BSL-2 cabinet enabling to work under biosafety containment


E. Forés: Investigation, Methodology, Formal analysis, Writing – original draft. S. Bofill-Mas: Methodology, Formal analysis, Writing – original draft, Conceptualization, Writing – review & editing. M. Itarte: Methodology, Formal analysis. S. Martínez-Puchol: Methodology. A. Hundesa: Methodology. M. Calvo: Formal analysis. C.M. Borrego: Investigation, Writing – review & editing. L.L. Corominas: Investigation, Writing – review & editing. R. Girones: Writing – review & editing. M. Rusiñol: Methodology, Formal analysis, Conceptualization, Writing – original draft, Supervision.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Sci Total Environ
PMC7557303,Numerical simulation of the novel coronavirus spreading(),"In December 2019 coronavirus disease (COVID-19) emerged in China. Within a few weeks, the disease spread far beyond China, reaching countries in all parts of the globe. At the beginning of March 2020, the governments in most countries, including Europe, closed the borders for international movement. Also, the freedom to travel within the countries has been significantly curbed. This is associated with the decision to take immediate actions to limit the spread of the COVID-19 virus(Wu, Leung, & Leung, 2020). Actions taken include stopping the inflow of people from abroad, and limiting or eliminating the possibility of gathering people in larger clusters and social groups(Lloyd-Smith, Schreiber, Kopp, & Getz, 2005). All persons coming to these countries are subject to quarantine for at least 14 days, while citizens are asked to minimize their stay away from home, and are encouraged to stay at home to decrease virus transmission (similar processes have been previously described in relation to the SARS epidemic(Chowell and Lee, 2015, Kucharski, 2015, Riley et al., 2005). At the same time, a few European governments adopted a strategy of maximum hygiene, self-control, and elimination of social activities of these groups of citizens who are particularly exposed to the risk of infection. The main attention was directed to the elderly people whose stay at home was highly recommended(Alwan et al., 2020).
Despite the weakening of the epidemic dynamics spread in most regions, forecasting the development of the COVID-19 remains an issue that plays an important role, helping to quantify possible control and manageable levels of the disease. Due to the global nature of the phenomenon, though the incomplete clinical COVID-19 description, the scale of availability and amount of collected epidemic data(World Health Organization, 2020) is unique and allows extensive use of data mining and modeling methods, which become essential parts of assessing the impacts of mitigation strategies(Anderson, Heesterbeek, Klinkenberg, & DeirdreHollingsworth, 2020). In this context, mathematical models of infectious disease transmission dynamics remain one of the most useful and popular methods, that allow to predict, assess, and control potential epidemic outbreaks(Djordjevic et al., 2018, Rachah and Torres, 2018).
Traditionally, differential equations have been used to describe the spreading of a contagious disease(Murray, 1993). An epidemic model usually falls under one of the following types: SIR, SIS, SEIR or SEIRS. This involves taking into account in our model parameters specific to the SEIR models. The components of these models, i.e.individuals susceptible (S), exposed (E), infected (I) and recovered (R), change their value over the time according to time-dependent differential equations(Fu and Milne, 2003, Liu et al., 2006, Milne et al., 2008, Pfeifer et al., 2008). Recently, more complex compartmental models have been proposed for COVID-19 analysis, i.e.SIRD model with death (D) class(Fanelli & Piazza, 2020) and SEIPAHRF model with new super-spreaders (P), asymptomatic (A), hospitalized (H), fatality (F) classes(Ndairou, Area, Nieto, & Torres, 2020). These models introduce new groups of population, which appear to be relevant in the context of medical reports, but still do not take into account the local characteristics of the epidemic spread process, individual contact processes and their effects, spatial aspects of the spread of the epidemic, and different vulnerability patterns groups of individuals(White, del Rey, & Sanchez, 2007).
In this paper we applied an improved cellular automata (CA) approach to verify (using available epidemiological and social data) the potential causes of the observed epidemic features and help to develop guidelines which will be more effective in terms of government goals. Our analyses are based on the use of a modified influenza spread model, which we presented in our earlier paper(Holko, Medrek, Pastuszak, & Phusavat, 2016). Our model remove the drawbacks of traditional models(Achmed & Agiza, 1998) by the inclusion of external infections attributed to moving individuals(Boccara & Cheong, 1993) and reflecting the realistic age structure of the population with age dependent vulnerability of individuals(White et al., 2007) and real population density distribution. Although classic CA model has some limitations like shape of cells, the regular neighbors pattern and simple rules of interconnections between people, researches try to overcome these disadvantages integrating e.g.the geographical assumptions necessary for studying the epidemics spread in a realistic way(Zhong, Huang, & Song, 0000). Our model develops such approach and introduces factors related to the actual demographic and geographic profiles of the simulated population. Consequently, we can now present a novel, complete SEIR model to simulate the epidemic spread based on CA. The simulation results obtained seem to be in agreement with the observed features of the COVID-19 epidemic. The considerations presented in the paper are aimed mainly at presenting a new simulation model and detailed analysis of the results of modeling in the social and economic perspectives will be the subject of our further work.
The paper is organized as follows: the next Section presents numerical model. The spatial and social parameters used in our simulations are described briefly in Section3. Section4 contains results of numerical simulations. The paper is concluded by a short summary of main results.
We introduced into the daily commutes model the assumption that exposed (E) and recovered (R) travelers are irrelevant to the spread of the epidemic since they cannot infect anyone and re-infect themselves. The numbers of individuals who travel to another cell at the t instant of time is denoted by the  (10)nijt=ϕhSijt,ϕinvIij|1t,…,ϕinvIij|bt,where ϕh and ϕinv denote the fractions of healthy and infective individuals commuting outside the cell, respectively. The states of the source (i,j) and destination (x,y) cells are defined by  (11)sij→xyt=sijt−nijt,forcell(i,j),sxyt+nijt,forcell(x,y).Moreover, we assume that the destination cell is randomly selected from the three cells with largest population over a neighborhood defined by the Chebyshev distance Dij→xy(Abello, Pardalos, & Resende, 2002) between the (i,j) and (x,y) cell given by  (12)Dij→xy=max|x−i|,|y−j|=3.

In our model the transition function is defined by the set of the following equations:  (13)Sijt+1=(1−μd+μb)((1−pijt)(Sijt−∑(x,y)∈CSij→xyt)+∑(x,y)∈C(1−pxyt)Sxy→ijt),(14)Eij|1t+1=(1−μd+μb)(pijtSijt),(15)Eij|kt+1=(1−μd+μb−μm)Eij|k−1t,(16)Iij|1t+1=(1−μd+μb−μm)Eij|at,(17)Iij|lt+1=(1−μd+μb−μm)Iij|l−1t,(18)Rijt+1=(1−μd+μb)Rijt+(1−μd+μb−μm)Iij|bt, where 2≤k≤a and 2≤l≤b denote the day number of E and I states respectively, μd and μb are natural deaths and births rates (Eq.(23)), μm is the COVID-19 mortality rate. Descriptions and initial values of all parameters used in eqs.(13)–(18) are listed in Table2. Additionally we introduced the direct contact rate βc which corresponds to the number of direct contacts of susceptible individuals (∈S) with infectious (∈I), which may reflect the population density(Hu, Nigmatulina, & Eckhoff, 2013), the epidemic phase and prevention. New infections appear according toEq.(14) where pijt is the random probability of infection given by  (19)pijt=0,gijt<0,1,gijt>1,gijt,0≤gijt≤1,(20)gijt=rndbi,j(βc,n,pst)=βcn⋅pstβc⋅qn−βci,j,cv, where gijt is a Gaussian random number with mean value bi,j(βc,n,pst) defined by the binomial probability of infection in βc direct contacts between susceptible S and infectious I individuals, n is the total number of contacts a person has with other people, pst=Ii,jtNi,jt is the straight probability of infection given by the ratio of infectious in the whole population, q=1−pst and cv is the variance of the Gaussian generator. Fig.2(a) shows the mean value of probability of infection as a function of direct contact rate c for four cases of straight probability pst=∈{0.01,0.05,0.10,0.15}.


To reflect different mortality for various age ranges A of a population we introduced into our model variable mortality rate μm, which is randomly chosen with the probability density which reflects the demographical structure of the population:  (21)Pr(A=a)∈{pa∀a},(22)∑apa=1 where a∈{0−9,10−19,..,70−79,80+} is the age range and pa is the probability density of belonging the individual to chosen age range. The values of μm we select with particular attention to empirical data(Lin et al., 2020) in Section2.2.
Our CA simulation system is based on heterogeneous distribution of the population across the cells (Fig.3) and can change over time due to births and deaths. We use numerical grids of population counts for Poland, France and Spain with the cell size ≈9x9 km (Poland), ≈13x13 km (France) and ≈12x12 km (Spain) where initial values Nij0 we set according to CIESIN population counts, v.3(Center for International Earth Science Information Network (CIESIN) / Columbia University; United Nations Food and Agriculture Programme (FAO); Centro Internacional de Agricultura Tropical (CIAT), 2005).
Since the mortality rate in our simulation varies for different age ranges of individuals (see Eq.(21)) we use the actual age distribution of Poland(CentralStatisticalOffice, 2017), France and Spain(United Nations, Department of Economic and Social Affairs, Population Division, 2020) to set the appropriate mortality rates for each age range of these populations (Fig.4).

According to recent reports COVID-19 mortality rate differs not only by age, but also by gender of the individuals. Although male COVID-19 mortality rate is generally higher than the COVID-19 female mortality rate across all ages in all countries, there are some notable differences between individual countries. Table1 shows the GMR (gender mortality ratio) defined by  GMR=MalemortalityrateFemalemortalityratefor age ranges 40+ reported by Reinsurance Group of America(Ng, Bakrania, Russell, & Falkous, 2020) for Spain (data for age groups 0−40, and Poland and France were not accessible). We use the GMR values and the age–gender structure of Spanish population(United Nations, Department of Economic and Social Affairs, Population Division, 2020) to obtain corresponding mortality rates for males and females in all age groups — they are presented in two last columns of Table1.
At initial stages of an epidemic, numerical modeling can help understand the dynamics of a new disease and identify key parameters affecting the speed of its spread. Table2 shows the initial values of key model parameters which we estimate according to recent reports from the regions that were affected by the COVID-19 epidemic — estimation sources are listed in the last column. The lengths of exposed a=1∕δ (Eq.(3)) and infective b=1∕γ
(Eqs.(4), (5)) states we set according to median incubation period of COVID-19 (5.1 days) reported by Lauer etal.(Lauer et al., 2020) and most infectious period (7 days) reported by Kelvin Kai Wang etal.(Kai-WangTo, 2020).

Our simulations are geographically located in three countries: Poland, France, and Spain. Fig.3 (left panel) shows the grids configuration for selected regions. Moreover, to show the age structure for each country we divided each population into age ranges corresponding to different reported mortality ratios of COVID-19. Fig.3 shows the structure of populations provided by Countrymeters.info database(CountryMeters, 2020) and corresponding COVID-19 mortality ratios(WorldoMeters, 2020). Respective values of natural birth μb and natural death μd rates per one time step (1 day) for each countries we calculated using demographic data on the number of births and deaths in Poland, France, and Spain(United Nations, Department of Economic and Social Affairs, Population Division, 2020) according to equation  (23)μb∕d=numberofbirths/deathsN⋅numberofdaysinayear,where N is the total population of each country.
Since the probability of dying from the disease depends on the age of an individual we use heterogeneous and age-dependent mortality rate per time step μm, which is chosen according to age population structure (Fig.4(a)) and age distribution of COVID-19 mortality rate (Fig.4(b)). Additionally, our model includes daily commutes of individuals with different commuters ratio for healthy ϕh and infected ϕs individuals and commuting over a longer distance ϕc(Holko et al., 2016). These parameters we estimate according to “Statistics on commuting patterns at regional level” provided by Eurostat(Eurostat, 2016), where the number of people commuting to another region (NUTS, level 2) is assessed to 8.1% of total persons in employment, which gives the number of daily commuters about 3.7% of total population (with respect to employment rate ≈70% and the percentage of people of working age ≈64.7% in Europe,(Eurostat, 2020). The fraction of commuting infected population we estimate as 4∕7 of the value of daily commuters according to the median interval between symptom onset and hospitalization (isolation) (4 days) reported by epidemiologists(Kai-WangTo, 2020) while the mean length of the infective state we previously assessed to 7 days.
As reproduction number R0 is the critical conditioning parameter for the disease, we started by determining the relationship between R0 and the parameter of our simulation — contact rate βc (Eq.(20)). To set R0(t=0), we use the equation  (24)R0=∑(i,j)∈C∑k=1aEij|ka∑(i,j)∈CIij|10,according toHolko et al..

Fig.5 shows that R0 grows with βc and R0βc=0.5=3.5 which corresponds to the estimated value of reproduction number for COVID-19(Hellewell et al., 2020). The direct contact rate βc=0.5 meets the case when an infectious individual (∈I) has contacts with susceptible person (∈S) once every two days. For values of βc>0.5 we can expect epidemic progress while for smaller values of βc the epidemic is suppressed.

Additionally we empirically verified that the relationship of R0(βc) is independent of the geometry of simulation and the population structure; therefore we can assume that it is the same for all countries considered.


All results presented in this part are ensemble-averaged over 10 runs performed for the same initial configuration of infected individual, which was generated by a random selection of 15 cells with the population above 10000 and moving in each of these cells a group of 20 individuals to the infectious state. We ensured that averaging over a larger number of realizations gave no significant changes in the results.
First, we perform simulation of spreading disease for set values of βc∈{0.15,0.20,0.50,0.70,1.00,2.00}, corresponding to the most likely R0 values, in the vicinity of reported R0(βc=0.5)=3.5. Fig.6 displays the time history (with time step t in days, horizontal axis) of the number of individuals in compartments S,E+I,R. Since in the upper row of Fig.6(a)–(c) we present results for smaller βc and the disease lasts much longer than for bigger βc (lower row of Fig.6(d)–(f)), we set the range of t-axis to 750 and 250 days for upper and lower row of Fig.6, respectively.

Fig.6 shows that for all values of contact rate βc the number of susceptible individuals S (dash–dot line) decreases, while the number of recovered ones R (dotted line) grows with time. It is the result of an ongoing epidemic whose intensity depends on the number of the infected E+I (solid line). For very small values of βc∈{0.15,0.20} the number of S never falls below the number of the recovered R
(Fig.6(a)–(b)), which means that the disease affected less than half of the population. For βc=0.15 the epidemic spreads for limited time (t<75 days) but the numbers of E+I and R is much smaller than S and they are not discernible on Fig.6(a).
The dynamic of the disease hinges on the values of contact rate parameter (βc). Higher values of βc accelerate the disease (lower row of Fig.6, from (d) to (f)) and the number of infected individuals (E+I) reaches its maximum value faster if the βc is greater. The maximum value of E+I increases with the contact rate, the disease is accumulated in time for higher values of βc, while for low contact rates the number of infected individuals E+I is blurred in time and becomes less intense.

Fig.7 illustrates the number of deaths for 0≤t≤100 days of epidemic for different values of contact rate βc. It is noticeable that this relationship is more non-linear for larger values of βc>0.2, while for small βc=0.2 (which corresponds to R0=1.28) the number of victims increases almost linearly (internal enlarged panel in Fig.7). Observed dependency is in general agreement with epidemic patterns shown in Fig.6, where the nonlinearity of E+I grows for larger βc values.

The disease reveals time signatures that follow similar scenario for the constant values of βc: a rapid increase in the number of E+I and a slower decrease after it reaches its maximum (Fig.6). In order to simulate preventive measures that inhibit the development of an epidemic, we conducted simulations with βc value which changes in time – Fig.8. To reflect the preventive action taken at various stages of the epidemic development we use initial configurations with βc=0.5
(R0=3.5) and reduce it 5 times, at tint=15,20,..,40 day of the disease. It corresponds to a five-fold reduction in the number of direct contacts among people in the epidemic population. The left panel of Fig.8 shows the number of E+I as a function of time t and it confirms that such a strong reduction of βc (corresponding to R0≈0.6) stops the development of the epidemic and reduces the number of infected individuals faster if the reduction occurs earlier. However, this relation is not linear and the effect of shortening the epidemic is stronger for smaller tint (right panel of Fig.8): intervention at tint=15 reduces the length of the disease to ≈38% of its original length, while changing βc at tint=30 gives the epidemic reduction time up to ≈59%. It means that strong intervention taken even later in the development of epidemic can effectively shorten its duration.
Another way to reduce the spread of an epidemic may be decreasing the population mobility. In our model we have three commuting rates, separately for healthy population (ϕh), infected population (ϕs) and for individuals commuting outside their neighborhoods (ϕc) – typical values of these parameters are presented in Table2.

To verify the influence of such defined mobility of individuals on the spread of the disease, we set at t=0 20 infectious in the most dense cell of our system (with the population of over 112 000) and check how the disease develops for different values of commuting ratio ϕh
(ϕs=4∕7ϕh and ϕc=0.23ϕh,s - see Table2). The results are presented in Fig.9 where (a) shows the evolution of infection for ϕh=0.04 and (b) for increased mobilities ϕh=0.1. A much faster development of the epidemic is noticeable (Fig.9(b)) due to greater population mobility and this relationship is quantitatively confirmed by the time history of R number for different values of ϕh, presented on Fig.9(c). The difference between R number for growing commuting ratios is more discernible for larger t which suggests, that in the early stages of an epidemic t<70, the impact of mobility of individuals on the speed of epidemic development may be less. To check it we plot on Fig.10 the number of R as a function of commuting ratio ϕh for three instants of time: t=50 (a), t=60 (b) and t=100 (c). Our results confirm that the acceleration of the epidemic due to increased mobility is clearly visible after some period of time (t=100, Fig.10(c)), while at shorter intervals (Fig.10(a), (b)) it is not clearly visible. It may be the result of acquiring population resilience over time due to the larger R compartment in limited area (Fig.10(a), (b)), whereas for longer time the disease propagates to new regions (CA cells) and the epidemic suppression effect for higher values of commuting ratio ϕh is not so significant (Fig.10(c)).


In this section we consider the impact of the age structure of the population on the mortality rate μm, which we define as an indicator quantifying the increase or decrease in mortality due to the epidemics, i.e. (25)μm=NdR,where R and Nd denote the number of recovered and deaths from the disease, respectively. To verify the impact of the age structure of the population in real conditions, we conducted simulations for three selected countries whose populations show discernible differences — the right panel of Fig.3 shows population structures of Poland, France, and Spain in the analyzed age ranges. In the case of Poland, the largest age groups are in the range of 20–69years, and the number of older people (70+) is rapidly decreasing. In the case of Spain, and France especially, the oldest groups (70+), for which the observed mortality rate is the highest (8% for 70–79 and over 14% for the 80+ group) are much more numerous. Moreover, France has the most balanced age structure — all groups below 70years are similar.

To reflect the age structure we used in our model heterogeneous mortality, which was introduced into the numerical system as the COVID-19 mortality rate per time step μm selected according to different age structures for countries analyzed (Fig.4).

Fig.11 presents averaged (over 10 runs) mortality rate μm as a function of the contact rate βc for the analyzed populations, for the first t=200 days of the epidemic. The highest values of μm were obtained for France, which has the highest percentage of age group 60+. Slightly lower values of μm occur for Spain, which has a similar percentage in the 60+ age group, but in this case the number of people in the 0-29 age group is much smaller than in France. For Poland, whose population is relatively the most numerous in the 0-39 age range, the mortality rate is the lowest, regardless of βc. In general, the values of mortality rates for France range from about μm(βc=0.2)≈0.045 (corresponding to 4.5%) to μm(βc≥0.5)≈0.02 (2%). The lowest values of βc were obtained for Poland, and they are in the range μm∈0.019,0.024, while for Spain we received intermediate values of μm∈0.022,0.038. Our results confirm expectations related to the impact of the size of most exposed age groups (which are the biggest in France), on the mortality rate expressed for the entire population.
Another interesting effect is the dependence of μm on the value of contact rate βc: mortality rates are lower for bigger values of βc. Since increasing value of βc accelerates the spread of the epidemic we conclude that this relationship is the result of a faster reduction in the number of the most vulnerable population age groups (60+), which follows more intensively in the beginning of disease.
Finally, to test the impact of the gender (different mortality rates for males and females) on total mortality rate μm, we run some simulation for Spain with age–gender dependent mortalities provided by Reinsurance Group of America (see Table1). Received values of μm for βc∈{0.2,0.3,0.5,0.7} where consistent (within the error limits) with values presented in Fig.11. We conclude that such result confirms our findings and to assess the value of total mortality ratio μm we can use the averaged mortalities for different age groups (regardless of gender).
A common approach to quantify model parameters that cannot easily be measured directly is to adjust the parameters until the model output closely matches empirical data. This approach is known as inverse modeling or model calibration(Schittkowski, 2002). We infer the model parameters based on the data provided by European Centre for Disease Prevention and Control(ECDC, 2020) about the evolution of COVID-19. Fig.12 shows the best fit of cumulative number of infection E+I+R we have been able to get for Poland (a), France (b), and Spain (c). To estimate the values of the parameters βc, ϕh,s,c that should realistically reproduce the data, we use a best-fit approach: (1) we started with initial values of contact rate and commuting ratios reported in Table3 for t=0, (2) then we checked if the simulation results deviate from the data by more than 10% for the subsequent time steps t; (3) if so, we tried to adjust the parameters βc,ϕh,c to achieve the assumed compliance. At the beginning of the calibration process for each country, we set the initial configuration of infected individuals, which was generated by a random selection of 5 cells with the population above 50000 of inhabitants and moving in these cells a group of 5 individuals to the infective state. The estimated values of the model parameters are presented in Table2.

For the very early stage of the epidemic (Fig.12, t∈(t1,t2)) we estimated the highest value of βc=1.5 (which corresponds to the reproduction number R0≈10.5) for Spain, while for France it is βc=1.4
(R0=9.5) and for Poland βc=1.2
(R0=8). Received values of R0 are slightly overestimated in comparison with values of R0∈(1.49,6.49) reported by Liu etal. (Liu, Gayle, Wilder-Smith, & Rocklov, 2020) and Yuan etal.(Yuan, Li, G., & Lu, 2020). However, the effective reproduction number values estimated for other SEIR-type models are higher than for different methods (e.g.statistical exponential Growth, statistical maximum likelihood estimation)(Liu et al., 2020) and it may be the result the significant impact of the initial configuration of the system. For longer time t we can observe significant reduction in the contact rate βc and commuting rates ϕh,c, first for Poland and Spain (t2=22) and then for France (t=33). This is the result of introducing prevention, travel limitation and quarantine. The imposed restrictions were initially the largest in Poland (e.g.relatively the earliest closing of schools after registering the first cases of COVID-19), but over time France and Spain introduced stricter restrictions (especially in terms of freedom of communication) which are maintained in a mild form up today, while in Poland after about 60 days travel restrictions were lifted. Such scenario is in general agreement with our findings (Fig.12), where initial value of R0 is reduced to ≈0.5 for France and Spain (β=0.10), and to ≈0.9 for Poland (β=0.15). The number of infected individuals for France and Spain after t≈50 and t≈42 (respectively) clearly drops (Fig.12(b)–(c), dashed lines) which corresponds to the effective suppression of the epidemic, while for Poland the size of E+I compartment is not reduced in time (Fig.12(a), dashed line), which can be interpreted as a sign of lower effectiveness of the preventive action taken (R0 is close to 1).
Obtained simulations results show also a good agreement with the reported COVID-19 data for active cases (E+I). Fig.13 presents the time history of the active cases for Poland (a), France (b), and Spain (c) for the configuration from Table3 (dotted line) and reported values (circles)(WorldoMeters, 2020). The number of CA based active cases (dotted lines) is close to the real values for all countries. Solid lines on Fig.13 show the numbers of active cases for reduced length of exposed state E and extended length of infective state I (respectively, a and b parameters from Table2). We made such modification since there are many reports that the transmission of the virus may be presymptomatic(Ferretti et al., 2020, Wei et al., 2020). We tried to check the impact of such presymptomatic infections on the disease spreading by changing the duration of E and I states. Received results indicate high dependence on lengths of E and I states: with the reduction a to 4 days (extension b to 8 days) the number of active cases (Fig.13, solid lines) increases rapidly and significantly exceeds the observed values (Fig.13, circles). Better results we received for the previous model configuration (Fig.13, dotted lines) which confirms the typical duration of the exposed (a=5 days) and infective (b=7 days) states.
We investigate numerically the SEIR epidemic model for the novel coronavirus spreading. Our model uses two-dimensional cellular automata. Numerical simulations were performed for three countries affected by the epidemic, i.e.Poland, France, and Spain. Although the results obtained refer to the SEIR models described in earlier publications, the approach we propose includes new elements that increase the scientific and practical value of the models used so far.
Since the empirical data show a strong relationship between the age of infected people and the level of mortality, we introduced into the system probability of death which depends on the age structure of the populations under analysis. Numerical results show varying mortality rates for different countries, e.g.for France, where the fraction of people in the most vulnerable age group 60+ is high, the mortality is higher than that determined for Spain and Poland, where the group of 60+ is smaller, which is in general agreement with the statistical mortality values of COVID-19(ECDC, 2020). Moreover, we examined the relationship of the basic reproduction number and direct contact rate between individuals. The results show that one per two days contact of infectious people leads to infection over three individuals. The mobility of population also influences the speed of the epidemic spreading: increasing the population mobility leads to a growth in the number of people infected, particularly in the long term and this finding is consistent with the results of global metapopulation disease transmission model(Chinazzi et al., 2020). Our model also enables an analysis of the optimal response time in the early period of the epidemic development, which may be the basis for taking appropriate actions as a function of the expected effects, described by the parameters of duration of the epidemic and the level of disease incidence of citizens. Numerical simulations show that the implementation of prevention by limiting the number of contacts in a population significantly reduces the duration of the epidemic. However, even the earliest application and continuous maintenance of strong restrictions on people-to-people contacts does not shorten the epidemic duration below 120 days. Our study also confirms that to control the pandemic it might not be enough to limit the mobility of individuals (ϕh,s,c) and that contact rates (βc) reduction interventions will provide the greatest benefit for mitigating the epidemic(Chinazzi et al., 2020, Wei et al., 2020). Moreover, the calibration of our model on real epidemic data from Poland, France, and Spain allows us to reconstruct the real course of the epidemic in these countries, and the obtained reproduction ratio values at the beginning and current stage of the epidemic (R0t=0∈(8,10.5) and R0t≈100∈(0.5,1.0)) are qualitatively consistent with the reported data(Yuan et al., 2020).
We conclude that because CA based numerical framework reproduces several observed features of coronavirus disease, it can be a useful tool to study the mechanism of the COVID-19 epidemic spread and it may create a broad spectrum of new useful data. In every aspect of social life our framework can be used to model the impact of the epidemic on the social and economic environment, where the number of people available on the market or excluded from participating in its processes is important.
Although the model presented has some limitations, we believe that it may constitute an area for future research to be carried out by other authors. We plan to focus future work on the applicability of the CA model in modeling different preventing scenarios and in applying the same in social and economic processes.

M. Medrek: Conceptualization, Methodology, Software, Formal analysis, Investigation, Writing - original draft, Visualization. Z. Pastuszak: Conceptualization, Methodology, Validation, Writing - review & editing, Text structuring.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Expert Syst Appl
PMC7481134,Loss rate forecasting framework based on macroeconomic changes: Application to US credit card industry,"Similar to any industry, the goal in the consumer credit industry is to maximize profits by measuring and controlling risk and avoiding exposure to default (also known as charge-off), as much as possible. The term charge-off means an outstanding credit card debt, which is written off as bad debt. Consumers must issue payments by the due date, and failure to do so will result in putting the consumer’s account into delinquency or default. Typically, a bad credit card debt will be marked as charged-off after six months of non-payment, and it is withdrawn as an asset from the lender’s accounts. This is usually a final action since it is an indication to lenders that the consumer will never pay off their account. Thus the account is written-off as bad debt. The charge-off rate for a given bank or issuer is calculated by dividing the dollar amount of charge-offs by average outstanding balances on credit cards issued by the firm. A higher charge-off rate exhibits a higher risk to a company. Usually, strategic business analysis is incorporated by credit card issuers to develop credit policy and guidelines with legal and regulatory constraints. Credit policy helps an institution develop strategies within the planned asset quality range that are consistent with the institution’s profitability goals. Accurate prediction of charge-off rates has been one of the major challenging tasks in the credit card industry. A forecasting model that over-predicts the charge-off values will lead the company to take credit tightening actions sooner which can lead to a considerable decline in the potential profit. On the other hand, a forecasting model which under-predicts the charge-off rate will delay the credit tightening actions and may result in a significant loss. Hence, it is imperative that the forecasting model predicts the charge-off rate as accurately as possible. The charge-off rate has shown a strong tie to economic conditions, and it has hit its highest level during the financial crisis, which was 10.79% according to U.S. Federal Reserve data. Increasing the charge-off rates during the 2008 financial crisis led to the question of how we can predict the charge-off rate based on macroeconomic indicators under different economic conditions.
There has been extensive research on the relationship between charge-off risk and general economic climate, resulting in a general belief that macroeconomic factors directly affect bad debts and charge-offs. Historical data obtained from credit bureaus along with consumer performance data are analyzed by lenders to predict the future behavior of consumers and their risk of going delinquent or charging off. These predictive models classify consumers into different segments and align the bank’s strategies towards these segments accordingly. The problem is that many businesses rely only on these models to make decisions, and fail to include certain economic factors into their risk models. Sometimes, to include economic conditions, these predictive models are adjusted by several percentage points in the charge-off rate using a fraction of macroeconomic indicators. However, most of the time, only a fraction of economic aspects are reviewed for these adjustments, as they are deemed to be the most influential.
Consumers’ charge-off behavior can be heavily affected as the economy goes through good times (expansion phase) and bad times (the contraction phase), and they are not explicitly modeled in prediction models developed by credit risk management, which raises the question of how charge-off rate will change in different economic conditions. During economic expansion, consumers and businesses have enough income to pay their debts by their respective due dates, and thus this phase is associated with a small number of delinquencies and charge-offs. On the other hand, in the contraction phase, the number of bad debts will increase, which eventually will lead to a significant jump in the charge-off rate. Credit card companies can be affected by economic factors, and including economic factors in the decision-making process may significantly impact their ability to make effective charge-off decisions proactively. Failing to incorporate economic factors may lead to consequences that may take years for the company to recover. Since many other factors, such as government regulations, are already reducing the profits of credit card business, there is a need for a new approach that incorporates the relationship between economic factors and charge-off.
Early credit card portfolio literature could not find conclusive evidence on the effects of macroeconomic factors on charge-offs over the business cycle. For example, personal bankruptcy and credit card delinquencies in the 1990s were investigated in Gross and Souleles (2002), and authors concluded that the relationship between charge-offs and macroeconomic factors had changed substantially over the investigation period and there was no conclusive evidence to prove a relationship between charge-off rate and macroeconomic factors. They also concluded that the unemployment rate has no significant impact on the charge-off rate. They used panel data on credit card accounts for their analysis. However, later in Agarwal and Liu (2003), the authors stated that the unemployment rate has significant predictive power for the charge-off rate. They noted that the reason behind the fact that previous empirical studies could not find a consistent relationship between economic factors and bankruptcy is that those studies were either suffering from inadequate data or the variation in the unemployment rate was not sufficient during their analysis period.
Following the Great Recession in 2008, credit card companies focused heavily on controlling credit losses. Their emphasis is mostly on the unemployment rate, as it has a strong correlation with the charge-off rate. However, in the past few years, the unemployment rate was going down while the charge-off rate was increasing, and a model using the unemployment rate as its only input may not be able to capture the uptrend in the charge-off rate. Hence, credit card companies need to focus on other economic factors that can affect charge-offs, and most importantly, they need to look at the economy as a whole. Analyzing the impact of variables from all segments of the economy will provide lenders with a holistic insight and will help them to make more effective decisions to reduce future losses.
There are limited cases in the body of literature that focus on charge-off prediction models incorporating macroeconomic variables in the United States. The slope of U.S. Treasury bond yields over time was mentioned by Estrella and Hardouvelis (1991) and Estrella and Mishkin (1998) to have a strong relationship with output growth and recessions in the United States up to eight quarters in the future. Stock prices (Estrella & Mishkin, 1998), credit market activity (Levanon et al., 2011), index of leading economic indicator (Berge and Jordà, 2011, Stock and Watson, 2002) and several interest rates, housing indices and unemployment rate measures (Ng, 2014) as leading indicators for future economic conditions. Moreover, there are different views regarding the significance of specific economic factors. For instance, industrial production was found to be a significant predictor of corporate charge-offs by Figlewski et al. (2012). However, research was done by Giesecke et al. (2011) has shown that it may not be an important factor in forecasting the charge-off rate. Stochastic and fuzzy optimization algorithms can also be used in the financial industry to improve the efficiency of the algorithms (Mokhtarimousavi et al., 2019, Mokhtarimousavi et al., 2018, Rosen et al., 2016, Taghiyeh et al., 2020b, Taghiyeh and Xu, 2016).
The author was motivated to perform this study when he started working as an analyst at one of the leading credit card issuer companies in the United States. The models in production were using only the unemployment rate as their input to forecast future values of the loss rate, which had an R-squared value of about 63%. Aside from the relatively low R-squared value, the charge-off rate was going up in the past couple of years, but the unemployment rate was going down. Therefore, their model was unable to predict uptrend in the charge-off rate, and it was crucial to develop a new prediction model for the charge-off rate by incorporating macroeconomic factors from all aspects of the economy.
In this study, we sought to identify and analyze economic indicators that have a significant relationship with the charge-off rate in the credit card industry. Next, we will use machine learning techniques, namely, linear regression with Lasso, linear regression with Ridge, random forest, and gradient boosting machine to develop a loss forecasting framework using selected macroeconomic indicators. Finally, using the model selection approach introduced in [59] (MSIC algorithm), we will forecast each of the selected indicators to predict year over year changes. Nineteen macroeconomic indicators from three major economic categories will be used for this analysis. These economic categories include consumer, business, and government segments. The use of indicators from all segments gives a comprehensive view of the economic impact on charge-offs. Credit card companies have recently identified the unemployment rate and housing indices as charge-off accelerators. These two metrics will be included in our analysis to confirm or deny their assumptions. The consumer confidence index is another factor that can be seen to have an impact on charge-off rates, as consumer behavior may change payment behavior when they are optimistic or pessimistic towards the future. However, this index is very volatile and may fluctuate each month as the report comes out (Censky, 2010). Other macroeconomic indicators used in this research are new from a charge-off analysis standpoint. Charge-off data from the top 100 banks in the United States from 1985 to 2019 were used in this study to confirm if the selected macroeconomic indicators have significant predictive power for the duration of the analysis. The design of a prediction model covering all aspects of the economy will add significant value to financial institutions. In 2019, the total revolving credit in the United States was an average of $1076.2 billion (Board of Governors of the Federal Reserve System (US), 2020a). Taking into account the 3.63% charge-off rate in 2019 (Board of Governors of the Federal Reserve System (U.S.), 2020), the total amount of charge-offs in the United States was $39 billion. Even a 1% decrease in the charge-off rate, which is indeed possible using an accurate forecasting model, could lead to $390 million in savings for the US economy. Executives and managers can incorporate this information into their decision process to anticipate any future credit losses and fluctuations and modify their policies to avoid such upcoming losses.
The remainder of this paper is organized as follows. Section 2 reviews the literature on loss forecasting. Section 3 presents the details of our proposed loss forecasting framework based on macroeconomic indicators. Section 4 presents an empirical evaluation of the approach using loss data from the top 100 banks in the United States. We summarize our conclusions and discuss the practical implications of our work in Section 5.
To the best of our knowledge, there is only one study that examines the relationship between economic factors and the charge-off rate in the US economy (Liu & Xu, 2003). In an empirical study by Liu and Xu (2003), the authors use step-wise regression and vector autoregression to identify economic factors which demonstrate prediction of credit card charge-offs. The goal of their research was to develop a predictive model based on these variables. The authors concluded that the unemployment rate, consumer confidence index, household debt service burden, inflation rate, personal bankruptcy filings, and stock market returns are the variables that are useful in predicting the charge-off rate. However, there are a few issues with their work that justifies the need for a more recent and thorough analysis of economic variables for developing a predictive model for charge-offs. The first issue is that their analysis is focused on the period of 1986–1998, and there have been quite a few changes in the credit card industry structure, as well as global economic conditions. Second, Liu and Xu (2003), only include seven economic variables in their analysis, and they are not covering all economic dimensions spanning government, business, and household spending.
There exist several studies on the relationship between charge-offs and economic conditions. Ausubel (1997) noted that in a generally healthy economy, in which unemployment is relatively low and gross domestic product is growing reasonably, both bankruptcy and charge-off rates increased. This statement was made against the foundational belief that the charge-off rate will increase during depressed economic periods and decrease in robust economic periods, but more recent research has shown that other economic factors may contribute to charge-offs. For instance, debt-to-disposable income ratio was found by Stavins et al. (2000) to have a strong correlation with credit card charge-offs and bankruptcy rates.
The unemployment rate, consumer price index and the number of bankruptcy filings were deemed to be highly correlated with the charge-off rate in the case of Hong Kong (Fung & Wong, 2002). The authors used a vector regression model as the basis for their analysis. Macroeconomic indicators were analyzed by Agarwal and Liu (2003) to investigate rates of credit card delinquency. The authors concluded that macroeconomic fluctuations correlated with bankruptcy and delinquency rates. They also found that the unemployment rate has a strong effect on the rate of delinquency. By applying portfolio theory to consumer lending, Desai et al. (2014) extend the work of Musto and Souleles (2006). The authors used credit scores along with charge-off and bankruptcy rates to predict charge-offs. These authors also state that the effect of fluctuations in housing prices is not homogeneous across the population, and people with low credit scores, who highly leverage their credit, are more sensitive to these changes in housing prices.
A regime-switching model was employed by Giesecke et al. (2011) to evaluate the predictive power of macroeconomic variables forcharge-off rates. Changes in the gross domestic product, stock returns, and their volatility were identified as significant variables. Reduced-form Cox intensity models were fit by Figlewski et al. (2012) to analyze the relationship between a range of macroeconomic and firm-specific factors and charge-off and significant credit ratings. They found that both factor categories were significant, but macroeconomic variables were highly dependent on the inclusion of other factors. In an extension to their work, in Bellotti and Crook (2013), a discrete time survival model was proposed to predict the probability of charge-off. They claim that using macroeconomic variables along with behavioral factors could produce the best predictive fit. Borrowers’ characteristic were also found in Leow and Crook (2014) to impact charge-off and recovery behavior significantly. In the study of Rubaszek and Serwa (2014), interest rate spread, and income uncertainty were found to impact the amount of household credit using both theoretical and empirical models. The relationship between the age of the borrower and the probability of charge-offs in the US was investigated by Debbaut et al. (2016). The authors concluded that the probability of charge-off is lower in younger borrowers. Using macroeconomic indicators in Turkey, [38] analyzed the reasons behind recent fluctuations in household debt. In a study performed in Korea, Kim et al. (2017) used account-level credit data to find a positive relationship between the probability of delinquency and the amount of debt.
As the literature review performed in this section suggests, the basis of this research is supported by scholars in the field. As we can see, most of the prior research shows that macroeconomic factors affect lenders and financial institutions, and by studying the effects of macroeconomic indicators, we predict a more accurate perception of future lending risks. It is essential for credit card companies to incorporate macroeconomic indicators in their risk models to predict future risks and operate effectively in both the expansion and contraction phases of the economy. This way, they can avoid any unnecessary loss in their portfolio due to a lack of perspective towards economic conditions. Several economic factors were studied in previous research studies regarding the charge-off rate. However, in this study, we will primarily cover economic indicators that encompass all segments of the economy, namely households, government, and business segments. Credit card issuers suffer from unexpected charge-offs due to lack of insight from economic conditions, and a charge-off prediction model which is based on macro-economy data will help managers to make effective business and strategic decisions. This research seeks to fill this gap and find the economic indicators with the most significant power to predict future charge-off rates and will use these indicators to build a loss forecasting model for predicting the charge-off rate using machine learning models.
Since machine learning models have been shown to be useful in improving forecasting accuracy, they were widely used before sensible interpretability measures were developed. A common issue with these models is that they operate as black-box algorithms to some extent. There exists a long history of discussion regarding the trade-off between interpretability and accuracy. This dilemma has led to two approaches (Krishnan, 2019):

•Accurate models but black-box: The most accurate classification models are typically the black-box models such as neural networks, random forest, gradient boosting machine or an ensemble of these models (Duda et al., 2012, Saeys et al., 2007, Scholkopf and Smola, 2001). These models are often referred to as black-box models as they are typically non-parametric or have very large number of parameters (Fernández-Delgado et al., 2014), and a common complaint is that the inner workings of these models are hard to understand. Most of these models just generate a value or probability as their output without providing a means of logically interpreting the prediction.•White-box models but relatively weak: At the other end of the spectrum are the models which are easy to understand and provide illustrative graphs and parameters, such as linear regression (Tibshirani, 1996) and decision trees (Quinlan, 1986). However, these models are inflexible and often provide lower accuracy as compared to the black-box models.

It is true that the understandability and interpretability of a model is vital in science and industry. Scientists and researchers need to understand the model to be able to trust the results as they may influence their work or even their lives. However, the existing tension is motivating analysts and data scientists to seek to develop more complex though less transparent predictive models and machine learning algorithms. Some of the most popular variants of these algorithms which have proven to be accurate and effective include artificial neural networks, gradient boosting machines, and random forest. As mentioned earlier, these models are labeled as black-box algorithms as their inner-workings are not as obvious as traditional regression models. The same reason that makes them more accurate is the reason behind the lack of interpretability in the predictions of these models, which are the complex non-linear methods behind them. Hence, we are faced with a trade-off as the black-box models are typically more accurate in predicting non-linear phenomena, but they come at the expense of lack of interpretability.
When it comes to commercial applications, such as financial problems and credit scoring, it is useful to be able to use interpretable models which let the user analyze the functional form of the model. Considering the degree of interpretability, one may categorize the regression and classification models into the following three groups (Hall & Gill, 2018):

•High interpretability (monotonic and linear models): This class of models include the ones that incorporate linear and monotonic functions, such as traditional linear regression algorithms, which gives them the ability to be explanatory and highly interpretable. Any change in the input variable will lead to a defined rate of change in the response function. This change will be in a specified direction and by a defined magnitude, which is given by coefficients of the corresponding input variables. Due to the monotonic nature of these models, users are able to use intuition and reasoning to explain the predictions made by them. Suppose that a credit application is denied by a creditor and customer asks for the reasons behind this decision. If they have used a linear regression model as the basis for their decision, they will be able to provide an explanation as their charge-off prediction model often uses factors such as credit score, length of credit history and account balance as input and they are monotonically related to the person’s ability to pay off any future debt. Most of the time, these explanations are generated automatically after a decision is made by the model.•Medium interpretability (monotonic and nonlinear models): Despite the fact that most machine learning models use nonlinear functions, some of them provide the ability to add constraints to force monotonicity with respect to each input variable. However, they will not include any coefficients representing the change in the output variable while changing a specific independent variable. The only difference is that the added constraints will ensure that the response variable will change in only one direction when a single input variable changes. These models are able to provide a level of reasoning behind the prediction and will provide a feature importance list as part of their output. There is also another class of machine learning models, such as the multivariate adaptive regression splines (Friedman, 1991), which are linear but nonmonotonic. These models are less interpretable than their monotonic counterparts and often less accurate than the nonlinear machine learning models, and hence, they are less popular in the machine learning field.•Low interpretability (nonmonotonic and nonlinear models): This is the case for the majority of existing machine learning models, in which the response functions are created using nonmonotonic and nonlinear functions. Since the changes in output variables are in both a positive and negative direction with a non-fixed rate for a change in any input variable, the relative importance measure is often the only interpretability measure that is provided by these models. However, due to a relatively higher accuracy associated with these models, they have attracted a lot of attentions from researchers and practitioners.

As mentioned earlier, nonmonotonic and nonlinear machine learning models can provide a list of feature importance that gives a level of interpretability to these models, and estimating the influence of each input variable to the prediction of the model is a question of interest to researchers. Being able to understand the importance of each feature will help the user understand the model and obtain a level of trust for predictions made by the model. There exists a body of research focusing on the estimation of the associated feature importance of each variable (Adebayo et al., 2018, Selvaraju et al., 2017, Zintgraf et al., 2017). Many of these estimation methods have interesting theoretical properties, such as preservation of relevance (Bach et al., 2015) or implementation invariance (Sundararajan et al., 2017).
In this research, we will employ machine learning models from both sides of the spectrum (black-box with low interpretability and white-box with high interpretability) to evaluate their accuracy and compare their performance to be able to make an educated decision about the trade-off between accuracy and interpretability. Our goal is to achieve an acceptable level of accuracy while maintaining the interpretability of the prediction as much as possible. Hence, first we will train and evaluate the results of our benchmark machine learning models, and when it comes to selecting the best performing model, our priority is to select the model with the highest interpretability if there is not a significant loss of accuracy. The machine learning models that we will use are linear regression with lasso, linear regression with ridge, gradient boosting machine and random forest. The first two belong to the class of monotonic and linear models, which are highly interpretable and provide coefficients for each input variable. The third and fourth model (gradient boosting machine and random forest), belong to the family of nonlinear and nonmonotonic machine learning models and provide a low level of interpretability. We will use the H2O library in R (Nykodym et al., 2016) to implement these machine learning models, in which the feature importance lists are generated using the specific methods tailored for each of the machine learning models.
Based on the literature review, several macroeconomic indicators that were likely to have correlations with the charge-off rate were selected. Among the selected macroeconomic indicators, 19 indicators were selected by the experts in the credit card industry to form the basis of this research. The goal is to use these indicators as independent variables in a machine learning based model to predict the charge-off rate, which is our dependent variable. In the first step, we apply different transformations (e.g., square root, exponential, …) to normalize the selected indicators and find the transformation with the highest correlation to dependent variables. We also add lags from 1 to 4 quarters to each indicator and find the correlation of each of the lagged indicators with charge-off rate. This way, we incorporate the lagged effects of each macroeconomic indicator. The next step in data preparation is to convert all indicators and charge-off rate to year over year changes. To do so, for each indicator, we record the percentage of change comparing to the corresponding period in the last year. This way, instead of using the actual values for macroeconomic indicators to predict the charge-off rate, we build a model that uses the changes in each indicator to forecast the change in charge-off rate. The data transformation, correlation analysis and converting to year over year changes steps that followed our data preparation step are standard approaches in statistical analysis and in the machine learning field. Moreover, we have taken one additional step in our data preparation process, which is adding lags to each indicator. Using multiple lags can help the model to capture the lagged effect of each indicator on the value of charge-off rates. For example, it takes one to two quarters between the time a spike is observed in unemployment insurance claims until the time that the charge-off rate increases. However, other algorithms that do not use lagged indicators are not able to capture this lagged effect.
After we have generated our input data, we used two versions of Lasso regression (Lasso with optimal lags and Lasso with all lags) to select the features with the most significant correlation to our output data. The difference between these two feature selection methods lies in the approach we use to generate their input. In the first feature selection model (Lasso with optimal lags), for each indicator, we select the lag, which has the highest correlation with the charge-off rate. Therefore, the model has 19 independent variables corresponding to optimal lags for each of the selected macroeconomic indicators. In the second approach, which is Lasso with all lags, we include all the lags in the input data and let the model select between lags. Note that, in the second feature selection method, we let the model choose more than one lag from each indicator. In doing so, the model can capture the trends for the year-over-year changes of each macroeconomic indicator. The advantage of using Lasso for feature selection over similar feature selection methods such as variants of stepwise selection (e.g. forward and backward selection) is that Lasso both improves the forecasting accuracy and selects between the correlated covariates to reduce the chance of overfitting. However, stepwise selection methods only focus on selecting between the correlated covariates without considering the improvement in prediction accuracy. The other advantage of using Lasso for feature selection is that the basis of the algorithm is linear regression, which provides a good level of interpretability to the final output of the model.
We used the indicators selected by each of the feature selection methods as the input to train machine learning models and capture the relationship between the selected macroeconomic indicators and the charge-off rate. As mentioned earlier, the benchmark machine learning models in this study are Lasso regression, Ridge regression, gradient boosting machine (GBM), and random forest (RF). The rationale behind the selection of these four models is to include both black-box (with less interpretability) and regression-based models with high levels of interpretability. Gradient boosting machine and random forest are among black-box models which are able to capture complex nonlinear trends, which consequently may improve their forecasting accuracy. However, it comes at the cost of lower interpretability and a higher chance of overfitting. On the other hand, Lasso and Ridge regression are from the family of linear regression models, which gives them a good level of interpretability and there is a low chance of overfitting. Nonetheless, due to their linear nature, they may not be able to capture very complex trends, which may result in lower forecasting accuracy comparing to black-box models. Using these four models as benchmarks can aid in the selection between both black-box (low interpretability) and white-box (high interpretability) models. All these machine learning models are readily available to use in machine learning packages such as H2O (Nykodym et al., 2016) and Scikit-Learn (Pedregosa et al., 2011). We have used H2O library in R to implement these machine learning models.
As it is common in the machine learning field, we split the data into training and test sets to train and evaluate the performance of each machine learning model. Two sets of machine learning models need to be developed since we have two versions of input data resulted from different feature selection approaches.
The last piece of building the loss forecasting framework is to predict future values for each of the selected macroeconomic indicators and use the trained machine learning model to predict future charge-off levels. To predict each macroeconomic indicator, seven well-known forecasting models have been used, namely, naiv̈e forecasting, moving average, simple exponential smoothing, Holt, Holt-Winters, ARIMA, and Theta. These models are selected among the models considered in the forecasting competitions, such as M3-Competition. Three variants of the MSIC algorithm proposed in Taghiyeh et al. (2020a) are used to select the best performing forecasting model for each macroeconomic indicator. The reason we selected the MSIC algorithm to forecast future values of macroeconomic indicators is that in a prior study by Taghiyeh et al. (2020a), the MSIC algorithm showed a significant improvement over traditional forecasting model selection methods, making it a good candidate to incorporate in our forecasting framework. Using the results from the forecasting model selected by the MSIC algorithm, the trained machine learning models are then used to predict the future values of the charge-off rate. The process that we followed in the forecasting step of our algorithm is a standard procedure in time series forecasting field, (with the exception of using the MSIC algorithm to select between benchmark forecasting models), thus providing us with more accurate forecasts. Fig. 1 shows the steps of the loss forecasting framework proposed in this study. The details of our proposed Loss rate forecasting framework are outlined in Appendix.

In the next section, we will apply the proposed loss forecasting model on the loss rate data from the top 100 banks in the U.S. from 1985 to 2019.
All the macroeconomic indicators are converted to quarterly values, and the lagged values are recorded (1 to 4 quarters). Hence, for each macroeconomic indicator, we have five columns of input data, and in total, we have 95 input columns for 19 macroeconomic indicators in this study. “bestNormalize” package in R (Peterson, 2017) is used for the normalization of each lagged input. The function “bestNormalize” in the aforementioned package performs several normalization transformations, including the Box–Cox transformation, the Yeo–Johnson transformation, the square-root transformation, log transformation, and arcsinh transformation, and uses the Pearson P test statistic for normality to select the optimal one. After performing the optimal transformation selected by “bestNormalize” function, we convert all the values for macroeconomic indicators and the loss rate to year over year changes by dividing them by corresponding values from the previous year. Now we have the input data ready for feature selection step.
To use the feature selection with optimal lags, we first need to find the optimal lag from the input data generated in step 1. We calculated the correlations of lagged values for each macroeconomic indicator and selected the lag with the highest correlation for each one. The results are shown in Table 2. As we can see, “initial unemployment insurance claims” and “unemployment rate” have the highest correlations with the loss rate, which is in line with what we have already seen in Fig. 2. Now we perform Lasso regression on these optimal lags to remove collinearity between variables and select the most significant features among the indicators list in Table 2. We used the feature importance list from the results of Lasso regression and selected the indicators with the importance values greater than 0.2. First, we have selected 0.2 as our cut-off point because in all our numerical experiments there was a significant gap between the variables with importance values greater than 0.2 and lower than 0.2. The second reason was that we sought to improve the level of interpretability to avoiding overfitting by using fewer variables. Hence, we selected a smaller subset of variables with higher importance values which could achieve the same level of statistical significance for the model (p−value<0.0001) comparing to when we were using all the variables selected by the Lasso regression. The results for this feature selection procedure is shown in Table 3.

As we can see in Table 3, only six macroeconomic indicators among the initial 19 indicators are selected using feature selection with optimal lags. These macroeconomic indicators are “buliding permits”, “initial unemployment insurance claims”, “M1”, “PMI”, “Weekly hours worked by manufacturing workers”, and “unemployment rate”. If we look at Table 1, we can see the interesting result that these indicators cover all the segments mentioned in the table. “Building permits”, “Initial unemployment insurance claims” and “unemployment rate” are from the consumer segment. “PMI” and “weekly hours worked by manufacturing workers” are from the business segment, and “M1” covers the government segment of the economy. The fact that our feature selection procedure selected indicators from all segments of the economy suggests that a holistic view of the economy is a requirement to build an effective loss forecasting framework. Additionally, we can see that “M1” is selected as a significant factor, and is in line with what we already suspected as the trend of “M1” is changed significantly after the great recession.
As opposed to the feature selection with optimal lags, in this version of feature selection, we do not select the optimal lags manually. We feed all the lagged values of macroeconomic indicators (95 input columns) to the model and let the model itself select the lagged indicators that are the most significant to predict loss. We applied Lasso regression on the input data and selected the indicators according to their relative importance. Lagged indicators with the relative importance greater than 0.2 are selected as final selection for the next step. The results are shown in Table 4. As we can see, the selected indicators are almost the same as what we have in feature selection with optimal lags, and all the indicators from feature selection with optimal lags (Table 3 are selected along with M2. Again, these macroeconomic indicators cover all the segments of the economy (consumer, business, and government segments). The main difference between the selected features in this version is that we allow multiple lags for one indicator to be selected. This way, the final model can also capture the trend of these macroeconomic indicators. It is interesting to see that in Table 4, for macroeconomic indicators that multiple lags are selected, these lags have at least two quarters difference. It means that the feature selection procedure tries to capture the most information by using the least number of variables in the cases that the trend had an important role.
The features selected by each of our feature selection procedures will be used as input to our machine learning models. The benchmark machine learning models that we use in this study are Lasso regression, Ridge regression, gradient boosting machine, and random forest. We use the data from the first quarter of 2011 to the second quarter of 2019 as the test set and develop two sets of results corresponding to each of our feature selection procedures. We report R2 for the training set and Mean Squared Error (MSE) for both training and test sets. The results using the output of “feature selection with optimal lags” are reported in Table 5. The corresponding plots for the fit of each machine learning model are shown in Fig. 6. Comparing the values of R2 in Table 5, we see that the gradient boosting machine shows a better performance in terms of R2, which means that 77% of variations in the loss rate can be explained by the gradient boosting method using optimal lags. The values of MSE in training and test sets are also in line with our conclusion, and the gradient boosting machine shows the best performance in terms of MSE on both training and test sets. Hence, the gradient boosting machine is selected for making the final prediction in the next step when we use Lasso with optimal lags as our model selection procedure (see Table 6).

Table 7 shows the statistics corresponding to the result of each machine learning method when using feature selection with all lags. The final fit for each method is depicted in Fig. 7. The R2 results in Fig. 7 suggest that both Lasso and Ridge regression have similar performance. However, looking at the values of MSE in the training and test sets, we see that Ridge regression has a better performance on both train and validation sets. Hence, we select Ridge regression for generating the final forecasts when we use the output of feature selection with all lags as the input of the machine learning model (see Table 8).
As Fig. 6, Fig. 7 show, the uptrend of the loss rate in the last four quarters can be captured by all the benchmark models using selected features, which is not possible when the unemployment rate is the only decision variable. Additionally, we can see that all the models are able to capture the trends of loss rate with an acceptable accuracy, which shows that our loss forecasting method can provide acceptable results using any of the benchmark machine learning models. We use the selected machine learning model in this step to generate final forecasts in the next step of our loss forecasting algorithm, which is explained in the next subsection.


The last step to build the loss forecasting framework is to predict each macroeconomic indicator and use the trained model in step 3 to predict the future values of the loss rate. We use the second quarter of 2018 to the second quarter of 2019 (1 year) as the prediction period. We predict each macroeconomic indicator for this period, and using the trained model in step 3, we will forecast the loss rate. We will use actual values for this period to evaluate the forecasted values.

To forecast the values of each macroeconomic indicator, we need to select the most appropriate time series forecasting model. Since the performance of forecasting models highly depends on the underlying characteristics of the time series, the selection of the best is not a simple task. As the forecasting model selection approach in Taghiyeh et al. (2020a) (MSIC algorithm) has shown promising performance, we will use this procedure to select our forecasting model for each macroeconomic indicator. Similar to Taghiyeh et al. (2020a), we select seven of the most well-known time series forecasting models as our benchmark, namely naiv̈e forecasting, moving average, ARIMA, simple exponential smoothing, Holt’s linear trend, Holt-Winters, and theta. For each macroeconomic indicator, the MISC algorithm will select the optimal forecasting model, and we will use the selected optimal model to forecast future values for each macroeconomic indicator.

Since MSIC needs multiple time series as input to train its classifiers, we need to convert the time series associated with each macroeconomic indicator into several series. To achieve this goal, we use non-overlapping four-year horizons to split the data for each macroeconomic indicator. We use this input data to train the MSIC classifiers. To make final predictions, we use the entire data for the corresponding macroeconomic indicator as input to the trained classifiers of the MSIC algorithm.
To evaluate the performance of the MSIC algorithm for each macroeconomic indicator, we compare the results of the MSIC algorithm to the traditional train/validation forecasting model selection method. Three variants of the MSIC algorithm, namely MSIC with logistic regression as the classifier (MSIC-LR), MSIC with support vector machine as a classifier (MSIC-SVM), and MSIC with decision tree as a classifier (MSIC-DT) are used for this comparison, and we report MSE and optimality gap reduction as the comparison measures. To be consistent with the results reported in Taghiyeh et al. (2020a), we use different values for separations points between train and validation sets (P1). Since in the feature selection step (step 2) only 7 of the macroeconomic indicators are selected (building permits, initial unemployment insurance claims, M1, M2, purchasing managers index, weekly hours worked by manufacturing workers and unemployment rate), we only use the MSIC algorithm to predict future values for these indicators. The comparison results for the selected macroeconomic indicators are shown in Table 9, Table 10, Table 11, Table 12, Table 13, Table 14, Table 15. The MSE results are also depicted in Fig. 8, Fig. 9, Fig. 10, Fig. 11, Fig. 12, Fig. 13, Fig. 14. The optimality gap improvements are summarized in Fig. 15.
The results suggest the same trend as numerical results in Taghiyeh et al. (2020a), as the MSIC algorithm shows a constant improvement in the optimality gap in all instances. Additionally, there is not a single winner among classifiers for the MSIC algorithm, and it is case dependent. As the overall performance in Fig. 15 shows, we can get an overall minimum of 60% improvement in optimality gap improvement using the MSIC algorithm over the traditional train/validation model selection procedure.

Now that the forecasting models are selected for each macroeconomic indicator, and the predictions are made, we use the forecast values as input to the trained models in step 3. Gradient boosting machine was selected as the best performing machine learning model using feature selection with optimal lags, and ridge regression was the winner when using feature selection with all lags. Therefore, these two models are used to generate the final forecasts for the loss rate. MSE results for final forecasts are reported in Table 16. Since all the variants of the MISC are generating the same results, we show all the predictions in one figure, which is representative of the results for all the variants of the MSIC algorithm. The prediction plots are shown in Fig. 16. As the MSE results in Table 16 show, we achieve significantly low values for MSE using our proposed loss forecasting framework that shows the efficiency of the algorithm. Moreover, looking at Fig. 16, we see that both variants of our loss forecasting model can closely predict the loss rate values, and it is able to capture the uptrend of the loss rate, which is not possible when using only unemployment rate as the decision variable. Overall, we see that ridge regression with all lags can obtain better results than gradient boosting with optimal lags. The reason is that in the feature selection with all lags, the lags are selected automatically by the model, and we allow the model to use more than one lag from each indicator. This way, more data is available to make predictions. Hence, the Ridge regression with all lags can perform better than gradient boosting with optimal lags. Moreover, Ridge regression is from the family of monotonic and linear machine learning models, which makes it highly interpretable and the assigned coefficients are available for each input variable.

Now that we have selected the macroeconomic indicators with a significant correlation with the charge-off rate and built a prediction model using these values, one may bring up the question that whether the selected macroeconomic indicators are actually the ones causing the fluctuations in the charge-off rate or not. While correlation and causation may exist at the same time, but the existence of a correlation does not necessarily imply causation. Causation applies in the situations that an action explicitly triggers another action, but correlation simply implies a relationship. When a correlation exists between two actions, it means that they are related to each other, but it does not necessarily mean that any of them cause the other one. We use the example from the book “Introduction to statistical learning” by James et al. (2013) to explain this issue. Suppose that we are evaluating the correlation between the sales of an ice cream vendor on a beach with a number of shark attacks. Interestingly, they have a high correlation, but it does not mean that selling ice cream on the beach causes more shark attacks or vice versa. However, when the weather is hot, people are more attracted to the beaches, and consequently, the number of ice cream sales increases. When there are more people on the beach, there is a higher chance of a shark attack, and the higher temperature is the cause of attracting more people to the beach, which results in more shark attacks. This example illustrates the difference between causation and correlation. Our primary focus in this research was on correlation rather than causality. The question regarding whether the final significant indicators that were selected to build the model are actually causing the chain of events that leads to the changes in the charge-off rate is left to the experts in the credit card industry and economists.
In this paper, we have proposed a machine learning based loss forecasting framework for the credit card industry using macroeconomic indicators. Our goal was to cover macroeconomic indicators from all segments of the economy to make predictions based on a holistic view of the economic conditions. Using the review of the literature and experts’ opinion, we selected 19 macroeconomic indicators, which cover consumer, business, and government sections of the economy as input to the proposed loss forecasting framework. The proposed procedure consists of four steps, data preparation, feature selection, model training, and forecasting. We used four machine learning models, namely Lasso regression, Ridge regression, gradient boosting machine, and random forest to develop two versions of the loss forecasting framework. The difference between these two versions is in the utilization of lags from input data. We also applied the proposed model selection procedure in Taghiyeh et al. (2020a) (MSIC algorithm) in the forecasting segment of the proposed loss forecasting framework to find the optimal time series forecasting model. To the best of our knowledge, this work is the first that uses an extensive number of macroeconomic indicators from all segments of the economy to build a machine learning based loss forecasting framework for the U.S. credit card industry. To show the performance of the proposed loss forecasting framework, we used the charge-off data for the top 100 banks in the U.S. ranked by assets from 1985 to 2019, and the data corresponding to selected macroeconomic indicators. We applied the proposed loss forecasting framework on the data, and the final results were very promising. We could achieve the test MSE of 1.15E−03 and 1.04E−03 corresponding to feature selection with optimal lags and feature selection with all lags, respectively, which shows the effectiveness of the proposed algorithm in forecasting the loss rate. The final fit for the prediction period shows that we could closely predict the actual values of the loss rate and the uptrend of the loss rate could be captured by our proposed model, which was not possible in the conventional version of the credit card loss forecasting frameworks that only use the unemployment rate as the decision variable.
In the future, we aim to further improve the proposed loss forecasting model in this paper by adding more machine learning models, such as deep neural networks, long-short term memory (LSTM) model, and extreme gradient boosting to the benchmark models and see if we can make more accurate forecasts. Additionally, more feature selection procedures can be explored to improve the feature selection step of the loss forecasting framework. The other future line of research would be to perform a more exhaustive number of transformation for the macroeconomic indicators to see if a better data transformation can be found to improve the efficiency of the algorithm further, as the final results are sensitive to these transformations. Another interesting future research path is to analyze the credit card charge-off rates due to the rapid changes in the economy caused by the Coronavirus pandemic and adjust the model accordingly.

Sajjad Taghiyeh: Conceptualization, Methodology, Formal analysis, Software, Visualization, Validation, Writing - original draft. David C. Lengacher: Data curation, Conceptualization, Methodology, Writing - review & editing. Robert B. Handfield: Supervision, Conceptualization, Validation, Writing - review & editing.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Expert Syst Appl
PMC7535806,Split Bregman iteration for multi-period mean variance portfolio optimization,"We consider the regularized multi-period mean variance optimization problem and its solution using the split Bregman method.
In recent years there has been a growing interest in the solution of fused lasso models [1], that are linearly constrained minimization of functions given as:(1)E(w)=f(w)+τ1∥w∥1+τ2∥Lw∥1,where f: ℜn → ℜ is a closed convex function at least twice continuously differentiable, and L is the difference operator. The l
1 penalty in (1) promotes sparse solutions, and the term ‖L 
w‖1 is included to produce smooth solutions. Problems described by fused lasso models arise, e.g., in image processing [2], classification [3], finance [4]. The nonsmoothness of the l
1-type regularization terms precludes the use of standard descent methods for smooth objective functions. Problems of this kind can be solved either by smoothing the l
1 terms, e.g., [5], [6], and applying optimization solvers for differentiable problems such as gradient methods [7], [8], [9] or by using directly optimization solvers for nondifferentiable problems, such as Bregman, proximal and ADMM methods [2], [10], [11], [12]. Due to the additive structure in (1), splitting methods have became popular because they yield algorithms which consist at each iteration of subproblems that are easier to solve [13], [14]. These subproblems often either admit closed form solutions or can be solved very quickly with specialized methods. In this context, methods based on Split Bregman iteration have proved to be efficient in different fields [2], [15], [16], [17]. At each iteration of the Bregman method an l
1 regularized unconstrained optimization subproblem is solved. Auxiliary variables allow to separate the two l
1 regularization terms making the use of splitting methods an easy task. In the field of portfolio optimization, both in the static and the dynamic case, Bregman iteration has been used to solve efficiently l
1 regularized models in Markowitz’s framework. The use of l
1 penalty terms in portfolio modelling has become popular for several reasons. Transaction costs are well described by the l
1 norm of the portfolio, especially in moderate size trades. The properties of this norm allow one to obtain sparse solutions, that is, small portfolios. Small portfolios are often considered preferable to large ones. They are feasible to small investors, for the reduced holding cost. Moreover, it seems that the estimation errors for variances and covariances are reduced in this case [18], [19]. Finally, it has been observed that the application of l
1 regularization has the effect of penalizing short positions [20], [21], forbidden in several markets. The structure of Bregman iteration has been exploited both in the static and the dynamic case, to develop procedures which adaptively fix the value of the regularization parameter; this value is chosen as one that provides solutions with certain financial properties, while preserving fidelity to data [21], [22].
In [4] a model based on the fused lasso approach is presented in a multi-period setting. This seems to be very promising, since the fusion term is a penalty on portfolio turnover, which produces strategies with low transaction cost by preserving the pattern of active position over time. The fused lasso model is also considered in this paper. The novelty is the focus on strategies in which the investor can exit before the end without incurring severe loss; this is particularly significant to protect investment from financial market crisis. At this purpose, control at intermediate periods on wealth is introduced in the model. According to the multi-period approach, the so called rebalancing dates are defined to divide the investment period into subperiods; at these dates, the investment strategy is revised according to evolving information. We fix a minimum level of expected wealth at intermediate dates. From the mathematical point of view, this leads to a nonsmooth optimization problem with equality and inequality constraints. We reformulate the problem as one with equality constraints only and apply the alternating Split Bregman method for its solution. The resulting algorithm requires, at each iteration, the solution of unconstrained subproblems which are easily solved exactly.
In order to test our model, we introduce some perfomance measures. In particular, we assess performance with respect to two benchmarks built on real market data; this task is usually referred to as the Enhanced Index Tracking problem [23], [24], where one aims at selecting a portfolio that outperforms a reference index.
In Section 2 we describe the mathematical model. In Section 3 we present the procedure for the numerical solution of the model, based on alternating Split Bregman iteration. In Section 4 we show results of our tests.
In this section we extend the fused lasso model presented in [4] with the aim of guaranteeing the investor in the case of early exit. The model refers to either a medium or long-term investment, in which the investor could exit before the term; thus, at this purpose, the expected minimum wealth is fixed at each rebalancing date.
Let m be the number of rebalancing dates, n the number of assets and (w
j)i the portion of the investor’s total wealth invested in security i at time j; the vector(2)w=[w1T,…,wmT]T∈ℜN,with N=m·n, defines the portfolio. At each rebalancing date j=1,…,m, the wealth is thus given by wjT1n, where 1
n is the column vector with n elements, all equal to one. We assume that j=1 is the starting date. We denote with r
j ∈ ℜn the expected return vector and with Cj ∈ ℜn × n the covariance matrix, that we assume positive definite. The model is stated as follows:(3)minw∑j=1m[wjTCjwj+τ1∥wj∥1]+τ2∑j=1m−1∥wj+1−wj∥1s.t.w1T1n=ξinitwjT1n=(1n+rj−1)Twj−1,j=2,⋯,mwjT1n≥(wmin)j−1,j=2,⋯,m(1n+rm)Twm≥(wmin)mwhere ξ
init is the initial wealth, wmin is the vector of expected minimum wealth.
The quadratic term in the objective function represents the portfolio risk. This is obtained by summing single-period variances. The successive terms are regularization ones introduced by fused lasso approach. The l
1 norm is well-known to promote sparsity. We apply it to w, weighted by τ
1 > 0, in order to have small portfolios. This improves the control on the investment and reduces holding cost. Moreover, we have observed that it penalizes negative components, thus resulting in a penalty on shorting [21], [22]. This turns out to be useful when short positions are not allowed, since one can obtain positive weights by properly tuning τ
1. The fusion term, that is the l
1 norm applied to the time variation Δw, has a smoothing effect on solution, preserving patterns of non-zero values across time. Its financial interpretation is a penalty on the portfolio turnover; it has then the effect of reducing transaction cost [4]. This term is weighted by τ
2 > 0. The values τ
1, τ
2 are referred to as the regularization parameters.
Both equality and inequality constraints are imposed on wealth. The first wealth must be equal to the initial investment, as the first constraint establishes. Constraints from 2 to m state the self-financing property, that is, money is neither added to the portfolio nor withdrawn from it for j > 1. Thus, at the end of each period the wealth is given by the revaluation of the previous one. Inequality constraints state that a lower bound is defined on the portfolio wealth at the end of each subperiod, that is, at all rebalancing dates. Finally, the last component (wmin)m is the minimum wealth expected by the overall investment. It is given by the revaluation of the last weight sequence produced by the investment strategy on the last rebalancing date. For sake of notation simplicity, we formulate problem (3) in compact form. We introduce the matrix C ∈ ℜN × N as the m × m diagonal block matrix C=diag(C1,C2,…,Cm). The blocks are the covariance matrices estimated at the beginning of each subperiod. The matrix C is symmetric positive definite (SPD) with (1−1m)% sparsity degree. Let L∈ℜ(N−n)×N be the discrete difference operator; it can be viewed as the (m−1)×n upper bidiagonal block matrix, with blocks of dimension n × n, defined by:diag(L)=(−I,−I,⋯,−I)supdiag(L)=(I,I,⋯,I)where I is the identity matrix of dimension n. L has (1−2N)% sparsity degree. The m × m lower bidiagonal block equality constraint matrix A, with blocks of dimension 1 × n and (1−2m)% sparsity degree, is defined as follows:diag(A)=(1nT,1nT,⋯,1nT)subdiag(A)=(−(1n+r1)T,⋯,−(1n+rm−1)T).Finally, let G be the inequality constraint matrix; it is a m × m upper bidiagonal block matrix with blocks of dimension 1 × n and (1−1N)% sparsity degree wherediag(G)=(0nT,0nT,⋯.,0nT,(1n+rm)T),supdiag(G)=(1nT,1nT,⋯.,1nT).Then, problem (3) admits the following compact formulation:(4)minw12wTCw+τ1∥w∥1+τ2∥Lw∥1s.t.Aw=bGw≥wminwhere b=(ξinit,0,0,…,0)T∈ℜm.
We solve (4) using the split Bregman scheme. Therefore, we first provide a short description of it. It is based on Bregman iteration method for convex optimization problems with equality constraints(5)minuE(u)s.t.H(u)=0.The main idea of Bregman iteration is to transform the problem into a sequence of easier ones which are constructed by adding a ”cost-to-move” term to the original objective function [14]. This term penalizes the distance between two iterates defining the Bregman distance at point u, as:(6)DEp(v,u)=E(v)−E(u)−<p,v−u>,where p ∈ ∂E(u) is a subgradient in the subdifferential of E. Note that if E is smooth, then (6) is the difference between E(v) and the first-order Taylor expansion of E at v. Bregman iteration applied to problem (5) produces the following scheme:(7){uk+1=argminuDEpk(u,uk)+λH(u),pk+1=pk−λ∇H(uk+1)∈∂E(uk+1),with λ > 0. The split Bregman method was introduced in [2], where authors proposed to use an auxiliary variable d before applying Bregman iteration to solve problem (5). The introduction of d is aimed at replacing the original problem with an equivalent one in which the smooth and nonsmooth portions of objective function are separated. Then, a further constraint is added, which forces the equality between d and the nonsmooth term.
In order to apply split Bregman method to problem (4) the first step is to reformulate it in terms of equality constraints only. We introduce the slack variable s ∈ ℜm in order to transform the inequality constraint in (4) into an equality one. We rewrite the minimization problem using the indicator function ID(s) to incorporate the non-negativity constraint on the slack variable into the objective function:(8)minw,s12wTCw+τ1∥w∥1+τ2∥Lw∥1+ID(s)s.t.Aw=bGw−s=wmin,whereD={s∈ℜm:s≥0}.According to split Bregman method, we introduce the auxiliary variables d and z such that d=Lw and z=w. Problem (8) is then reformulated in the following way:(9)minw,s,d,z12wTCw+τ1∥z∥1+τ2∥d∥1+ID(s)s.t.Aw=bGw−s=wminLw=dw=z.Alternating split Bregman method proposes to minimize the function in (9) with respect to the variables w, s, d and z alternately. Note that this algorithm is equivalent to other well-known methods such as the Douglas-Rachford splitting and the alternating direction method of minimizers [14]. Due to linearity of constraints in (9), a simplified version of split Bregman iteration can be used. In this version, the Bregman vectors allow one to use the function E rather than its Bregman distance [25]. This leads to the following simplified alternating minimization algorithm:(10)wk+1=argminwQ(w;sk,dk,zk)sk+1=argminsID(s)+λ22∥s−Gwk+1−bks∥2dk+1=argmindτ2∥d∥1+λ32∥d−Lwk+1−bkd∥2zk+1=argminzτ1∥z∥1+λ42∥z−wk+1−bkz∥2bk+1w=bkw+λ1(b−Awk+1)bk+1s=bks+λ2(Gwk+1−wmin−sk+1)bk+1d=bkd+λ3(Lwk+1−dk+1)bk+1z=bkz+λ4(wk+1−zk+1).with quadratic function Q defined as(11)Q(w;sk,dk,zk)=12wTCw+λ12∥Aw−bkw∥22+λ22∥sk−Gw−bks∥22+λ32∥dk−Lw−bkd∥22+λ42∥zk−w−bkz∥22.Closed form solutions can be obtained for minimization with respect to s, d and z. Minimization with respect to d and z can be done efficiently using soft thresholding operator, defined as:(S(x,γ))i=xi|xi|max(|xi|−γ,0),where x is real vector and γ > 0, while the proximal mapping of the indicator function on a given set is the orthogonal projection operator onto the same set. Regarding the quadratic minimization with respect to w, we note that at each step k the optimal value can be obtained by solving the system(12)Hw=rhsk,with(13)H=C+λ1ATA+λ2GTG+λ3LTL+λ4Iand(14)rhsk=λ1ATbkw+λ2GT(s−bks)+λ3LT(d−bkd)+λ4(z−bkz).We observe that the coefficient matrix defined in (13) does not depend on the iteration and it is SPD and sparse, as shown in the next proposition.Proposition 1
Matrix H defined in
(13)
is a SPD, m × m tridiagonal block matrix with blocks of dimension n.

Proof
H is the sum of C and I, that are SPD, and of other matrices that are semi-positive definite; then the first statement follows. We analyze the structure of matrices in (
13
). L, A and G are bidiagonal block matrices with blocks of dimension 1 × n, then for each of them the product of its transpose by the matrix itself is a tridiagonal block matrix with blocks of dimension n × n. It follows that the sum has a block tridiagonal structure.
 □

In the next proposition we give bounds on the eigenvalues of H.Proposition 2
Let λ(H) be the set of eigenvalues of matrix H; we have
λ(H)⊆[χ−,χ+]

with
χ−=λmin(C)+λ4χ+=λmax(C)+λ1λmax(ATA)+λ2λmax(GTG)+λ3λmax(LTL)+λ4.

Proof
We recall that if A and B are real, symmetric matrices, then
A+B
has real eigenvalues, and the following inequalities hold:
λmin(A)+λmin(B)≤λmin(A+B)≤λmax(A+B)≤λmax(A)+λmax(B).

The matrix H is the sum of real and symmetrix matrices, then
χ−≤λmin(H)≤λmax(H)≤χ+,
with
χ−=λmin(C)+λ1λmin(ATA)+λ2λmin(GTG)+λ3λmin(LTL)+λ4χ+=λmax(C)+λ1λmax(ATA)+λ2λmax(GTG)+λ3λmax(LTL)+λ4.
The matrices A, G and L have rank smaller then N, so, for each one of them, the product between the matrix and its transpose is rank deficient. This completes the proof.
 □


Proposition 1 suggests to use sparse Cholesky factorization to solve the systems (12). Sparse direct methods are a combination of techniques from numerical linear algebra, graph theory, graph algorithms, permutations, and other topics in discrete mathematics. They exploit the sparsity of a matrix to solve problems much faster and using far less memory than if all the entries of a matrix were stored and took part in explicit computations (see [26], [27] and references therein). We note that the factorization is computed only once, while at each step two triangular linear systems are solved. The resulting method is outlined in Algorithm 1
.
In this section, we show some results of tests that we perform on real market data. Algorithm 1 is applied to several data sets generated using real-world price values provided in [28]. The datasets contain weekly return time series of assets belonging to several major stock markets across the world, cleaned from errors as much as possible. We simulate 10 years investment strategies, where the investor revises decisions once a year. In Table 1
we summarise information on the datasets.
The problem requires an estimate of the covariance matrix. It is well known that the sample covariance matrix is affected by estimation error; this is particularly severe when the number of stocks, which is the dimension of the matrix, is large relative to the number of historical returns, that is the sample size. We thus apply the linear shrinkage estimator proposed in [29] to C. This method acts on the eigenvalues of C, reducing their dispersion by shrinking them towards their grand mean: as a consequence, it strongly improves the conditioning of the covariance matrix, as Table 2
shows. In this table we report the condition number of the sample matrix and the condition number of its estimator.
We compare optimal portfolios produced by the investment strategy with two benchmarks. The first one is the naive strategy, that extends the classical 1/n
[30] to the multi-period case. The investor splits the money evenly among available assets, at the beginning of the investment as well as at rebalancing dates. Thus, at each rebalancing date we set as expected minimum wealth the expected value produced by the recursive application of the 1/n allocation strategy:(15)(wmin)1=ξinitn1nT(1+r1)(wmin)i=(wmin)i−1n1nT(1+ri−1),i=2,…,mMoreover, for datasets 1−5 in Table 1 also weekly return time series for the index are reported in [28]. So for this datasets the market index is also used as benchmark. In this case the expected minimum wealth is the one of the market index:(16)wmin=rindexwhere rindex∈Rm is the index return.
We introduce six performance measures to evaluate the goodness of results:
M1we estimate the risk reduction when the naive strategy is taken as benchmark, by means of the following quantity:RR=wnaiveTCwnaivewoptTCwopt,where the numerator is the variance of the portfolio produced by the naive strategy, the denominator is the variance of the optimal portfolio produced by Algorithm 1;
M2 the number of nonzero elements in the solution (percentage), that gives an estimation of holding cost;
M3 the transaction costs. In order to evaluate them we define the matrix V∈ℜn×(m−1), with:Vi,j={0if|(wj+1)i−(wj)i)|>01otherwisefor i=1,…,n and j=1,…,m−1. Note that, as in [4], in order to discard variations not significant from the financial point of view, we neglet the differences below 10−6*ξinit. The number of estimated transactions of the optimal strategy is therefore:Topt=∑i=1n∑j=1m−1Vi,j.We then relate Topt to the maximum value that it can assume, that is, to the number of transactions of the portfolio with full turnover, which is the size N of the portfolio:(17)T=ToptN;

M4 the excess return (ER) calculated in comparison to the benchmark:ER=wmT(1n+rm)−(wmin)m(wmin)m;

M5 the Sharpe Ratio (SR) [31] is the ratio between the average of the expected return of the portfolio and its standard deviation. In the multi-period framework we compute the SR in the following way:SR=1m∑j=1mRjσ(R),where R=(R1,….Rm), andRj=rjTwjwjT1n,j=1,…,m;

M6 the Information Ratio (IR) [32] is the average excess return per unit of volatility in excess return. We compute it as:IR=1m∑j=1mAERjσ(AER),where AER=(AER1,…,AERm), andAERj=wjT1n−(wmin)j(wmin)j,j=1,…,m.
 We assume that one unit of wealth is invested, so we fix ξinit=1. We set λi=1,∀i=1,…,4. The stopping criterion is based on constraint violation, so the algorithm stops when all constraints are satisfied within Tol=10−6. In Algorithm 1 we set a lower bound on wmin to guarantee the investment:(18)wmin=max(ξ¯,wmin).In our experiments we set ξ¯=ξinit·1n, to preserve the initially invested amount.
In Table 3
we report the condition number of H. We observe that in almost cases the conditioning of H is better with respect to C. This is motivated by the shift of the spectrum to the right, according to Proposition 2.
Regularization parameters τ
1 and τ
2 are chosen in the set {10−4,10−3,10−2}; the combined choice of them depends on the specific metric one focuses on.
We start by analyzing the behaviour of the wealth produced by the optimum portfolio over time, and compare it with the benchmarks. Figs. 1
and 2
show the values of wealth at rebalanging dates on datasets FTSE 100 and Dow Jones, but similar results are observed also for the other datasets. The first row of figures refers to dataset FTSE 100, compared with the naive strategy. The second row of the figure refers to dataset DowJones, compared with the index return. In Fig. 1 parameter τ
2 has been set to 10−3 while τ
1 values range in the set {10−4,10−3,10−2} from left to right. According to the analysis in [4] for both the datasets we have that increasing τ
1 results in a reduction of the number of short positions, from 102 to 0 for FTSE 100 and from 30 to 0 for Dow Jones, and the number of transactions, from 15% to 9% for FTSE 100 and from the 23% to the 16% for Dow Jones. This is due to the reduced size of the portfolio, as result of the sparsification effect of regularization on portfolio wealth. Focusing on wealth, Fig. 1 shows that the excess return is penalized as τ
1 increases. Indeed, our model outperforms the benchmark, showing an expected wealth higher than the one of the index, in almost all cases, but the difference is higher for smaller values of τ
1, while the gain in terms of cost reduction is valuable. All experiments exhibit a breakdown in the benchmark at the fourth year of the simulation period. This is probably due to the fact that t=4 corresponds to year 2008, so the lower return can be ascribed to the Crisis. Thus, at this date the excess return of the optimal portfolio is higher, as effect of (18).
In Fig. 2 the behaviour of wealth over time is shown for τ
1 equal to 10−3 and for τ
2 varying in {10−4,10−3,10−2}. For both the datasets, we have, as expected, a reduction on the number of transactions, from 22% to 5% for FTSE 100 and from 47% to 10% for Dow Jones. Limitation on transactions results in a slight increase in risk, and thus higher return at intermediate periods is observed.
As already pointed out, financial targets of the investment and market conditions drive the choice of the regularization parameters. In the following tests τ
1 is chosen as the smallest number that guarantees the minimum number of short positions. This is an important issue as in some cases stock market regulators can impose bans on short-selling like in the two European countries hardest hit by the Covid-19 in March 2020, Italy and Spain. Once fixed τ
1, τ
2 is chosen so to have a good trade-off among the other performance metrics.
In Table 4
we report on all the datasets the comparison with the index in terms of excess return and Information Ratio. However for completeness we report also the other metrics of the optimal portfolios, that are the amount of shorting, the percentage of active positions and of transactions, and the Sharpe Ratio. In all tests the optimal portfolio outperforms the benchmark. We achieve an excess return of about the 7% on the average, varying between the 2% and the 14%. The IR ranges between 0.301 and 0.453; SP500 exhibits the highest value of IR, coherently with the observed value of the excess return. On the other hand, FSTSE100 provides the highest excess return but its IR is slightly affected by the dispersion of excess returns.
In Table 5
we show comparisons with the naive strategy. In this case we furthermore report the value of RR defined in M1. The reduction of transaction costs is about the 90% on the average. Note that the naive portfolio is a full-turnover one, thus the value of T represents the percentage of transactions made by the optimal strategy with respect to the benchmark. We also observe an higher excess return, varying between the 8% and the 17%, with an average value of 12%. The IR ranges between 0.302 and 0.440; DJ exhibits the highest value of IR, while the excess return is maximum for SP500 and FF49. We note that the SR values are greater than the corresponding values obtained when the benchmark is the index. Finally, our strategy produces optimal portfolios that outperform the benchmark in terms of final wealth with a lower risk, as shown by RR, that varies between 1.510 to 4.962.
In this work we use split Bregman method for the problem of defining an optimal long-term investment strategy, where the investor can exit the investment before maturity without severe loss. We propose a model in a multi-period Markowitz framework, which extends the fused lasso model proposed in [4]. The inequality constraints on expected minimum wealth at each rebalancing date are introduced to guarantee the investment throughout the period, especially during the unforeseen events such as market crisis. Alternating Split Bregman produces an algorithm that yields subproblems that are solved by fast methods. Numerical comparisons with respect different benchmarks on real databeses show the its effectiveness.",Appl Math Comput
PMC7561320,Emotional responses to prosocial messages increase willingness to self-isolate during the COVID-19 pandemic,"In the span of just a few months, COVID-19 has ripped through almost every country, infecting 30 million people, killing close to a million individuals as of September 17th, 2020 (John Hopkins University, 2020), and severely crippling dozens of economies. Without a vaccine in hand, it seems that the virus can only be slowed by extreme behavioral change and societal coordination (Arenas et al., 2020). Some countries, like South Korea, were quick to respond by instituting enforced quarantines and entreating citizens to practice social distancing (Beech, 2020; Fisher & Sang-Hun, 2020). Other countries, like the United States and the United Kingdom, were reluctant to impose widespread shelter-in-place measures (The Associated Press, 2020). In the United States, for example, individual states began gradually issuing social isolation practices to combat the spread of the virus through the months of March and April of 2020 (Mervosh, Lu, & Swales, 2020). In both cases, the countries hoped their citizens would readily comply with public health messages. Preliminary reports, however, show vast differences in people's willingness to practice measures that can reduce pathogen transmission (Lunn et al., 2020).
At present, public health advisors, such as the World Health Organization, argue that mitigating the spread of COVID-19 necessitates people swiftly adapt and change their usual habits to obey new social distancing measures (World Health Organization, 2020). Problematically, social distancing measures increase unemployment rates (Coibion, Gorodnichenko, & Weber, 2020), influence work productivity, and acutely affect mental wellbeing (Kawohl & Nordt, 2020). Thus, the actions needed to reduce the spread of COVID-19 are in direct opposition to functioning daily life. This poses a critical challenge for accomplishing extreme behavior change compliance, especially in such large populations.
Decades of research show that emotional engagement is a critical component of behavior change (Bagozzi & Pieters, 1998; Cooper & Nisbet, 2016; Hartley & Phelps, 2010; Nabi, 2007; Perugini & Bagozzi, 2001), which is why it is often employed in public health campaigns (Dillard and Nabi, 2006; Lang & Yegiyan, 2008; Nabi, 1999, Nabi, 2002; Zeelenberg & Pieters, 2006). However, the relationship between emotion and behavior change is not straightforward (O'Keefe, 2012). For instance, tailoring messages to evoke a specific emotional response can backfire: When public service announcements about binge drinking evoke shame—rather than the intended guilt—vulnerable populations can increase their alcohol consumption (Duhachek, Agrawal, & Han, 2012). Fear is also notoriously fickle in creating successful behavior change (Hastings, Stead, & Webb, 2004; Leventhal, 1970; Petty & Cacioppo, 1996). Some research shows that only those most at risk for certain behaviors, such as drunk driving, are least responsive to messages with fearful language (Tay & Ozanne, 2002). While widespread and rapid adoption of preventative measures is unlikely to occur without messages that include emotional appeals (Myers, Nisbet, Maibach, & Leiserowitz, 2012), it is crucial that current public health officials and researchers understand the relationship between emotional engagement and different persuasive messages related to COVID-19.
Despite the complexity of the relationship between emotion and behavior, some media outlets have been leveraging fear language in order to motivate people to stay home and socially distance. A recent article, for example, highlighted grim outcomes, staggering death tolls, and an inability for an overwhelmed health system to treat citizens (Pueyo, 2020). There is good reason to specifically focus on fear related to COVID-19 (Feldman & Hart, 2015; Moser, 2010; Nisbet, 2009): Evoking fear can potently effect attitudes and behaviors (Tannenbaum et al., 2015), likely because fear can enhance attention towards the message (Baron, 1994) and increase perceptions of threat (Leiserowitz, 2006). However, the relationship between fear and disease prevention behaviors is not straightforward (Hastings et al., 2004). A message that is perceived as too threating can cause people to engage in defensive avoidance, which leads them to disregard the message altogether (Janis & Feshbach, 1953). Indeed, across a host of behaviors, a message that evokes too much (Janis & Feshbach, 1953; Krisher, Darley, & Darley, 1973), too little (Boster & Mongeau, 1984; Witte & Allen, 2000), or in some cases, any amount of fear at all (O'Neill & Nicholson-Cole, 2009), can fail to produce any noticeable behavioral change. Thus, while the use of fearful language is widely adopted as a means for behavior change, the evidence to date illustrates that its efficacy is variable (O'Keefe, 2012).
On the other hand, appeals that use prosocial rather than threatening language can play a potent role in the efficacy of public health campaigns (Lewis, Watson, White, & Tay, 2007), serving as a distinct contrast to fear-based appeals. For example, describing prosocial actions that can lead to positive outcomes in the face of public health problems can produce positive emotions, such as hope or joy (Nabi et al., 2018; Ojala, 2012), which can increase reception to the message by reframing the issue as being more personally relevant (Monahan, 1995). Indeed, some recent research illustrates that prosocial public health messages that underscore behaviors linked to societal and communal benefits (e.g., help protect your fellow citizens)—rather than focusing on behaviors that only benefit the self (e.g., protect yourself)—may be an especially effective method (Kelly & Hornik, 2016; Li, Taylor, Atkins, Chapman, & Galvani, 2016) for communicating public health recommendations related to COVID-19 (Jordan, Yoeli, & Rand, 2020).
One additional difficulty in designing public health messages is the heterogeneity of emotional responses to interventions (Carey & Sarma, 2016). Although typically outside the scope of public health research, characterizing how stable personality traits interact with emotional experiences can provide inroads for understanding the link between emotions and a message's efficacy. For example, the biological theory of personality explores how extraversion and neuroticism are linked with the body's physiological response (Eysenck & Eysenck, 1991), and these traits generally correlate with positive and negative mood, respectively (Costa & McCrae, 1980; Rusting & Larsen, 1997). Whereas neurotic tendencies are linked to increased emotional arousal (Haas, Constable, & Canli, 2008; Kehoe, Toomey, Balsters, & Bokde, 2012), extraverts are less likely to be as reactive to arousing stimuli. When considered within the framework of public health messaging, this suggests that neuroticism, and not extroversion, may predict stronger arousal responses to emotionally evoking messages.
Presently, it is unknown whether messages using threating or prosocial language are equally effective in promoting changes in willingness to self-isolate regarding COVID-19. Research on public health campaigns typically examine specific emotions (Nabi et al., 2018; Ojala, 2012; Tannenbaum et al., 2015; Witte & Allen, 2000), but these approaches constrain a person's emotional experiences by limiting them to identifying with a set of discrete emotions pre-selected by the researcher. For example, asking how afraid one feels after reading a message imposes an emotional structure that the participant “ought” to feel afraid. Scaffolding the question in such a manner assumes that these emotional words are interpreted in similar ways across individuals, and may even influence how the very emotion is experienced (Kassam & Mendes, 2013). Here, we circumvent these issues by using a model of emotion that avoids specific emotion states and partitions emotional experiences into a two dimensional space: the affective dimensions of valence (pleasurableness) and arousal (alertness/activation; Russell & Barrett, 1999). Using this approach, we can characterize the heterogeneity in emotional responses to both threat and prosocial appeals related to COVID-19, and directly relate emotional engagement on the independent dimensions of valence and arousal to message efficacy. Given that past research suggests that the intensity of emotional engagement (i.e., arousal) increases learning, memory, and attention (Kensinger & Corkin, 2004; Reisberg & Heuer, 1992; Storbeck & Clore, 2008), we posited that increases in emotional responses would result in greater compliance. However, because of the inconsistent relationship between evoked fear and behavioral change in prior research, we were agnostic as to whether stronger valence and arousal reactions to the threat intervention, compared to the prosocial intervention, would result in more willingness to self-isolate regarding COVID-19.
On March 24th, 2020, we began recruitment through the online site Prolific to collect a representative United States sample (based on sex, age, and ethnicity; Prolific Team, 2019) of N = 1000. Because effect sizes of persuasion on behavior are highly variable, our study used a conservative estimate of the smallest effect size of interest (Lakens, 2017). Using a lower equivalence bound of d = −0.10 and upper bound of d = 0.10, our study was well powered (87%) to detect effect sizes with a greater absolute magnitude than 0.1 with an alpha of 0.05. Participants received monetary compensation and provided informed consent in a manner approved by Brown University's Institutional Review Board. The experiment was conducted within a week of the COVID-19 infection reports in the United States reaching 10,000 (John Hopkins University, 2020). We only recruited U.S. participants to ensure that national messages and questionnaires specific to the United States would be relevant. For example, on March 13th, the White House released a proclamation declaring a national state of emergency related to the COVID-19 outbreak (The White House, 2020) and on March 16th, social distancing guidelines were issued in the United States (The White House & Centers for Disease Control and Prevention, 2020). Using the preregistered exclusion criterion that aimed to ensure high quality data, we excluded 45 individuals' data using a conservative measure of noncompliance based on instructions for an emotion classification task (see Measuring Emotional Experiences for a description of the task). This resulted in a final sample of 955 participants recruited between March 24th and March 26th, 2020 (506 females; age M = 44.8, SD = 15.9). Participants reported being 73.0% White, 13.4% Black, 4.4% East Asian, 3.9% Hispanic / Latinx, 2.1% South Asian, 1.6% Mixed Race, 0.4% Native American, 0.3% Middle Eastern, and 0.9% Other.
Here we detail every measure that participants responded to, however, only the intervention measures, personality measures (BFI-2-S; Soto & John, 2017) and a questionnaire on COVID-19 preventative behaviors (e.g., “I stayed at home”, which provided a baseline for COVID-19 self-isolation behavior), were analyzed for this experiment (all detailed below). All other measures were collected for another experiment, whose hypotheses and methods were preregistered on OSF (https://osf.io/y2uj6). All participants completed a series of tasks and questionnaires in the following order: an emotion classification task, a variety of self-report questionnaires with a randomly presented order including the emotion regulation questionnaire (Gross & John, 2003), interpersonal regulation questionnaire (Williams, Morelli, Ong, & Zaki, 2018), extraversion and neuroticism subscales of the Big Five Inventory-2-S (Soto & John, 2017), intolerance of uncertainty (Carleton, Norton, & Asmundson, 2007), and clinical measures of depression (Radloff, 1977), anxiety (Spitzer, Kroenke, Williams, & Lowe, 2006), and alexithymia (Bagby, Parker, & Taylor, 1994), a questionnaire that assessed their knowledge of COVID-19, a fear intervention, questionnaires that assessed behavioral responses towards COVID-19, fear of COVID-19, media consumption of COVID-19, motives related to COVID-19 behaviors, social support related to COVID-19, information about work related to COVID-19, an altruism intervention, and demographics.
In a within-subject design, participants were given two prompts we created in the following order: The threat intervention followed by the prosocial intervention. The threat intervention was inspired by a recent Medium article (Pueyo, 2020) that tapped into fear of COVID-19: “The coronavirus is coming for you. When it does, your healthcare system will be overwhelmed. Your fellow citizens will be turned away at the hospital doors. Exhausted healthcare workers will break down. Millions will die. The only way to prevent this crisis is social distancing today.” This generated threat message contains two traditional components of threat appeals that emphasize: 1) the severity of the issue through negative consequences, and 2) the likelihood these consequences will occur to the reader (Dillard et al., 2016).
After reading this prompt, participants were asked three questions: (a) How does this statement make you feel? (responses recorded using a granular emotion measure, see details below); (b) On a scale from 0 (not at all) to 100 (completely), how willing are you to self-isolate?; (c) On a scale from 0 (no change) to 100 (a lot of change), how much does the previous statement change your willingness to self-isolate? In the second prompt (which was temporally spaced by multiple questionnaires in between), participants were given a prosocial intervention that was designed to be as similar as possible in structure to the threat prompt, but which emphasized prosocial actions: “Help save our most vulnerable. Together, we can stop the coronavirus. Everyone's actions count, every single person can help to slow the crisis. We have the tools to solve this problem. Together, by self-isolating we can save millions of lives.” This prosocial message focused on internal efficacy (how the individual can take successful action to mitigate the spread of COVID-19) and response efficacy (emphasizing the effectiveness of the group working together; Hart & Feldman, 2014). After this prompt, participants were again asked the three questions denoted above.
After reading both the threat and prosocial appeals, participants reported their affective experiences using the dynamic Affective Representation Mapping (dARM) tool (a measure we have used in our work; (Heffner, Son, & FeldmanHall, under revision)), which was adapted from the affect grid used in past research (Russell, Weiss, & Mendelsohn, 1989). This measure allows participants to rate their affective experiences on a subjective map where the horizontal axis characterizes an unpleasant-pleasant dimension (i.e., valence), and the vertical axis characterizes a low-high activation dimension (i.e., arousal). The dARM has a sampling resolution of 500 × 500 pixels, enabling us to measure fine-grained self-reports of both the valence and arousal dimensions without forcing discrete emotional labels on their experiences. To ensure participants were able to effectively use the dARM to rate their emotional experiences after appeals (“How does this statement make you feel?”), participants completed an emotion classification task at the beginning of the experiment. The emotional classification task asked participants to rate 20 canonical emotion words (e.g., angry, sad, happy) using the dARM measurement. Critically, participants were told where to rate a specific feeling, neutral, in the instructions as an attention check: “The center of the square represents a neutral, average, everyday feeling. It is neither positive nor negative”. Our preregistered exclusion criterion was to remove participants who failed to rate neutral within a 100 × 100 pixel square around the center (N = 45/1000).
We used linear mixed-effects regressions to predict participants' self-reported 1) willingness to self-isolate, and 2) change in willingness to self-isolate after reading the interventions. Predictor variables were participant's emotional ratings on the dARM, separated by the arousal and valence dimensions, as well as the type of intervention (threat/prosocial). Separate regressions were run for predicting willingness to self-isolate (labeled “willingness”) and change in willingness (labeled “change”). For the personality analyses, we used separate linear mixed-effects regressions to predict participants' arousal and valence ratings as a function of the personality trait and intervention type. All regressions were run using the nlme package in R (Pinheiro et al., 2020).
To create a measure of each intervention's effectiveness, we subtracted reports of current self-isolation from reported willingness to self-isolate after reading the threat and prosocial interventions (both scales ranged from 0 to 100). Comparing intervention’ scores to 0 (i.e., no effect of intervention) revealed that both the threat intervention (M = 6.44, SD = 15.41; t(954) = 12.92, p < .001; Cohen's d = 0.42) and prosocial intervention (M = 6.50, SD = 15.71; t(954) = 12.79, p < .001; Cohen's d = 0.41) increased willingness to self-isolate, confirming the efficacy of both interventions. Importantly, these results remain the same when we use an aggregate measure of all preventative COVID-19 behaviors, rather than a single item assessing willingness to stay home (threat Cohen's d = 0.31, prosocial Cohen's d = 0.30). We then examined whether the threat or prosocial intervention produced differences in people's reported willingness to self-isolate (termed “willingness”; Fig. 1A), as well as their reported change in self-isolation behavior after reading the intervention (termed “change”). Although participants reported high levels of willingness to self-isolate after reading both the threat intervention (M = 93.75, SD = 12.96) and the prosocial intervention (M = 93.81, SD = 13.43), a paired sample t-test showed the two interventions did not produce significantly different reports of willingness (t(954) = 0.25, p = .81) or changes in self-isolation (t(954) = 0.17, p = .87). The correlation between willingness and change was significant for both the prosocial (r(953) = −0.07, p = .04) and threat interventions (r(953) = −0.07, p = .04). Together, these results illustrate that both prosocial and threat interventions nudged willingness to self-isolate in comparable ways to help mitigate the spread of the virus.
While the interventions were similarly effective (Fig. 1A), examining the emotional reactions to both interventions revealed they were associated with distinct emotional experiences. The average emotional response to the threat intervention was very unpleasant and highly arousing while the average emotional response to the prosocial intervention was fairly pleasant and moderately arousing (Fig. 1B). The emotional responses to the threat intervention were heavily clustered in the upper-left corner of the dARM, indicating more homogeneity in emotional responses compared to the prosocial intervention responses. Formal tests comparing experienced arousal and valence between the two interventions revealed that the threat intervention was experienced as significantly more arousing (M = 115.46, SD = 126.60) than the prosocial intervention (M = 81.88, SD = 99.37; paired sample t(954) = 7.90, p < .001; Cohen's d = 0.26). Moreover, while the threat intervention was unsurprisingly significantly more negatively valenced (M = −158.67, SD = 94.28) than the prosocial intervention (M = 134.60, SD = 90.95; t(954) = −68.50, p < .001; Cohen's d = 2.22), it was critically experienced as more unpleasant than the prosocial intervention was experienced as pleasant (absolute value of valence, t(954) = 7.56, p < .001; Cohen's d = 0.24). This suggests that participants had a stronger emotional reaction on both dimensions to the threat intervention than the prosocial intervention.
Given the heterogeneity of emotional responses to the two interventions (Fig. 1B), we next examined whether personality traits known to predict positive and negative moods—extraversion and neuroticism, respectively (Costa & McCrae, 1980; Rusting & Larsen, 1997)—explain the observed emotional variance. We found that neuroticism interacted with intervention type to predict increasing arousal (interaction β = −0.10 ± 0.03, p < .001) but not valence (interaction β = −0.02 ± 0.02, p = .52), and this was uniquely carried by the threat intervention (β = 0.07 ± 0.02, p = .004; prosocial intervention: β = −0.03 ± 0.02, p = .19). There was also an observed main effect of neuroticism predicting negative valence for both intervention types (threat β = −0.05 ± 0.02, p = .006; prosocial β = −0.06 ± 0.02, p < .001), suggesting that individuals higher in neuroticism generally experienced more negative emotions to the interventions. Although less predictive, extraversion also interacted with intervention type to predict increasing arousal in the opposite direction as neuroticism (interaction β = 0.06 ± 0.03, p = .02), and this was uniquely driven by the prosocial intervention (β = 0.05 ± 0.02, p = .04) and not the threat intervention (β = −0.01 ± 0.02, p = .56). Finally, we observed that greater extraversion predicted increasingly positive valence for the prosocial intervention (β = 0.06 ± 0.02, p = .001) but not the threat intervention (β = 0.02 ± 0.02, p = .31). However, because of a nonsignificant interaction between extraversion and intervention type predicting valence (interaction β = 0.04 ± 0.02, p = .10), these simple effects should be interpreted with caution.
Examining how these emotional responses influenced willingness to self-isolate revealed that the strength of experienced arousal and valence was more associated with willingness to self-isolate for the prosocial intervention compared to the threat intervention (arousal: interaction β = 0.07 ± 0.03, p = .023; valence: interaction β = 0.16 ± 0.05, p < .001; Fig. 2
). Indeed, the fact that the simple effects of the threat intervention (dark red and dark purple lines in Fig. 2) were not significant suggests that the efficacy of the threat intervention does not rely on the strength of the emotional response, whereas the prosocial intervention does. A similar behavioral pattern was found for changes in self-isolation (Fig. 3
), where the effect of valence on behavior change was significantly higher for the prosocial intervention than the threat intervention (interaction β = 0.24 ± 0.06, p < .001). However, unlike before, the relationship between arousal and change was similar across both interventions (interaction β = 0.02 ± 0.04, p = .644), suggesting that increases in arousal for both interventions lead to more intention to change behavior.
The effectiveness of public health messages is crucial for successfully combating large public health crises such as the COVID-19 pandemic. Problematically, the behaviors associated with preventing the spread of the virus are difficult to adhere to, as they include vigilant hand washing, donning facial masks, and most disruptively, practicing extreme social distancing measures. This makes it challenging for public health officials to create messages that are effective in motivating behavior change. Here, we explore how emotion shapes the efficacy of two different persuasive appeals, one that highlights threat and one that emphasizes prosociality. Unlike previous research that has found prosocial frames to be more effective than threat frames (Shen, 2011), we find that both threat and prosocial messages were equally effective in stimulating willingness to engage in disease prevention health behaviors. However, while threat messages created a stronger emotional reaction (which were more negative and arousing) than the prosocial message, the efficacy of the threat intervention depended less on the strength of the emotional response compared to the prosocial intervention. In contrast, the prosocial message was more effective at boosting willingness to self-isolate if it produced a strong, positive, and arousing emotional response.
These findings reveal that although threat and prosocial interventions were similarly successful in changing people's self-isolation intentions, they do not operate from the same emotional mechanisms. While successful prosocial messages depend on strong, positive emotional engagement, effective threat messages leveraging fear-mongering language are less reliant on the strength of emotional reactions. Given the lack of observable relationship between emotion and reported willingness to self-isolate in response to fear-mongering language, other mechanisms such as a negativity bias (Rozin & Royzman, 2001), or selective attention to negative information (Carretié, Mercado, Tapia, & Hinojosa, 2001), may subserve the efficacy of fear messaging. Moreover, because stronger negative emotional responses did not yield influence on willingness to self-isolate, designing a message with more graphic and emotionally evocative language would likely not improve the success of a fear-mongering appeal, but it may increase the efficacy of prosocial messages. Since self-isolation and monetary hardship related to economic downturns can result in increases in depression and anxiety (Brooks et al., 2020), changing behavior without resorting to fear-mongering tactics would be important for public health officials to consider when designing public service announcements. Indeed, it is possible that messages associated with positive emotions may help buffer against any unnecessary increases in clinical mood disorders. Simply put, in a situation which may already exacerbate anxiety and depression, messages that promote behavioral change while simultaneously appealing to positive emotions are needed now more than ever.
However, the observed heterogeneity of emotional responses to these messages suggests a lingering challenge in fine-tuning the emotional language of either a threatening or prosocial message. Although exploratory in nature, we found evidence that two commonly measured personality traits, extraversion and neuroticism (Hamann & Canli, 2004) explain some of the emotional variance. Dovetailing with past research illustrating a link between positive and negative affect and extraversion and neuroticism, respectively (Canli, Sivers, Whitfield, Gotlib, & Gabrieli, 2002), our results reveal that neuroticism uniquely mapped onto arousal for the threatening intervention while extraversion uniquely mapped onto arousal for the prosocial intervention. Furthermore, neuroticism and extraversion generally predicted negative and positive valence across the intervention types. Overall, this suggests that individuals high on neuroticism will respond more strongly to threat-based messages while extraverts will engage more with the prosocial ones. Although a clear limitation is that we did not examine the full spectrum of personality traits, these findings may help policy makers consider the type of public health message given the demographics of a specific population.
It is worth noting, however, that participants in our studies were simply asked to report their willingness to change their behaviors. Research on message interventions illustrates that reported behavior change does not always coincide with actual behavior changes in the real world (Gibbons, Gerrard, Ouellette, & Burzette, 1998). Although previous work has demonstrated that perceived message efficacy is a relatively good measure of actual effectiveness (Dillard, Shen, & Vail, 2007; Dillard, Weber, & Vail, 2007), it will be important to confirm that these results generalize to actual COVID-19 related behaviors, where readers are being bombarded with many different messages and likely exhibit divided attention when consuming news or reading public health messages. Furthermore, it is also critical to highlight that, while the rapid transmission of COVID-19 is unfolding on a global scale, our sample was limited, by design, to the United States. As there are known cultural differences in how emotion is conceptually represented (Jackson et al., 2019) and expressed (Gendron, Roberson, van der Vyver, & Barrett, 2014), caution should be taken when interpreting the widespread applicability of these results since findings may not translate cross-culturally. One additional limitation of the current design is that participants were given the threat message first, followed by the prosocial appeal. While future work should consider counterbalancing the messages, in general, fixed-order effects typically present minimal to no changes in results (Sauer, Auspurg, & Hinz, 2020).
As of the beginning of September 2020, the United States had still not achieved widespread compliance with social isolationist measures (Canipe, 2020; Fitzpatrick & DeSalvo, 2020), despite repeated calls for citizens to shelter in place from specific States. To help speed the global goal of “flattening the curve” (Qualls et al., 2017), governments and public health officials need to find the most effective messaging for stimulating behavioral compliance. While threat appeals to mobilize society during this time might be tempting to motivate behavioral compliance, we found that prosocial calls to action not only created more positive emotions, but they also elicited just as much willingness to self-isolate compared to deploying threatening language. Although these are preliminary results, it suggests that when collaborative efforts are needed to fight a global pandemic, interventions that appeal to prosocial sentiments might have more to gain than those that appeal to threats.
Behavioral data and analysis script of the reported experiment are available at: https://github.com/jpheffne/covid_intervention.
J.H., M.L.V. and O.F.H. designed the study. J.H. collected and analyzed the data. J.H., M.L.V. and O.F.H. wrote the manuscript.
The authors declare no competing or conflict of interests.",Pers Individ Dif
PMC7545237,Predictors of anxiety during the COVID-19 pandemic in Poland,"The 2019 novel coronavirus (COVID-19) pandemic, believed to have originated in a wet market in Wuhan, China at the end of 2019, has gained intense attention nationwide and globally. The emergence of the COVID-19 pandemic has parallels with the 2003 outbreak of severe acute respiratory syndrome (SARS), which was caused by another coronavirus (Brug et al., 2004; Fung & Cairncross, 2006; Leung et al., 2003). Although the diseases have different clinical presentations the infectious cause, epidemiological features, fast transmission pattern, and insufficient preparedness of health authorities to address the outbreaks are similar (Cao et al., 2020; Wang, Di, et al., 2020). As of 3rd July 2020, the World Health Organization reported 11,018,636 laboratory confirmed cases of COVID-19 and 524,825 deaths (WHO, 2020). Poland was no exception and many deaths were reported (35,405 total cases and 1507 total deaths as of 3rd July 2020; WHO, 2020). Given the seriousness of the situation and lack of any specific vaccine against COVID-19, mitigation measures around the world have so far focused on identifying, treating, and isolating people who have the disease and educating the public about the steps that individuals can take to reduce the risk of transmission.
COVID-19 could be seen as a stressor that elicited a strong anxiety response among people in the epidemic regions (Cao et al., 2020; Wang, Pan, et al., 2020; Xiang et al., 2020). Understanding the psychological factors that predict anxiety in response to such phenomena is important because for some people this results in clinically significant anxiety (Xiang et al., 2020). Thus, the main objective of our study was to investigate different factors associated with coronavirus-related anxiety. Additionally, we wanted to examine how members of the general population in Poland perceived different aspects of COVID-19, their views and beliefs about the COVID-19, as well as precautionary actions and information sources about the COVID-19. This study represents a unique opportunity to better understand pandemic concerns. As this study is the first of its kind, we considered our analyses to be exploratory in nature and thus did not have specific a priori hypotheses regarding which variables would emerge as independent predictors of coronavirus-related anxiety.
The sample was composed of 1069 Polish adults (610 female and 459 male) of all ages ranging from 18 to 74 years (M = 38.54, SD = 15.95). Participation was voluntary and anonymous. Data were collected in an online study administered via a tool for online surveys: SosciSurvey facility. Individuals were recruited through advertisements posted on social media (i.e., Facebook, Twitter). A web-based approach has several advantages—in particular, high efficiency and low cost (Best & Krueger, 2002). Additionally, results from a number of studies indicate that the administration of anxiety-related assessment measures using Internet-based and paper-and-pencil formats yield highly comparable results (e.g., Coles et al., 2007). All participants provided a consent which was obtained online after a detailed instruction describing main purposes and approximate duration of the study. Study was approved by the appropriate ethics review committee of the University of Economics and Human Sciences in Warsaw, Poland, prior to initiation. The data were collected in the period between March 29 and April 17, 2020. During this period, the COVID-19 pandemic was still present in Poland in terms of infections and deaths.
Forty-two of these respondents had been diagnosed with the COVID-19 infection. They were omitted from data analyses because, due to their immunity, they would not be expected to have any motivation for protective behaviors. Additionally, seven control items (e.g., “Please answer ‘Disagree’ to this question”) were included throughout the full-length survey to screen for inattentive and negligent responding. Because previous research has demonstrated that removing inattentive participants improves reliability and power (Maniaci & Rogge, 2014), eight participants who failed to provide correct responses to two or more of these control questions were consequently excluded from the data analysis. Hence, a total of 1019 (441 men, 578 women) respondents were included in the analyses. Their average age was 37.72 years (SD = 15.22).
The research form included questions regarding the following demographic factors: gender, age education, socioeconomic status, marital status, and having children. In addition, the respondents' were questioned about their health conditions with the following two questions: “How good is your health generally?” with the choices of “Very good”, “Good”, “Bad” and “Very bad”, and “Do you have any of the following chronic illnesses?” with the choices of “cancer”, “heart disease”, “lung disease”, “liver or kidney disease” and “any other illness” (Table 1
).
Anxiety sensitivity scores have been found to be more predictive than trait anxiety (Martin et al., 2014; Schmidt et al., 2006). Thus, the anxiety levels were measured using the Anxiety Sensitivity Index-3 (ASI-3). The ASI-3 (Taylor et al., 2007), the most widely used self-report measure of anxiety sensitivity, is an 18-item version of the original ASI (Reiss, Peterson, Gursky, & McNally, 1986) that measures beliefs about the feared consequences of symptoms associated with anxious arousal (e.g., “It scares me when I become short of breath”, “It is important for me not to appear nervous”). Respondents were asked to indicate the degree to which they agree with each item on a 5-point Likert-type scale ranging from 0 (very little) to 4 (very much). Scores range from 0 to 72. The ASI-3 has been found to be a psychometrically sound and valid measure of anxiety sensitivity (Taylor et al., 2007). Within the current investigation the total measure demonstrated excellent internal consistency (α = 0.96).
The perceptions and beliefs regarding the COVID-19 pandemic were measured with four questions (Table 2
). These included questions about susceptibility, the severity of the long-term consequences of the epidemic, prediction of the situation surrounding the COVID-19 epidemic two months in the future, and the belief/disbelief that COVID-19 infection depends on one's own behaviors. Additionally, we evaluated respondents' risk perception in terms of their self-perceived likelihood of contracting COVID-19 and survival if diagnosed with the disease. Respondents were also asked about their confidence in physicians' ability to diagnose the disease. Next, because an earlier study has demonstrated that a citizen's trust of information regarding COVID-19 and trust in the recommendations of health authorities are significant predictors of protective behavior (Rubin et al., 2009), we measured the public's trust of health authorities with three questions (see Table 2). More specifically, these three questions included belief/disbelief in the accuracy of the government's COVID-19 information, government's success in managing pandemic, and likelihood that government will be able to effectively control pandemic in the future.
Respondents were asked which actions they had taken to avoid getting the coronavirus (Table 3
). The total number of actions taken was regarded as an overall COVID-19 precautionary behavior score (range 0–13, α = 0.79). Sample items included: washing hands more often; using disinfectants; wearing facemasks, avoiding shaking hands or kissing.
Finally, respondents were asked to indicate how much information about COVID-19 they obtained from different sources (i.e. television, Internet, newspaper/magazines, health officials, friends/family, word of mouth) and how much confidence they had in these sources (Table 4
). Answer format for all options ranged from 1 = very little to 5 = very much.
All questions mentioned above measuring perceptions and beliefs regarding COVID-19, actions to prevent infection, and sources of information about COVID-19 were taken from previously published articles (Brug et al., 2004; Gaygısız et al., 2012; Rubin et al., 2009).
The characteristics of the respondents can be found in Table 1. Table 1 shows that the sample consisted primarily of individuals under 50 years old. The respondents generally had higher level of education, were either single or married, and had children. Almost one-fourth of the respondents reported having a chronic illness, whereas the majority (over 84%) reported their health condition as “good” or “very good.”
A large number of the respondents in this study estimated their risk of being infected as high or very high (50.1%) and the long-term consequences of the infection to be severe or very severe (58.8%). When asked about their prediction for the COVID-19 situation in Poland in 2 months, only 23.9% of respondents expected the situation to improve, 50.4% expected it stay the same, and 25.7% expected the situation to become worse. When respondents were asked about their own behaviors and risk of COVID-19 infection, a majority of 83.4% perceived themselves to have control over their risk of infection to at least some degree (i.e., “little control”, “much control” or “a great deal of control”).

Table 2 also shows that almost a half of the respondents (49%) believed that they were “very likely” or “somewhat likely” to contract COVID-19 during the current outbreak. Regarding the likelihood of surviving COVID-19 if they contracted the disease, fewer than 18% believed they were unlikely (14.7% “not very likely” and 3.1% “not likely at all”) to survive but over one-third (34.9%) were certain to survive COVID-19 if infected. The actual case fatality ratio in Poland as of 17th April 2020 (last day of conducting this study) was 3.9% (332 deaths of 8379 confirmed cases), whereas current best estimates vary between 4.2% to 4.6% (WHO, 2020). Most respondents were confident (28.9% “very confident” and 50.8% “somewhat confident”) that their physician would be able to recognise the symptoms and signs of COVID-19 and properly diagnose the disease.
The majority of the respondents (over 70%) were suspicious of the accuracy of the COVID-19 information provided by the health authorities (Table 2). Moreover, 79.8% evaluated the government's success in managing the epidemic as “very unsuccessful” or “unsuccessful.” Majority of respondents (62.6%) perceived the likelihood that the government would be able to manage the epidemic in the future to be “very unlikely” or “unlikely”. At the same time only 7.6% of respondents said that it is very likely that government will be able to effectively control and manage COVID-19 epidemics in the future.
Many respondents reported that they took precautionary actions to reduce their risk for COVID-19. Notably, based on multiple responses, all respondents reported taking at least one precautionary action; 57.1% reported one or more specific actions, especially washing hands more often, being more attentive to cleanliness and using disinfectants. Three-fourth of people worked or studied from home. Additionally around 70% of participants avoided traveling or gathering with other people. Over 68% of respondents declared wearing facemasks. The other respondents indicated they had done something else to avoid getting COVID-19, e.g. got enough sleep, exercised regularly or had a balanced diet (see Table 3).
Based on multiple responses, in our study over 80% of respondents learned about the COVID-19 from television while about 70% came to know about the disease from the Internet. Only 20% of participants got their information from health officials and the minority of 6% of participants got their information through word of mouth. Television and Internet were also rated as the most confident sources of information, while word of mouth was the least trustworthy source of information
Participants reported anxiety level with mean 39.06 (SD = 8.95). This score is higher than the established previously mean of 22.53 (SD = 9.05) for high-anxious individuals (Holas et al., 2013). We next computed a multiple regression analysis predicting anxiety scores. To determine which variables would make significant contributions in predicting coronavirus-related anxiety we computed a regression in which the ASI-3 served as the dependent variable, and the other study measures were entered simultaneously as predictors. The variables were entered into the model in two blocks: demographic factors were entered first, followed by COVID-19 related beliefs and factors (see Table 5
). Prior to the analysis, “marital status” was classified into two categories, “single, divorced or widowed” and “married or cohabiting”. Summary statistics for each variable in this equation are presented in Table 5. Together, the predictor variables accounted for 36% of the variance in ASI-3 scores, and the model was highly significant (p < 0.001).
Major predictors of higher anxiety related to the pandemic outbreak included demographic factors, like being female, being older, being married or cohabiting, and having children. Additionally, greater anxiety was reported among people who reported chronic illnesses and generally worse health condition. From COVID-19 related factors, higher frequency of recommended protective behaviors, greater perceived risk of infection, greater likelihood of contacting COVID-19 during the current outbreak, greater amounts of information about COVID-19 received from various sources, and very little or lack of belief that degree of catching COVID-19 depends on one's own behavior predicted greater anxiety among individuals.
A number of limitations of this study should be mentioned. First, the cross-sectional nature of this investigation precludes us from drawing causal inferences regarding the relationships between the psychological variables and concerns about the COVID-19. It is important to note that the variables found to be significant predictors of anxiety cannot be assumed to cause such symptoms. The additional limitation of this rapid survey during the COVID-19 outbreak is that it was administered at a single period in time and the stability of the responses is unknown. Future longitudinal research is needed to determine the direction of causality for these associations, as well as the presence of any intermediary factors. It would also be desirable to compare the public's psychological responses in other countries that were similarly affected. Additionally, results showed that anxiety was significantly related to perceptions about risk of infection. However, risk perception and compliance with preventive measures may have changed during the pandemic period (Wheaton et al., 2012). It was not possible to evaluate any change related with pandemic period in beliefs and perceptions with the current study. Further longitudinal studies might overcome this limitation. Finally, stress management training, which has been shown to be effective in reducing anxiety, should be provided to all individuals as a preventive measure during future outbreaks (Shapiro et al., 2000).

Marta Malesza: Conceptualization, Methodology, Data collection, Writing- Original draft preparation, Writing- Reviewing and Editing. Magdalena Claudia Kaczmarek: Data Collection, Writing- Reviewing and Editing.
Author Marta Malesza declares that she has no conflict of interest. Author Magdalena Claudia Kaczmarek declares that she has no conflict of interest.",Pers Individ Dif
PMC7538945,"Personality regulation of decisions on physical distancing: Cross-cultural comparison (Russia, Azerbaijan, China)","The roots of the concept of IT go the works of G. Kelly, R. Tagiuri, and others. It emerged in the domain of intelligence (Sternberg et al., 2000) and as “lay theories” (A. Furnham). Functioning implicitly, they influence interpretations of situations and behavioral strategies. C. Dweck has made a distinction between fixed IT and malleable IT based on the perceived nature of attributes (Dweck & Leggett, 1988; etc.).
IT of emotions (Tamir, John, Srivastava, & Gross, 2007) as beliefs about the controllability of emotions might have important influence when emotional regulation is essential for decision making. Fixed IT of emotions correlate with avoidance of negative experiences (Kappes & Schikowski, 2013).
Nationwide research in China (Qiu et al., 2020) and meta-analysis of data from all over the world (Luo, Guo, Yu, Jiang, & Wang, 2020) have shown a prevalence of depression and anxiety during the pandemic. Presumably, ability to manage one's emotions might improve adaptation to a changed reality.
The categorization of risks doesn't determine the direction of behavior by themselves, neither do personality dispositions. But the interaction of situational and personality factors influences judgment and risk-taking. In recent years, researchers work on improving risk literacy, in particular, in medical risks (Gigerenzer, 2015).
The concept of risk intelligence (Evans, 2012) emphasizes cognitive control of judgments on risk. Perception of threat is influenced by its representation in the media (Slovic, 2000), and individual differences (Chauvin, 2018; Kornilova, Pavlova, Bogacheva, Kamenev, & Krasavtseva, 2020). Moreover, the presence of affect impairs judgment on the probability of events (Slovic & Peters, 2006).
The DT traits include Machiavellianism, subclinical psychopathy, and narcissism which have different etiologies and closeness of interconnections in different countries (Jonason et al., 2017). Аll three aversive traits characterize the so-called “unstable” emotional core and are related to the need for social domination and utilitarian solutions of moral dilemmas.
Narcissism might be the brightest from all DT traits because it is positively associated with intelligence and tolerance of uncertainty (Krasavtseva & Kornilova, 2019). Some data suggest that narcissism is a more “distinctive” trait (Savard, Simard, & Jonason, 2017).
Dark Triad traits predict lower adherence to COVID-19-related restrictions (Zajenkowski, Jonason, Leniarska, & Kozakiewicz, 2020; Zettler, Schild, Lau, & Böhm, 2020).
Emotional regulation is studied less in eastern cultures. Indirect conclusions stem from the emotional attitude to another person and how empathy changes when moving along the collectivism-individualism scale. Empathy differs depending on whether the person we experience empathy for belongs to our in-group or not (Abu-Akel, Fischer-Shofty, Levkovitz, Decety, & Shamay-Tsoory, 2014). Assuming that relationships between people in Chinese society are closer than in individualistic cultures, we can expect that during the pandemic Chinese people will show high emotional empathy.
Empathy to the most vulnerable to the coronavirus was related to compliance with social distancing in Western countries (Pfattheicher, Nockur, Böhm, & Sassenrath, 2020).
Empathy, risk readiness, and rationality regulate decision making through the interaction with a person's world view which is largely influenced by the media. Contextual variables of cultural traditions influence behavior, and since health threats are probabilistic by nature, the role of emotional and personality factors in decision making is important to investigate.

1.In countries with higher collectivism (China, Azerbaijan), choices based on caring for others (not just caring for oneself) will be frequent while autonomy-based choices will be less frequent.2.Personality measures of empathy, rationality, and malleable IT of emotions are positive predictors of physical distancing compliance while risk readiness and DT traits are negative predictors.

The overall study sample included 1077 online participants recruited using snowball technique.1.Russian sample: 308 participants 18 to 80 y.o. (M = 32.3, SD = 11.71), 80% female.2.Azerbaijani sample: 352 participants 17 to 74 y.o. (M = 30.5 SD = 10.40), 74% female.3.Chinese sample: 417 participants 17 to 52 y.o. (M = 25.1, SD = 7.16), 59% female.

After providing informed consent to participate in the study, participants were asked if they trust information from the media that they might be asymptomatically infected with coronavirus. Then they made choices in verbal tasks-vignettes and filled out questionnaires.
We developed 5 verbal tasks – situations where decisions on whether to wear a mask (reasons A1 and A2) or not (B1 and B2) were made by choosing from four given reasons. We used a quasi-experimental design: all participants received one of four tasks with different framing in reasons for and against wearing a mask and one other tasks that was as a control task for every participant (see example Task 2, Appendix 1). In different tasks, reasons for wearing a mask represented the following categories: 1, 2 and 3) Care for Self vs Others, 4) High risk for Self vs Law-abidingness, 5) High risk for others vs Law-abidingness. Reasons for choice not to wear a mask also varied across tasks: 1 and 4) Autonomy for Oneself vs Others, 2) Risk for Oneself vs Others, 3) Risk Underestimation vs Autonomy for Others, 5) Autonomy for Oneself vs Risk Underestimation.

1.
Implicit theories of emotions (ITE) scale (Tamir et al., 2007) includes four items, two of them refer to fixed ITE and two – to malleable ITE. Higher scores correspond to malleable ITE. Cronbach's alpha for this scale are: Russia (α = 0.692), Azerbaijan (α = 0.633), China (α = 0.630).2.
Questionnaire of Cognitive and Affective Empathy (QCAE) consists of 31 items divided into 5 subscales and 2 scales: perspective taking and online simulation (cognitive empathy scale), emotion contagion, proximal responsivity, and peripheral responsivity (affective empathy scale) (Reniers, Corcoran, Drake, Shryane, & Völlm, 2011). We used Chinese (Wang & Su, 2019) and Russian versions.3.
Personality Factors of Decision-making Questionnaire measures risk readiness and rationality (Kornilova, Chumakova, Kornilov, & Novikova, 2010), and was validated on Russian and Azerbaijani samples.4.
The “Dirty Dozen” questionnaire (Jonason & Webster, 2010) measures DT traits: subclinical narcissism, subclinical psychopathy, and Machiavellianism. It was validated on Russian and Azerbaijani samples (Kornilova, Kornilov, Chumakova, & Talmach, 2015; Kornilova, Zirenko, & Guseynova, 2017).

The two last measures weren't administered in China. All measures in Azerbaijan were presented in Russian language.
Descriptive statistics on personality measures and results of Kruskal-Wallis Test are presented in the table below.
Cultural groups showed significant differences in all measures except for affective empathy and narcissism (Table 1
).
Participant groups from different countries differed in theirs answer on trusting the media (χ
2=176.55, p < .001) (Table 2
). The answer “I don't trust the media” was more frequently observed in Azerbaijan where the pandemic was just starting (hundreds of cases daily), while “I trust the media, but I couldn't be infected” – in China where the pandemic has decreased.
Using chi-square test, we examined the differences between choices of reasons for wearing or not wearing a face mask in cultural groups (see Fig. 1
).
In Tasks 1, 2, and 3 in all countries the choice to wear a mask for a reason “care for self” prevailed over“care for others”, more often in the Chinese sample (79.5 vs 19.6%, 72 vs 28% and 87.3 vs 11.8%) compared to the Russian and Azerbaijani samples (χ
2=62.488, p = .001 for Task 1, χ
2=103.262, p = .001 for Task 2, χ2=44.377, p = .000 for Task 3). The choice to remain without a mask was very rare in the Chinese data (less than 1% in Tasks 1–3) while in Azerbaijani and Russian samples it was made with the reasons of autonomy for oneself over autonomy for others (Task 1), low fear of getting infected (Task 2) and risk underestimation over autonomy for others (Task 3).
In Task 4, as reasons for wearing a mask high risk assessment and law-abidingness were chosen with almost equal frequency in Russia (38.6 vs 40.4%), in Azerbaijan prevailed law-abidingness (22.2% vs 46.7), and in China – high risk assessment (71.6 vs 28.4). Not wearing a mask was explained predominantly by autonomy for oneself (not for others) in both Russia (15.8 vs 5.3%) and Azerbaijan (24.4 vs 6.7%). Among the Chinese participants, no one chose to remain without the mask.
In Task 5, law-abidingness prevailed over the risk of infecting others in all groups. When choosing not to wear a mask, Russians more often chose personal autonomy over risk underestimation (13.3 vs 9.7%), Azerbaijani participants showed the opposite trend (10.2 vs 17.9% of personal autonomy). Only 0.2% of Chinese participants chose not to wear a mask.
Correlations between personality traits for Russian and Azerbaijani participants are presented In Table 3
; for Chinese participants – in Appendix 2 (see Table 5).
On the Azerbaijani sample ITE showed positive associations with online simulation and cognitive empathy, and negative – with emotion contagion (Table 3). On the Chinese sample, ITE was positively associated with cognitive empathy, and overall score of empathy.

Risk readiness was positively associated with Machiavellianism and perspective taking in both samples, with proximal responsivity and cognitive empathy in Azerbaijan, with affective empathy and narcissism in Russia; and negatively – with rationality and emotion contagion in both samples.
We ran individual logistic regression analyses for each of the personality measures as independent variables and a binary variable “wear a mask” or “remain without a mask” as dependent variable (regardless of reasons for the decision). The Chinese participants rarely chose “remain without a mask” therefore regressions weren't performed.

Rationality was a positive predictor of the choice to “wear a mask” in Russia (Tasks 2 and 5) and in Azerbaijan (Task 1) (see Table 4
). Narcissism was a positive predictor in Russia (Task 3) and a negative predictor in three out of five tasks in Azerbaijan. Risk readiness and psychopathy were negative predictors in three cases.
Different empathy subscales and scales were positive predictors for Russian and Azerbaijani participants.
Using a mixed logistic regression, we investigated personality variables as predictors of the probability of making the choice “care for others” vs the reference level “care for self” across Tasks 1–3. The baseline model included fixed effects of sex, age, and group (Russian as the reference level and dummy-coded Chinese and Azerbaijani group status). All continuous predictors were mean-centered (age) or scaled to have M = 0, SD = 1. Task effects were modeled as random effects. Analysis was focused on establishing the main effects of personality variables on choice as well as the interaction effect between personality variables and the group that would reflect the moderation of the relationship conditional on group status.
Two sets of analyses were performed: 1) using variables measured in both Russian and Azerbaijani samples, and 2) using variables measured in all three samples (see Fig. 2
). First, the baseline model revealed lower probability of this choice in the Chinese group overall (B = -1.03, SE = 0.21, Z = -4.83, P = .0000014).
Second, we found that several variables positively predicted the probability of choice “care for others”: using the Russian sample as the baseline, we established that this choice was positively predicted by ITE (B = 0.30, SE = 0.15, Z = 2.06, P = .039), perspective taking (B = 0.57, SE = 0.17, Z = 3.32, P = .001), online simulation (B = 0.44, SE = 0.17, Z = 2.60, P = .009), overall empathy (B = 0.46, SE = 0.16, Z = 2.88, P = .004) and, most strongly, cognitive empathy (B = 0.62, SE = 0.18, Z = 3.53, P = .0004). Notably, for two of these variables, we established a significant interaction with the group status: for cognitive empathy and perspective taking, the two strongest predictors of the choice, the effects were significantly smaller in the Chinese group (for the interaction, B = -0.46, SE = 0.22, Z = -2.10, P = .03533 for cognitive empathy, and B = -0.45, SE = 0.22, Z = -2.07, P = .0389 for perspective taking, respectively). No other main or interaction terms reached nominal significance.
In Russia and Azerbaijan we observed similar relationships between empathy and risk readiness, rationality, and DT traits. Previous cross-cultural study showed that DT traits and emotional intelligence do not correlate in these cultural samples (Kornilova, Chumakova, & Gadjieva, 2016), therefore, the observed relationship between empathy and DT traits is not likely to be mediated by emotional intelligence which we didn't measure in this study.
The Chinese sample was characterized by higher cognitive empathy, but the three groups didn't differ in affective empathy. On Azerbaijani and Chinese samples IT of emotions correlated with cognitive empathy, suggesting IT of emotions is rather a cognitive than affective component of emotion regulation.
Since Chinese sample didn't receive the measures of risk readiness, rationality, and DT traits, we couldn't build a more distinctive personality profile. And since extremely low percentage of Chinese participants chose to “remain without a mask” we couldn't identify predictors of this choice.
The choice to wear a mask was most often made for a reason of care for self in all countries. This reason prevailed mostly among the Chinese participants, less – among Azerbaijanis and less so – among Russians. For Russians, as representatives of a more individualistic culture, the gap between the frequency of choosing this reason and care for others was the smallest.
This result contradicts hypothesis 1 and suggests that the concepts of collectivism and individualism as characteristics of cultures may not correspond to the individual reasons of decision making. It also contradicts the idea that in relational contexts prosocial behavior is guided by interpersonal responsibilities and in autonomous contexts – by personal choice and autonomy (Köster, Schuhmacher, & Kärtner, 2015). At the same time, the Chinese participants showed higher trust in the media message that they may be asymptomatically infected, therefore these results on choice of reasons could be due to varying risk representation in different countries.
Contrary to hypothesis 1, Azerbaijani participants chose “not to wear a mask” most often and for the reasons of risk underestimation and autonomy for themselves (the latter is contrary to showing concern for others, which we expected to observe in collectivistic cultures).
We assumed that the risks of contracting a virus with and without symptoms are equal, therefore, this factor couldn't be the one influencing the asymmetry in choice reasons.
Risk readiness influenced the decision not to wear a mask for Russians and Azerbaijanis which allows us to accept hypothesis 2. Rationality was a positive predictor of complying with the norms which corresponds to the US data (Stanley, Barr, Peters, & Seli, 2020). Our findings on the positive role of empathy are also consistent with data from the USA, UK, and Germany (Pfattheicher et al., 2020). ITE wasn't a significant predictor of decision to wear a mask, contrary to what we expected.
In line with the Danish study (Zettler et al., 2020), we assumed the negative role of the DT traits in adhering to the restrictions. The difference was that in the Russian sample psychopathy was a negative predictor of3 wearing a mask while narcissism was a positive predictor, corroborating the idea of it being “the lightest” trait in DT (Krasavtseva & Kornilova, 2019) while in Azerbaijani sample narcissism was a negative predictor. It could be possible that cultural context mediates whether narcissism leads to protesting restrictions (seen as an ego threat) and disregarding for caring for others.
The results of this study might be influenced by the different severity of the epidemic in three countries. Moreover, we found that strict normative regulation of behavior makes it almost impossible to reveal personality regulation of choices.
IT of emotions and subscales of cognitive empathy emerged as the variables that predict caring for others over caring for self as reasons for wearing a mask suggesting these components of emotional regulation play a role in prosocial behavior. But further studies are needed to understand why IT of emotions didn't influence decision to wear a mask.
We also need to study further why in comparison with Russia collectivist countries (Azerbaijan and China) have shown higher indices of cognitive, but not emotional empathy which could be expected in cultures with closer interpersonal relationships.

Maria Zirenko: Methodology, Investigation, Data curation, Writing - original draft, Writing - review & editing. Tatiana Kornilova: Conceptualization, Methodology, Writing - original draft, Writing - review & editing, Funding acquisition. Zhou Qiuqi: Investigation. Ayan Izmailova: Investigation.",Pers Individ Dif
PMC7547372,The role of culture on the link between worldviews on nature and psychological health during the COVID-19 pandemic,"This study was designed to elucidate the way worldviews about nature are linked to psychological health during the COVID-19 pandemic. During the height of the 2020 COVID-19 pandemic (May 2020), participants residing in Japan and the United States (US) completed self-report scales to measure 1) impact of the COVID-19 pandemic (personal, family and financial), 2) worldviews on nature (harmony, mastery, subjugation and incremental theory), and 3) psychological health (perceived stress, negative and positive affect). In addition, we also sourced data from a prior large-scale cross-cultural study in Japan and the US, Midlife Development in the Midlife in Japan (MIDJA) and the Midlife Development in the U.S. (MIDUS). We compared levels on each of the psychological health outcome measures collected during the COVID-19 pandemic to data collected prior to the COVID-19 pandemic. We tested three hypotheses: H1: Across cultural contexts, people would report greater psychological distress during the COVID-19 pandemic than prior to the pandemic (MIDJA and MIDUS data); H2: Across cultural contexts, individual differences in harmony-with-nature worldviews would be positively associated with improved psychological health; and H3: Individual differences in mastery-over-nature worldviews would be more strongly associated with negative affect in the United states than in Japan. Lastly, we also tested for links between incremental theory about the natural world and psychological health during the COVID-19 pandemic.
A power analysis, using an alpha level set to 0.05 indicated that a sample size of 306 per group was necessary to detect a small effect size (f
2 = 0.04) with a high level of power (95%) (Faul et al., 2007). During May of 2020, 813 participants provided informed consent and agreed to take part in a study on “people's thoughts about the world, the current COVID-19 pandemic and how they are coping.” Sample data were collected using online crowdsourcing websites (Japan: www.lancers.co.jp, US: www.mturk.com). Participants self-reported on demographic (age and sex), survey measures (pandemic impact, worldviews on nature, and psychological health), and a single attention check item. Based on responses to the attention check item, 23 (Japan = 9, US = 14) respondents were removed from the data set. The final data set consisted of 381 in Japan (200 females, mean age = 39.81, SD = 10.13) and 409 in the United States (174 females, mean age = 37.11, SD = 13.39).
As a proxy of psychological health prior to the COVID-19 pandemic, we sourced publicly available data from the MIDJA and MIDUS studies. The MIDJA project collected data within the Tokyo metropolitan area and the MIDUS project collected data across the United States. Both the MIDJA and MIDUS studies included measures on perceived stress, positive affect (PA) and negative affect (NA). We pooled data from the second wave of data collection (MIDJA II: 2004–5, MIDUS II: 2012) because perceived stress was not collected during the first wave of the MIDUS study (MIDJA II: n = 657, 348 females, mean age 59.25, SD = 13.54; MIDUS II [PSS]: n = 1255, 679 females, mean age = 55.74, SD = 12.33; MIDUS II [PA and NA]: n = 4963, 2647 females, mean age = 55.44, SD = 12.46).
Participants reported on 3 items related to how much (1 = not at all, 2 = slightly, 3 = somewhat, 4 = very, 5 = extremely) they were affected by the COVID-19 pandemic for each of the following domains: personal, family and job/financial situation, using a single item for each (How much have you been personally affected by the COVID-19 virus pandemic? How much has your friends and family been affected by the COVID-19 virus pandemic? How much has your job and financial situation been affected by the COVID-19 virus pandemic?).
Participants also responded to 12 items measuring individual differences in worldviews on nature (Supplementary materials). Nine items (people/nature) were selected from the Tertiary Student Values Scale (TSVS) (Kluckhohn & Strodtbeck, 1961; Marino & Stuart, 2005). TSVS People/nature consists of 3 subscales (3 items each: harmony-with-nature, mastery-over-nature, and subjugation-to-nature). Participants also competed 3 items on implicit theories about the natural world (Dweck et al., 1995). The implicit theories about the natural world items were included in order to explore the association between the belief that the natural world is changeable, in general, and psychological health during the COVID-19 pandemic. Prior psychometric research demonstrates each subscale to have adequate discriminant validly and reliability (Dweck et al., 1995; Marino & Stuart, 2005), with the exception of the subjugation-to-nature subscale, that was shown to have marginally acceptable internal consistency (Marino & Stuart, 2005).
The items used to measure the COVID-19 impact (3 items) and worldviews on nature (12 items) were translated to Japanese using back translation (Brislin, 1970). First, items were translated from English to Japanese by a bilingual translator. Next, a separate bilingual translator translated the Japanese items back to English and the two English versions were compared for discrepancies. Lastly, any discrepancies were discussed and subsequently resolved.
Participants also completed the Perceived Stress Scale (PSS) (10 items) (Cohen et al., 1994) and the Negative and Positive Affect Scales (12 items) (NAPAS) (Mroczek & Kolarz, 1998). The PSS and NAPAS scale have been shown to be reliable and valid across Japanese and US cultural contexts (Joshanloo, 2018; Sumi, 2006). Participants were prompted to report on their level of stress and affect throughout the last 60 days. The Japanese versions of the PSS and NAPAS items were obtained from the MIJDA study questionnaire.
Cronbach's alpha for each subscale of the worldviews on nature measure indicated adequate reliability (harmony-with-nature: Japan = 0.82, US = 0.85, mastery-over-nature: Japan = 0.65, US = 0.69, implicit theory on nature: Japan = 0.70, US = 0.84), with the exception of subjugation-to-nature (Japan = 0.29, US = 0.71). Because of low reliability of the subjugation-to-nature subscale, these items were excluded from all subsequent analyses. Cronbach's alpha for each of the outcome measures also indicated adequate reliability (PSS: Japan = 0.85, US = 0.87; NA: Japan = 0.89, US = 0.92; PA: Japan = 0.91, US = 0.93).
We performed a multigroup confirmatory factor analysis to test for configural and metric invariance across cultural contexts (Cheung & Rensvold, 2002). Across all measures, we obtained evidence for either full or partial configural (comparative fit index: CFI > 0.95, root mean square error of approximation: RMSEA < 0.10) and metric (∆CFI < 0.01, ∆RMSEA < 0.015) invariance across cultures (Table 1
). The multigroup confirmatory factor analysis for the PSS indicated substantially better fit when items 5 and 7 were removed and were thus excluded from subsequent analyses. Lastly, in accordance with prior cross-cultural research on personality and individual differences (De Raad et al., 2014; Paletz & Peng, 2008), the item level data for the worldviews on nature scale were standardized per person (ipsatization). This method involves recalculating each item score to control for each individual's mean score and standard deviation on that scale and can reduce spurious effects due to differences in response style such as acquiescence or extremity bias between cultural contexts (Church et al., 2008; Fischer, 2004; Rammstedt et al., 2013). Statistical analysis included independent sample t-tests to compare outcome measures collected during the COVID-19 pandemic to data collected within the MIDJA and MIDUS studies. We then carried out a series of regression analyses to test for associations between worldviews on nature and psychological health during the COVID-19 pandemic, with age and sex entered as covariates.
Japanese and US participants self-reported how much they were affected by the COVID-19 pandemic within personal, family and job/financial. In order to gauge the existence of cultural differences in impact of the pandemic on people's life, we compared responses to each item between cultures. Across all domains, we did not observe any statistically significant differences in self-reported impact due to the COVID-19 pandemic between Japanese (mean: personal = 3.31, family = 3.39, financial/career = 3.15) and American (personal = 3.17, family = 3.31, financial/career = 3.14) cultural contexts (all p's > .05). These findings, however should be considered with caution, as response styles may be different according to cultural context.
Descriptive statistics, reliability coefficients and bivariate correlations between all variables are shown in Supplementary Table 1. For H1, we compared each of the outcome measures collected during the COVID-19 pandemic to data collected within the MIDJA and MIDUS studies (Table 2
). Within each culture, people tended to report greater psychological distress during the COVID-19 pandemic as compared to during the MIDJA and MIDUS studies. We also tested for associations between self-reported impact during the pandemic within each domain (personal, family and job/financial) and each of the psychological health outcome measures, with age and sex entered as covariates. Within each cultural context, self-reported impact was significantly associated with increased psychological distress (PSS and NA) (all p's < .005). However, we found that PA was not significantly associated with impact to one's family in Japan, and to one's financial/job situation in the US.
Next for H2, we tested for associations between worldviews on nature and psychological health. We conducting a series of regression analyses with individual differences in harmony-with-nature worldviews entered as the predictor variable and each of the psychological health measures entered as criterion variables, with age and sex entered as covariates. The results of this analysis demonstrated that both Japanese and American samples showed a positive association between harmony-with-nature worldviews and each of the psychological health measures (PSS, NA and PA) (Table 3
).
We tested H3, that individual differences in mastery-over-nature worldviews would be more strongly associated with NA in the US than in Japan. We found that culture moderated the link between mastery-over-nature worldviews and NA (Table 3). The American sample showed a strong positive association between mastery-over-nature worldviews and NA (r = 0.18, p < .001), while the Japanese sample did not (r = 0.06, p = .26). The effect of culture on the strength of the association between mastery-over-nature worldviews and NA was statistically significant (t = 2.26, p = .026).
Lastly, we explored the link between implicit theories on the natural world and psychological health during the COVID-19 pandemic. The implicit theory items were coded such that lower values correspond to incremental theories and higher values correspond to entity theories. We found that incremental theories on nature tended to be associated with increased PA in both American (p = .004) and Japanese (trend: p = .05) cultural contexts (Table 3).
In this study we found that individual differences in worldviews about nature are associated with psychological health during a severe natural disaster. Across both Japanese and American cultural contexts, holding a worldview that humans and nature are best thought of as being be harmonious with one another, corresponded to improved psychological health during the COVID-19 pandemic. This finding further supports the biophilia hypothesis, that humans possess an innate tendency to seek connections with nature and other forms of life (Wilson, 1984). We also found that cultural context moderated the link between mastery-over-nature worldviews and NA during a natural disaster. Americans showed a stronger link between mastery-over-nature worldviews and negative affect than Japanese. This finding supports theories differentiating Japanese and American cultural contexts based on naïve dialecticism (Spencer-Rodgers et al., 2010) and susceptibility to cognitive dissonance (Heine & Lehman, 1997; Hoshino-Browne et al., 2005; Wong, 2009).
This study contributes to a growing body of empirical research demonstrating positive outcomes associated with spending time in nature and thinking about nature in an interconnected and harmonious way. Exposure to natural environments reduces aggressive responses to being ostracized (Poon et al., 2016), self-control depletion (Wang et al., 2018), and improves cognition and affect in depression (Berman et al., 2012). Individual differences in nature connectedness are associated with reduced anxiety (Martyn & Brymer, 2016) and increased positive affect (Mayer et al., 2009). This body of work indicates that interacting and thinking about nature in a harmonious way may be a culturally universal construct linked to improved psychological health.
We found that culture moderated the link between mastery-over-nature worldviews and NA during the COVID-19 pandemic. This finding may in part, represent cross-cultural differences in the tolerance of contraction (naive dialecticism). Americans holding contradictory self-views tend to experience greater anxiety and depression, while this does not tend to occur for Japanese (Brown, 2013). Japanese also tend to report greater contradictory self-views than North Americans (i.e., Canadians) (Hamamura et al., 2008). Contradictory self-views are linked with improved physical health in Japan more so than the North America (Miyamoto & Ryff, 2011). There also exists prior evidence that Americans and Japanese differ in their susceptibility to cognitive dissonance and that is particularly apparent during the processing of self-referent information. Americans tend to experience dissonance across different types of social cues (both self and other), while Japanese tend to experience dissonance when thinking about others, but not when thinking about one's self (Hoshino-Browne et al., 2005; Kitayama et al., 2004). Participants in the current study during the COVID-19 pandemic were tasked to think about their own (i.e., self) worldviews and psychological health (stress and affect). Thus, the interpretation that dissonance occurred more in Americans than in Japanese is consistent with prior research on cultural differences in cognitive dissonance susceptibility.
An alternative interpretation about the reason why the link between mastery-over-nature worldviews and psychological distress differs between cultures may involve cultural differences in trust in authority, and more specifically the government. Americans tend to display lower levels of trust in their government than Japanese. The most recent Edelman's Annual Global Study on the Trust Barometer (2020) reported that 39% of Americans versus 43% of Japanese trusted their government to do what's right. During the COVID-19 pandemic, both American and Japanese governments placed restrictions on many individual liberties in order to reduce rates of person-to-person infection. The tendency to hold a mastery-over-nature worldview may correspond with an increased aversion to being restricted; if humans are indeed masters over the natural world, there is little need to restrict behavior. Holding a mastery-over-nature worldview may correspond to increased negative affect more within a cultural context where one is restricted by a government that is less trusted (US as compared to Japan). Furthermore, it may also be the case that cultural differences in discomfort with maintaining “social distance” may impact the levels of NA.
This study is limited in several important ways (Supplementary materials). Although the COVID-19 pandemic has influenced the lives of people throughout the entire world, we only collected data across two different cultural contexts. We are thus limited in our ability to generalize the observed worldviews on nature and psychological health associations to other cultural contexts. We measured perceived impact to people's lives within personal, family and job/financial domains. However, many other factors, including infection rates, were different between Japan and the United States. It is thus possible that between-country differences in damage caused by the pandemic influenced participant responses during this study. This study is also limited in terms of the extent to which observed effects can be specifically attributed to responses to the COVID-19 pandemic. We did not collect data using the same sample of participants prior to the pandemic, and we are thus not able to rule out the possibility that many of the current results would be similar during a non-pandemic period of time. As a proxy of psychological impact, we compared the psychological health responses during the pandemic to two independent samples (MIDJA/MIDUS). The sampling and data collection methods were different between the MIDJA/MIDUS projects (in person or phone) and the present study (online) and the MIDJA II was conducted in 2004–5, whereas the MIDUS II was conducted in 2012. There exist many relevant social and economic factors that are different between 2005, 2012 and 2020. Combined we suggest that the current findings be considered with a reasonable amount of caution.
In spite of several limitations, this study advances the way the link between worldviews on nature and psychological health is understood. We found that viewing humans and nature as interconnected and harmonious is positively associated with psychological health during a natural disaster and that the link between viewing humans as masters over nature and experiencing of NA during a natural disaster differs according to cultural context.
BWH designed the study, analyzed data and wrought the paper. FH and KO collected data and contributed to the writing of the paper.",Pers Individ Dif
PMC7723399,"The impact of social distancing during COVID-19: A conditional process model of negative emotions, alienation, affective disorders, and post-traumatic stress disorder","Undoubtedly, the outbreak of COVID-19, first reported in Wuhan, Hubei, China (Huang et al., 2020), is an unexpected disaster. Owing to the highly infectious nature of the coronavirus, over nine million confirmed cases have been reported globally (World Health Organization, 2020). Notably, the results of quick surveys after the outbreak of COVID-19 have revealed that people are vulnerable to mental problems associated with the pandemic, such as negative emotions, anxiety and depression symptoms, and post-traumatic stress symptoms (Kang et al., 2020; Vindegaard & Eriksen Benros, 2020). Besides, almost every country around the world has implemented a social distancing policy to reduce the spread of the virus. However, this measure undermines our social activities and relationships. and thus its impact on people's psychological health cannot be ignored (Loades et al., 2020). Due to limited knowledge of the underlying mechanism of its impact, our study attempts to explore the mental problems related to this measure in COVID-19 and what the role it plays.
Negative emotions commonly appear among people in a crisis. When encountering desperate situations, individuals tend to lose the internal balance between the environment and themselves, being referred to as a process of emotional stress. Emotional stress encompasses the experience of negative emotions, including fear, anger, and hopelessness, which are likely to result from stressors that are beyond an individual's control, for example, a novel virus (Dohrenwend, 2000). Research has repeatedly demonstrated the link between emotional stress and the development of mental disorders (Folkman, 2013), among which post-traumatic stress disorder (PTSD) is a prominent one after a crisis. PTSD is defined as persistent disturbances and symptoms after experiencing or witnessing a life-threatening event like a pandemic. The typical symptoms include hyperarousal, re-experiencing of events, avoiding (American Psychiatric Association, 2013; Xu et al., 2011). Empirical research has found negative emotions to be significantly related to the severity of PTSD symptoms (Dutheil et al., 2020; McLean & Foa, 2017). Theoretically, the cognitive model of PTSD has proposed individuals’ appraisal of trauma leads to negative emotions which further contribute to persistent symptoms of PTSD. For example, negative emotions may mislead one to appraisal the event in an emotional way and reinforce the emotional memory of trauma (Deprince, Zurbriggen, Chu, & Smart, 2010; Ehlers & Clarks, 2000).
To explore the underlying mechanisms of emotionally traumatic-related consequences, the feeling of alienation also worth more attention in a social distancing situation. As John T. Cacioppo, the past president of the Association for Psychological Science (APS) asserted, “By nature, we are social creatures”, when individuals are forced to self-isolate, a feeling of alienation is consequently aroused (Cacioppo & Patrick, 2008). Alienation is defined as a loss of connection with oneself and others and the incidental negative feelings, typically exhibited as the feelings of loneliness, uncontrollability, hopelessness, and so forth. (DePrince, Chu, & Pineda, 2011; Yang, Zhang & Huang, 2002). It is found that alienation is significantly associated with physical and psychological symptoms, as well as problematic behaviors (i.e. alcohol use and delinquency) among adolescents (Rayce et al., 2009; Walsh et al, 2019). And a meta-analysis on the alienation's correlates indicated that alienation influences one's attitudes and health symptoms (Chiaburu et al., 2014).
In addition, it is revealed that alienation is highly predictive of poor mental health and diverse trauma-related distress (Sprang & Silman, 2013), and alienation appraisal is the most related predictor of trauma-related distress among the most common categories of appraisals (Mitchell et al., 2020). Furthermore, prior studies have identified alienation appraisal as a critical predictor of the severity of PTSD in children as well as females (Hebenstreit, Maguen, Koo, & DePrince, 2015; Srinivas, DePrince, & Chu, 2015). A meta-analysis also found a large effect size of alienation appraisal on PTSD symptoms in adults (McIlveen et al., 2020), providing another empirical evidence for the relationship between these two variables. Individuals with a high level of alienation from others are more likely to lose the opportunity to reappraisal the trauma experience, impeding the effectiveness of exposure therapy for PTSD. This phenomenon may be a consequence of the lack of the beneficial effects of social support, in that they negatively interpret others’ words or behaviors (Baumeister & Leary, 1995; Cohen, 2004; Ehlers et al., 1998). As such, we consider alienation as a key factor that mediates the relation between negative emotion and PTSD.
While negative emotions and alienation has been identified to be positively associated with PTSD symptoms, moderating factors of this association remain unclear. Depression and anxiety, which have been diagnosed repeatedly, are prevalent disorders among the public (Kessler, Chiu, Demler, & Walters, 2005; Steel et al., 2014) and frequently coexist with PTSD in patients (Brady et al., 2000; Holman, Silver, & Waitzkin, 2000; Möller et al., 2016). Armour et al. (2014) found that higher levels of anxiety and depression were observed among patients with PTSD, and it is inferred that depression and anxiety could increase the risk of developing PTSD (Brady et al., 2000). Without sufficient evidence to confirm the inference, a more in-depth examination is warranted.
Individuals with depression or anxiety may have cognitive biases compared to mentally healthy people. For example, feeling uncertain about loss tends to be associated with anxiety, while being sure of loss is linked to depression (Ehlers & Clark, 2000), which potentially influence the effect of negative emotions and alienation. Specifically, people with a high level of depression have been quite likely to suffer from negative emotions, feelings of loneliness, worthlessness, and hopelessness (American Psychiatric Association, 2013; Deprince et al., 2010; Rosenström & Jokela, 2017), which may aggravate the feeling of alienation. Depression is also characterized by social avoidance, rumination, and these outcomes will further make one indulge in negative thinking and undermine social support, enhancing the maintenance of PTSD (Ebert & Dyck, 2004; Fernández-Theoduloz et al., 2019; Berman et al., 2011; Spinhoven et al., 2015; Pugach et al., 2020). Moreover, neuropsychological research leaves controversy over whether depression would make individuals play down the cues of social exclusion to alleviate their grief (Hooley et al., 2009), or more vulnerable (Jobst et al., 2015). It is plausible to posit a similar controversy about the feeling of alienation since it often appears after social exclusion (Ren et al., 2018).
As for those anxious individuals, they incline to expect some possible outcomes as negative and endlessly worry about the uncertain future (Craske et al., 2009; Gu et al., 2010). Therefore, in the COVID-19 context, current negative emotion and alienation can pose a more severe and long-lasting impact on them because of people's irrationally worry. On the contrary, the fever model of self-disclosure proposed that individuals with a higher level of anxiety tend to disclose more, which is helpful to release psychological distress (Stiles et al., 1992). So, probably, anxious people could alleviate the burden of negative emotion and feeling of alienation via more self-disclosure. Taken together, the exact moderating effects of depression and anxiety are not yet determined.
In summary, one may deduce that there is an inferior understanding of the impact of negative emotions on PTSD interfering with alienation. Moreover, how affective disorders, namely, anxiety and depression, alter this process is also unclear. Consequently, it is imperative to understand the possible relationships between negative emotions and potential mental illnesses among the general public in the context of the COVID-19 pandemic to advance scientific knowledge and effective psychological assistance.
We hypothesized that while negative emotions predicted more severe PTSD symptoms, alienation played a mediating role in this process. Moreover, anxiety and depression disorders were hypothesized to moderate the direct and indirect effects of negative emotions and alienation on PTSD.
Stratified random sampling was employed to select 7,145 participants from among the residents of Wanzhou District in Chongqing city, where, in comparison to the other areas in Chongqing, most of the infectious cases had been reported. However, 479 participants’ data were omitted, because they had taken less than five minutes to complete all the questions. Finally, 6,666 pieces of data were used in the statistical analysis. The participants comprised 4,718 males (70.8%) and 1,948 females (29.2%), most between 35- and 50, years of age, and 96.3% have completed high school or higher education. This study was conducted in accordance with the Declaration of Helsinki and the protocol was approved by the review board of the Faculty of Psychology of Southwest University (H20032). Participation in the study was entirely voluntary, with explicit permission of the participants obtained through online consent for the confidential use and processing of data.
The negative emotions questionnaire is a self-reported 7-point Likert scale designed to investigate people's emotional state. In accordance with published reports, six words that describe individuals’ most prevalent emotions were selected: anxious, depressive, sad, helpless, angry, and fearful. The participants were required to rate the extent to which they experienced each of these emotions. The scores of the six items were summed. Higher total scores were indicative of a poor emotional state. Cronbach's α for this questionnaire in the current study was 0.923.
SCL-90 was designed to assess psychological symptoms to evaluate the outcomes of mental health interventions as well as for research purposes. The symptoms are assessed about the previous seven days and are classified into nine dimensions, including anxiety and depression, with scores indicating the severity of symptoms. Cronbach's α values between 0.77 and 0.90 for its dimensions indicated adequate internal reliability (Folkman, 2013). The participants completed two subscales of SCL-90 to measure the level and prevalence rates of anxiety (10 items) and depression (13 items). Cronbach's α values for anxiety and depression were 0.91 and 0.925, respectively.
PCL-C is a 17-item self-report rating-scale instrument corresponding to the diagnostic criteria for PTSD of the fourth edition of the Diagnostic and Statistical Manual of Mental Disorders (DSM-4), which is designed for civilian-populations use. Higher scores indicate higher PTSD levels, with scores of 30–35 considered probable PTSD among non-clinical populations (National Center for PTSD, 2019; Walker, Newman, Dobie, Ciechanowski, & Katon, 2002). This scale demonstrated good internal and test-retest reliability in a Chinese sample (Jin, Xu, Liu, & Liu, 2014). In the current study, Cronbach's α was 0.915.
This scale was originally developed in the Chinese version to examine the feeling of alienation in Chinese people, especially adolescents. It comprises 52 items in four dimensions that are rated on a 5-point Likert- scale, ranging from 1 (totally disagree) to 7 (totally agree). The ASAS possesses good validity and reliability as confirmed by studies in China. In the current study, this scale was modified to fit the conditions of adults during COVID-19. Moreover, Cronbach's α was 0.957.
All the data were collected anonymously between February 25 and March 3, 2020, one of the worst periods of the outbreak, via an online survey research platform powered by www.wjx.cn. First, the participants were required to fill in demographic information. Subsequently, they completed the survey in the following order: negative emotions questionnaire; SCL-90 Anxiety and Depression; PCL-C; and ASAS. Data analyses were performed by employing SPSS with PROCESS macro (Hayes & Rockwood, 2020), as there is a significant advantage of PROCESS is that two or more mediators in the moderated- mediation model can be tested simultaneously. We examined the common method bias by using Harman's one-factor test (Podsakoff, MacKenzie, Lee, & Podsakoff, 2003). No significant common method bias in our dataset was found.
The descriptive statistics of key variables are represented in Table 1
. The demographic variables were tested using t-tests and one-way ANOVAs to assess the differences in means between groups. Significant gender and age differences were found only in the negative emotions (tGender = −3.127, p = .002; FAge = 3.317, p = .036) and PTSD scores (tGender = −2.569, p = .010; FAge = 9.556, p < .001). However, the negative emotions, PTSD, anxiety, and depression scores were all significantly different at the various levels of education (FNegEmo = 11.080, p < .001; FPTSD = 5.866, p = .001; FAnx = 14.581, p < .001; FDep = 16.148, p < .001). Given the significant differences, these variables were controlled for subsequent mediation and moderation analysis models.
The results of Pearson's correlations are also displayed in Table 1. As expected, all the included variables were positively and significantly correlated with one another.
Due to the high correlation between the variables of interest, we conducted a collinearity test. According to the strict criteria, the results showed that there is a risk of collinearity problem, most serious in the variables related to depression. We also used Lasso regression to estimate the model (McNeish, 2015). The results strongly suggested that the interaction terms of negative emotions with depression and the interaction terms of alienation with depression should be excluded from the model, but depression itself was a quite predictive variable (see. Supplementary material). Considering the high correlation of depression with other variables and its significant effect on PTSD, we set it as a control variable in further analyses (Allison, 2010). The new theoretical hypothesis model is depicted in Fig. 1
.
Mediation analyses were performed with gender, age, education, and depression as the control variables. The results are presented in Table 2
. First, negative emotions predicted the severity of PTSD symptoms significantly (Model 1 in Table 2). When the mediating predictor, alienation, was added, the direct effect of negative emotions on PTSD remained significant (Model 3 in Table 2). About the indirect effect, negative emotions significantly predicted alienation, and subsequently, alienation significantly predicted PTSD (Models 2 and 3 in Table 2). Furthermore, the Bootstrapping indicated that alienation significantly mediated the effect of negative emotions on PTSD (ab = 0.038, SE = 0.004, Boot 95% CI = [0.032, 0.047]), and the indirect effect via alienation accounted for 24.36% of the total effect.
Thereafter, we performed moderated mediation analyses by controlling the demographic variables and depression noted previously. The results demonstrated that the effect of negative emotions on PTSD was significantly moderated by anxiety (X*Z: B = −0.038, p < 0.0001). Particularly, the mediation of alienation was significantly moderated by anxiety (M*Z: B = 0.085, p < 0.0001) (Table 3
).
Furthermore, the simple slope plot corresponding to the conditional indirect effect analysis revealed the interactions in a more specific way (Fig. 2
). Higher levels of anxiety predicted more severe PTSD symptoms. However, while anxiety enhanced the effect of alienation, it weakened the effect of negative emotions. (Table 4
).
Given the current global concern regarding the COVID-19 pandemic, it is exigent to research the prevalence and risk factors of potential mental health problems to address the intervention and governance thereof under emergent conditions. While our study was conducted during a severe period of the COVID-19 spread, it is a little relief that most people did not exhibit severe symptoms of mental disorders. And there are some differences in demographic variables, concurred with other studies on trauma-related mental crises (Liu et al., 2020; Tang et al., 2020; Tian et al., 2020).
The current study revealed a significant mediation of alienation in the development of PTSD symptoms in adults, which concurred with results identified in adolescents (Srinivas et al., 2015). This relation is reasonable in the light of the connotation of alienation and the characteristics of PTSD. It has been alleged that the construction of alienation contains aspects including a sense of meaninglessness, powerlessness, social isolation, and self-alienation (Seeman, 1959), which are all closely related to symptoms associated with PTSD, such as estrangement from others and social withdrawal (Ehlers et al., 1998). In addition, the sense of alienation usually originates from the objective absence of social support, the buffering effect of distress (Woodward et al., 2015), which could erode the psychological resistance of an individual faced with such a crisis. It is also shown that higher levels of anxiety exacerbate the mediating effect of alienation. For individuals with high levels of anxiety, from a physiological and cognitive perspective, their hyperarousal symptoms may be interpreted as an explicitly negative signal that there is something wrong (Mineka & Zinbarg, 2006; Maloney, Sattizahn, & Beilock, 2014), and they are prone to hold pessimistic expectations about uncertain events (Grupe & Nitschke, 2013). Therefore, they could view the feeling of alienation as more disastrous.
Besides the insight into alienation, a significant effect of negative emotions on PTSD was found in our study. Emotions permit individuals to construct a memory of certain events with value, named emotional memory. Such a form of memory is more vivid and could be more easily retrieved, which however increases the risk of PTSD, especially the flashback symptoms (Dolan, 2002). Accordingly, negative emotions can be regarded as a “prodrome” (a prior manifestation before the onset of disorders) of PTSD (Jacobson & Newman, 2017; Pérez-Edgar & Guyer, 2014). If we could alleviate people's negative emotions in the early stages of a crisis, then there is a chance to prevent them from more severe mental disorders. As for the moderated direct effect of negative emotions, it was weakened to non-significant at a high level of anxiety. One possible explanation is that there exist other factors more readily inducing PTSD than negative emotions, such as alienation based on our result. Another is that anxiety itself has a strong effect on PTSD, which covers the minor effect of negative emotion. These may imply that the original negative emotions are not serious enough to directly cause symptoms of PTSD but through further appraisal or some affective disorders.
With regard to the perspective of practice, firstly, the findings of the present study suggest that it is imperative to assess the feelings of alienation when conducting an intervention with a post-trauma client. Secondly, psychotherapists could adopt an alternative approach to protect individuals from traumatic experiences by reducing their sense of alienation by restructuring their cognition. Besides, it is significant to screen for mental symptoms in the public for the management of mental health during a pandemic. Once mild or moderate manifestations of affective disorders are detected, timely psychological counseling or mental health first aid is necessary to decrease the risk of PTSD. Moreover, attention should be particularly paid to those individuals’ later mental condition, because they are at higher risk of PTSD. The implementation of this notion could be advanced through the use of digital technology, which may be beneficial in maintaining interpersonal and social connections as well as providing information, training, supervision, and support online (Kola, 2020). Exploration of more specific ways of applications is recommended.
The contributions of the current research cannot be considered without reflecting on its several limitations. First, the generalizability of these results may be limited in that the sample comprised non-clinical individuals residing in Wanzhou, Chongqing. Thus, the entire public or groups in which PTSD symptoms are more prevalent were not represented. Thus, future research needs to examine other communities to exclude the potential influence of compound factors. Second, usually mental disorders gradually develop from mild psychological distress, whereas this cross-sectional study could not measure the alterations in alienation and PTSD symptoms over time. Consequently, a causation relationship between variables cannot be determined. Besides, it not sure whether the symptoms are merely induced by the social distancing in COVID-19 or by other events, thus limiting the theoretical and directional conclusions that can be drawn from the research. Third, because the participants were in quarantine, self-report scales were employed to collect the data. Consequently, a single source bias, which is the deviation caused by the common method variance, may have occurred. Even though the test of the common method bias is acceptable, it may still undermine the power of the results. Additionally, albeit the high correlation between variables, particularly depression, anxiety, and PTSD, can be attributed to their high rate of comorbidity and theoretical overlap, it caused a problem of collinearity. Because of this problem, unfortunately, we failed to examine the moderating effect of depression. However, it is not yet sure whether these characteristics of depression can reduce individuals’ sensitivity to newly developed negative emotions and alienation or exaggerate their effects. Examination of this question is intriguing and requires further research using measurements that better distinguish variables. Finally, other influential factors of people's mental health leave to be uncovered by future studies, which will benefit therapeutic practice.
Confronted with the global spread of COVID-19, it is essential to attend to the mental health of individuals. Social distancing is likely to result in more feelings of alienation (Pancani et al., 2020), which may play a role in the development of mental problems in the public. To offer an enhanced explanation of the situation and explore feasible treatments, this study examined the relationship between negative emotions and PTSD, wherein the mediation effect of alienation, as well as the moderation effects of anxiety, were particularly considered. The results of statistical analyses indicated that: First, negative emotions and alienation are both predictors for PTSD symptoms; second, their direct and indirect effects are moderated by levels of anxiety. The findings of this study are beneficial for both academic and practical purposes, considering the limitation of such rapid empirical research. Based on our confirmed theoretical model, suggestions for the implementation of health care are proposed, which helps to improve our practice in the future.
Conceptualization, Yue Zhu and Dong Yang; methodology, Yue Zhu. and Dong Yang; formal analysis, Yue Zhu; investigation, Dong Yang, Yue Zhu, Lihua Zhang, Xia Zhou and Chenxiang Li; resources, Dong Yang; data curation, Yue Zhu; writing original draft preparation, Yue Zhu; visualization, Yue Zhu; supervision, Dong Yang; project administration, Dong Yang; funding acquisition, Dong Yang and Yue Zhu. All authors have read and agreed to the published version of the manuscript.
The datasets used and/or analyzed during the current study are available from the corresponding author on request.
This work was supported by the Fundamental Research Funds for the Central Universities (Dong Yang, grant number SWU2009101), Chongqing Planed Social Science Research Program (Dong Yang, grant number 2020TBWT-ZD07), and Chongqing Research Fund for graduates (Yue Zhu, grant number CYS20093).
(Connection, Critical Illness, 2020, Dong et al., 2002, Gómez de La Cuesta et al., 2019, Hänninen and Valkonen, 2019, Kato et al., 2020, Rauch et al., 2010, Reynolds et al., 2008, Wu et al., 2005, Chong et al., 2004)
All other authors declare that they have no conflicts of interest.",J Affect Disord
PMC7539826,COVID-19-related stress and anxiety are associated with negative body image in adults from the United Kingdom,"The novel coronavirus (COVID-19) pandemic presents a serious threat to physical health in populations worldwide. To limit the spread of COVID-19, many nations introduced mandatory lockdown or social-distancing measures; in the United Kingdom, these included only leaving the home for food, health reasons, and work if individuals were unable to work from home. While such prevention measures can be effective against disease transmission (e.g., Tian et al., 2020), the impact of social-distancing and lockdown – including attendant changes to everyday behaviour and functioning – can have adverse impacts on psychological health (e.g., Galea et al., 2020). Indeed, emerging evidence from the United Kingdom indicates that levels of anxiety and stress are elevated compared to pre-pandemic levels (Shevlin, McBride, et al., 2020), which is consistent with evidence from other nations (e.g., Tull et al., 2020).
Notably, increased anxiety and stress caused by the pandemic, as well efforts to reduce its spread, may have adverse effects on other aspects of mental health (Reger et al., 2020), such as eating disorder symptomatology (Touyz et al., 2020). It is also possible that the pandemic presents a threat to body image (Cooper et al., 2020), although this has not been investigated to date. Certainly, some pre-pandemic research – mostly with samples of undergraduate women – has shown that perceived stress (i.e., a person's appraisal of stress caused by environmental conditions) and stressful life events were associated with greater body dissatisfaction (e.g., Haddad et al., 2019; Johnson & Wardle, 2005; Murray et al., 2011). Likewise, trait anxiety (i.e., a differential trait reflective of a tendency to worry) has been found to be significantly associated with body dissatisfaction, independently of perceived stress, in women (e.g., Davey & Chapman, 2009) and men (Barnes et al., 2020).
In view of the aforementioned findings, it is important to investigate the extent to which COVID-19-related stress and anxiety specifically are associated with body image outcomes. As intimated by some scholars (e.g., Cooper et al., 2020; Rodgers et al., 2020), the stress and anxiety triggered by the COVID-19 pandemic may present unique threats to body image, possibly because of changes to daily routines (e.g., exercise, eating, and sleep patterns) that impede adaptive body image coping mechanisms and amplify maladaptive coping, heightened concerns about weight and/or shape changes, and greater frequency of negative body ruminations. The absence of empirical data on these issues, however, is an impediment to both ongoing theorising and health policy considerations in the face of the pandemic.
In the present study, therefore, we examined associations between stress, anxiety, and negative (attitudinal) body image in a sample of adults from the United Kingdom. More specifically, we allowed for the possibility of gendered differences in outcomes and examined the extent to which COVID-19-related stress and anxiety are associated with gender-specific body image outcomes (i.e., body dissatisfaction and drive for thinness in women, body fat dissatisfaction and muscularity dissatisfaction in men). Additionally, to account for the unique effects of COVID-19-related constructs, we considered the extent to which COVID-19-related anxiety and stress would be associated with body image outcomes over-and-above generalised stress and anxiety. We hypothesised that greater COVID-19-related stress and anxiety would be associated with greater negative body image, after accounting for the effects of demographics (age and body mass index) and perceived stress, stressful life events, and trait anxiety.
Participants were an online sample drawn from the United Kingdom adult population (N = 506). Of the sample, 255 identified as women and 251 as men. Participants ranged in age from 18 to 73 years (M = 34.25, SD = 11.36) and in self-reported body mass index (BMI) from 15.43 to 47.25 kg/m2 (M = 26.35, SD = 5.88). The majority of participants self-reported their sexual orientation as heterosexual (89.1%) and their ethnicity as White (88.5%). In terms of relationship status, 27.9% were single, 38.2% were partnered but not married, 32.0% were married, and the remainder had some other status. In terms of education, 10.9% had completed the General Certificate of Secondary Education (GCSEs), 27.9% had an Advanced-Level qualification, 38.3% had an undergraduate degree, 19.0% had a postgraduate degree, and the remainder had some other qualification.
Participants completed the 10-item Perceived Stress Scale (PSS; Cohen et al., 1983), which measures an individual's subjective appraisal of the degree to which situations in their life are stressful over the preceding month.1
All items were rated on a 5-point scale ranging from 0 (never) to 4 (very often) and an overall score was computed as the mean of all items (higher scores reflect greater perceived stress). Scores on the PSS have adequate factorial and construct validity, and good test-retest reliability in diverse populations (Lee, 2012). Here, McDonald's ω for PSS scores was .88 (95% CI = .86, .89).
The List of Threatening Experiences Questionnaire (LTE-Q; Brugha, Bebbington, Tennant, & Hurry, 1985) was used to assess the incidence of stressful life events. The scale consists of 12 items with dichotomous responses (0 = no, 1 = yes) about the occurrence of 12 prevalent major stressful events that may have occurred in the preceding month. A total score was computed as the sum of all affirmative responses, with higher scores reflecting the occurrence of more stressful life events. Scores on the LTE-Q have been shown to have adequate factorial and construct validity (Brugha et al., 1985). In the present study, McDonald's ω for scores on the LTE-Q was .75 (95% CI = .71, .78).
To measure trait anxiety, we used Form Y-2 of the STAI (Spielberger et al., 1983), which measures a differential trait reflective of a tendency to worry. The scale consists of 20 items that were rated on a 4-point scale, ranging from 1 (almost never) to 4 (almost always). An overall score was computed as the mean of all items (higher scores reflect greater trait anxiety). This form of the STAI has been shown to have adequate factorial and construct validity (Spielberger et al., 1983). Here, McDonald's ω for STAI scores was .94 (95% CI = .93, .95).
Because the PSS does not specifically assess COVID-19-related stress, we also asked participants to complete a novel 5-item measure. The items asked participants how stressed they felt about the impact of the COVID-19 pandemic on their daily lives, their personal relationships, their work and/or studies, their finances, and their future in general. Items were rated on a 7-point scale (1 = not at all stressed, 7 = extremely stressed). An exploratory factor analysis with a promax rotation indicated that all items loaded onto a single dimension (eigenvalue = 2.96, 59.7% of variance explained), with all items loading at .68 or greater. We, therefore, computed an overall score as the mean of all five items. Although this measure has not been used previously, evidence of construct validity was established in the present study through significant associations with all other included measures (see Table 1
). McDonald's ω for scores on this measure was .82 (95% CI = .80, .85).
To measure anxiety caused by the COVID-19 pandemic specifically, participants were asked to respond to a novel 1-item measure (“How anxious are you about the coronavirus [COVID-19] pandemic?”) on a 7-point scale (1 = Not anxious at all, 7 = Extremely anxious). This measure has been used previously and scores have been shown to have adequate construct and predictive validity (Shevlin, Nolan, et al., 2020).
Women were asked to complete the Body Dissatisfaction subscale (EDI-3-BD; 10 items) and the Drive for Thinness subscale (EDI-3-DT; 7 items) of the Eating Disorder Inventory-3 (Garner, 2004), both of which capture attitudinal dimensions of negative body image relevant to women. The EDI-3-BD measures general dissatisfaction with one's overall shape and size of key body areas, whereas the EDI-3-DT measures an extreme desire to be thin, concern with dieting, and preoccupation with weight. All items were rated on a 6-point scale ranging from 0 (never) to 6 (always), with higher mean scores reflecting greater body dissatisfaction or drive for thinness. Garner (2004) reported that the EDI-3 was suitable for use with non-clinical populations and that scores had adequate construct and factorial validity. Here, McDonald's ω for EDI-3-BD scores was .89 (95% CI = .87, .91) and for EDI-3-DT scores was .93 (95% CI = .91, .95).
Men were asked to complete two subscales from the 24-item Male Body Attitude Scale (MBAS; Tylka et al., 2005): the Low Body Fat subscale (12 items) and the Muscularity subscale (10 items). The MBAS includes a third dimension reflective of height dissatisfaction, but this factor has been theoretically problematised (Ryan et al., 2011) and so was not included here. Items were rated on a 6-point scale ranging from 1 (never) to 6 (always). Mean subscale scores were computed so that higher scores reflect greater body dissatisfaction. Scores on the MBAS have been shown to have adequate factorial and construct validity, and good test-retest reliability (Tylka et al., 2005). In the present study, McDonald's ω for Low Body Fat scores was .93 (95% CI = .92, .93) and for Muscularity scores was .91 (95% CI = .90, .93).
We requested demographic information consisting of age, gender identity, ethnicity, sexual orientation, highest educational qualification, and relationship status. We also asked participants to self-report their height and weight, and used these data to compute BMI as kg/m2.
Once the project was approved by the School ethics committee at [blinded for review], data were collected via the Prolific website on May 21, 2020. The project was advertised as a study on “social-distancing and body image” and included an estimated duration. Inclusion criteria included being a resident and citizen of the United Kingdom, being of adult age, and being fluent in English. Prolific ID codes and IP addresses were checked to ensure that no participant completed the survey more than once. After providing digital informed consent, participants were directed to the scales described above, which were presented in a counter-balanced order in Qualtrics™. An attention check item (“Select the third answer option if you're reading this”) was embedded halfway through the survey and was passed by all participants. Demographic items were completed first to split participants into their respective body image questionnaires. The questionnaire was anonymous and participants were paid £0.84. All participants received debriefing information.
Thirty-nine participants had missing height and/or weight data or had improbable BMI values (<12 or >50 kg/m2), so these were replaced using multiple imputations. Missing values in the remainder of the dataset were infrequent (<0.5% of the total dataset) and were replaced using multiple imputations. Descriptive statistics, gender differences, and inter-scale correlations between all variables included in the present study are reported in Table 1. As can be seen, the only significant gender difference was found for COVID-19-related stress, but because negative body image variables were gender-specific, further analyses were computed for women and men separately.
To test the study hypotheses, we computed hierarchical regressions with the body image variables (body dissatisfaction and drive for thinness in women, low body fat and muscularity in men) as criterion variables. Age and BMI were entered in a first step; perceived stress, stressful life events, and trait anxiety were entered in a second step; and COVID-19-related stress and anxiety were entered in a third step. This allowed us to examine the extent to which COVID-19-related stress and anxiety incrementally predicted body image variables once the variance associated with the additional variables had been accounted for. All parametric assumptions for multiple regression were met and multicollinearity was not a limiting factor in any of the regressions (all variance inflation factors < 1.24, with values < 10 indicative of inconsequential collinearity; Hair et al., 1995).
For women, the final step of the regression with body dissatisfaction was significant: COVID-19-related anxiety but not stress was significantly associated with body dissatisfaction (ΔF p = .045, Adj. ΔR
2 = .02; see Table 2
). The final step of the regression with drive for thinness was also significant, with both COVID-related anxiety and stress significantly associated with drive for thinness (ΔF p < .001, Adj. ΔR
2 = .07; see Table 2). In men, the final step of the regression with low body fat was significant, with COVID-related anxiety but not stress significantly associated with greater dissatisfaction (ΔF p = .38, Adj. ΔR
2 = .02; see Table 3
). The final step of the regression with muscularity was also significant: both COVID-related stress and anxiety were significantly associated with greater dissatisfaction (ΔF p < .001, Adj. ΔR
2 = .10; see Table 3).
The results of the present study confirm that COVID-19-related stress and anxiety are associated with more negative body image, over-and-above the variance explained by perceived stress, stressful life events, and trait anxiety, which is consistent with earlier scholarly commentary (Cooper et al., 2020; Rodgers et al., 2020). Although our data cannot speak to mechanistic pathways, it is possible that COVID-19-related stress and anxiety diminish coping resources to manage threats to body image, increase exposure to thin/athletic ideals via media messaging (e.g., given increased screen-time under lockdown; see Pietrobelli et al., 2020), and heighten concerns about weight and/or shape changes that occur during conditions of lockdown (e.g., because of decreased physical activity) (Cooper et al., 2020; Rodgers et al., 2020). COVID-19-related stress may also be associated with greater frequency of negative body ruminations that lead to a preoccupation with body shape and/or weight and desire to reassert a degree of control through body work (Ruggiero et al., 2008).
In women, greater COVID-19-related anxiety (but not stress) was significantly associated with body dissatisfaction, whereas both COVID-19 anxiety and stress were associated with greater drive for thinness. It is possible that these findings are reflective of women's lived experiences under conditions of lockdown. Anxiety-inducing fear-mongering over weight-gain due to changes to routine during lockdown (e.g., poorer diets, less frequent exercise), greater pressure to conform to traditionally feminine roles and norms, and messaging about self-improvement may lead women to feel dissatisfied with their bodies, but more importantly to increase restriction and weight control ruminations that are central to drive for thinness. To the extent that women act on such ruminations (e.g., by increasing unhealthy weight control behaviours to reduce the risk of weight gain), it may function to regulate the anxiety, stress and uncertainty associated with the COVID-19 pandemic (e.g., see Brown et al., 2017).
In men, COVID-19-related anxiety (but not stress) was associated with body fat dissatisfaction, whereas both COVID-19-related anxiety and stress were associated with greater muscularity dissatisfaction. It may be that these findings reflect the way in which stress and anxiety impact men's relationships with their bodies, particularly in terms of masculine body ideals (e.g., Swami & Tovée, 2005). Specifically, given that hegemonic masculinity emphasises the value of toughness, self-reliance, and the pursuit of status, COVID-19-related stress and anxiety may lead men to place greater value on the importance of being muscular (for discussions, see Frederick et al., 2017; Griffiths et al., 2015). Moreover, because conditions of lockdown may limit men's ability to derive masculine capital through everyday masculine activities (e.g., sport, strength-training in gyms), they may instead seek to reassert feelings of control and increase masculine capital through a desire for greater muscularity and ruminations about perceived body size (see Edwards et al., 2017).
The main limitation of the present study is that we were only able to document direct associations between COVID-19-related stress and anxiety, respectively, and body image. It would be useful for future work to examine mechanistic pathways, including via weight gain, change in behaviours under conditions of lockdown (e.g., increase in sedentary behaviours, eating patterns), and psychological constructs such as loneliness. Doing so may also help to explain why COVID-19-related stress was not significantly associated with some outcomes in our regression. In addition, we operationalised generalised stress and anxiety using a limited range of constructs, although associations between perceived stress and trait anxiety, respectively, and body image were in line with previous reports. Likewise, we constructed novel instruments to measure COVID-19-related stress and anxiety, and although we have no reason to believe that these measures lack construct validity, this should be assessed more thoroughly in future work. It should be noted that our results may have limited generalisability, given our recruitment methods and the specificity of lockdown conditions in the United Kingdom.
These limitations notwithstanding, our results suggest that the COVID-19 pandemic may have important consequences for body image in women and men. The present findings are particularly important because they suggest that the stress and anxiety related to the COVID-19 pandemic specifically, as opposed to generalised stress and anxiety, significantly contribute to body image outcomes. To the extent that negative body image is a prognostic risk factor for the onset and maintenance of eating pathology (e.g., Stice & Shaw, 2002), our findings also highlight possible additional complications that may stem from COVID-19-related stress and anxiety. In turn, efforts to deal with negative body image under conditions of lockdown will require novel mitigation interventions (e.g., telehealth, guided self-help interventions; Cooper et al., 2020).

Viren Swami: Conceptualization, Methodology, Formal analysis, Data curation, Writing - original draft, Writing - review & editing, Project administration. George Horne: Investigation, Writing - review & editing. Adrian Furnham: Investigation, Resources, Writing - review & editing, Supervision.",Pers Individ Dif
PMC7765765,"Excited-state electronic properties, structural studies, noncovalent interactions, and inhibition of the novel severe acute respiratory syndrome coronavirus 2 proteins in Ripretinib by first-principle simulations","Gastrointestinal (GI) stromal tumors (GIST) are rare cancers that are associated with the possible metastatic invasion of other body parts, such as lungs, bones, and bone marrow [1]. They are due to the aberrant signaling of the proto-oncogene c-KIT [2,3]. GIST originates from cells that are known as the interstitial cells inside the wall of the GI tract. The interstitial cells are referred to as the GI tract “pacemaker cells” because they are the muscles that contract to push food and liquid along the GI tract. Imatinib, a cancer growth inhibitor called a tyrosine kinase inhibitor, along with the surgical removal of tumors is a gold standard treatment procedure for GIST [4]. Mahadevan demonstrated the resistance to imatinib while applying it to the treatment of cancer and proposed a TK switch to explain the drug resistance [4]. Ripretinib, another kinase inhibitor for treating advanced GIST, was recently developed as an efficient drug to inhibit the entire mutant KIT and PDGFRA kinases that are present in cancers and myeloproliferative neoplasms especially in drug-resistant cases [5]. Employing the structural drug design approach, Flynn and coworkers developed an inhibitor that could bind to the key amino acid residues via the KIT switching mechanism, and it was approved by FDA [6,7] and followed by intense clinical trials [8,9].
Severe acute respiratory syndrome (SARS), which is due to the novel coronavirus 2 (n-CoV-2) (SARS-n-CoV-2) has now emerged to the level of a pandemic that has impacted the lifestyle and health of most people globally [10]. Scientists worldwide are tirelessly working to establish the pathology [11] and epidemiology [11] to develop drugs and vaccines [12]. Chloroquine has been highlighted as a wonder drug for managing the coronavirus disease (COVID) despite the existing differences in opinions [13]. Remdesivir is now presently utilized widely to treat COVID-associated pneumonia [14]. The lopinavir, umifenovir, favipiravir, and oseltamivir molecules are also being studied as potentially active drugs against the virus [15]. Moreover, we have already reported that melatonin is active against this deadly virus [16] along with tucatinib [17] and selpercatinib [18]. Owing to the extensive time that is required to design and develop a drug to treat the virus, it is reasonable to reroute the existing drugs as molecular targets against the virus. Therefore, we considered rimegepant as a potential candidate in this study.
Here, we studied the structural and electronic features of the drug molecule, ripretinib. We employed the density-functional theory (DFT) to study its geometry and electronic and reactivity descriptors. Further, we evaluated the intramolecular electron delocalizations, noncovalent interactions (NCIs), and average local ionization energy indices of the molecule. The most beneficial finding of the study is the potential reuse of the drug as a supplement for the management of SARS-n-CoV-19. The molecular docking of the compound was performed with three known COVID proteins.
The antitumor drug, ripretinib, was optimized by the Gaussian-09 [19] software employing DFT [20] with B3LYP functional [[21], [22], [23]] and a 6-311G + (2 d,p) [24] basis set. We calculated the frequency to ensure that there was no imaginary frequency, thus ensuring that the obtained geometry corresponds to a global minimum for obtaining an optimized geometry. We employed the same geometry to calculate the frontier molecular orbital (FMO), the natural bonding orbitals (NBOs) and to generate the wave function files (.wfn files). To simulate the ultraviolet–visible (UV–Vis) spectrum, we employed the time-dependent DFT (TD-DFT) method [25] with long-range corrected CAM-B3LYP [26,27] functional and 6-311G + (2d,p) as a basis set since the electronic transitions were time-dependent phenomena in a methanol solvent and an Integral Equation Formalism Polarizable Continuum Model (IEFPCM) implicit solvation atmosphere [28,29]. GaussSum was employed to analyze the excited-state electronic transitions and electronic spectra [30]. The ripretinib molecule possesses more than two reaction sites, e.g., the phenylamide, 4-bromo-2-fluorophenyl, methanone, ethyl, methyl, and naphthyridin groups. The reaction sites of ripretinib were calculated by the Multiwavefunction suite employing the generated wfn file [31]. The other energy and reactivity descriptors, including the total electrostatic potential V(r) [23], average localized ionization energy (ALIE), hardness, and softness [32], were determined by the qualitative study of the different NCIs [32]. PDB IDs of the suitable proteins to assess the anti-CoV-2 biological activity of the ripretinib molecule were downloaded from the RCSB [33] site. The energy was obtained from SwissDock, and the score values were obtained from PatchDock [34]. Furthermore, the docked results were obtained from the Bio-discovery studio.
The molecular structure of ripretinib was optimized by DFT, and DFT-B3LYP was employed for the structural confirmation with 6-311G + (2d,p) as the basis set. The optimized structure is shown in Fig. 1
and the details of its geometry are presented in Table 1
.
The bond angles 1Br–22C–16C, 1Br–22C–24C, 2F–25C–23C, 2F—25C— 24C, 3O–13C–11C, 3O–13C–5 N, 10C–5 N–13C, 13C–5 N–14C, 10C–5 N–14C, 4O—27C, 4O–27C–8 N, 27C–8 N–45H, 27C–8 N–23C, 27C–9 N–49H, 27C–9 N–28C, 29C–28C–30C, 18C–6 N–19C, 6 N–19C–7 N, 19C–7 N–44H, and 19C–7 N–26C were 121.23°, 117.21°, 117.01°, 119.59°, 123.36°, 119.72°, 123.31°, 115.80°, 120.87°, 124.16°, 123.20°, 119.25°, 126.94°, 117.5690°, 128.0°, 119.52°, 117.58°, 115.99°, 118.47°, and 122.91°, respectively. The two halogens were in the meta positions of the middle aromatic ring, thus affording a unique structure.
FMO offers valuable information about the energy band gap. Thus, the various physical and chemical descriptors of the molecule, which enabled the elucidation of its reactivity, stability, and biological activity, could be predicted by the highest occupied molecular orbital (HOMO) and lowest unoccupied molecular orbital (LUMO) energies [35]. The energies were calculated at the B3LYP/6-311G + (2d,p) level of the theory. The excited states were calculated at the same level by TD-DFT. The frontier energies and other chemical descriptors were related [36,37], and the data are presented in Table 2
. HOMO and LUMO were in the 4-bromo-2-fluorophenyl and naphthyridin rings, respectively.
The ground- and excited-state properties are different. The energy gaps in the ground and excited states were 10.12 and 4.05 eV, respectively. This indicates that the excited state was less stable than the ground state, as expected. The free energies of the excited and ground states were − 3.69 and − 2.89 eV, respectively [16,[38], [39], [40]]. The electron-accepting power of the ground state was higher than that in the excited state, whereas the electrodonating power of the excited state is significantly higher than that of the ground state. This may be due to the triplet state of the excited state. Owing to the inherent instability of the excited state, the fraction of the charge that can be transferred is 1.82, and that, which can be transferred in the ground state, is 0.57 only. Therefore, there is increased electrophilicity in the excited state compared to in the ground state [[41], [42], [43], [44]].
The electronic transition of ripretinib was studied by TD-DFT utilizing CAM-B3LYP functional and 6-311G + (2d,p) as the basis set in a methanol implicit solvent atmosphere employing the IEFPCM solvation model. The UV–Vis spectrum and the different orbitals involved in the transition are given in Fig. 2, Fig. 3
, respectively.
There are two prominent electronic transitions of the compound. The energy, wavelength, oscillator strength (f), and symmetry of the first transition are 32,154.32 cm−1, 311.00 nm, 0.58, and singlet asymmetry, respectively. The major contributions to these transitions (91%) are from HOMO to LUMO. HOMO is in the 4-bromo-2-fluorophenyl ring, and LUMO is in the naphthyridn one. Hence, the HOMO–LUMO transition involves electromigration from one region of the molecule to another, thereby inducing an intramolecular charge-transfer process. Regarding the second transition, the energy, wavelength, f, and symmetry are 39,373.03 cm−1, 253 nm, 0.32, and singlet asymmetry, respectively, with major contributions from the seventh lowest HOMO (HOMO-7) to LUMO, the second HOMO (HOMO-2) to LUMO, and HOMO to the second LUMO (LUMO +2) with 26%, 27%, and 13% contributions, respectively.
For the first transition, f was 0.58, which implies that the molecule possessed good light-harvesting efficiency (LHE) that is expressed as a function of f, as follows: LHE = 1–10−f [36,[45], [46], [47], [48], [49], [50]]. The value was 0.7376 for the first transition, which indicated that the compound could absorb 73.76% of incident-light energy for electronic excitation at that wavelength.
The study of light–matter interactions is very beneficial, especially for organic molecules. The ability of the molecule to bend the linear light can be determined by the polarizability and hyperpolarizability values, which were obtained from the simulation of the Raman spectra. These NLO activities are very beneficial to employing the compound in the organic electronics industry [[51], [52], [53], [54]]. The polarizability and hyperpolarizability data that were obtained during the simulation of Raman spectra were utilized for the estimation. The simulation was conducted at the same theoretical level as that of the optimization and compared with those of the standard NLO-active substance, urea [[55], [56], [57]]. The parameters of the NLO properties of ripretinib are shown in Table 3
.
The dipole moment (μ), mean polarizability (α0), the anisotropy of the polarizability (Δα), and molar refractivity (MR) of ripretinib are 0.9804 D, 341.3780*10−23 esu, 795.2260*10−23 esu, and 8614.8331 esu, respectively, which are 3.1091 times lower than urea, 9.5752 times higher than urea, 11.5122 times higher than urea, and 9.5752 times higher than urea, respectively, when compared against those of the standard, urea. Thus, this molecule exhibits higher NLO properties than urea.
Intramolecular electron displacements are very essential because they determine the inherent stability of a compound. The NBO analysis is an excellent tool for studying such interactions via hyperconjugations [[58], [59], [60], [61]]. The occupancy values of NBOs and their delocalization energy avails valuable information on the aforementioned stabilities. NBOs were calculated with the NBO suite [62] that is available on the Gaussian-09 software.

Table 4
summarizes the delocalization energy during the electronic transitions. The electrons are transferred from the donor bonding orbitals to the acceptor antibonding orbitals with suitable occupancies utilizing energy, i.e., from σ (N6–C18) with an occupancy of 1.7872 to σ* (C10–C12) and σ* (C17–C19) with energies of 10.35 and 26.82 kcal/mol, respectively; from σ (C10–C12) with an occupancy of 1.5410 to σ* (N6–C18), σ* (C11–C15), and σ* (C17–C19) with energies of 33.68, 19.50, and 14.63 kcal/mol, respectively; from σ (C11–C15) with an occupancy of 1.7933 to σ* (O3–C13) and σ* (C10–C12) with energies of 25.98 and 12.56 kcal/mol, respectively; from σ (C17–C19) with an occupancy of 1.6378 to σ* (N6–C18) and σ* (C10–C12) with energies of 12.00 and 29.59 kcal/mol respectively; from σ (C22–C24) with an occupancy of 1.6861 to σ* (C16–C21) and σ* (C23–C25) with energies of 21.63 and 20.68 kcal/mol, respectively; from σ (C23–C25) with an occupancy of 1.6521 to σ* (C16–C21) and σ* (C22–C24) with energies of 18.32 and 23.88 kcal/mol, respectively; from σ (C28–C30) with an occupancy of 1.6392 to σ* (C29–C31) and σ* (C32–C33) with energies of 19.85 and 18.45 kcal/mol, respectively; from σ (C29–C31) with an occupancy of 1.7001 to σ* (C28–C30) and σ* (C32–C33) with energies of 21.93 and 18.45 kcal/mol, respectively; and from σ (C32–C33) with an occupancy of 1.6651 to σ* (C28–C30) and σ* (C29–C31) with energies of 20.55 and 24.06 kcal/mol, respectively.
The lone pairs of electrons were transferred from the bonding orbitals to the antibonding lone pairs of the antibonding orbitals, i.e., from the lone pair orbitals, n(F2), n (O4), and n(N7), with occupancies of 1.9463, 1.5404, and 1.7224, respectively, to the antibonding orbitals, σ* (C23–C25), n* (C27), and σ* (C17–C19), with energies of 13.01, 286.47, and 51.50 kcal/mol, respectively; from n (O3) with an occupancy of 1.8789 to σ* (N5–C13) and σ* (C11–C13) with energies of 25.50 and 15.65 kcal/mol, respectively; from n (O4) with an occupancy of 1.8708 to σ* (N8–C27) and σ* (N9–C27) with energies of 22.19 and 21.82 kcal/mol, respectively; from n (N5) with an occupancy of 1.5969 to σ* (O3–C13) and σ* (C10–C12) with energies of 54.25 and 44.45 kcal/mol, respectively; from n (N6) with an occupancy of 1.9150 to σ* (C12–C18) and σ* (C17–C19) with energies of 11.42 and 11.03, respectively; from n (N8) with an occupancy of 1.7035 to n* (C27) and σ* (C23–C25) with energies of 106.55 and 34.35 kcal/mol, respectively; and from n (N9) with an occupancy of 1.7000 to n* (C27) and σ* (C28–C30) with energies of 114.22 and 31.82 kcal/mol, respectively.
The electrostatic potential, V(r), which is generated around a molecule by its nuclei and electrons and treated as static charge distribution, is a very beneficial property for studying and predicting molecular reactivity. This is narrowly defined and can be calculated experimentally and computationally. The capacity has been especially essential in indicating the positions or regions of the molecule where the advancing electrophile is initially drawn and has also been effectively extended to analyzing the associations that require a certain optimal relative orientation of the reactants, such as between the product and its cellular receptor [35,63,64]. MESP of the ripretinib molecule was generated from the data that was obtained from the previous calculation (Fig. 4
).
The blue and red colors correspond to the numerical values between −0.1000 and 0.1000 and the molecule in the Bohr3 range of 17.08 to −22.50. The blue color corresponds to the oxygen atom (the electrophilic region) in the amide group, the fluorine atom in the phenyl ring, and the ketonic oxygen atom in the naphthyridin group, which are the electron-rich sites, indicating that the electrophiles could easily attack these sites. The red color corresponds to all the protons in the amide group (the nucleophilic region), bromine atom in the phenyl group, and all the protons in the methylamine group, which are electron-poor sites, indicating that nucleophiles can easily attack these sites.
The local, I(r), average ionization energy of ionization is the energy that is required to remove an electron from point r into the system. The lowest values represent the positions of the least tightly held electrons, which are, therefore, the selected reaction sites with electrophiles or radicals. Beyond its relevance to the reactive behavior, I(r) is significant in other fundamental fields, including atomic shell composition, electronegativity, and local polarizability and hardness [65]. ALIE of ripretinib is pictorially shown in Fig. 5
.
A color code can be employed to identify the ALIE surface of the molecule. The average volume of the molecule is in the −17.17 to −17.17 Bohr3 range. The bluish-green region indicates the delocalization of the electrons in the phenyl group, in the amide chain, from fluorine to the 4-bromo-2-fluorophenyl group, in the naphthyridin group, and in the methylamino chain, which produced several resonance structures that stabilized the molecule. The blue color indicates the sigma-bond, as well as the stable bond between the atoms in the ripretinib molecule, which are the protons to be attached to the methyl, ethyl, naphthyridin, and phenyl groups.
NCI differs from a covalent bond because it does not involve the sharing of electrons, although it involves more dispersed variations of the electromagnetic interactions between the molecules or within a molecule. The three-dimensional arrangement of large molecules, such as proteins and nucleic acids, is crucial to NCI. Additionally, it is involved in many biological processes where large molecules bind to each other specifically but transiently. These interactions also significantly impact drug design, crystallinity and material design, self-assembling, and the design of the synthesis of tailored organic molecules [44]. The molecular structure of ripretinib was optimized and the multiwfn file was generated by DFT employing DFT-B3LYP as a method and 6-311G + (2d,p) as a basic set. NCI of ripretinib is shown in Fig. 6
.
A graph of energy against the reduced density gradient was plotted. The hydrogen bond appeared between −0.005 and − 0.021 a.u. from the hydrogen atoms in the amide nitrogen and the phenyl fluorine atom in the 4-bromo-2-fluorophenyl group. The van der Waals force attraction was observed in the range of −0.005 to 0.008 a.u. from the protons in the phenyl group to the amide oxygen and from the protons in the naphthyridin group to the ketonic oxygen. The steric force exists in the range of 0.008–0.25 a.u. involving the bromine atom in the 4-bromo-2-fluorophenyl group and the ethyl group in the naphthyridin group. All these interactions stabilized the system and ensured its reactivity toward biological systems.
Scientists globally are researching drugs to manage the COVID pandemic. It is generally preferable to reroute existing drugs during this pandemic to save a lot of precious time that is required for new drug discovery. Therefore, we evaluated the activity of this drug against known COVID proteins. Molecular docking explains the structure-related activity of ripretinib against coV-2 proteins (PDB IDs:6M03 [66], 6 W63 [1], and 6 LU7 [1]) that have been deposited in the RSC database [33]. Table 5
explains the docking result between ripretinib and the coV-2 proteins (PDB IDs: 6M03, 6W63, and 6LU7), as follows: the 6 M03 protein possessed the highest inter-full fitness, ΔG ligand–solvent polarity, and total ΔG among the proteins. The 6 W63 protein possessed the highest surface-full fitness, ΔG complex–solvent nonpolarity, and ΔG protein–solvent nonpolarity among the proteins. Further, the 6 LU7 protein possessed the highest energy, simple fitness, full fitness, intra-full fitness, solvent-full fitness, ΔG complex–solvent polarity, ΔG protein–solvent polarity, and ΔG ligand–solvent nonpolarity among the proteins.
Ripretinib against the coV-2 proteins (6 M03, 6 W63, and 6 LU7) obtained the respective score values of 5242, 5328, and 5780; interaction areas of 578.70, 658.40, and 634.60; and minimum atomic contact energies of −192.77, −270.60, and − 288.10.

Fig. 7
shows the skeletal structure of the interactions between ripretinib and the 6 M03, 6 W63, and 6 LU7 proteins. Fig.S1 shows the interactions between ripretinib and the 6 M03, 6 W63, and 6 LU7 residues, and Table S1 presents the interactions of ripretinib with 6 M03, 6 W63, and 6 LU7. All the names of the protein residues and their labels, hydrophobicity, pKa values, average isotropic displacements, secondary structures, residue solvent accessibility, sidechain solvent accessibility, percentage solvent accessibility, and the percentage sidechain solvent accessibility values for interactions with ripretinib are presented in the table.
Table S2 presents the nonbond interactions between ripretinib and the 6 M03, 6 W63, and 6 LU7 proteins with the distance, category, type, from chemistry, and to the chemistry of the favorable, unfavorable nonbond, and unsatisfied bonds within the ripretinib molecule.

Table 6
and Figs. S2, S3, S4, S5, and S6 show the noncovalent bonds between ripretinib and the coV-2 proteins (6 M03, 6 W63, and 6 LU7) and explain the hydrophobicity, hydrophilicity, neutral group-, acidic group-, and basic-group interactions, respectively.
We studied the structural features, energy features, energy descriptors, and other beneficial physical properties of ripretinib. The UV–Vis spectra exhibit a significant peak at 311 nm with f of 0.5812. From the NLO property of ripretinib, the mean polarizability and anisotropy of the polarizability are 9.5752 and 11.5122 times greater than those of the standard material, urea. The stability and intramolecular-charge delocalization were studied employing NBO. The properties of the reactive site, such as MESP, ALIE, and NCI, were detailedly explained, and it was confirmed that they occurred mostly in the amide oxygen, nitrogen, and protons in the phenylamide group; the fluorine and bromine and protons in the 4-bromo-2-fluorophenyl group; and the ketonic oxygen, methylamino, and ethyl protons in the naphthyridin group. Most significantly, the docking studies indicate that the molecule docks extensively with three important docking proteins (6 M03, 6 W63, and 6 LU7) that are related to CoV-2. Hence, this compound should be studied as a possible drug against SARS-n-CoV-2. ΔGs of the dockings of 6 M03, 6 W63, and 6 LU7 are − 8.66, 8.50, and − 8.03 kcal/mol, respectively, which are appreciable values. Thus, this compound could be developed as a drug to treat CoV-2 after screening via biological studies.

Fahad A. Alharthi : Simulation, data curation, writing original draft; Nabil Al Zaqri : Experiment design, Fund acquisition, Supervision; Ali Alsalme: Writing, reviewing and editing, Validation, Data analysis; Afnan Al-Taleb : Simulations, Validation; T. Pooventhiran.: Investigation, Simulation, Data curation, Writing- original drafts, Writing- revised draft; Renjith Thomas: Conceptualization, Methodology, Software, Supervision; D.J Rao: Simulations, Validation, Formal analysis.
Authors declare no conflicts of interest.",J Mol Liq
PMC7576372,Self-compassion and life-satisfaction among Chinese self-quarantined residents during COVID-19 pandemic: A moderated mediation model of positive coping and gender,"Self-compassion refers to being kind and caring about oneself when facing hardships (Neff, 2003). Specifically, people with a high level of self-compassion are self-kind to themselves instead of self-judgment and criticism. Furthermore, they perceive a sense of common humanity that suffering is not personal but universal. Additionally, they are mindful of the present experience without over-identification (Neff, 2003). From the positive psychological perspective and the key resource theory (KRT), as a personal character, self-compassion is an individual's internal positive strength and resources, which is an important determinant of subjective well-being and life-satisfaction (Seligman, 2002; Thoits, 1994).
Empirical studies supported that self-compassion is positively related to life-satisfaction across ages and Western and Eastern cultures (Jennings & Tan, 2014; Kim & Ko, 2018; Neff et al., 2008; Yang et al., 2016). For instance, a study demonstrated a positive link between self-compassion and life-satisfaction in Chinese adults (Yang et al., 2016). Self-compassion was found to enhance life satisfaction among 203 older adults aged over 65 in Korea (Kim & Ko, 2018). Meta-analyses further revealed that self-compassion improves life-satisfaction (Macbeth & Gumley, 2012; Muris & Petrocchi, 2017; Zessin et al., 2015). People with higher self-compassion could generate positive psychological resources, which could improve their life-satisfaction during the quarantine period (Gunnell et al., 2017; Ryan & Deci, 2017). Therefore, based on previous evidence, we hypothesized that self-compassion is positively related to life-satisfaction in self-quarantined people.
Coping is defined as purposeful adjustment and response to stress (Carver et al., 1989). Positive coping, also known as problem-focused coping, refers to directly solving pressure-related problems in stressful situations rather than avoiding and distancing (Folkman & Lazarus, 1984; Xie, 1998). Positive coping involves a set of strategies, such as seeking emotional support and striving for change. These strategies are either helpful (adaptive) or helpless (inadaptive). Fullana et al. (2020) recently displayed that people with high-level positive coping may use such as recognize self-quarantine as a chance to rest, develop hobbies, communicate with friends, and seek support from the health cares to deal with the COVID-19-relevant issues. These positive coping strategies have always been associated with better psychological outcomes (e.g., higher life-satisfaction; Hamarat et al., 2001; Li et al., 2016). The adaptive calibration model (ACM) proposes that people with positive coping will adapt to the stressful environment faster and better, thus improving psychological health and well-being, such as life-satisfaction (Del Giudice et al., 2011).
Furthermore, the transactional model of stress (TMS; Carver & Connor-Smith, 2010) believes that personality characters (e.g., self-compassion) are related to the choice of coping strategies (Bolger, 1990; Folkman & Lazarus, 1984). As mentioned above, self-compassion, as a positive character, could provide psychological resources for self-quarantined residents to cope with isolation-related problems directly (Allen & Leary, 2010). The general strain theory (GST; Agnew, 1992) also pointed out that under the stressful events, personality characters (i.e., self-compassion) influence the outcomes of adaptation (i.e., life-satisfaction) through positive coping. Using the ACM, TMS, and GST as the theoretical frameworks, we assumed that positive coping might mediate the association between self-compassion and life-satisfaction among self-quarantined residents.
Consistent with the theoretical standpoints above, multiple empirical studies supported that self-compassion is linked with positive coping (Allen & Leary, 2010; Leary et al., 2007; Ștefan, 2019; Thompson & Waltz, 2008). For instance, students with high self-compassion might take positive coping strategies to relieve stress when faced with academic failure (Neff et al., 2005). Similarly, an empirical study suggested that individuals with high self-compassion promote the recovery of traumatic events by accepting reality (Thompson & Waltz, 2008). Furthermore, several studies have indicated that positive coping enhances people's life-satisfaction (Hamarat et al., 2001; Li et al., 2016). For instance, Li et al. (2016) found that positive coping improves college students' and employees' life-satisfaction. Therefore, this research hypothesized that positive coping could mediate the linkage between self-compassion and life-satisfaction.
Although self-compassion might be related to life-satisfaction via positive coping, not all people with positive coping could effectively improve their life-satisfaction (Del Giudice et al., 2011). Thus, it is necessary to explore the factors that could weaken the strength of the association of positive coping and life-satisfaction. Social role theory (SRT) proposes that each gender benefit differently from positive coping in stressful situations (Eagly & Wood, 2012). That is, individuals' internalized gender stereotypes may result in different consequences in coping with stressful events (Howerton & Van Gundy, 2009). Inspired by the SRT, this study examined whether gender moderates the relationship between positive coping and life-satisfaction among self-quarantined residents.
According to SRT, influenced by social norms, males and females may generate different psychological expectations and behaviors (Eagly & Wood, 2012). Specifically, males tend to show more optimistic, active, and take responsibility in adversity (e.g., self-quarantine in the pandemic). By contrast, females are more likely to be emotional, rely on others, and hold negative expectations when encountering difficulties (Basow & Rubenfeld, 2003; Broderick & Korteland, 2002). Moreover, some studies have demonstrated that individuals with positive goals can overcome difficulties more effectively than those with less positive goals (e.g., Gaudreau et al., 2002). Consistent with the SRT, an empirical study found gender differences in coping with the COVID-19, with females use more emotional and less effective coping (Hennekam & Shymko, 2020). Another empirical study investigated 2816 adults from 18 to 65 years old and found that males tend to be more effective in solving stress life events and perceive a lower sense of stress than females (Matud, 2004). Based on SRT and empirical evidence, this study assumed that gender might moderate the relationship between positive coping and life-satisfaction.
The current study aimed to examine the mediating role of positive coping and the moderating role of gender between self-compassion and life-satisfaction in self-quarantined people during the COVID-19 pandemic. Based on the above literature review, this study proposed three hypotheses. (1) Self-compassion is positively related to life-satisfaction among self-quarantined residents. (2) Positive coping mediates the relationship between self-compassion and life-satisfaction. Self-compassion is positively related to positive coping, which in turn positively relates to life-satisfaction. (3) Gender moderates the relationship between positive coping and life-satisfaction (Fig. 1
).
The convenient sampling method was used in the current study. Participants were recruited through WeChat talking group (a message communication application in China) with community workers' help. Three hundred fifty-five quarantined residents were collected in a community with COVID-19 infections in Liaoning Province, China, on March 13th 2020. These residents in this community were self-quarantined from March 2nd to 16th. After eliminating the 18 invalid responses, the final valid data was 337 cases (129 men, 208 women). Table 1
shows the demographic characteristics of the participants.
Before data collection, we calculated the minimum sample size through G-power 3.1. Previous studies have found that the correlation coefficient between self-compassion and life-satisfaction was about 0.47 (Booker & Dunsmore, 2019). Thus, when we set α = 0. 05 (two-tailed), 1-β = 0.80, the minimum sample size was 155. This study takes 155 as the minimum number of participants and collects as much data as possible to ensure reliability.
During the data-gathering phase, we recruited quarantined residents with the help of community workers. We obtained informed consent from all the quarantined residents and explained the requirements to all participants with standard instructions. The authenticity, independence, and integrity of the answers were also emphasized. Participants completed the online questionnaires (www.sojump.com). After filling out the questionnaires, they acquired 2 RMB online as a reward. The authors' university ethics committee approved the current research.
In this study, demographics included gender, age, occupation, subjective economic status (SES), and attention degree (AD) of COVID-19 the pandemic situation. Explicitly, gender was set as dummy variables (male = 0, female = 1). SES was accessed by an item of “What do you think of your economic situation?” This item is scored from 1 (Very Low) to 5 (Very High). AD of the COVID-19 pandemic situation was measured by an item of “What is your attention degree towards the COVID-19 situation?” This item is scored from 0 (Never) to 3 (Always). Previous findings indicated that the demographic variables mentioned above might link with the current main variables (Mann et al., 2020; Yuan et al., 2009). Thus, age, occupation, SES, and AD were controlled as covariables in the data analysis process.
Positive coping was measured by the Simplified Coping Style Questionnaire (SCSQ; Xie, 1998). We used the subscale of positive coping in SCSQ. The subscale has 12 items, such as “I try to find the positive side of negative events,” “I develop hobbies, such as entertainment and sports activities,” “I talk to people about my worries.” Participants were asked to respond to how often they used the positive coping strategies in self-quarantine during the COVID-19 pandemic on a 4-point scale, ranging from 0 (Never) to 3 (Very Often). The higher mean score of positive coping representing the higher frequency of positive coping. Previous studies indicated the Cronbach's α coefficient of the positive coping subscale of SCSQ ranged from 0.79–0.89 (Li et al., 2016; Li et al., 2020). The Cronbach's α of positive coping in this study was 0.83. Confirmatory factor analysis (CFA) of the SCSQ showed that it fitted well (χ2/df = 3.18, CFI = 0. 91, TLI = 0. 90, SRMR = 0. 05, RMSEA = 0.08, 90% C.I. = [0.06, 0.09]). These results suggested that this scale is a reliable measurement.
The self-compassion was assessed by the Self-Compassion Scale (SCS; Tang, 2015). The scale has 16 items. It consists of three subscales, including Self-kindness (e.g., “I often do things that make me happy.”), the Sense of Common Humanity (e.g., “I am not the only one who has been treated unfairly.”), and Mindfulness (e.g., “I can concentrate well.”). Participants responded on a 5-point scale ranging from 1 (Strongly Disagree) to 5 = (Strongly Agree). The final score of SCS was the mean of the 16 items scores, with higher scores reflecting higher self-compassion. The Cronbach's α coefficient of SCS ranging from 0.85 to 0.89 in previous studies (Tang, 2015; Tang, 2017). The Cronbach's α of SCS in the present study was 0.90. CFA of SCS showed that the model fitted well (χ2/df = 3.63, CFI = 0. 90, TLI = 0. 89, SRMR = 0. 05, RMSEA = 0.08, 90% C.I. = [0.068, 0.089]). These findings indicated that the scale has good reliability and validity.
The Satisfaction with Life Scale (SWLS) was used to measure participants' life-satisfaction (Diener et al., 1985; Xiong & Xu, 2009). The SWLS consists of 5 items (e.g., “If I could live my life over, I would change almost nothing”). Participants responded on a 7-point scale ranging from 1 (Strongly Disagree) to 7 (Strongly Agree). The higher the mean score indicating the higher level of life-satisfaction. In previous studies, the Cronbach's α coefficient of SWLS, ranging from 0.83 to 0.86 (Shao et al., 2020; Shen & Zhang, 2020). The Cronbach's α of the SWLS in the study was 0.85. CFA of SWLS suggested that the model fitted well (χ2/df = 5.8, CFI = 0. 97, TLI = 0. 93, SRMR = 0. 03, RMSEA = 0.09, 90% C.I. = [0.05, 0.12]). These results indicated that this scale is reliable and has good validity and reliability.
SPSS 21.0 and PROCESS version 3.0 (www.afhayes.com) were performed to analyze data (Hayes, 2013). The first step was data screening. Data distribution and multicollinearity tests showed that the coefficient of kurtosis and skewness of the main variables were smaller than |±2|, indicating that the variables were in line with the normal distribution (Curran et al., 1996). The variance inflation factor (VIF) of self-compassion and positive coping was smaller than 5, reflecting no severe multicollinearity (Liu, 2019). The predictors were mean-centered to minimize multicollinearity for examining the moderated mediation model. Additionally, Harman's single factor test suggested that a total of 13 characteristic roots were bigger than 1. The maximum factor variance interpretation rate was 23.27% (lower than the critical value of 40%), indicating that common method biases were insignificant (Harman, 1967). To further test the common method bias, we recruited single-factor CFA (Podsakoff et al., 2003). The results showed that the fit index is not good (χ2/df = 10. 32, CFI = 0. 20, TLI = 0.10, RMSEA = 0. 15, SMRM = 0. 23), suggesting that the common method bias in this study is not significant, indicating the validity of the statistical analysis results is not affected. The second step was data analysis. Descriptive statistics, difference comparisons, and Pearson correlation analysis were calculated through SPSS 21.0. Model 4 and Model 14 of PROCESS version 3.0 were performed to examine the mediating effect and moderated mediating effects. According to Cohen's (1992), Pearson correlation or β coefficient around 0.10 indicated a minimum effect size, near 0.30 meant a moderate effect, and higher 0.50 reflected a strong effect.
An independent-sample t-test was performed to explore the gender differences in self-compassion, positive coping, and life-satisfaction. Table 2
presents that gender difference in positive coping was statistically significant. The female's positive coping score was higher than the male (t = −3.81, p < .001, Cohen's d = 0.443). Further, the independent-sample t-test was used to analyze each item's gender differences in the Simplified Coping Style Questionnaire (SCSQ). The results indicated that the gender differences of item 2 (“Talking to people and sharing inner troubles”) were statistically significant. The score in female (M = 2.86, SD = 1.11) was significantly higher than that in male (M = 2.59, SD = 1.01; t = 2.07, p = .03, Cohen's d = 0.26).
Additionally, the Pearson correlations are shown in Table 3
. The results indicated that self-compassion was significant and positive related to positive coping and life-satisfaction and positive coping significantly and positively associated with life-satisfaction (rs > 0.20, ps < .001).
As shown in Table 4
, after controlling for the age, occupation, SES, AD of COVID-19 pandemic situation, a positive and strong relationship was found between self-compassion and life-satisfaction (β = 0.61, SE = 0.10, p < .001). A positive and medium association was found between self-compassion and positive coping (β = 0.24, SE = 0. 06, p < .001). However, the correlation between positive coping and life-satisfaction was not significant (β = 0.08, SE = 0.05, p = .06). The indirect effect of self-compassion on life-satisfaction was not significant (β = 0.04, 95% CI = [−0.02, 0.11]).
According to the Model 14 (see Table 4), the interaction of positive coping and gender was positively related to life-satisfaction, and the effect size was moderate (β = −0.41, SE = 0. 17, p = .01). This result indicated that gender moderated the relationship between positive coping and life-satisfaction. Furthermore, simple slope analysis (see Fig. 2
) displayed that positive coping was positively related to life-satisfaction in males (β
simple = 0.54, t = 3.48, p < .001). However, for the female group, positive coping was not significantly linked with life-satisfaction (β
simple = −0.12, t = −0.76, p = .45).
Additionally, the bootstraps (5000 times) analysis showed that the mediating effect was moderated by gender (see Table 4). Specifically, in the male group, positive coping mediated the relationship between self-compassion and life-satisfaction with the small indirect effect size (β = 0.15, 95% CI = [0.05, 0.24]). By contrast, in female group, the indirect effect was not significant (β = −0.07, 95% CI = [−0.15, 0.02]).
Self-compassion was positively linked with life-satisfaction, which was consistent with Hypothesis 1, KRT, and previous studies (Jennings & Tan, 2014; Kim & Ko, 2018; Seligman, 2002; Thoits, 1994; Wei et al., 2011; Yang et al., 2016). This finding indicated that self-compassion, as a positive character, could provide psychological resources for individuals in adversity to improve life-satisfaction (Seligman, 2002; Thoits, 1994). Furthermore, following the concept of self-compassion, individuals with higher self-compassion may generate more self-kindness and warmth during the quarantine period (Neff, 2003; Soysa & Wilcomb, 2015). Moreover, their sense of common humanity (i.e., a component of self-compassion) may lead them to treat pandemic and self-quarantine as a universal event rather than personal misfortune. They may also tend to accept the self-isolation issue without emotional over-involvement. Thus, self-quarantined residents with a high level of self-compassion were more likely to possess higher life-satisfaction.
The results showed that self-compassion was positively related to positive coping and life-satisfaction. These findings were consistent with TMS, a theory that believes that personality characters (e.g., self-compassion) are positively linked with positive coping (Bolger, 1990; Carver & Connor-Smith, 2010; Folkman & Lazarus, 1984). However, the association between positive coping and life-satisfaction was non-significant. We further found that positive coping mediated the relationship between self-compassion and life-satisfaction in male residents. However, in the female group, it is found that self-compassion was positively related to positive coping and life-satisfaction, and the mediating effect was non-significant. These results were partially consistent with Hypothesis 2 and GST (Agnew, 1992). The GST suggested that under stressful events, personality characters (i.e., self-compassion) would influence adaptation outcomes (i.e., life-satisfaction) through positive coping. This study only verified this theory in the male residents in quarantine.
Our findings demonstrated the moderating role of gender between positive coping and life-satisfaction, which supported Hypothesis 3, SRT, and previous studies (Esnaola et al., 2019; Hennekam & Shymko, 2020; Joshanloo & Jovanovic, 2019; Matud, 2004; Soysa & Wilcomb, 2015). This study found that positive coping was significantly related to life-satisfaction in the male group, while positive coping was not associated with life-satisfaction in the female group. These findings may indicate that, among the quarantined residents, females' positive coping might not be as effective as males in increasing life-satisfaction.
Two possible explanations are as follows: First, although the current study showed that women's positive coping was higher than men. Further, it found that women used more emotional support-seeking strategies than men (“I talk to people about the troubles”). Previous studies have pointed out that emotional support-seeking strategy as positive coping strategies may not always be adaptive in stressful situations (Carver et al., 1989; Matud, 2004). Moreover, some studies have found that the overload of empathy and emotional caring towards people experiencing quarantine and COVID-19 introduces helpers' empathy fatigue, indicating that the helpers may encounter emotional and psychical strain and burnout in the helping process (Liu et al., 2020; Zhuang et al., 2020). Additionally, quarantined individuals were also stigmatized by others (Hooper et al., 2020). Thus, other people might not offer sufficient emotional support. Therefore, the life-satisfaction of female residents with higher positive coping was not higher than that of men in the present study.
Second, based on SRT, social expectations and stereotypes may lead to gender differences of goal-setting in positive coping, and coping with a positive goal will be more rewarding (Howerton & Van Gundy, 2009; Sorkin & Rook, 2006). Studies found that men's coping-related goals tend to be more optimistic to solve problems than seek emotional caring among women, which may significantly increase life-satisfaction (Basow & Rubenfeld, 2003; Broderick & Korteland, 2002). Based on these results, it is crucial to adopt effective positive coping strategies to improve life-satisfaction during the COVID-19 pandemic.
Some limitations of this investigation should be emphasized. First, the moderated mediation model was tested through a cross-sectional method, which prevents us from providing strong causal inference. However, our moderated mediation model is proposed based on a positive perspective and the theoretical framework of ACM, TMS, GST, and SRT, suggesting that self-compassion contributes to life-satisfaction. Admittedly, high life-satisfaction may become the driving variable behind greater self-compassion. Thus, to further explore the relationship between the two variables, future studies should use a randomized controlled trial or a longitudinal design to test the variables' casual relationships. Second, this study only measured positive coping styles rather than specific coping styles, such as planning, suppressing competitive activities, and seeking instrumental support. The present study specifically aimed to explore the role of positive coping between self-compassion and life-satisfaction. Further studies could identify the effects of specific coping strategies. Third, this study was conducted only in the Chinese context with Eastern culture. Trzebiński et al. (2020) recruited 317 Polish participants during the COVID-19 pandemic. The score of life-satisfaction (M = 4.33) in their study was smaller than the score (M = 4.43) among the sample in this study, the context of Eastern culture. We speculated that the underlying reason might be that self-compassion is a spiritual characteristic deprived of the Eastern culture (Esnaola et al., 2019; Neff et al., 2008). Future studies could compare the cultural differences of psychological characteristics (e.g., life-satisfaction, self-compassion) and their associations during the COVID-19 pandemic. Forth, it is undeniable that not all people confirm gender stereotypes from social norms. Future studies could explore personality differences rather than gender diversity, such as the big five personalities (Neff et al., 2007), to get more details about the association between self-compassion and life-satisfaction.
Although this study has some limitations, it may provide an essential insight into the mechanism of self-compassion and life-satisfaction among people in quarantine. First, the finding served to emphasize that self-compassion contributed to life-satisfaction among quarantined individuals during the isolation period. Based on this finding, psychologists should pay more attention to self-compassion for increasing life-satisfaction in self-quarantine. Previous therapy programs have been implemented in this field, such as Mindful Self-Compassion (MSC), Compassion-Focused Therapy (CFT), and Loving-Kindness Meditation (LKM) (Leaviss & Uttley, 2015). Given the outbreak of COVID-19, the online psychological intervention of self-compassion could be carried out. The existing therapy and programs may shed light on the psychological intervention of individuals experiencing self-isolation during the pandemic. Second, this study's significant contribution is to examine a mediating role of positive coping of self-compassion and life-satisfaction of individuals in quarantine. The test of the mediator of positive coping provides empirical evidence that positive coping strategies do matter. Thus, psychological practitioners should provide self-quarantined residents with helpful and adaptive coping strategies during the epidemic, such as regular exercise at home and developing hobbies (Fullana et al., 2020). Third, the current work results advance the understanding of the moderating role of gender between positive coping and life-satisfaction in quarantine, which provides avenues of the quarantined people's psychological intervention during the COVID-19 pandemic. Specifically, the relationship between positive coping and life-satisfaction is not significantly linked in the female group. The finding reflected that the female's positive coping (i.e., seeking emotional and social support) might not be adaptive in the self-quarantine period. This result indicates that psychological intervenors should pay more attention to women's psychological health during the pandemic and provide them with more adaptive coping strategies to ride out the pandemic.
This study probed the relationship between self-compassion and life-satisfaction among quarantined residents during the 14-day quarantine period in the COVID-19. Furthermore, we examined the mediating effect of positive coping and the moderating effect of gender in this relation. The results showed that self-compassion was significantly and positively correlated with life-satisfaction. Moreover, for quarantined male residents, self-compassion was positively correlated with positive coping, which in turn, positively correlated with life-satisfaction. For female quarantined residents, self-compassion is positively linked with life-satisfaction and positive coping. The positive coping was significantly associated with life-satisfaction among male groups, but not for those of the female group. These findings provide theoretical and empirical evidence for psychological intervention to improve quarantined residents' life-satisfaction of COVID-19.

Angyang Li: Conceptualization, Methodology, Data Collection, Visualization. Writing - original draft, reviewing, and editing.

Shuo Wang: Writing - original draft, reviewing, and editing.

Minmin Cai: Writing - original draft preparation.

Ruiqi Sun: Reviewing and Editing.

Xiangping Liu: Supervision, Reviewing and Editing, Funding Support, and Submission.
All procedures performed in studies involving human participants were in accordance with the institutional and/or national research committee's ethical standards and with The 1964 Helsinki Declaration and its later amendments or comparable ethical standards. The Research Ethics Committee of the authors' university approved this study.
Informed consent was obtained from all individual participants in the study.
This research was supported by the Priority Projects of 10.13039/501100002888Beijing Municipal Education Commission Grant CFEA19061.
All authors declared no conflicts of interest.",Pers Individ Dif
PMC7575438,Staying on track in turbulent times: Trait self-control and goal pursuit during self-quarantine,"Quarantine measures implemented to fight the COVID-19 pandemic have radically changed the lives of millions of people worldwide. Besides having various negative consequences for psychological well-being (Brooks et al., 2020; Rajkumar, 2020; Rodriguez, Litt, & Stewart, 2020), quarantine measures are likely to pose major challenges to personal goal pursuit because they disrupt people's daily routines and make it hard or even impossible to continue engaging in behaviors people used to engage in to reach their goals. People's struggle to stay on track and keep pursuing their goals despite major upheavals in almost all spheres of life has been often addressed in the popular press (Samuel, 2020; Times staff, 2020). What predicts individuals' ability to stay on track and stick to their goals despite major disruptions in their lives?
The literature has long identified a personality trait that predicts successful goal pursuit: self-control. People with higher (vs. lower) self-control are more successful at reaching their goals across various life domains, including health, well-being, relationships, academic, career, financial and others (De Ridder, Lensvelt-Mulders, Finkenauer, Stok, & Baumeister, 2012; Tangney, Baumeister, & Boone, 2004). Herein, we asked whether trait self-control also passes the ‘quarantine test’: Using the COVID-19 pandemic as a natural laboratory to study goal pursuit under exceptionally disruptive circumstances, we examined whether trait self-control is associated with more goal progress.
Prior research on self-control has shown that one of the reasons why people with higher (vs. lower) self-control are more successful at goal attainment is because they use adaptive behavioral strategies, such as turning goal-directed behaviors into habits (Adriaanse, Kroese, Gillebaart, & De Ridder, 2014; De Ridder & Gillebaart, 2017; Ent, Baumeister, & Tice, 2015; Galla & Duckworth, 2015; Stavrova, Pronk, & Kokkoris, 2020; Stavrova, Pronk, & Kokkoris, 2019). This tendency to develop “beneficial habits” could facilitate goal attainment during self-quarantine for high self-control individuals. Herein, we examined whether during the pandemic people with higher (vs. lower) trait self-control were more likely to stick to their “beneficial habits” and continue engaging in behaviors they had developed to reach their goals prior to the pandemic.
At the same time, regardless of whether high self-control people were more likely to continue engaging in their pre-pandemic goal-directed behaviors, it is intriguing whether self-control promotes flexibility and the ability to develop new goal-directed behaviors to adapt to the current situation as well. Developing new adaptive strategies might be necessary for goal pursuit when external circumstances change and existing routines may no longer serve one's goals. Although it has been argued that self-control might also be instrumental in the development of new habits (e.g., Wood, 2016), there has not been much empirical research examining the relation between self-control and new habit formation. The COVID-19 pandemic provides a very suitable context for the study of initial formation of beneficial habits. Thus, we investigated whether people with higher self-control would be more flexible to adjust to the new situation, would find it easier to develop new behaviors to reach their goals and would be more likely to turn these behaviors into habits that support their goal pursuit.
In sum, we used the COVID-19 pandemic as a context to examine whether people with higher (vs. lower) self-control made more progress towards their goals, and whether they did so by continuing performing their pre-existing goal-directed behaviors and/or by being more flexible and able to develop new behaviors and turn them into habits.
Participants were 271 undergraduate students (147 women, 18–35 years old, M = 21.68, SD = 2.81) recruited via the subject pool of a large European university for course credit. A sensitivity power analysis showed that this sample size can reliably detect effect sizes of ρ = 0.17 (two-tailed) with an alpha level of 0.05 and power of 0.80.
The study was conducted online from June 8 to 16, 2020. After an explanation of what goals are (Stavrova et al., 2019; Stavrova et al., 2020), participants were asked to write down one personal goal that they had started pursuing before the lockdown and that they still wanted to achieve. Then, they wrote down up to five behaviors they had been using to achieve this goal before the lockdown started. For each behavior, they indicated to what extent they were able to continue performing it after the lockdown started (α = 0.68; 1 = not at all; 7 = very much).
Participants were also asked whether they had developed any new behaviors to achieve their goals after the lockdown started (yes/no), and if yes, to write down up to five of them. For each one of the new behaviors, they indicated how easy it was to develop this behavior (α = 0.67; 1 = not at all; 7 = very much) and to what extent it had already become a habit for them, i.e. part of their daily routine (α = 0.69; 1 = not at all; 7 = very much).
Goal progress was assessed with three items (α = 0.80) adopted from Milyavskaya and Inzlicht (2017); e.g., “I feel like I'm on track with my goal plan”; 1 = strongly disagree; 7 = strongly agree).
In addition, participants filled out a measure of flexibility regarding their overall response to the COVID-19 crisis, which we developed for the purpose of this study. It comprised the following five items (α = 0.80): “I accepted the challenge to reconsider my routines,” “I responded to the demands of the situation with flexibility,” “I tried to adjust to the new situation as best as I could,” “I discovered new ways of doing things,” and “I found alternative solutions to my problems” (1 = not at all true; 7 = very true).
Finally, trait self-control was measured with the Brief Self-control Scale (Tangney et al., 2004), which comprises 13 items (α = 0.83; e.g., “I am good at resisting temptation”; 1 = not at all like me; 7 = very much like me). Self-control was measured in counterbalanced order at the beginning or the end of the questionnaire.
On average, participants reported 3.87 behaviors (SD = 1.21, min = 1.00, max = 5.00) that they had been using to reach their goals before the lockdown started. The number of behaviors reported was uncorrelated with trait self-control, r = 0.00, p = .961. However, during the lockdown, people with higher (vs. lower) trait self-control were more likely to continue engaging in behaviors they had developed to reach their goals prior to the lockdown, r(268) = 0.25, p < .001.
As our data have two levels, with participants (level 2) being able to report multiple behaviors (level 1), we additionally analyzed the data using multilevel regression. Multilevel regression is particularly suitable here as it accounts for the non-independent data structure (behaviors nested within participants) by modelling participants as random (i.e., including a random intercept at the level of participants; Hox, 2002). All variables were standardized before the analyses, so that the parameters can be interpreted as standardized coefficients. We used lme4 package (Bates, Maechler, Bolker, & Walker, 2015) in R. Consistent with the correlation analyses reported above, trait self-control was positively associated with the ability to continue performing pre-pandemic goal-directed behaviors during the lockdown, β = 0.18, p < .001.
Among all participants, 42.1% (n = 114) started new behaviors to reach their goals during lockdown. Starting new behaviors (dummy-coded, 1 = yes) was uncorrelated with trait self-control, r(268) = 0.05, p = .443. That is, people with higher self-control were not more or less likely to have developed new behaviors to reach their goals. If we examine only the group of participants who have started new behaviors, we can see that they reported to have started on average 2.62 new behaviors (SD = 1.42, min = 1.00, max = 5.00). Moreover, among these participants who developed new behaviors, the number of new behaviors reported was again uncorrelated with trait self-control, r = 0.06, p = .529. That is, people with higher self-control were not more or less likely to report more new goal-directed behaviors. However, people with higher self-control found it easier to develop new behaviors, r(112) = 0.32, p = .001, and were more likely to report that these behaviors have already become habits, r(112) = 0.20, p = .032.
Multilevel regression results supported these conclusions: self-control was positively associated with the ease of developing new goal-directed behaviors, β = 0.23, p = .001, and the perception that the new behaviors have become habits, β = 0.17, p = .031.
People with higher self-control reported more progress towards their goals, r(268) = 0.26, p < .001. We further explored whether the ability to stick to pre-pandemic goal-directed behaviors, the perceived ease of developing new goal-directed behaviors or the ability to turn new behaviors into habits explain high self-control individuals' success at goal attainment. We used parallel mediation analyses with the three variables (average values across the reported goal-directed behaviors) as parallel mediators. The results of the mediation are shown in Fig. 1
. The indirect effects of the ability to continue pre-pandemic goal-directed behaviors and to turn newly developed behaviors into habits were significant mediators. That is, trait self-control predicts goal attainment as it is associated with both sticking to pre-pandemic goal-directed behaviors and turning new goal-directed behaviors into habits.
Developing structures, routines and beneficial habits explains high self-control people's success at goal attainment (Adriaanse et al., 2014; De Ridder & Gillebaart, 2017; Ent et al., 2015; Galla & Duckworth, 2015; Stavrova et al., 2020; Stavrova et al., 2019). Is this also true during challenging times such as the COVID-19 pandemic? Our results showed that self-control passes the ‘quarantine test’: Individuals higher (vs. lower) in self-control made more progress towards reaching their goals during quarantine. This was explained both by continuing pre-pandemic goal-directed behaviors and by turning newly developed goal-directed behaviors into habits.
This finding adds to prior literature by showing that the benefits of high self-control persist under uniquely disruptive circumstances. Even though the world had changed dramatically, high self-control people demonstrated a remarkable capacity to stick to pre-existing habits and had the flexibility to develop new habits that better met situational demands. The combination of these two – maintaining past habits and developing new ones – is high self-control people's recipe for success in turbulent times. A practical implication of our findings is that interventions aimed at increasing self-control may be beneficial also in the context of the challenges posed by the COVID-19 pandemic. Further research using objective measures of goal attainment, longitudinal data and non-student populations is needed to corroborate these insights.

Michail D. Kokkoris: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Project administration, Resources, Software, Visualization, Writing - original draft. Olga Stavrova: Conceptualization, Formal analysis, Investigation, Methodology, Software, Visualization, Writing - review & editing.",Pers Individ Dif
PMC7560166,A novel integrated quasi-zero stiffness vibration isolator for coupled translational and rotational vibrations,"Quasi-zero stiffness (QZS) vibration isolators possess the high-static-low-dynamic stiffness characteristics, which use the negative stiffness structures to reduce the dynamic stiffness of the system for a desired payload. The QZS characteristics have found their applications in the platform vibration isolators [1], [2], beam vibration systems [3], [4], and rotor systems [5], [6].
The structures with negative stiffness can be achieved by applying different mechanisms. Euler buckled beam was frequently used for the negative stiffness in the early stage [7], [8], [9]. Then coil spring was developed for horizontal-spring type or oblique-spring type [10], [11], [12]. Cam-roller-spring mechanism was also used for generating QZS characteristic for isolating vertical vibrations [13], [14], [15], [16], torsional vibrations [6], [17], and for adaptive pneumatic vibration isolator [1]. Other negative stiffness elements, such as bio-inspired structures [18], [19] and electromagnetic structures [20], [21], [22], were investigated for generating QZS feature. Recently, metamaterials and origami structures were also applied to achieve the QZS characteristics [23], [24], [25], [26], [27].
The QZS system can be divided into two types; the passive type and the semi-active (or active) type [28], [29], [30]. Passive QZS isolators have simple structures but require precise combination of the positive stiffness and negative stiffness structures. Few passive QZS systems were discussed for mitigation of vibrations of multiple degree-of-freedom (DOF) systems. A three-DOF QZS system was developed by applying the symmetrically scissor-like structures [31], to achieve the vibration isolation in both vertical and horizontal directions. Two six-DOF isolation platforms were designed by assembling multiple QZS struts to form either a pyramidal platform [14] or a hexapod platform [15]. The QZS strut used in both isolation platforms was constructed based on the cam-roller-spring mechanism. A Stewart isolator using multiple QZS struts was also proposed to realise high-static-low-dynamic stiffness in each single-DOF system of six directions [32]. Several QZS vibration isolators were used for isolating vibrations in multiple directions [3], [33], [34], but the interaction between the DOFs was seldom discussed. A torsion–translational QZS isolator was recently proposed and two independent excitations were considered in two DOF systems [6]. The interactions of the vibrations induced by these two excitations were discussed.
Compared to one-DOF QZS isolators proposed for practical engineering applications, such as vehicle seat [35] and transport incubator [36], an integrated translational-rotational QZS vibration isolator is proposed in this paper to isolate the vibrations in two directions simultaneously. The high-static-low-dynamic stiffness characteristics can be provided in two DOFs, not only in the translational direction, but also in the rotational direction. The workable range of the QZS system and its limitations are numerically identified by studying the static responses and the physical connection conditions. Typical nonlinear dynamic responses are theoretically discussed by considering the external excitations in both translational and rotational directions, which are independent but with dynamic interactions of their responses generated. The jump-down frequencies for small-amplitude oscillations are determined from their amplitude-frequency relationships. Furthermore, the force transmissibility and moment transmissibility of the QZS system are compared with those of the corresponding linear system (i.e. the system without incorporating the cam-roller mechanism), which clearly demonstrate better isolation performance in both translational and rotational DOFs.
This paper is organized as follows. Section 2 presents the theoretical model of the proposed QZS system and studies its static characteristics. Section 3 numerically discusses the nonlinear dynamic behaviour with jump phenomena under two independent excitations. Section 4 investigates the effects of the design parameters on the isolation performance of the QZS system. Concluding remarks are summarized in Section 5.
The relationship between the response force and moment generated from the QZS system, the vertical motion y, and the rotational motion θ of the platform can be derived according to the geometrical relations of the structure. The resultant displacement of cam (roller side) in the vertical direction due to the motion of the platform can be found according to Fig. 1(b) as:(1)yt=y+Lsinθ

For the corresponding linear system without the cam-roller structure, the resultant force and moment produced from the spring deformations can be expressed as:(2a)Flinear=2kly
(2b)Mlinear=2dv2klsinθ

For the proposed QZS system, due to the displacement of the cam and the relative motion of the cam and roller, the roller will be pushed by the horizontal spring, and the force in the horizontal direction is given by:(3)Fh=khδ-Δxrwhere δ represents the per-compression of the horizontal spring, Δxr=r+R+L-Pr, is the roller’s relative displacement in the horizontal direction, and Pr=r+R2-yt2+Lcosθ, is the distance of geometric centre of the roller to the mass centre of the platform.
The resultant force from the cam-roller structure in the vertical direction and the resultant moment about the mass centre of the platform can be calculated as:(4a)FN=-N×FrRsinϕ
(4b)MN=N×FrR×Prsinϕ=FN×Prwhere FrR=khδ-r+R+L+Prsinϕ is the interaction force between the roller and the cam, ϕ is the angle between the line connecting the geometric centres of the cam and roller and the horizontal axis. From Fig. 1(b), it can be obtained that sinϕ=y+Lsinθr+R2-y+Lsinθ2.
By introducing the non-dimensional form of parameters and substituting Eq. (1) and Eq. (3) into Eq. (4), the resultant force in the vertical direction and the moment acting on the platform can be expressed as:(5a)F-=2y--αδ_-1+L-+1-y-+L-θ2+L-1-θ2y-+L-θ1-y-+L-θ2
(5b)M-=2dv-2θ-αδ_-1+L-+1-y-+L-θ2+L-1-θ21-y-+L-θ2+L-1-θ2y-+L-θ1-y-+L-θ2where y_=yR+r,F-=Fkl(R+r),α=khkl,L-=LR+r,δ_=δ(R+r),M-=MR+r2kl,dv-=dvR+r, and here it has been assumed that θ is small by considering small amplitude vibrations, thus sinθ≈θ.
Differentiating Eq. (5a), (5b) with respect to the vertical displacement or angular displacement yields the translational stiffness and the torsional stiffness:(6a)k-v=2+αy-+L-θ21-y-+L-θ2-αy-+L-θ21-y-+L-θ232δ--1+L-+1-y-+L-θ2+L-1-θ2-αδ--1+L-+1-y-+L-θ2+L-1-θ21-y-+L-θ2
(6b)k-r=2dv-2-αy-+L-θ-L-θ1-θ2-L-y-+L-θ1-y-+L-θ21-y-+L-θ2+L-1-θ21-y-+L-θ2-αδ--1+L-+1-y-+L-θ2+L-1-θ2y-+L-θ-L-θ1-θ2-L-y-+L-θ1-y-+L-θ21-y-+L-θ2-αδ--1+L-+1-y-+L-θ2+L-1-θ2L-y-+L-θ21-y-+L-θ2+L-1-θ21-y-+L-θ232-αδ--1+L-+1-y-+L-θ2+L-1-θ2L-1-y-+L-θ2+L-1-θ21-y-+L-θ2

To impose the QZS conditions concurrently in both directions, let k-v,k-r=0,0 represent the system stiffness at the equilibrium position, y-,θ=0,0, then the zero-stiffness characteristics can be rewritten from Eq. (6a), (6b) as(7a)αδ-=2
(7b)αδ-L-L-+1=2dv-2

To meet the QZS requirement, the non-dimensional parameters α,δ-,L- and dv- should satisfy the relationships given by Eq. (7a), (7b). In engineering applications, these parameters can be flexibly adjusted to determine the system stiffness k-v,k-r in both directions. However, it should be noted that the parameters could affect the size of the effective region of the QZS characteristics. The cam-roller mechanism would only be achieved when the cam and roller remain in contact, which is referred to here as the engagement region. While in disengagement region, the QZS system will return to a linear system condition and become a linear vibration isolator (with only two main springs supporting the platform).
The response force and moment corresponding to the translational and rotational motions are illustrated in Fig. 2
. It is easy to notice from the figure that both force and moment loads near the equilibrium position 0,0 have a typical QZS characteristic. However, when away from the equilibrium position, the system stiffness would change according to its motion condition y-,θ. In this regard, the system stiffness in the translational and rotational directions are of interest for the QZS system. The stiffness ratio of the stiffness in the translational and rotational directions of the QZS system to the corresponding linear system is shown in Fig. 3
by means of the contour maps. Only when the ratio is less than 1, which means the QZS system stiffness is lower than that of the linear system, the proposed QZS system can have better isolation performance than the corresponding linear system in the lower frequency range. This requirement can be easily satisfied by properly designing the system parameters.
In order to keep the cam and roller in contact and gain the physical insights to make the system workable, the absolute displacement of the cam in the vertical direction should be not larger than the sum of the cam and roller radius, which can be expressed as:(8)yt=y+Lsinθ≤R+r

By imposing the QZS condition, the upper and lower limits of the equilibrium position due to the translational and rotational motion of the platform are shown in Fig. 4
, where both engagement and disengagement regions are labelled. The influence of the design parameter dv- on the engagement region is also shown. The engagement region of the system becomes larger when reducing dv-.
In order to investigate the dynamical behaviour of the proposed QZS system, analytical approximated solutions for the force and moment generated are simplified by using Taylor series expansion for the two-DOF system with keeping up to the third-order about the equilibrium position (0,0), which are succinctly written as:(9a)F-(y,θ)(3)=λ1+λ2y-+λ3y-2+λ4y-3+Oy(4)
(9b)M-(y,θ)(3)=γ1+γ2θ+γ3θ2+γ4θ3+Oθ(4)whereλ1=-αLδ-θ+12αL21+L-Lδ-θ3+Oθ4
λ2=2-αδ-+12αL1+3L-3Lδ-θ2+Oθ4
λ3=32αL1-δ_θ+34αL21+5L-5Lδ-θ3+Oθ(4)
λ4=12α1-δ-+14αL1+15L-15Lδ-θ2+Oθ4
γ1=-αδ-(1+L)y-+12α1+L-Lδ-y-3+Oy4
γ2=2dv-2-Lαδ--L2αδ-+32αL1+L-Lδ_y-2+Oy4
γ3=12αL1+4L+3L2+δ--3L2δ-y-+14αL-1+6L+15L2+δ--15L2δ-θ3+Oy(4)
γ4=12αL21+2L+L2+δ--L2δ-+14αL2-3+8L+15L2+3δ--15L2δ-y2+Oy4and Oy4,Oθ4 present the higher order components.
The exact values and approximated values of the force and moment corresponding to different translational and rotational conditions are shown in Fig. 5
(a) and (b), respectively. By using the difference between the exact and approximation values over the exact value, the relative fitting errors for the force and moment are shown in Fig. 6
by means of the contour maps. It is easy to observe from the figure that the relative fitting error of the response force has a narrow range when θ=0, meanwhile the relative fitting error of the response moment has a narrow range when y=0. It should be mentioned that the Taylor series expansion is only valid when both translational and rotational vibrations are small. Thus the motions within a low relative fitting error range (normally less than 5%) are simulated for dynamic analysis.
It is worth noting that the workable ranges of the proposed QZS vibration isolator should take into account all the limitations including the system stiffness, the engagement region, and the relative fitting error for analysis issue. By implementing the limitations due to effective stiffness range, as shown in Fig. 4, and the relative fitting error caused by Taylor series expansion, as shown in Fig. 6, only the scenario that the motions fall within a specified range will be considered and discussed in the following sections, that is, y-≤±0.2 and θ≤±0.05.
The dynamic behaviours of the coupled translational-rotational QZS system are investigated in this section. It is assumed that a desired payload is located at the mass centre of the platform, and the platform is at its equilibrium position when no external excitations are applied. The payload mass and its moment of inertia about the axis passing through the mass centre of the platform are m and I, respectively. The equivalent harmonic force and moment are applied to the mass centre of the platform due to the external excitations applied to the base of the platform. The equations of motion of the two-DOF QZS system can be established by applying Newton’s second law of motion as:(10a)my¨+cyy˙+Fv=Fecos(ωvt+φv)
(10b)Iθ¨+crθ˙+M=Mecos(ωθt+φθ)where cyand cr are the damping coefficients, Fe,ωv,φv and Me,ωθ,φθ are the amplitudes, frequencies and initial phases of the external excitations in the transitional and rotational directions, respectively. Symbols y¨,y˙,θ¨and θ˙ denote the differentiations with respect to the time t.
By introducing the non-dimensional notations, Eqs. (10a), (10b) can be rewritten as:(11a)y-¨+2ξvy-˙+F-=Fe-cos(Ωvτv+φv)
(11b)θ-¨+2ξθθ-˙+M-=Me-cos(Ωθτθ+φθ)where ωnv=klm,ωnθ=R+r2klI,ξv=cy2klm,ξθ=cy2R+r2klI,F-=FklR+r,M-=MR+r2kl,Fe-=FeklR+r,Me-=MeR+r2kl,y-¨=y¨R+rωnv2,y-˙=y˙R+rωnv,θ-¨=θ¨ωnθ2,θ-˙=θ˙ωnθ,Ωv=ωvωnv,Ωθ=ωθωnθ,τv=ωnvt, and τθ=ωnθt.
Since the corresponding linear system without the cam-roller structure uses a two-spring set for isolating vibrations in both translational and rotational directions, the natural frequency of the linear system is different from a typical one-spring system. According to the system parameters, Eq. (2a), (2b), the natural frequency of the corresponding linear system in the translational and rotational directions can be calculated as 2Ωv and 2dv-Ωθ, respectively.
The Harmonic Balance Method is used to solve Eq. (11a) and Eq. (11b). The solutions to these equations are assumed to be:(12a)y=Avcos(Ωvτv)
(12b)θ=Aθcos(Ωθτθ)where Avand Aθ are the amplitudes of the vibration response in the transitional and rotational directions, respectively.
Substituting the solutions Eqs. (12a), (12b) into Eqs. (11a), (11b), and replacing the force and moment expressions of Taylor series expansion Eqs. (9a), (9b), yields:(13a)-Ωv2AvcosΩvτv-2ξvΩvAvsinΩvτv+F-AvcosΩvτv,AθcosΩθτθ=Fe-cosφvcosΩvτv-Fe-sinφvsinΩvτv
(13b)-Ωθ2AθcosΩθτθ-2ξθΩθAθsinΩθτθ+M-AvcosΩvτv,AθcosΩθτθ=Me-cosφθcosΩθτθ-Me-sinφθsinΩθτθwhere F-AvcosΩvτv,AθcosΩθτθ=α1+α2Aθ2Av+α3+α4Aθ2Av3cosΩvτv,α1=2-αδ-,α2=12αL1+3L-3Lδ-,α3=38α1-δ-,α4=316αL1+15L-15Lδ- and M-(AvcosΩvτv,Aθcos(Ωθτθ))=β1+β2Av2Aθ+β3+β4Av2Aθ3cosΩθτθ, β1=2dv-2-Lαδ--L2αδ-,β2=32αL1+L-Lδ-,β3=38αL21+2L+L2+δ--L2δ-,β4=316αL2-3+8L+15L2+3δ--15L2δ-.
It should be noted that by considering a small-amplitude periodic motion about the equilibrium position, the coefficients of the trigonometric functions cosΩvτv and sinΩvτv on both sides of Eq. (13a), and cosΩθτθ and sinΩθτθ on both sides of Eq. (13b) should be equal, which leads to the following resultant equations:(14a)-Ωv2Av+α1+α2Aθ2Av+α3+α4Aθ2Av3=Fe-cosφv-2ξvΩvAv=-Fe-sinφv
(14b)-Ωθ2Aθ+β1+β2Av2Aθ+β3+β4Av2Aθ3=Me-cosφθ-2ξθΩθAθ=-Me-sinφθ

From Eqs. (14a), (14b), the initial phase of the resultant excitations can be obtained as:(15a)tanφv=2ξvΩvα3+α4Aθ2Av2+α1+α2Aθ2-Ωv2
(15b)tanφθ=2ξθΩθβ3+β4Av2Aθ2+β1+β2Av2-Ωθ2

Squaring both sides of Eqs. (14a), (14b), and then adding the resultant equations, leads to the amplitude-frequency equations as:(16a)Ωv4-2C11Ωv2+C12=0
(16b)Ωθ4-2C21Ωθ2+C22=0where C11=α1+α2Aθ2-2ξv2+α3+α4Aθ2Av2,C12=α1+α2Aθ22+2α1+α2Aθ2α3+α4Aθ2Av2+α3+α4Aθ22Av4-Fe-2Av2,C21=γ2+34Aθ2γ4-2ξθ2, and C22=Aθγ2+34Aθ3γ42-Me-2Aθ2.
Solving the quadratic equations of Ωv and Ωθ gives rise to(17a)Ωv1,2=C11±C112-C12
(17b)Ωθ1,2=C21±C212-C22

The maximum transitional amplitude Av and rotational amplitude Aθ would appear when Ωv1=Ωv2 and Ωθ1=Ωθ2 i.e.(18a)C112-C12=0
(18b)C212-C22=0

Eqs. (16a), (16b) can be used to obtain typical nonlinear resonance curves with stable and unstable regions, which are also known as jump phenomenon. The jump-down frequency can be calculated by substituting the maximum transitional amplitude Av and rotational amplitude Aθ into Eqs. (17a), (17b), respectively.
The transitional force and rotational moment responses can be determined by(19a)Ft-t=2ξvy-˙+F-AvcosΩvτv,AθcosΩθτθ≈α1+α2Aθ2Av+α3+α4Aθ2Av32+2ξvΩvAv2cosΩvτv+ϕv
(19b)Mt-t=2ξθθ-˙+M-AvcosΩvτv,AθcosΩθτθ≈β1+β2Av2Aθ+β3+β4Av2Aθ32+2ξθΩθAθ2cosΩθτθ+ϕθwhere tanϕv=2ξvΩvAvα1+α2Aθ2Av+α3+α4Aθ2Av3 and tanϕθ=2ξθΩθAθβ1+β2Av2Aθ+β3+β4Av2Aθ3.
According to the definition of transmissibility, the force transmissibility and moment transmissibility of the QZS system can be calculated as:(20a)Tv=α1+α2Aθ2Av+α3+α4Aθ2Av32+2ξvΩvAv2Fe-
(20b)Tθ=β1+β2Av2Aθ+β3+β4Av2Aθ32+2ξθΩθAθ2Me-

The numerical solution of the nonlinear amplitude-frequency relationship can be solved from Eqs. (16a), (16b) to investigate the dynamic behaviour of the proposed QZS system. However, some characteristics of the nonlinear behaviour, such as jump-down frequency and large amplitude excitations, cannot be captured in the semi-analytic solutions by using the Harmonic Balance Method. The transitional force response and rotational moment response with respect to the frequencies of the excitations applied within a workable regions are shown in Fig. 8
. Since the excitations in the translational and rotational DOFs are considered to be dynamically coupled, two jump phenomena can be found in the amplitude-frequency response curves, which represent the coexistence of stable and unstable solutions. Fig. 8(a) shows that the secondary jump-down frequency of the force response is decreased when the frequency of the rotational excitation is increased.
Under different excitation amplitudes, it can be found that for the translational response as shown in Fig. 9
(a–c), the primary jump-down frequency is induced by the translational excitation and the secondary jump-down frequency is generated by the rotational excitation. While for the rotational responses as shown in Fig. 9(d–f), the primary jump-down frequency is caused by the excitations in both DOFs meanwhile the secondary jump-down frequency is mainly induced by the translational excitation, which is hard to be recognised from the figure as it is too small.
The unstable regions of the translational and rotational responses with respect to the excitation frequencies are illustrated in Fig. 10
. Since the responses in both DOFs are mutually coupled, the unstable region of the QZS system should be combined by integrating Fig. 10(a) and (b). As shown in Fig. 9(a–f), the small-amplitude oscillations of the QZS system in both DOFs appear immediately after the primary jump-down, which means the QZS system can attenuate vibrations only in the upper right corner of the excitation frequency region as shown in Fig. 10(a) and (b).
From Fig. 8, there are coupled effects under different excitation frequencies in both DOFs. The force and moment transmissibility of the proposed QZS system are calculated and compared with those of the corresponding linear system by removing the cam-roller structure as shown in Fig. 11
(a) and (b). As the undesirable vibration of the QZS system in the unstable regions is not of interest to vibration isolation, only the force and moment transmissibility in the stable regions (after jump-down frequencies) are discussed in this section. For the force transmissibility, as illustrated in Fig. 11(a), the variation of the rotational excitation frequency has an insignificant effect on the vibration in the translational direction. On the contrary, for the moment transmissibility, as illustrated in Fig. 11(b), the variation of the translational excitation frequency has a significant influence on the rotation performance of the system, not only on the isolation performance but also on its bandwidth. Overall, it indicates that the proposed translational-rotational QZS system could have significant improvement on the isolation performance in the lower frequency range than the corresponding linear system, where the linear system would demonstrate vibration isolation only after 2 times of its natural frequency. Additionally, different damping ratios are also simulated and presented in Fig. 12
(a–f). An increase of the damping ratio in both DOF systems can generally improve their vibration isolation performances.
According to Fig. 10 and Eqs. (20a), (20b), the force transmissibility and moment transmissibility of the translational and rotational DOFs under different excitation conditions are illustrated in the contour maps, as shown in Fig. 13
, in which different colours indicate the amplitude levels of the transmissibility and the blank (white) area implies the system transmissibility is higher than 1. Since the QZS characteristic is mainly effective in the low frequency range, only the frequency ranges of interest are displayed. The colour change of the texture patterns shown in the figures illustrates that the transmissibility varies nonlinearly according to the excitation frequencies.
In this paper, a coupled translational-rotational QZS vibration isolator has been proposed by using the cam-roller mechanism, which includes two main support springs, one unsymmetric cam-roller structure and motion restriction structure on its platform. The proposed QZS system has been proved to be able to provide the high-static-low-dynamic stiffness simultaneously in the translational and rotational directions.
The static characteristics of the nonlinear QZS vibration isolator were numerically identified by considering the structure limitation and system stiffness. The quasi-zero stiffness condition was ensured about the equilibrium position in both translational and rotational directions. Engagement region of the cam-roller structure and the effective QZS region were discussed under different system parameters. Subsequently, the equations of motion of the proposed QZS system were established as a two-DOF nonlinear system. Excitations in both translational and rotational directions were applied to study the dynamic behaviour of the two-DOF QZS nonlinear system. Both excitations were considered to be independent but with interactions between the responses they induced to the system. By using the Harmonic Balance Method, typical nonlinear dynamic responses with jump phenomena were theoretically discussed and two jump-down frequencies were determined from the amplitude-frequency relationships. Furthermore, the force and moment transmissibility of the QZS system were compared to those of the corresponding linear system without the cam-roller structure, to clearly demonstrate the desired isolation performances in the low frequency range in both translational and rotational directions.
A prototype of the proposed QZS isolator will be fabricated and the validation of the theoretical results will be conducted in our future work. Due to the COVID-19, the fabrication of the prototype has been significantly delayed.
This work was partially supported by the Coal Services Health & Safety Trust (CSHST) through project 20651.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Mech Syst Signal Process
PMC7552984,"The impact of the COVID-19 pandemic on subjective mental well-being: The interplay of perceived threat, future anxiety and resilience","Mental well-being is necessary for society's effective functioning (Tennant et al., 2007). In a state of well-being, individuals can cope with the traditional stress of life, be productive, and contribute to their community (Surya et al., 2017). Previous research has stated that unexpected events, such as pandemics or natural disasters, produce significant emotional effects on people, that are detrimental to their mental well-being (e.g., Folkman & Greer, 2000; Maunder et al., 2003). Recent research indicates that the circumstances surrounding the Covid pandemic (e.g., social distancing, isolation, uncertainty, fear, etc.) increase stress-related symptoms, affecting mental well-being (Duan & Zhu, 2020; Satici et al., 2020). For instance, individuals reported higher levels of depression, anxiety (Roy et al., 2020), post-traumatic stress (Liu et al., 2020), frustration, isolation (Giallonardo et al., 2020), anger-hostility, and sadness-depression (Pérez-Fuentes et al., 2020).
Relevant for its impact on mental well-being is less the objective than the perceived threat level. In the case of diseases, threat perception is influenced by a number of factors, including the likelihood of vulnerability or contagion and the harshness of the changes produced by the disease in case of infection (Pérez-Fuentes et al., 2020). Perceived threat has been related to higher levels of worry (Berenbaum et al., 2007). Individuals who experience a higher threat perception therefore experience a greater risk to face detrimental consequences on subjective mental well-being. In the Covid case, threat perception is related to the individuals' perceptions of how COVID-19 may produce an undesirable outcome which may cause negative consequences in their life. Also, individuals have been shown to experience fear due to the perceived Covid threat that may harm their mental health (Usher et al., 2020; Garfin et al., 2020; Killgore et al., 2020; Lima et al., 2020). Thus, we expect that the more severe the threat from Covid is perceived, the more negatively affected will be an individual's mental well-being.Hypothesis 1The degree of perceived threat of Covid has a negative effect on subjective mental well-being.

The changes and uncertainty provoked by the pandemic and the measures implemented (e.g., quarantining, wearing a protective mask, social lockdowns; Montemurro, 2020) have a profound psychological impact on the population's mental well-being, causing an increase in stress, depression, anxiety, and suicidal ideation (Garfin et al., 2020; Killgore et al., 2020; Lima et al., 2020). In addition, mass media communication may provide information that leads to confusion and uncertainty, magnifying the emotional distress (Han et al., 2018; Usher et al., 2020).
Previous research on significant outbreaks (e.g., pandemics, natural disasters, terrorist attacks) has demonstrated that the psychological effects remain years after the incident (Blackmon et al., 2017; Bonanno et al., 2008). Individuals may be affected by future negative thinking undermining their mental well-being (Holman & Silver, 2005). COVID-19 has increased individuals' worries about their present and future situations (Giallonardo et al., 2020; Usher et al., 2020) since there is not a known end to the crisis, and its effects cannot be controlled (Liu et al., 2020). Traumatic events such as COVID-19 remind individuals of the possibility of death, generating anxiety as a common response to a stressful situation (Roy et al., 2020). Potential economic and social problems (e.g., unemployment, risk of infection, economic collapse) from the pandemic may encourage anticipatory fear. Individuals are concerned about unfavorable changes to their future state. Therefore, we expect that the perceived threat of COVID-19 will increase future anxiety, which, in turn, will have a negative impact on subjective mental well-being:Hypothesis 2The degree of perceived threat of Covid has an indirect negative effect on subjective mental well-being mediated by its positive effect on future anxiety.

Resilience has been acknowledged as a complex construct since it can be viewed as a trait, a process, or an outcome (Agaibi & Wilson, 2005), which may be determined by different biological, cultural, social, and psychological factors that regulate how individuals cope with stressful events at different situations across multiple domains of life (Southwick et al., 2014). It may vary according to an individual's development and interaction with the environment (Kim-Cohen & Turkewitz, 2012).
Resilience plays an important role in overcoming the adverse effect of stressful situations. For instance, in the sports domain, where athletes have to overcome difficult challenges to become successful, resilience allows individuals to adapt to adverse conditions (e.g., Hill et al., 2018). Previous research has shown that when facing stressful or adverse situations, resilient individuals tend to experience lower levels of depression or anxiety, have the ability to recover more quickly to pre-crisis stages, and arrive at a pre-stress baseline more quickly (Luthar et al., 2000). Resilience reduces the negative mental consequences caused by disasters or stressful events (e.g., Blackmon et al., 2017; Osofsky et al., 2011). Following Connor and Davidson (2003), this study understands resilience as a self-perceived trait that enables individuals to cope with adversity or stressful life events.
Resilience may help people cope with adversity and reduce the negative impact of traumatic events on mental health (Osofsky et al., 2011). It has been positively related to mental well-being (e.g., Arslan, 2019). Research has recently identified resilience as a strategy to cope with the mental health challenges derived from COVID-19 (Prime et al., 2020). For instance, in a study performed on U.S. adults, Killgore et al. (2020) found that higher scores in resilience were related to lower levels of worry about COVID-19 effects. Likewise, individuals with less resilience expressed greater difficulty in coping with the situation's emotional challenges. Therefore, we expect that the indirect effect of the perceived threat of COVID-19 on mental well-being, mediated by future anxiety, will be weaker for individuals with higher levels of resilience and greater for individuals with lower levels of resilience:Hypothesis 3The indirect effect of the degree of perceived threat of Covid on subjective mental well-being through activating future anxiety is moderated negatively by the individual's degree of resilience.

The theoretical model is represented in Fig. 1
.
The study was conducted between the 15 and 20 of June 2020 during a severe lockdown measure which was initiated one week before the invitation mail was sent. Residents of the interviewed area were allowed to leave their home only for essential activities such as purchasing food, visiting a doctor, or work in essential economic sectors that could not be conducted online. According to the National Health Institute, in the corresponding region, at the moment of the study, there were 46.028 active cases with 1289,5 cases per 100.000 individuals. For the data collection, an invitation email with a link to an online questionnaire was sent to a database of 19,000 undergraduate and postgraduate students of a major public university. The invitation email was sent from the university communication management through the official communication channel of the institution. The invitation explained the overall aims of the study and data treatment. Participants had to give informed consent before accessing the main questionnaire. The study received ethical approval. Through the online platform SurveyMonkey, 711 valid questionnaires were received (43.9% female, 56.1% male, Mage = 21.60; SD = 4.72). The age of participants ranged from 18 to 49 years (18–20, 39.5%, 21–25: 43.6%, 26–30: 11.4%, 31–49: 5.5%); 71.7% were undergraduate and 28.3% postgraduate students. The low response rate of 4% can be explained by the fact that participation in the survey was voluntary without incentive, and only one invitation without a follow-up message was sent. Participants responded to the online questionnaire, assessing their perception about the threat of COVID-19, their future anxiety, subjective mental well-being, and their level of resilience as a personality trait.
The analyzed variables were assessed with validated measurement scales stemming from the literature. The measure for the perceived threat of COVID-19, assessed on four items with 7-point scales ranging from not at all = 1 to very much = 7, was adapted from Tyler and Cook (1984) by specifying the Covid pandemic as the threat concept mentioned in the four items of the scale. Respondents were asked to indicate how information on the COVID-19 pandemic they had received from television news, the internet, and newspapers had made them concerned about the threat, the spread, the severity, and the impact of the pandemic on their lives. To assess the individuals' future anxiety, we used Zaleski's (1996) scale. Participants rated six items on a 7-point Likert-type scale (1 = strongly disagree; 7 = strongly agree). Subjective mental wellbeing was assessed on ten items of the Positive and Negative Affect Schedule (PANAS; Watson et al., 1988) as used in prior research (Adler & Fagley, 2005; Mackinnon et al., 1999). Participants were instructed to indicate what they felt was their dominant overall mood or feelings state recently, rating the following five positive and five negative affective items on scales ranging from 1 (not at all) to 7 (extremely so): relaxed, alive and full of energy, stress-free, confident, happy, sad, anxious, lonely, vulnerable, and fragile. To measure resilience as a personality trait, we used nine items from Connor and Davidson's (2003) scale. We asked participants to indicate the traits they believed fit their way of being or their personality. Participants rated each item on a 7-point Likert-type scale (1 = not at all; 7 = extremely so). All measurement items and their properties are displayed in Table 1
. Cronbach's alpha confirmed the reliability of all the scales.
A correlation analysis (Table 2
) confirmed a significant positive relationship between the perceived threat of the COVID-19 pandemic and future anxiety (r = 0.212, p < .01) and a significant negative relationship between future anxiety and subjective mental well-being (r = −0.553, p < .01). Results also confirmed a significant negative relationship between the perceived threat of COVID-19 and subjective mental well-being (r = −0.137, p < .01), providing support for H1.
Mediation analysis of indirect effects using Hayes' (2013) PROCESS with 10,000 bootstrap samples and bias-corrected bootstrap confidence intervals (Hayes, 2013), confirmed that the effect of the perceived Covid threat on subjective mental well-being was mediated by future anxiety (bind = −0.13, Boot SE = 0.02, 95% Boot CI [−0.18, −0.08]), providing support for H2. The mediation was complete with the remaining direct effect being nonsignificant (b = −0.023, SE = 0.03, t = −0.66, p = .51).
Moderated mediation analysis with PROCESS of the moderating effect of resilience on the former relationship revealed a significant moderated mediation index (10,000 bootstrap samples; bmodmed = 0.052, SE = 0.02, 95% Boot CI [0.02, 0.09]). Therefore, the results confirmed that the indirect effect of the perceived threat of the pandemic on mental well-being through future anxiety was moderated by the level of resilience, providing support for H3. Table 3
and Fig. 2
present the pattern of moderation at different values of the moderator resilience.
The findings of our study contribute to the understanding of the antecedents of mental well-being during a pandemic and, specifically, during the COVID-19 outbreak. To provide adequate mental health interventions, it is necessary to understand the impact of the pandemic on mental well-being (Giallonardo et al., 2020). Our results confirmed that the pandemic's perceived threat generates uncertainty and fear, increasing stress and vulnerability, which, in turn, has a detrimental impact on subjective mental well-being. Furthermore, the mediating effect of future anxiety provides evidence on how the perceived threat also activates individuals' worries for their future situation, leading to the experience of negative perceptions about future consequences. These findings support the results of previous research on significant viral outbreaks and their detrimental consequences for mental well-being (e.g., Folkman & Greer, 2000).
Prior research has assessed the role of social support, social isolation, loneliness, prior history of trauma, and prior mental health history, among other factors affecting wellbeing during a pandemic (Keshavan, 2020; Pappa et al., 2020). Our findings add to this literature by providing a process explanation based on the mediating effect of future anxiety. Furthermore, the results support the findings of recent studies that proposed adverse effects on mental health from the circumstances surrounding COVID-19 (e.g., Garfin et al., 2020; Usher et al., 2020).
Further findings of this study indicate that resilience moderates the indirect influence of the perceived threat on mental well-being through future anxiety. Individuals with higher levels of resilience were less susceptible to the harmful effects of the perceived threat of COVID-19 on subjective mental well-being through the activation of future anxiety. This finding implies that resilience, as a personality trait, prepares individuals to cope with the pandemic's adverse effects. Individuals with higher levels of resilience reported lower levels of future anxiety and, in turn, lower effects on subjective mental well-being, experiencing greater success in coping with the emotional distress provoked by the pandemic. This result is consistent with research that analyzes the importance of resilience in coping with adversities, such as the negative mental health impact of disasters (e.g., Blackmon et al., 2017; Osofsky et al., 2011). Taha et al.'s (2014) study on emotional reactions to the health threat of pandemic outbreaks showed that appraisals of the threat, control, and the use of emotion-focused coping mediate the psychological impact of the physical threat of a pandemic, and that uncertainty moderates the effect on anxiety regarding the pandemic. Our confirmation of the moderating influence of resilience on the impact of threat perception on future anxiety adds resilience as a further variable to this perspective.
COVID-19 has been considered one of the recent outbreaks with the greatest psycho-social impact, requiring in the cases of many individuals the implementation of mental health interventions to improve psychological well-being. The literature has identified different strategies to strengthen individual resilience. For instance, there is evidence that mindfulness as a trait—the disposition to pay attention to the present moment—, positively links with resilience (Garland et al., 2011; Zarotti et al., 2020). This mindfulness trait can be increased through mindfulness-based interventions, leading to mental health benefits (Kiken et al., 2015). Specifically, in the context of pandemics, recent literature has documented the benefits of digital mindfulness-based interventions (Mrazek et al., 2019). Digital platforms may serve as alternatives to continue with social support and contact with family and friends, elements that promote resilience (Polizzi et al., 2020). In addition, there is also evidence that exercise, better sleep, and spiritual health also enhance resilience (Killgore et al., 2020).
Implementing public measures and plans to respond to mental health issues can help to reduce the perceived threat and future anxiety generated by the pandemic. Governments should promote clear communication strategies because social media consumption and news outlets may provide confusing information, increasing fear and anxiety. Communication campaigns should promote messages encouraging preventive actions to avoid the spread of the virus. Messages should be concise and focused on practical ways to reduce risk and create tranquility in the population (Wang et al., 2020). During and in the aftermath of the pandemic, as “telehealth” services have proven to be similar in effectiveness as in-person services (Golberstein et al., 2020), it is essential to open communication channels through digital media to provide mental health services, such as medication management or assessment.
The present study has a number of significant limitations. The study was based on a cross-sectional data collection, carried out at a point in time during the pandemic; therefore, conclusions about long-term effects cannot be inferred. Our study also did not evaluate the previous mental health conditions of the participants. Future research should implement longitudinal studies to evaluate changes in mental health due to the evolution of the pandemic. Further studies may also include experimental and observational designs to measure actual behavior during the pandemic (Bish & Michie, 2010).
As a complementary explanation to the proposed model, it is also feasible that individuals with a higher level of well-being may perceive the perceived Covid threat as less severe and also experience less future anxiety. Since this research is cross-sectional, the directionality of the causality of effects cannot be established empirically, but only based on theory. Based on the data alone, an inverse effect would potentially also be feasible, as well as a bi-directional interrelationship of these three constructs. Future research should further address the directionality of effects with experimental studies manipulating the dependent variable perceived threat.
Furthermore, the data collected are based on a student sample, which may cause a bias in the findings. Our sample represents a part of the population who has access to higher education and the internet; therefore, caution must be taken about the generalizability of the results. Future research should include different populations who may not have access to this level of education or technology, and who may also be at greater risk of mental well-being issues. Since most participants (83,1%) were centered in the age group between 18 and 30 years we have not provided an age-related group assessment. Future research should extend the study to a wider age group with the aim to analyze the observed pattern of effects in different sub-groups. In addition, future research should assess the role of further mediators and moderators of the observed process. Factors like social isolation, intolerance to uncertainty, loneliness, or previous mental health history, may also influence individuals' mental well-being during an outbreak.
Our results provide empirical evidence on the antecedents of subjective mental well-being during COVID-19. The pandemic's perceived threat has a detrimental impact on mental health. This process can be explained by the activation of future anxiety, and it is moderated by resilience as a personality trait. Individuals with higher resilience are less susceptible to the pandemic's negative psychological consequences because they experience a lower increase in future anxiety, compared to individuals with lower levels of resilience. Our findings imply that mental health intervention strategies aimed at strengthening resilience and preventing future anxiety have a significant potential to mitigate the adverse impact on mental well-being of the Covid-19 pandemic itself and the social measures adopted to curb the pandemic.

Mario R. Paredes: Conceptualization, Investigation, Writing - original draft. Vanessa Apaolaza: Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Resources, Software, Supervision, Validation, Visualization, Writing - original draft. Cristóbal Fernandez-Robin: Data curation, Funding acquisition, Investigation, Project administration, Validation. Patrick Hartmann: Data curation, Formal analysis, Funding acquisition, Investigation, Methodology, Resources, Software, Validation, Visualization, Writing - review & editing. Diego Yañez-Martinez: Data curation, Investigation, Project administration, Validation.",Pers Individ Dif
PMC7543707,"Gender, face mask perceptions, and face mask wearing: Are men being dangerous during the COVID-19 pandemic?","To date, the COVID-19 pandemic has resulted in 1,000,000 deaths worldwide (Wood et al., 2020). Because no end to the pandemic is currently in sight, public health officials have called for the widespread adoption of preventative behaviors that can curb the spread of COVID-19. Among the most effective preventative behaviors is face mask wearing, which has been extensively supported to reduce airborne transmission of viruses (Leung et al., 2020; O'Dowd et al., 2020); however, many people are resistant to face mask wearing despite the effectiveness of the practice, which poses extreme risks in the context of the COVID-19 pandemic (Howard, 2020; Lyu & Wehby, 2020). These risks are exponentially heightened as more people refuse to wear face masks, because each unmasked person multiplicatively increases the likelihood of infecting each other (Howard et al., 2020). For these reasons, it is important to understand the antecedents of face mask wearing that can identify avenues to encourage the practice.
Many popular press authors have suggested that men are less likely to wear face masks than women (Haischer et al., 2020; Vershbow, 2020).1
Men are known to engage more in risky active health behaviors2
than women, such as smoking, drinking, and drug use (Finucane et al., 2000; Hughes et al., 2016; Minugh et al., 1998), but men and women are known to engage in similar amounts in passive health behaviors, such as vaccinating and presenteeism (Flanagan et al., 2017; Miraglia & Johns, 2016). Some limited research also supported that men and women reported similar face mask wearing willingness and behaviors surrounding the SARS pandemic (Barr et al., 2008; Bish & Michie, 2010; Brug et al., 2004), but such preventative measures were not formally recommended by most governments during this time and such gender differences would be difficult to observe due to low base-rates (Hair et al., 2019). In is therefore unclear whether men would indeed be less likely to wear face masks during the COVID-19 pandemic. To aid in understanding the relation of gender and face mask wearing, we investigate face mask perceptions due to their pivotal role in behavioral decision making (Ajzen, 1991).

Howard (2020) recently developed the eight-dimension face mask perception scale (FMPS) and supported that face mask perceptions are important in understanding face mask wearing. We stress the relevance of gender to two perceptions. First, one of Howard's (2020) eight face mask dimensions is the perception that face masks infringe upon the wearer's independence. Desires for independence are deeply integrated into notions of masculinity within Western societies, such that men are conditioned to even resist help from others (Smith et al., 2007). Some authors have argued that the extreme demand for independence is a central aspect of toxic masculinity (Jones et al., 2019), and we therefore expect men to have stronger perceptions of face masks infringing upon independence. Second, popular press outlets have also suggested that women find face masks less comfortable then men (Porterfield, 2020; Pugh, 2020). Many face masks are designed to be worn by both men and women (e.g., one-size-fits-all), but their sizes may be too large for most women. For this reason, women may have a worse perception of comfort regarding face masks. Lastly, due to the integral relation of perceptions and behaviors (Ajzen, 1991), we suggest that face mask perceptions mediate the relation of gender and face mask wearing. We do not propose a firm hypothesis regarding the direction of these indirect effects, as the perceptions are not overwhelmingly associated with masculinity or femininity. Nevertheless, by testing the role of this explanatory mechanism, we provide a more complete depiction of differences in face mask wearing between the genders.
From these efforts, the current investigation poses many benefits for research and practice. First, we identify a potential population (i.e., men) that may be particularly susceptible to not wearing face masks, and future interventions could be created to encourage this population to wear face masks and reduce the spread of COVID-19. Second, the current article assesses several popular press assertions regarding face masks, such as differences between genders and perceptions of women. The current results provide insights regarding the accuracy of these claims and whether they should be used for subsequent investigations or dismissed entirely. Third, if no relation is supported between gender and face mask wearing, then the current results would provide further support that face mask wearing is a passive health behavior – even in the context of the COVID-19 pandemic. Fourth, the FMPS was very recently developed, and the current article can provide further support for the importance of perceptions in understanding face mask wearing. Fifth, by using the FMPS, we identify specific perceptions (e.g., independence, comfort) that can be targeted in interventions to increase face mask wearing in certain populations. Sixth, our results provide insights into theoretical lenses that may be beneficial for the study of face mask wearing (e.g., toxic masculinity; Kupers, 2005) as well as the role of gender in broader models of health behaviors (e.g., COM—B; Michie et al., 2011).
Participants in all three datasets were recruited from MTurk and provided monetary compensation. All surveys included multiple attention checks, and participants were removed from analyses if they failed any. All statistics, including the reported sample sizes below, reflect the sample after removing these participants' responses.

Dataset 1. Participants (Mage = 36.76, SDage = 12.59, 45% female, 85% Western English-speaking countries) enrolled into the study via MTurk on 28 April 2020, provided their demographic information, and answered an item regarding face mask wearing within the past six months (n = 745). One day later, they completed a second survey that included items regarding face mask perceptions (n = 475). Two days after the second survey, they completed a third survey that included an item regarding face mask wearing within the past three days (n = 393).

Dataset 2. Participants (Mage = 36.46, SDage = 11.52, 43% female, 66% Western English-speaking countries) enrolled into the study via MTurk on 3 May 2020 and provided their demographic information (n = 667). One day later, they completed a second survey that included items regarding face mask perceptions (n = 327).

Dataset 3. Participants (Mage = 36.97, SDage = 12.14, 50% female, 86% Western English-speaking countries) enrolled into the study via MTurk on 25 June 2020 and provided their demographic information (n = 567). One week later, they completed a second survey that included measures not discussed in the current article (n = 317). One week after the second survey, they completed a third survey that included items regarding face mask perceptions (n = 251). One week after the third survey, they completed a fourth survey that included items regarding face mask wearing (n = 209).

Gender. Participants were asked to report their gender as “Male” (0), “Female” (1), or “Other”. Those who responded as Other could type their gender. Not enough participants responded as Other to include in analyses, and thereby these responses were removed.

Face mask wearing. The face mask wearing items were slightly different across the three datasets. In Dataset 1, participants were given the following two items: “Have you worn a face mask in public within the past six months?”, and, “Have you worn a face mask in public since the first survey (three days ago)?” Participants could answer, “Yes” (1), or, “No” (0). For the second item, analyses were restricted to only those who responded affirmatively to the item, “Have you gone in public since the first survey (three days ago)?”. In Dataset 2, no face mask wearing items were administered. In Dataset 3, participants were given three items that read, “Within the past [six months/three weeks/week], how often have you worn a face mask when going into public?”. Participants responded on a 1 (Never) to 7 (Every Time) frequency scale, and they were also given the option, “N/A – I did not go into public during this time”.

Face mask perceptions. The FMPS was administered (Howard, 2020), which includes four items for each of the eight dimensions. The scale's instructions read: “Please indicate the extent to which you disagree to agree with the following statements regarding face masks, which refers to cloth coverings worn on the face typically intended to prevent the spread of disease and illness. Answer each of the following items as if they began with: When I do not wear a face mask in public, it is because…” Example items are, “I value my independence” (independence), and, “Face masks disrupt my breathing” (comfort). Higher scores for each dimension represent more negative face mask perceptions.
Correlations of gender with face mask wearing and face mask perceptions are provided in Table 1. We provide correlations among these variables for each individual dataset, but we also provide the sample-size weighted correlations that average the effects across the three datasets using a random-effects meta-analytic model. Using this approach, gender did not have a statistically significant relation with face mask wearing (r¯ = 0.04, 95%C.I.[−0.05, 0.12], n = 698). It did, however, have significant relations with two face mask perceptions. Men were significantly more likely to perceive face masks as infringing upon their independence (r¯ = −0.10, 95%C.I.[−0.16, −0.03], n = 1038), and women were significantly more likely to perceive face masks as uncomfortable (r¯ = 0.12, 95%C.I.[0.06, 0.18], n = 1038). Supplemental Material A includes analyses assessing the mediating effect of face mask perceptions between the relation of gender and face mask wearing, which were conducted using Hayes's (2017) PROCESS macro that provides bootstrapped estimates of effects. No indirect effect was consistently significant (1 of 50 analyses), including both the total indirect effect as well as the individual indirect effects via each dimension. Therefore, while gender does relate to certain face mask perceptions, it does not have a relation with face mask wearing whether directly or indirectly.
Lastly, we replicated all analyses while controlling for whether the participants' location enforced a face mask ordinance at the time of their final survey (Supplemental Material B), as this could have influenced their responses. All significant results in our primary analyses remained significant in these supplemental analyses, and all non-significant results remained non-significant. These supplemental analyses suggest that our findings are robust.

Our goal was to provide novel insights regarding the relations of gender, face mask perceptions, and face mask wearing. We did not find significant direct or indirect effects between gender and face mask wearing, indicating that men and women are equally likely to wear face masks during the COVID-19 pandemic. We did, however, support that men and women have differing perceptions of face masks. Men were more likely to perceive face masks as infringing upon their independence, whereas women were more likely to perceive face masks as being uncomfortable. These results provide many implications for research and practice.
While men take greater active health risks (Finucane et al., 2000; Minugh et al., 1998), men and women perform similar amounts of passive health risks (Flanagan et al., 2017; Miraglia & Johns, 2016). The current results provide further support that face mask wearing is a passive health behavior, even in the context of the COVID-19 pandemic, and face mask wearing should thereby be associated with other passive health behaviors. For instance, future research should generalize prior results on vaccination and presenteeism rather than drinking and drug use to the study of face mask wearing. We suggest that adapting prior models of vaccination willingness could be particularly beneficial, as prior authors have already applied a variety of theories to better understand this health behavior (e.g., protection motivation theory; Liu et al., 2016).
Further, the current results speak towards the role of masculinity and toxic masculinity in the context of health behaviors. Both are associated with a pronounced desire for independence (Kupers, 2005), which is likely the cause for the association between gender and perceptions of face masks infringing upon independence. Future research should extend these findings in two manners. Researchers should assess whether perceptions of independence explain the relation of gender and other health behaviors. Men may be, in part, more likely to perform certain risky health behaviors because they are counter-cultural, and men may enjoy feelings of independence from performing them. Also, researchers should test whether other aspects of masculinity and toxic masculinity predict health behaviors, such as the fear of appearing weak (Kupers, 2005). Men may be more likely to perform risky active health behaviors because they are dangerous, thereby implying that they are strong and capable of performing dangerous activities. Research has already supported a link between masculinity and risky active health behaviors (Capraro, 2000; Mullen et al., 2007), and future researchers should therefore apply modern gender theory to better understand perceptions surrounding health behaviors, including face mask wearing.
The current results can also improve our understanding of gender, perceptions, and behaviors in broader models of health behaviors, such as the COM-B model (Michie et al., 2011). This model identifies the interrelationships between behavioral sources, intervention functions, and policy categories in understanding health behaviors. Howard (2020) positioned face mask perceptions in the COM-B model by starting,“Face mask perceptions are a type of reflective motivation source, which involves evaluation and cognition in developing behavioral attitudes; reflective motivation sources are most closely associated with the intervention functions of education, persuasion, incentivization, and coercion; and these intervention functions are associated with each of the policy categories except environmental/social planning.” (p. 8).

Generally absent from the COM-B model is the role of individual differences, which are not present in the statement above. The current results therefore suggest that the predictive ability of the COM-B model can be improved by integrating the role of individual differences, such as gender, because such aspects significantly related to perceptions. We urge future authors to perform further integrations of individual differences with the COM-B model, which could be aided by novel experimental and intervention-creation designs (e.g., multiphase optimization strategy [MOST], sequential multiple assignment randomized trial [SMART]; Howard & Jacobs, 2016). MOST and SMART can identify the influence of individual differences on health behaviors, but they can also analyze any effects of interventions on health behaviors that are dependent on individual differences. Men and women may respond differently to face mask interventions due to their differing perceptions, which can be analyzed via MOST and SMART.
Several additional avenues for future research are also uncovered by our results. The relation of gender and face mask wearing may differ across contexts, as unobserved moderating influences may alter the relation of gender and face mask wearing. We suggest that one possible moderating influence is political orientation. Face mask wearing has become a source of political contention in many countries (Adolph et al., 2020). In the United States, for example, President Donald Trump claimed that some Americans wear face masks as a signal of disapproval towards him (Lovelace, 2020). While political orientation may have direct effects on face mask perceptions and wearing, we suggest that it may also produce moderating effects. For instance, conservative men may have an even stronger need for independence; their political orientation may exacerbate their sense of masculinity, which are both intertwined with notions of independence (Kupers, 2005). If the case, conservative men may be particularly sensitive to perceptions of subservience produced by wearing face masks, and they would be less likely to wear face masks than conservative women, liberal women, and liberal men. Therefore, the antecedents of face mask wearing may be quite complex, and a non-significant overall relation should not preclude subsequent research on an antecedent effect.
It is also important to highlight that, although gender did not indirectly relate to face mask wearing via perceptions, it did significantly relate to certain face mask perceptions. Face mask perceptions may relate to broader outcomes than face mask wearing. Because face masks have become a politicized topic in many countries, it is likely that people share extensive word-of-mouth regarding face masks' appearance, efficacy, and other topics (Adolph et al., 2020; Lovelace, 2020). People may also act as “social police”, wherein they criticize others based on their personal perceptions of face masks. For this reason, gender may not significantly relate to personal face mask wearing, but it may relate to word-of-mouth regarding face masks and subsequently others' face mask wearing behaviors. Future research should therefore investigate both the broader relations of face masks perceptions as well as the role gender in such relations.
In conducting these future studies, researchers should analyze longitudinal trends in the relations of face mask perceptions and wearing, especially in the context of the continuing COVID-19 pandemic. The relation of gender and independence weakened across the three datasets, which were collected approximately one month apart. Men may feel that their independence is less threatened as the pandemic continues. At the same time, we observed stronger relations of gender and the perception of comfort as time progressed across the datasets. Unlike men and independence, the discomfort of wearing face masks may grow for women as they are expected to wear them for longer periods of time. These differences were not statistically significant in unreported moderation analyses, but it is possible that predictors of face mask perceptions and wearing, such as gender, may further change as additional time progresses. Such considerations are important for the development of face mask interventions. Practitioners should be aware that interventions designed to target a specific face mask perception may have differing efficacy at a later date.
The current results also pose many implications for the development of face mask interventions. The null relation between gender and face mask wearing suggests that neither gender is more beneficial to target via interventions to promote face mask wearing. The significant relation between gender and specific face mask perceptions, however, suggests that certain interventions may be more effective at altering specific perceptions of men or women. For men, interventions should focus on the notion of independence, which has been discussed in some popular press outlets (Duarte, 2020; Vershbow, 2020). Specifically, these outlets have argued that face mask wearing has become a threat to masculinity for certain men (e.g., “e-mask-ulating”), and these men perceive mask wearing as a symbol of subservience. To counteract this notion, interventions directed towards men should reinforce their masculinity and strength, perhaps in a similar manner to public service announcements after the creation of the seatbelt.
Alternatively, interventions for women may need to be more practical. That is, women's perception that face masks are uncomfortable may be because face masks are indeed uncomfortable for women. Face masks are often designed as “one size fits most”, but one size may not fit all comfortably. Manufacturers of face masks should investigate whether face masks in different sizes and/or shapes may be more comfortable for women, which could increase the adoption of face masks by women. If such a mask were developed, then interventions could be created to alter the perception that face masks are uncomfortable for women.
Lastly, future researchers should also replicate the current results by addressing our limitations. We considered gender a dichotomy, but gender exists on a spectrum (Cameron & Stinson, 2019). Future research should assess gender using a continuous format. Similarly, we allowed participants to report their gender as “Other”, but we did not obtain enough Other responses to analyze this population. Future research should reassess our results using samples with greater gender diversity. Also, while our sample represented participants from many different countries, future research should replicate our results using more geographically diverse samples. These researchers should also assess person-context interactions, as certain individual differences, such as gender, may more strongly predict face mask wearing and behaviors in certain geographic locations and cultural contexts. Lastly, we measured face mask wearing via a self-report measure, but different results may have been obtained if we measured face mask wearing via an observational or other-report design. A future study should reinvestigate the current findings with these alternative measurement approaches, which can support the robustness of our results. Therefore, while the current article provides many insights into the relation of gender and face mask wearing, it should only be the first of many studies on the topic.
The following are the supplementary data related to this article.


Dr. Matt C. Howard completed all portions of the current manuscript.",Pers Individ Dif
PMC7526525,COVID-19 pandemic: Solid waste and environmental impacts in Brazil,"Worldwide public health and economy have been severely affected by the COVID-19 pandemic, with deaths and increased economic vulnerability especially in middle-income countries (Chakraborty and Maity, 2020; UN, 2020). Recently, the World Health Organization has declared South America the new epicenter of the COVID-19 pandemic (Feuer, 2020; WHO, 2020), as Brazil has become one of the most affected countries, being currently the second leading country in number of cases with 1,759,103 confirmed cases as of July 09, 2020 (Worldometers, 2020), albeit social isolation measures have been implemented in the Federal District on March 11, 2020, in São Paulo state and in Rio de Janeiro state on March 16, 2020 and March 17, 2020, respectively.
Besides the alarming socioeconomic impacts, indirect environmental impacts caused by social isolation have been described in several studies, reporting positive impacts such as cleaner beaches and environment noise reduction (Zambrano-Monserrate et al., 2020), immediate improvements in air quality (Bao and Zhang, 2020; Collivignarelli et al., 2020; Nakada and Urban, 2020), and in surface water quality (Braga et al., 2020; Yunus et al., 2020). Nevertheless, negative impacts related to increased solid waste generation and reduced recycling programs may produce medium- or long-term effects and thus constitute a reason for concern (Zambrano-Monserrate et al., 2020).

Kampf et al. (2020) have reviewed the persistence of coronaviruses on different surfaces and have reported viruses' survival on metal for 5 days, on plastic for up to 5 days, on paper for 4 to 5 days, on glass for 4 days, and on aluminum for up to 8 h. Furthermore, one recent investigation on the stability of SARS-CoV-2 on several surfaces has reported viable SARS-CoV-2 virus on plastic for up to 72 h, on stainless steel for up to 48 h, and on cardboard for up to 24 h (van Doremalen et al., 2020). Considering that plastic plus paper/cardboard represent 64.6% of recycling materials in recycling programs in Brazil, and because the majority of recycling centers in Brazil are based on manual waste sorting (Fidelis et al., 2020), COVID-19 infection risk for workers in recycling centers is high. Therefore, the Brazilian Association for Environmental and Sanitary Engineering has recommended the suspension of recycling programs in Brazil (ABES, 2020a).
The aim of this study was to assess environmental impacts caused by shifts on solid waste production and management due to the COVID-19 pandemic.
In this study, we have analyzed data from the Federal District, and all 26 state capital cities of Brazil plus 03 non-capital cities with more than 1 million people, totalizing 30 cities, which were selected based on the following criteria: i) state capital cities may represent the features of each state, considering social, environmental and economic diversity among Brazilian states; ii) data availability; and iii) solid waste production associated with large cities with high urbanization rates. So far, a total of 636,778 COVID-19 confirmed cases have been reported for the 30 analyzed cities, being the number of cases for each city as for July 09, 2020 presented in Table S1.
For the assessment of the impacts on solid waste management system in Brazil, we have analyzed official time-series data (SNIS, 2019a), and the latest published data about solid waste management in Brazil (Brazil, 2019), made available by the National System for Sanitation Information. Estimates of sale prices for recyclable materials were obtained from the Business Association for Recycling (CEMPRE, 2020). Resources saved by recycling were calculated according to Eq. (1), adapted from Calderoni (2003), being resources data presented in Table S2. Environmental and economic impacts caused by the suspension of recycling programs were calculated using Eq. (1), considering 30 days of suspension only in cities where recycling programs were actually suspended.(1)ResourcesX=∑i=1nRec.Matn×αnX×30365where:
Resources
X: Amount of resources of type X from recycling programs
X: Sale price; or volume in landfill; or saved: electric power/potable water/trees/oil/ore/sand
Rec. Mat.
n: Daily amount of solid waste of type n: 1: Plastic; 2: Paper; 3: Metal; 4: Glass
α
i
X
: Transformation coefficient of amount of solid waste of type n to amount of resources of type X

The numbers of daily disposable facemasks potentially used in cities under study were estimated using Eq. (2) (Nzediegwu and Chang, 2020).(2)TDF=Pop.×Urb.×FAR×ADFPC10,000where:
TDF: Total daily disposable facemasks
Pop.: Total population
Urb.: Urban Population (%)
FAR: Facemask acceptance rate = 80%
ADFPC: Average daily disposable facemasks per capita = 2

Being Brazil a middle-income country, the purpose of recycling is mainly income generation, besides resource recovery (Conke, 2018). The Brazilian legislation regarding solid waste (Brazil, 2010) encourages the integration of informal workers into the formal recycling sector, being the organization as a cooperative an important means to reduce socio-economic fragilities (Fidelis et al., 2020; Ibáñez-Forésa et al., 2018). Considering the continental size of the country with its cultural and economic diversity, solid waste management also varies from similar to low-income countries to similar to high-income countries (Cetrulo et al., 2018). Informal workers such as waste pickers, itinerant traders, and middlemen constitute one important characteristic of recycling programs in Brazil (Conke, 2018), and even formal workers conduct manual waste sorting in recycling centers. Therefore, the Brazilian recycling system is highly vulnerable to the effects caused by the COVID-19 pandemic, considering both environmental and economic impacts of the suspension of recycling programs in Brazilian cities due to the COVID-19 pandemic (Table 2
).
As a measure to avoid SARS-COV-2 transmission in recycling centers, 14 out of 30 cities have suspended recycling programs. In São Paulo, the largest city in Latin America, recycling program has not been suspended; nevertheless, only automated segregation is still working (São Paulo, 2020b). As a consequence of the suspension of recycling programs, considerable amounts of natural resources have not been saved over a month, such as 24,076 MWh of electric power – amount enough to supply 152,475 households over a month, considering an average consumption of 157.9 kWh/household∙month (Brazil, 2018), and 185,929 m3 of potable water – amount enough to supply 40,010 people over a month, considering each person uses 154.9 L/day (SNIS, 2019b). Furthermore, total sale price for recyclable materials during the suspension of recycling programs reaches more than 781 thousand dollars, being these materials disposed in landfills demanding an extra volume of 19,000 m3 – reducing landfill lifespan, and hence causing a double loss: economic and environmental.
An important income loss has been reported because of the suspension of recycling programs using manual waste sorting in recycling centers, albeit this measure was intended to safeguard public health, and therefore some city governments – for example, Belém-PA and São Paulo-SP – have approved emergency financial support for recycling-related workers (MPF, 2020; Jovem Pan, 2020). Because there is a high rate of turnover in recycling centers (Fidelis et al., 2020), at least 6581 formal workers have been affected by the COVID-19 crisis (Table S4). In locations where recycling programs have not been suspended, sales for recycling materials have also been compromised because some sectors – such as recycling facilities and also middlemen – of the complex solid waste management system are not fully working (Conke, 2018; Peduzi, 2020).
The latest data on medical waste in Brazil has shown installed treatment capacity for 479,653 t/year, and an annual production of 252,948 t, being 63.8% of this amount properly treated (ABRELPE, 2020).
Based on the evidence that medical waste production has increased up to 6 fold in Wuhan, China due to the COVID-19 pandemic (Calma, 2020), a recent study has foreseen an increment in medical waste production (Saadat et al., 2020). Assuming a 2 fold increase in medical waste in Brazil, the current treatment capacity would be exceeded. Moreover, although Brazil is one of the developing countries with most studies on its medical waste (Ansari et al., 2019), improper management of medical waste in small medical units is still a reason for concern (Moreira and Günther, 2013).
The COVID-19 pandemic has become more critical in Brazil in middle April 2020, and non-official preliminary data report an increment in medical waste production in May 2020 (Azevedo et al., 2020). By contrast, estimates on medical waste production in Brazil in the first week of April 2020 point out a 17% decrease in collected and treated waste (ABETRE, ABLP, ABRELPE and SELUR/SELURB, 2020), possibly because of the suspension of non-emergency medical and odontological appointments from late March 2020 on, and also improperly disposal among domiciliary waste (Azevedo et al., 2020). Furthermore, increasing use of personal protective equipment such as facemasks and gloves (Calma, 2020; Zambrano-Monserrate et al., 2020), both in hospitals and in general, also increases the chances for inappropriate disposal leading to environmental- (Saadat et al., 2020) and public health- (Nzediegwu and Chang, 2020) risks associated with potentially infective material.
Recently, a few studies have depicted improper disposal of facemasks in distinct parts of the world, such as Soko Islands, Nigeria, Portugal, and Canada (Kalina and Tilley, 2020; Fadare and Okoffo, 2020; Prata et al., 2020). During the social isolation period in Brazil, the press has reported inappropriate disposal of facemask in several cities analyzed in this study such as Campinas-SP, Campo Grande-MS, Goiânia-GO, João Pessoa-PB, Palmas-TO, São Luís-MA and São Gonçalo-RJ. Using the criteria described by Nzediegwu and Chang (2020), an estimate show that more than 85 million facemasks may be daily disposed (Fig. 1
). Considering the high demand of disposable facemasks and in order to control improper disposal, the Ministry of Health of Brazil (MS, 2020) and the Brazilian Health Regulatory Agency (ANVISA, 2020) have recommended the use of disposable masks only by health personnel, and the use of homemade reusable fabric facemask by population in general, according to the World Health Organization recommendations. One recent study has assessed the effectivity of cotton facemask as an alternative to disposable facemasks and has concluded that daily use of washable cotton facemask by healthy people in community is a suitable measure (Ho et al., 2020).
São Paulo is the largest city in Brazil, producing the highest amount of solid waste in the country, being data regarding solid waste collection monitored by an information system maintained and made available by the city government (São Paulo, 2020a).
Time-series data on solid waste production from January to April over the last 11 years (Fig. 2
) reveal some impacts on solid waste production caused by social isolation measures in the city of São Paulo, Brazil. As a result of environmental education campaigns as well as inspection of irregular waste disposal by the city government (São Paulo, 2020a), before the COVID-19 pandemic the following situations have been observed: i) variations in domiciliary solid waste collection, with a stable trend; ii) increasing recyclable collection; iii) increasing voluntary deposit in containers for recyclables; and iv) decreasing amount of solid waste on streets. In April 2020, during the COVID-19 pandemic and consequent partial lockdown, the following situations have been observed: i) the lowest (276,684 t) domiciliary solid waste collection over 11 years; ii) increased recyclable collection; iii) decreased voluntary deposit in containers for recyclables; and iv)) the lowest (3887 t) amount of solid waste on streets over 11 years.
The COVID-19 pandemic has caused several impacts on the solid waste management system in Brazil, considering socioeconomic and environmental effects, and hence has hampered advances in sustainable development. The suspension of recycling programs over a month has hindered natural resources from being saved, with emphasis on 24,076 MWh of electric power and 185,929 m3 of potable water – respectively enough to supply 152,475 households and 40,010 people, over a month. Recycling-related workers have experienced economic issues, albeit the government has approved emergency financial support.
Given behavior shifts in the post-pandemic period, the solid waste management system may demand adjustments seeking to: i) increase both recycling capacity and environmental education, considering the increment in the use of disposable utensils and also packages from food delivery and online shopping; ii) encourage training of waste pickers for adoption of safe methods for recyclable sorting; and iii) monitor both the production and the installed capacity for medical waste treatment, in order to assess an eventual need for system expansion.

Rodrigo Custodio Urban: Conceptualization, Methodology, Formal analysis, Investigation, Writing - original draft, Writing - review & editing. Liane Yuri Kondo Nakada: Conceptualization, Methodology, Investigation, Writing - original draft, Writing - review & editing.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Sci Total Environ
PMC7768217,Alcohol use and mental health during COVID-19 lockdown: A cross-sectional study in a sample of UK adults,"Since the emergence of COVID-19 as a global pandemic in March 2020, governments across the globe have instigated public health restrictions on the movement of people to prevent the spread of transmission. These restrictions have included legislation or guidance to stay at home, which has been referred to as ‘lockdown’. In the UK from 23rd March 2020, all but essential workers were ordered to stay at home and self-isolate from people outside their household. As there are yet no vaccines, with limited therapeutic options, the goal was to reduce transmission by limiting social contact and physical distancing.
In addition to reducing the spread of COVID-19, the social distancing measures have also had unintended consequences in society. The impact of the COVID-19 social distancing on alcohol consumption has been highlighted. In an editorial in the British Medical Journal, Finlay and Gilmore noted that supermarket sales of alcohol rose by 67 % in the United Kingdom (UK), a higher percentage increase than overall supermarket sales (Finlay and Gilmore, 2020). They noted that the potential impact from increased alcohol harm may be felt for a generation. Alcohol harm costs the National Health Service (NHS) in excess of £3.5bn and the wider economy at least £21bn per annum (Home Office - GOV.UK, 2012). Currently however, it is uncertain what impact the COVID-19 pandemic will have on alcohol consumption in the UK, though they are likely mediated by psychosocial factors such as social isolation, grief and anxiety (Dubey et al., 2020) as well as job insecurity. Indeed, increases in alcohol consumption have been identified during previous global events, such as during recessions, perhaps to seek relief from unpleasant emotions, stress, anxiety or depression (Chodkiewicz et al., 2020).
Emergent data from various other countries during the COVID-19 pandemic have demonstrated an increase in alcohol use during this time, including the USA (Rodriguez et al., 2020), Australia (Stanton et al., 2020), Germany (Anne et al., 2020) and Poland (Chodkiewicz et al., 2020). These studies have further shown that between one fifth and one quarter of adults have increased the amount of alcohol they usually consume, and that increased alcohol consumption was related to psychological distress and perceived threat associated with COVID-19 (Rodriguez et al., 2020).
However, there is less research on the correlates of changes in alcohol consumption. In a study of 5158 Australian adults, increased drinking during the pandemic was more common in those who were heavier drinkers before the pandemic, middle aged, had an average or higher income, had lost their job, were eating more, had experienced changes to sleep and reported stress and depression (Neill et al., 2020). Identifying the correlates of increased alcohol consumption resulting from the COVID-19 pandemic lockdown will help to target public health interventions towards ameliorating this, now that restrictions associated with the initial restriction of movement are easing. Furthermore, this can lead to the identification of those who may require further targeted intervention should restrictions be put in place again (or for future global events of this nature).
Therefore, the aim of this paper is to identify correlates of increased alcohol consumption following COVID-19 social distancing restrictions, using cross-sectional data in a sample of UK adults.
Participants were asked to identify if they were consuming less alcohol than previously, more alcohol than previously or if they were drinking about the same. Participants who had not increased their alcohol consumption (remained same or decreased) were grouped together for the analyses.
Mental health was measured using the 21-item Becks Anxiety Inventory (BAI) (Beck et al., 1988) and Becks Depression Inventory (BDI) (Beck et al., 1961). Higher BAI and BDI scores indicate more severe anxiety and depressive symptoms, respectively. The short Warwick-Edinburgh Mental Well-being Scale was used to measure mental well-being (Fat et al., 2017; Stewart-Brown et al., 2009). As mental health is a multi-component construct, we created a mental health score to capture a wider range of aspects of mental health in individuals than usually is examined. Poor mental health was defined as the presence of at least one of the following three criteria: moderate-to-severe anxiety symptoms (BAI score ≥16), moderate-to severe depressive symptoms (BDI score ≥20) (Carney et al., 2011) or poor mental wellbeing (SWEMWBS score ≤15.8) (Warwick Medical School, 2020). Therefore, BAI, BDI and SWEMWBS scores were used as continuous variables when studied separately and as dichotomous variables when studying overall poor mental health.
Demographic data was collected, including sex, age (18−34 years, 35−64 years, and 65 years and over), marital status (single/separated/divorced/widowed or married/in a domestic partnership), employment status, annual household income (<£15,000, £15,000-<£25,000, £25,000-<£40,000, £40,000 < £60,000, ≥£60,000) and the region of the UK they resided in (England, Northern Ireland or Scotland/Wales).
Health status was defined as the number of chronic physical conditions. Chronic physical diseases included obesity, hypertension, myocardial infarction, angina pectoris and other coronary diseases, other cardiac diseases, varicose veins of lower extremities, osteoarthritis, chronic neck pain, chronic low back pain, chronic allergy (excluding allergic asthma), asthma, chronic bronchitis, emphysema or chronic obstructive pulmonary disease (COPD), type 1 diabetes, type 2 diabetes, diabetic retinopathy, cataract, peptic ulcer disease, urinary incontinence or urine control problems, hypercholesterolemia, chronic skin disease, chronic constipation, liver cirrhosis and other hepatic disorders, stroke, chronic migraine and other headaches, hemorrhoids, cancer, osteoporosis, thyroid disease, renal disease, and injury. Participants also reported if they had experienced any of the physical symptoms of COVID-19 and the number of days they had been self-isolating for.
Sample characteristics were compared between adults with and without increased alcohol consumption using chi-squared tests for categorical variables and t-tests for continuous variables. In addition, BAI, BDI and SWEMWBS scores were compared between the two different alcohol consumption groups using t-tests. Effect sizes were estimated using phi coefficient for categorical variables with two levels, Cramer’s V for categorical variables with more than two levels, and Cohen’s d for continuous variables. Furthermore, Pearson’s correlation coefficients were used to estimate the correlation between BAI, BDI and SWEMWBS scores. Finally, the associations between increased alcohol consumption (independent variable) and mental health outcomes (dependent variables) were studied in regression analyses. Poor overall mental health (dichotomous variable) was included in a logistic regression model, while anxiety symptoms, depressive symptoms and mental well-being (continuous variables) were included in linear regression models. Regression models were adjusted for sex, age, marital status, employment status, annual household income, region, the number of chronic physical conditions, the number of days of self-isolation, and any physical symptom experienced during self-isolation. Results from the logistic and linear regression analyses are presented as an odd ratio (OR) and unstandardized beta coefficients with 95 % confidence intervals (CIs), respectively. The level of statistical significance was set at p < 0.05. The statistical analysis was performed with R 3.5.2 (R Core Team, 2018).
This study included 691 adults (61.1 % women; 48.8 % aged 35−64 years; Table 1
). Overall, 17 % of participants had increased their self-reported alcohol consumption. Sample characteristics were similar between participants with and without increased alcohol consumption except for age. The proportion of people aged 18−34 years was higher in the increased than in the no increased alcohol consumption group (50.4 % versus 29.4 %; p-value<0.001). The prevalence of poor overall mental health was significantly higher in individuals with than in those without increased alcohol consumption (45.4 % versus 32.7 %; p-value = 0.01), while anxiety and depressive symptoms were more severe and mental well-being poorer in those that increased their alcohol consumption compared to those that did not (Fig. 1
). Furthermore, there was a moderate-to-strong correlation between anxiety symptoms, depressive symptoms and mental well-being (BAI and BDI scores: 0.72; BAI and SWEMWBS scores: -0.56; and BDI and SWEMWBS scores: -0.71).
The results of the adjusted regression analyses are displayed in Table 2
. There was a positive and significant association between increased alcohol consumption and poor overall mental health (OR = 1.64; 95 % CI = 1.01, 2.66). Similar findings were obtained for depressive symptoms and mental well-being but not anxiety symptoms. Regression models were adjusted for sex, age, marital status, employment status, annual household income, region, the number of chronic physical conditions, the number of days of self-isolation, and any physical symptom experienced during self-isolation.
In this sample of UK adults, more than one in six individuals had increased their alcohol consumption during the COVID-19 lockdown period. This was particularly apparent among younger adults, such that 50.4 % of people who had increased their alcohol consumption were aged 18−34 years. Furthermore, increased alcohol consumption was independently associated with poor overall mental health, increased depressive symptoms, and lower mental wellbeing, but not with anxiety symptoms.
Similar findings have been reported from other countries. A study of 1491 Australian adults demonstrated that a similar proportion (26.6 %) increased their alcohol consumption, and this was associated with depression, anxiety and stroke (Stanton et al., 2020). However, where other studies have found an association between alcohol consumption and anxiety the present study did not. It is not clear why the present study did not find an association between alcohol consumption and anxiety and further research of a qualitative nature is now needed to shed light on this. In a study of German adults, of the 2102 participants that responded to a survey, 34.7 % reported drinking more or much more alcohol since the beginning of the lockdown (Anne et al., 2020). In the present study, self-isolation lasted on average nine days, and the proportion of people increasing their alcohol consumption may have been even larger if the survey had been conducted at a later stage of the lockdown. Together, these studies likely demonstrate that the increase in supermarket alcohol sales seen in many countries may not be reflective of a displacement of drinking habits from social or publicly licenced settings to the home, but reflect an increase in alcohol consumption. However, this hypothesis remains untested and research of a qualitative nature is required to shed further light on this point.
Increased alcohol consumption is commonly observed after a crisis (De Goeij et al., 2015). There are a number of reasons that alcohol consumption might increase during the COVID-19 pandemic. These include boredom and disruption to routines caused by the lockdown, or the threat of the disease or changes to life circumstances, and associated distress. A study of 754 adults from the USA demonstrated that psychological distress caused by the COVID-19 pandemic was associated with increased alcohol consumption, whereas perceived threat from the virus itself was not associated with increased alcohol consumption (Rodriguez et al., 2020). Interestingly that same study demonstrated that gender moderated this relationship, suggesting a more pronounced effect on women, effect that we did not observe in our data. Other reasons people drink during a crisis include the inhibiting effect of alcohol on the nervous system, offering temporary relief from emotions, anxiety or depression associated with lockdown (Abrahao et al., 2017). A separate study from the USA further showed that perceived social support was associated with lower alcohol consumption (Lechner et al., 2020), which at least partly suggests the need to promote maintained social support during any future lockdowns, should subsequent waves of COVID-19 materialize.
The findings of this study and those from other countries highlight the importance of planning for targeted support as we emerge from lockdown and plan for potential second and subsequent waves. They indicate the importance of addressing the mental health impacts of COVID-19 lockdown, which may have far reaching consequences for society. The effect of the approaches taken by different countries is yet to be determined. For example, South Africa implemented an alcohol sales ban during lockdown (Matzopoulos et al., 2020), which is one of the more direct measures taken to limit the impact of alcohol consumption on both transmission and also health service demand. There will also be a need to continue to address myths about COVID-19 as they emerge. In some countries, there was a myth propagated that drinking alcohol was protective against COVID-19 (Chick, 2020), providing one clear example of how misinformation can perpetuate wider societal problems during a global health pandemic.
It is also important to note that increased alcohol consumption was significantly more frequent in participants aged 18−34 years (50.4 %) than in those aged 35−64 (45.4 %) and ≥65 years (4.2 %). Therefore, it may be that COVID-19 social distancing measures are disproportionally affecting younger adults in relation to increased alcohol consumption. It is plausible that social distancing measures may have limited impact on those greater than 65 years in the UK, since by this age both females and males will receive a state pension and thus likely retired with some financial security (Batchelor, 2017). Owing to COVID 19 social distancing younger adults may had been furloughed and thus concerned about their financial security and future per se, increasing their alcohol intake in the attempt to mitigate depressive symptoms. However, these hypotheses are untested and further research of a qualitative nature is now required.
Findings from the present study must be interpreted in light of its limitations. Self-reported changes in alcohol consumption may introduce self-reporting bias into the findings with participants intentionally or unintentionally underestimating their consumption. Additionally, we did not quantify the change in alcohol consumption, so it is not possible to determine if the reported changes were clinically significant. As with all online surveys, self-selection bias cannot be ruled out. Furthermore, as this survey was administered very early into the lockdown period, it was not possible to establish whether the effects on drinking habits are sustained over time or persist following the easing of restrictions – which is an important area for future research. Moreover, some of the associations analysed in this study may be statistically but not clinically significant, and more research using diagnostic data are warranted to corroborate the present results. Besides, changes in employment status is a likely key factor that influences changes in alcohol consumption during this unique period, however, such data was not collected in the present study. Finally, the present data is cross-sectional in nature thus it is not known whether an increase in alcohol consumption resulted in a decline in mental health or if a decline in mental health resulted in an increase in alcohol consumption. Moreover, it may be possible that that those who increased alcohol consumption already had worse mental health prior to the COVID-19 lockdown period. Future research of a longitudinal nature is now needed.
In conclusion, in this sample of UK adults, increased alcohol consumption associated with COVID-19 lockdown was associated with poorer mental health, depressive symptoms and lower mental wellbeing. A high proportion of young people reported increased alcohol consumption. However, given our knowledge of the impacts of other international crises on alcohol consumption, policy makers need to start planning targeted support to address the impact of COVID-19 lockdown on alcohol consumption and strategies to prevent increased alcohol consumption in future lockdowns should a second and subsequent wave of COVID-19 emerge.
JF is supported by a University of Manchester Presidential Fellowship (P123958) and a UK Research and Innovation Future Leaders Fellowship (MR/T021780/1).
All authors listed (LJ, LS, NCA, AY, YB, LB, DTM, AK, JIS, JM, JF, OR, GFLS, MAT) have made a substantial, direct and intellectual contribution to the work, and approved it for publication.
No conflict declared.",Drug Alcohol Depend
PMC7656159,Mental health of college students during the COVID-19 epidemic in China,"The coronavirus disease 2019 (COVID-19) was first reported in Wuhan, Hubei, China and is now rapidly spreading around the world, posing a substantial threat to the health of people. As of June 22, 2020, the WHO had reported 8,860,331 laboratory-confirmed cases, and 465,740 deaths globally, with cases of the virus and the death toll still increasing (World Health Organization). In addition to causing physical damage, COVID-19 has also caused unbearable psychological pressure to people in China and the rest of the world (Xiao, 2020). Recent research showed that during the COVID-19 epidemic, mental health problems such as fear, anxiety and depression were common among the general public, patients, medical staff, children, and older adults (Yuchen Li et al., 2020).
Due to the continuous spread of the epidemic, the Chinese government implemented nationwide school closures. So far, the infection has caused 150 countrywide school suspensions globally and has affected 1,186,127,211 students (UNESCO). The need to protect the mental health of college students during confinement is warranted, however, to our knowledge, research focused on the psychological status of college students in China during the epidemic is limited. Given the dearth of existing research, the current study aimed to examine the mental health of 89,588 college students during the COVID-19 epidemic in China and to offer some theoretical evidence for psychological intervention of college students.
The current cross-sectional survey was conducted from May 10, 2020 to June 10, 2020. Twenty-one colleges were selected by a convenience sampling technique. The study was approved by the Research Ethics Committee of Hainan Medical University in Haikou, China. The Questionnaire Star (https://www.wjx.cn) was used to collect data online using an anonymous, self-rated questionnaire that was distributed to all selected colleges. All participants provided electronic informed consent prior to registration. To avoid the same participant repeatedly answering the questionnaire, each device (e.g. mobile phone or computer) was eligible to answer only once and logic checks were concurrently running in the background to identify invalid questionnaires. The answers to all valid questionnaires were automatically loaded into a data file and checked by two independent researchers. A total of 89,588 college students were surveyed. The online questionnaires included general demographic characteristics, concerns about COVID-19, the impact of COVID-19 on life, social support, and anxiety symptoms.
Anxiety symptoms were measured by the Generalized Anxiety Disorder 7-Item Scale (GAD-7). GAD-7 is a seven-item anxiety scale developed by Spitzer et al. (Benjamin et al., 2014), with a score of 0 to 3 for each item. The GAD scale ranges from 0 to 21, in which a total score of 0 to 4 suggests no anxiety symptoms, a score of 5 to 9 reflects suggests mild anxiety, a score of 10 to 14 suggests moderate anxiety and those with a total score of ≥ 15 are considered to have severe anxiety. The GAD scale had a good factorial validity and reliability (Cronbach's α = 0.901). Furthermore, the validity of GAD in assessing anxiety in the Chinese population has been confirmed (Spitzer et al., 2006).
The social support of participants was assessed via the Multidimensional Scale of Perceived Social Support (MSPSS), which includes 12 items with response options ranging from 1 (very strongly disagree) to 7 (very strongly agree) (Altman and Bland, 2003). The MSPSS estimates social support quality from three sources: family, friends, and significant others (Osman et al., 2014). All item scores were added up and then divided by 12. Mean scores ranging from 1 to 2.99, 3 to 5 and 5.01 to 7 were classified as low, medium and high perceived support levels, respectively (D et al.). The Chinese version of the MSPSS has shown good reliability and validity in different populations (Guan et al., 2015).
Categorical data were reported as number and percentage. Chi-square tests were conducted to compare the prevalence of anxiety across groups as defined by demographic data and social support levels. Multivariate logistic regression models were used to assess the association between various factors and anxiety. All statistical analyses were conducted using SPSS 21.0 (SPSS Inc, Chicago, Illinois, USA). A value of P < 0.05 (two-tailed) was considered statistically significant.
A total of 89,588 college students participated in the current study, among which 39,194 (43.75%) were males and 50,394 (56.25%) were females. Of the 89,588 participants, 36,865 students (41.1%) reported anxiety symptoms. The prevalence of anxiety was significantly different among the college students with different age, grade and social support levels (all P <0.0001). The prevalence of anxiety among college students who lived in rural areas was significantly higher than in those who lived in urban areas (χ2=79.183, P<0.0001). College students with lower paternal education were more likely to have anxiety symptoms than those with a higher paternal education level. (all P <0.0001). Low family economic status, reporting a greater impact of COVID-19 on life, and experiencing higher levels of concern about COVID-19 were associated with increased prevalence of anxiety (P<0.05). (Table 1
).
In the multivariate logistic regression analysis (Table 2
). Compared with male students, female students had a higher risk of anxiety symptoms (OR=1.073, 95% CI: 1.044-1.104). Students aged 26-30 years were more likely to show anxiety compared to other ages (OR=1.456, 95% CI: 1.357-1.561). Compared to freshman (first year students), sophomores (second year students) (OR=1.038, 95% CI: 1.001-1.076), juniors (OR =1.087, 95% CI: 1.041-1.134), and seniors (OR =1.161, 95% CI: 1.096-1.230) all present a higher risk of anxiety. Those who reported that COVID had a moderate, slight, or no impact on their life, compared with those who reported a substantial impact, showed a decreased risk of anxiety symptoms (OR=0.562, 95% CI: 0.544-0.579; OR=0.366; 95% CI: 0.347-0.385, respectively). Low (OR=1.542, 95% CI: 1.390-1.711) and moderate (OR =1.862, 95% CI: 1.809-1.915) levels of social support were associated with a higher risk of anxiety compared to those with high levels of social support.
In the current study, 41.1% of college students reported anxiety symptoms, which is higher than other investigations in China (Yueqin Huang 2019). The outbreak of COVID-19 in China has had direct and indirect impacts on all areas of society. In order to curb the outbreak and protect students from COVID-19, all schools have been closed until the epidemic is under control. Students facing long-term isolation at home and using online learning are prone to a series of emotional stress responses. Additionally, college students are more concerned about COVID-19 and any additional consequences. At the early stages of this pandemic, people received little information about nature, treatments, the fatality rate, etc., which fueled the fear about the virus (Ahmed et al., 2020). With the rapid spread of COVID-19, college students who received a large amount of negative information may be at a greater risk of psychological maladjustment (Lu et al., 2013). Therefore, it is necessary to pay special attention to the psychological status of college students who are in long-term home isolation and to take timely and appropriate interventions to maintain and improve their mental health.
The present study found no significant difference in gender, which was in line with previous studies (Ji X et al., 2020). This indicates that male and female college students experienced similar stresses and negative emotions as a result of the COVID-19 epidemic. We also found that sophomore, junior and senior students were more likely to have anxiety than freshman students. This may relate to differences in the curriculum design. Compared to sophomore, junior and senior students, freshmen students are not required to undertake any practicum. Previous research found that exemption from the practicum may relieve some stress and anxiety (Teris et al., 2016). In addition, for more senior students the academic pressure is greater, and some of them face graduation, employment, and practice, etc., but the epidemic of COVID-19 inevitably affects the development of various things.
Self-perceived family economic status also was a significant factor of anxiety for college students during the COVID-19 epidemic. Some researchers showed that financial vulnerability may exacerbate anxiety among college students (Kaya et al., 2007; Lu et al., 2013; Teris et al., 2016). Consistent with previous studies, we also found that college students who reported low economic status were more likely to have anxiety symptoms than those who reported higner economic status. During the COVID-19 pandemic, many companies and factories have postponed their operation, which inevitably affected the economic income of some families. Under such circumstances, it is hard for students to maintain mental wellbeing.
Social support is an important environmental resource for individuals in social life and is closely related to mental health (Tambag et al., 2018). The degree of impact of COVID on life is also a factor for college students' anxiety, which might be related to the high contagiousness of the COVID-19 (Song et al., 2019). Our study also found that college students whose father's education level was higher experienced a greater risk of anxiety symptoms. Previous research found that social support is an important variable that has been shown to be negatively associated with anxiety in college students (Ratanasiripong, 2012). Similarly, our study showed that lower levels of social support are associated with an increased risk of anxiety symptoms. Therefore, we should pay attention to the role of social support in maintaining college students' mental health. On the one hand, parents should strengthen communication with their children and ensure that they receive family psychological support. On the other hand, universities should set up online mental health education courses about the COVID-19 epidemic to improve college students' psychological adaptability.
The present study has several strengths. Firstly, to the best of our knowledge, this is the largest sample survey on the mental health of college students during the COVID-19 epidemic. Secondly, this study indicated that a considerable number of college students have mental health problems, and findings of this study could provide valuable references for preventing college students’ mental problems in other areas and countries. Limitations of this study include that this is a cross-sectional study; as the epidemic changes, the mental health of college students may also change. Further research is needed to track the dynamic changes of the college students’ mental health status throughout the epidemic.
About two-fifths of Chinese college students experienced anxiety symptoms during the COVID-19 epidemic. Timely and appropriate psychological interventions for college students should be implemented to reduce the psychological harm caused by COVID-19 epidemic. Meanwhile, psychological skills training should be strengthened to better regulate the psychological status of college students as well as to mitigate the psychological problems of patients.
WNF, SJY, QZ and CZL conceived and designed the study. WNF, SJY, QZ, DAL, XYS, ZYL and CZL participated in the acquisition of data. WNF and SJY analyzed the data. CZL gave advice on methodology. WNF and SJY drafted the manuscript, WNF, SJY, QZ, DAL, XYS,ZYL and CZL revised the manuscript. All authors read and approved the final manuscript.
The authors declare that they have no conflicts of interest.",J Affect Disord
PMC7577260,Time dependent correlations between the probability of a node being infected and its centrality measures,"The dynamics of diffusion, contagious disease spread, rumor, a new idea, or computer viruses exhibit common spreading mechanisms [1], [2], [3], [4], [5], [6]. In all of these phenomena, the transmission requires contact interaction within neighboring nodes. All real-world systems, such as social, technological, communication, transportation, are organized in a connectivity structure that results in a complex network of nodes (vertex) connected by links (edges) [7]. Therefore, understanding of the underlying connectivity structure of the system of concern is essential for a realistic model of the contact driven spreading phenomena [8], [9]. Not only are such models vital to estimating or understanding the behavior but also to manipulate the system into a preferred state [10]. The effects of connectivity structure on the evolution of the dynamic processes on the network are well studied [11], [12], [13]. Power network breakouts, failures in communication networks, crisis in financial networks, and many cascading processes may be related to negligible changes or failures in the connectivity structure of a system [14]. In all these works, detailed knowledge of the network structures is the crucial element on the success or failure in taking precautions to protect society from the spread of disease. A method less dependent on the detailed underlying connectivity will be of great benefit to complex network science.
Some network nodes are more effective than others in accelerating the spreading process [15]. Their strength in spreading disease is related to their local and global positioning in the network. Mathematical formulation of the relation between the network structure and local and global weights of each network node is the centrality measures. There exist more than 200 centrality measures, with each classifying different aspects of the weight of member nodes according to their importance and inter-relational strength on the network. Despite the complexity of modern systems such as social, technological and communication networks, centrality measures are useful to quantify the local and global positions of the nodes. Each centrality measure aims another aspect of the role of the nodes. The centrality measure, which is related to the number of neighbors, is called degree centrality. Similarly, betweenness, closeness, eigenvector, clustering and PageRank centrality measures are among the most commonly used centrality measures.
Despite abundance of centrality measures, only a limited number of centrality measures are totally independent and are commonly used in the literature [16]. Correlations between centrality measures are indication of degree of dependence among the centrality measures. Moreover, the centrality measure correlations also depend on network topology. Network modularity is the source of this cross-network variations [17] and is also affects dynamic process factors. For this reason, the relation between network centrality measures and the spreading phenomena is far from clear [17].
In controlling the diffusion processes such as an epidemic outbreak, the optimum performance can be achieved only with complete knowledge of the network [12]. There are a considerable number of recent articles which studied the efficient methods of immunization and isolation. In these studies, the observed fact is that, in real-world networks, the hub nodes – the nodes with a high degree of connectivity – play a crucial role in the spreading phenomena [18]. Real-world networks are far more complicated than a simple network. News diffusion on a communication network may affect the other diffusion processes proceeding on other layers. In multi-layer networks, the news spreading on one layer increases awareness, hence can prevent disease from spreading on another [2], [4].
Fighting the spread of contagious disease is a race against time. The main tools to slow the spread of an infection are vaccination and quarantine. In most cases, the means of immunization may not be readily available, or time-consuming, which makes large-scale application impossible. Quarantine is an extreme prevention method; it can be efficient only if used selectively and for a limited period. Either or both of these methods on selected nodes decisively control the diffusion. Two questions thus emerge: (i) Is the spread at its initial stages? (ii) which nodes are the most vulnerable? In most cases, even the identification of the spread requires good knowledge of the status of the nodes. The local and global position nodes determine the effect of the spreading process. Centrality measures parameterize the vulnerability of the node during a diffusion process. If a node is vulnerable, has many connections, remains between large communities, its centrality measures reflect the vulnerability level. Therefore, the knowledge of the correlations between local and global node importance and the spreading dynamics becomes crucial for prevention planning. At the initial stages of the spread, almost all nodes are susceptible. At this stage, there are no correlations between the node infection probability and the node centrality measure values. As the infection spreads, the first nodes to be infected are the ones that have high centrality values. The correlation between node infection probability and high centrality values increases as the infection spread widens. At the final stages, the number of infected nodes is large, and the relative importance of the node position is lost, indicating a lower correlation between the centrality measures and node infection probability. Hence, there exists a time-dependent relation between infection probability and node centrality values. Here, two questions, which centrality measures are more relevant for a given network, and knowing the centrality value of a node can one predict the possible time of being infected.
The present work aims to introduce a systematic scheme to identify the relevant network centrality measures to predict the infection probability of a node given the time interval. The relevance of different centrality measures depends on network typologies This knowledge can be a guide to prevent the spread of a contagious disease at an early stage of an outbreak. The time dependencies of correlation between the node centrality measures and spreading dynamics have not been considered in the literature yet.
In the proposed scheme, the correlations between the node centrality values and the node infection probability at a given time slice are calculated for selected centrality measures. Hence studying the relation between the spreading of disease and centrality measures cannot be abstracted from the correlations among the centrality measures [17]. Correlations among the centrality measures and the correlations between node centrality values and node infection probability give evidence for the relevant centrality measures given the network topology. The main aim is to make model predictions on the real-world systems. The existing observations show that there are two different types of artificial networks, Erdős–Renyi [19] and scale free [20] networks, which have the same characteristics as the real-world systems. These network structures have their distinct characteristic connectivity patterns, Pk(k), which gives the probability of a node having k neighbors. To test the proposed scheme, two artificial networks, namely, Barabási–Albert and Erdős–Renyi are employed. Later, Airline [21] and Facebook [22] network data are used as real-world examples. Susceptible–Infected–Recovered (SIR) model [23] is employed for the dynamics of the spreading of the contagious disease. Barabási–Albert and Erdős–Renyi network models are used as model networks. The observations are tested on real-world networks.
For the preparation of the network connectivity structure and the calculation of the network parameters NetworkX python package [24] is employed. The created network topologies are used as the input for Idlib python library [25] which is used for the SIR model spreading dynamics. The python libraries, pandas [26], and NumPy [27] are used for data analysis and correlation calculations.
The work is organized as follows. Details of the methodology are discussed in the following section. Section 3 is devoted to the results and discussions. Finally, conclusions are presented in the fourth section.
SIR epidemic model is based on the scenario in which those susceptible S become infected, I denote infected nodes, R denote nodes recovered. The probabilities β, gamma γ control the number of infected and recovered individuals. A third parameter, λ is the ratio of initial infected nodes which determines initially infected individuals. During a dynamic process, the number of individuals does not change. Hence, the total number of individuals, N=S+I+RwhereI=λNremains constant. At the initial stages, all individuals except a small number of infected individuals, I(0), are susceptible. Since the individuals are grouped under three categories, such models are also called compartmental models. By using s=S∕N, i=I∕N, r=R∕N to denote the fraction of the population in each compartment, the SIR model becomes dsdt=−βsi(1)didt=βsi−γidrdt=γi.

SIR model sets the dynamics of the spreading of the contamination. If the number of infected increases more than the recovered, an epidemic occurs. Hence the epidemic condition: (2)βsi−γi>0

The spreading of contamination is a function of three parameters: transmissibility, duration of illness, and the average rate of contact between susceptible and infected individuals. The first two, transmissibility and duration of contamination, are characteristics of the contaminating agent, while the third parameter is directly related to the topology of the interaction network. The reproduction number R0, is (3)R0=τc¯d.

If R0 has a non-vanishing value, then the spreading becomes an epidemic. In Eq. (3)
τ is the transmissibility, c¯ is the average rate of contact between susceptible and infected individuals, and d is the duration of illness. SIR model assumes a well-mixed population with an equal probability of contacting any susceptible individual. In this model, the basic reproduction number is simply (4)R0(SIR)=βγ

Comparing Eqs. (3), (4) , the relation, β=τc¯ and d=1∕γ can be obtained.
The SIR model is an aggregate (compartmental) model where each interacts with all others. The model in which all interact with all others is not realistic for modern societies. An agent-based SIR model with an interaction pattern constitutes a more realistic model of the infection spreading. Complex networks or real-world networks represent the connectivity structure of a society. The links of the determine the node–node interaction pattern. Two variables, the node index and the state (S,I or R), represent the position and the state of the node. At time t, the individual living at site i, is denoted by the variable Xi(t) where i=1,…,N. The node variable Xi can take three values, S, I or R. The transition probabilities of the changing state of an individual are given by (5)Pr(Xi(t+Δt)=I|Xi(t)=S)=β∑j=1NNiδXj(t),IΔt+o(Δt),(6)Pr(Xi(t+Δt)=R|Xi(t)=I)=γΔt+o(Δt). where δXj(t),I is the Kronecker delta. The sum over the nearest neighbors (NNi), ∑j=1NNiδXj(t),I, counts the number of infected neighbors. Eqs. (5), (6) are the probabilities of the agent living on the node i being infected (if it is susceptible at time t) and recovered (if it is infected at time t) at next time step (t=t+Δt). On the regular networks as N→∞ and Δt→0 the probabilistic model gives the same results as expected from the augmented model. (7)Pr(Xi(t+Δt)=I|Xi(t)=S)=β∑j=1NNiδXj(t),IΔt(8)Pr(Xi(t+Δt)=R|Xi(t)=I)=γΔt

The number of neighbors differs according to the connectivity structure of the nodes. If a susceptible node has a large number of neighbors, it is more likely to be infected. Similarly, if an infected node has a large number of neighbors, it is more likely it may cause someone to be infected, which means the probability of spreading the illness is also high. The connectivity structure depends on the topology of the network. In this work, three different categories are considered: Barabási–Albert, Erdős–Renyi, Real-World networks.
Regardless of the network structure, nodes possess characteristic parameters which uniquely identify its weight and importance in the network. Nodes can be associated with many different measurable quantities. One of the most commonly used is the degree of a node, which determines the number of connected neighboring nodes. Among over 200 centrality measures the quantities

•degree centrality,•betweenness centrality,•closeness centrality,•eigenvector centrality,•clustering coefficient,•pagerank centrality

are the network parameters which are used widely in network analysis. All of the network parameters are designed to give special information on the connectivity structure of a complex network. Each is designed to measure a different aspect of the complex relations among the nodes. Despite centrality, measures emphasizes a different aspect of complex relations; they are correlated and some of them have strong correlations. These correlations are also reflected in the spreading dynamics. The relation between the speed of the spreading phenomena and the network parameters of the nodes gives a clear indication of the correlations between network parameters and the dynamics of spreading.
The model is based on the comparison between the correlations among the centrality measures and the spreading dynamics on the same network topology. To address the problem of predicting the relationship between the centrality measures and the spreading dynamics on a given network, the model is tested on well-known Erdős–Renyi and Barabási–Albert network topologies. The SIR Model dynamics are simulated on both artificially generated and real-world network structures. The replicas of the networks with an equal average degree are used to follow the spreading dynamics for 50-time steps. In order to eliminate the artifact effects of the seed nodes of the contamination, the contamination started at the randomly chosen seed sites, and the averages are calculated over a large number of statistically independent samples. The correlations between the network parameters and the probability of a node being contaminated are calculated at each time step.
Barabási–Albert network is well known for its characteristic power-law degree distribution, which indicates the existence of a small number of nodes with high connectivity (hub nodes), while a large number of nodes with a small number of neighbors. First, the correlations among the centrality measures are calculated to check the dependencies. In calculating correlations among the centrality measures of nodes, 50 statistically independent Barabási–Albert networks are used.

Fig. 1 show the correlations between selected centrality measures. The correlations are obtained as the averages over 50 replicas of Barabási–Albert networks with 6
(Figs. 1(a)) and 12
(1(b)) average connections per site. The comparison of the subfigures, Fig. 1, Fig. 1 indicate that increasing average number of connections also increases the existing correlations. Moreover, page rank and degree centrality measures are highly correlated, give the same information with the same strength. The clustering centrality measure does not correlate with any other measure, which does not change with the increasing connectivity of the system. Similarly, the closeness centrality exhibits a relatively weak correlation with the other measures. Its correlations increase with increasing connectivity.

Fig. 2 shows the correlations between the node centrality measures and the node infection probability. The node infection probability denotes the probability of being infected if an infection starts to spread at any node in the network. For every independent graph, 500 different runs are performed with statistically independent initial configurations. During 50 time steps, the spread of infection is followed. At every time step, the infected nodes are labeled as susceptible, infected, or recovered. The node infection probabilities are calculated over 500 sample runs at each time step. If a node is infected once, this node is considered as infected for all the time steps.
After calculation of the node infection probabilities, the correlations between infection probabilities and centrality measures are obtained and the averages are taken over all 50 independent graphs.

Correlations among the centrality measures are reflected in the centrality-infection probability correlations. Fig. 2, shows that degree (dgr) and page rank (pgr) follow closely each other within the accuracy of the plot. Eigenvector (eig) and Betweenness (btw) centrality measures follow a similar pattern with the page rank and degree centralities but they remain slightly lower as expected (Fig. 1). Remaining two centrality measures, closeness (clo) and clustering (cls), behave independently from the other.

Fig. 3 show the percentage changes of susceptible, infected and recovered populations for 50 time steps. If Fig. 2, Fig. 3 are considered together, the relation between the peaks and the spreading dynamics can be better interpreted. Both Fig. 3, Fig. 2 contain two subfigures for 6 and 12 average degree respectively. Increased connectivity increases the speed of the infection spread. Hence, from Fig. 3, Fig. 3 it can be seen that between the average degrees 6 and 12 the speed off the spread of infection approximately doubles. A characteristic feature of SIR-like epidemics, at the initial stages, the slope of the increase in the number of infected individuals is small up to a critical percentage. After the initial stage, a new phase with a higher slope starts which may lead to an epidemic situation. The correlations between the infection probability and centrality measures reflect the observed initial stages of the contamination spread. Correlations start to grow at the initial stage where the slope of the infection spread is low, reach to a peak at the point where the slope changes. The position of the peak is the position of the point where the slope changes. The slopes are calculated by fitting the infected population data for both average degrees 6 and 12. As the infection spreads, after the peak of the correlations, a large number of nodes have the same probability of being infected, hence the correlations start to decrease.

The position of the peak gives an indication of the timing of any planned action. The peak position of the correlations is much earlier than the peak of the infection spread. At the peak, the spread can be controlled by pointing the nodes with the highest centrality values. Immunizations, isolation, or quarantine are most useful before or at the peak of the correlations. The degree and page rank centralities are the decisive factors for the control of infection spreading (Fig. 2).
The role of topology on the spreading phenomena can be better understood by comparing the results of scale-free and random networks. In the following subsection spread of SIR type infection on Erdős–Renyi networks will be subject to discussion.
Erdős–Renyi random networks are one of the oldest and best-studied models of node connectivity. However, its resemblance to the real-world networks such as the Internet, social networks or biological networks is limited since it lacks network clustering or transitivity, and its Poisson degree distribution does not overlap with the degree distributions of the real-world networks. Despite that, the real-world networks are mostly scale-free networks, depending on the network size and the relation among the nodes, some parts or the whole network may exhibit random connectivity.

Fig. 4 show the correlation between different centrality measures using 50 statistically independent graphs. The correlations of centrality measures of Erdős–Renyi networks for 6, Fig. 4(a) and 12, Fig. 4(b) average degree per site indicate that increasing average number of connections also increases the existing correlations. In the random network case, the correlations among the centrality measures are stronger than the scale-free network. Page rank and degree centrality measures are highly correlated as it is for the scale-free networks (Fig. 4, Fig. 1). Clustering centrality measures do not have a correlation with any other measure for both scale-free and random networks. This fact does not change with the increasing connectivity of the system.

The effect of the network topology on the spreading dynamics can be seen in Fig. 5. The most distinct feature of the Erdős–Renyi network results is the observed smooth rise in the correlations between the node centrality measures and the node infection probability (Fig. 2). The peak, seen in the Barabási–Albert network case is lost. Hence the identification of the infection spread by observing the peak in the early stages of the infection spread (Fig. 6) cannot be easily done. Moreover, apart from the clustering centrality measure, all centrality measures follow closely with each other.

Fig. 5, Fig. 6 contain information on the affect of the average degree, 6 and 12 respectively. Increased connectivity increases the speed of the infection spread. Hence, it can be seen that the speed of the spread of infection approximately doubles as the average connectivity increases from 6 to 12. Comparisons between the Figs. 3(a) with Fig. 6, Fig. 3 with 6(b) that the influencer (hub) nodes of the scale free networks play an important role in increasing the speed of the spread.


To compare scale-free and random networks with the real-world network data sets Airline Data [21] (3425 nodes (vertex) and 19 257 links (edges)) and Facebook ego network [22] (4039 nodes (vertex) and 88 234 links (edges)) are used as test ground.

Fig. 7 show the Airline and Facebook network diagrams. Despite the fact that both networks possess power-law degree distribution, Airline Network is a uni-center network while Facebook has more than one center. In the Facebook network case the local centers of dense connectivity [28], [29] are sparsely connected with the remaining centers. Fig. 7, Fig. 7 show the node distributions and connection of the Airline and Facebook networks.

The topological differences in the connectivity structures between the airline and the Facebook networks are reflected in the correlations among the centrality measures. Fig. 8 shows the correlations between centrality measures of airline network (Fig. 8(a)) and Facebook Network (Fig. 8(b)). The correlations among the airline network centrality measure closely follow the Barabási–Albert network as expected. For the airline network page rank, eigenvalue, and degree centralities are closely related. Similarly, betweenness also shows a correlation with page rank and degree centralities. Clustering centrality shows no correlation with any other centrality measures. For the Facebook case, degree and betweenness centralities correlate with the page rank centrality. Apart from these correlations non of the centrality measure exhibit significant correlation.

The effect of the correlations between the centrality measures can be seen on the centrality and the infection-spread probability correlations. Fig. 9 show the time-dependent changes in the centrality and the infection spread correlations and the spreading dynamics in the airline network. As one can see, highly correlated centrality measures exhibit similar correlations (Fig. 9(a)). The curves, corresponding to the highly correlated centrality measures (degree, page rank, eigenvalue centralities) follow each other closely. Betweenness, have the same shape, the peak position but the height of the peak, and in general, the whole curve is lower than the group of highly correlated three centrality measures. All these four centrality measures resemble closely the behavior of the Barabási–Albert case (Fig. 2). The closeness centrality measure curve has no peak, similar to the case of centrality measures of random networks, increases smoothly, and reaches a saturation level. Finally, the behaviors of the clustering centrality correlations very low and carry no significant information. The peak value and the correlation curves correspond to the point where the infection spreading slope changes. Fig. 9(b) show the time-dependent changes in susceptible, infected, and recovered individuals. The initial slow-spreading regime remains only for a very short period. After the initial stage, the slope of the curve changes. During the initial spreading phase the correlations between the probability of being infected and the node centrality measures show a strong correlation. After the slope change, these strong correlations become weaker.

The Facebook network, due to its multi-centered connectivity structure, exhibits no strong correlations among the centrality measures (Fig. 8(b)). Hence, Fig. 10(a) show that the correlations between the node centrality measures and the infection probability curves separated from each other. However, degree and eigenvector centralities have similar shapes and peak positions. The peak positions also in accord with the slope change point of the infection spread (Fig. 10(b)). The curves corresponding to page rank and betweenness centrality measures have similar behavior, but the peak positions and the peak heights indicate little correlation with the infection spreading phenomena.
At the beginning of the contamination spread, separated centers of high activity (Fig. 10) act like small communities with a high degree of connectivity, which causes the fast spread of infection. The spread of infection and the correlations between the node centrality values and the infection probability are presented by Fig. 10. Comparing with the previous cases, relatively fast initial contamination spread (Fig. 10(b)) is reflected to the peak positions of the centrality correlation curves (Fig. 10(a)).


Advanced technologies increased the quality and standards of life. One of the most significant impacts of the new technologies is on the pharmaceutical and medical research which opened the possibilities for a better and longer lifespan for large populations living in the developed and also developing countries. Another impact of technological advancement is on communication and transportation. All of the goods are available globally, while the individuals travel to see the natural, historical sites and exotic lifestyles. On the communication side, worldwide information networks made it possible to reach information globally. Despite advanced technologies used for vaccines, medicine, and medical equipment, the spreading of contagious diseases is one of the problems. Starting with the Spanish Flue, many virus-based diseases cost a great many lives. Today, COVID-19 is a striking example of a new type of virus infection. It is seen in all of the countries globally. It has no vaccine or a specific method of treatment. A unique tool to fight with this highly contagious and deadly virus is isolation or quarantine. It is almost impossible to impose long term personal isolation globally, reducing travel, identifying and isolating the most vulnerable groups or individuals, and the possible super spreaders seemingly the most effective method for fighting the spread. At this point, technology comes into play. The advanced communication technologies give a clear indication for the connectivity structure of the nodes: interactions and movements of the individuals in the societies. Hence, the knowledge of the connectivity structure of society is a tool for disease prevention attempts.
In this work, the observed facts are:

•The correlations among the centrality measures reflect the topological structure of the network.•On the complex networks, the contamination starts from the seed sites. The majority (Particularly for BA and real-world networks) of the seed sites are nodes with low connectivity. When the spreading starts from such a relatively isolated site, contamination shows a slow paste until it reaches to the highly connected nodes. After this initial transient regime, the system enters a second phase that has a higher slope. Hence, two distinct phases can be linearized separately (Figs. 3, 6, 9, and 10). Hence, the infectious disease spreading curve exhibits a short-flat initial stage (low slope) followed by a relatively faster spreading regime (higher slope).•There exists a close, time-dependent relation between the node infection probability and the node centrality values. The correlations between the centrality measures and the node infection probability increase until the end of the flat initial stage, reach its peak at the crossing point of the fitted lines indicating two separate phases.•The correlation behaves differently after the initial-stage for scale-free and random networks. 1.For scale-free networks, the increase in the correlations reaches a peak value at the point where the initial slow-spreading regime leaves its place to a fast-spreading regime.2.Random networks show a different behavior, the correlation between the centrality measures and node infection probability increases in the initial slow-spreading stage, and it levels off at the time where the spreading speed increases.
•The strength of the correlation between node infection probability and the node centrality measures depends on the centrality measure and the topology of the network.•The selected real-world networks, namely, airline and Facebook networks, both have power-law degree distribution, but exhibit different centrality-infection probability correlation patterns.•The difference is due to the connectivity structure of the networks. Airline networks have uni-centered structures, while in the Facebook case, nodes are centered around more than one loosely connected large communities.•Among the studied centrality measures, degree and page rank provide the most reliable information.

The world has experienced various influenza outbreaks in the recent past. In light of the observed facts, the existing infection spread data can be combined with the connectivity information of the individuals (nodes) for the disease prevention planning. For efficient planning, the network structure of the society must be sketched out, the centrality measures of each node must be calculated, correlations with the existing infection spread data, and centrality measures can be used to identify the society specific prevention planning.

Semra Gündüç: Conceptualization, Methodology, Software, Data curation, Writing - original draft, Simulation. Recep Eryiğit: Data curation, Writing - original draft, Visualization.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Physica A
PMC7554484,Eating behavior and food purchases during the COVID-19 lockdown: A cross-sectional study among adults in the Netherlands,"In 2020, the world has become a different place as COVID-19 (Coronavirus disease 2019) evolved from an isolated disease in the Wuhan region of China to a global pandemic (AMJC, A Timeline of COVID-19 Developments in 2020, 2020). Five weeks after confirmation that COVID-19 is transmittable from person to person, the first positive test for COVID-19 was confirmed in the Netherlands on February 27, 2020. On March 11, 2020, the WHO declared COVID-19 a pandemic, and not long after, many countries implemented measures to flatten the curve. On March 15, the Dutch Government implemented lockdown measures that were first in place for only a few weeks (until April 6, 2020). Not long after, these measures were extended until June 1st 2020 because number of deaths and hospitalizations of patients with COVID-19 remained increasing.
During the COVID-19 lockdown in the Netherlands, people were requested to work from home if possible, to avoid busy places, travel outside peak hours, stay at home and get tested when having symptoms of the virus (Dutch Government, Approach and measures against the coronavirus, 2020). Although self-quarantine and social-distancing measures were in place, restrictions were less severe compared to other countries. While Dutch participants were requested to stay at home as much as possible, they were allowed to go out for a walk or run while other citizens (e.g. Italy) were only allowed to go out for essential movement (groceries, healthcare, work) (Italian Government, Coronavirus Covid-19 Italy, 2020) or had to stay within their local area (New Zealand Government, Alert system overview, Unite against COVID-19, 2020). By means of their lockdown strategy, the Dutch government wanted to cushion the psychological, social and economic costs of social isolation, while containing the spread of the virus. Within this context, pubs and restaurants closed their doors while supermarkets and meal delivery services improved revenue (e.g. kantar.com) and local food shops like the butcher or bakery also remained open.
Already early in the pandemic, it was recognized that diet-related chronic conditions, such as cardiovascular disease, diabetes type 2, and obesity are major risk factors for being hospitalized for COVID-19, severe complications and mortality (Killerby et al., 2020; Li et al., 2020; Yadav et al., 2020). Primary measures taken by national governments during the pandemic aimed to eliminate the virus by transmission reduction via social distancing and hygiene measures. Less attention however has been directed to the potential lockdown side-effects such as unhealthy lifestyle behaviors that could even further increase those at risk. Nevertheless, prior studies indicated that self-quarantine has been associated with negative psychological effects such as psychological distress (Brooks et al., 2020). The COVID-19 lockdown has also been associated with more direct lifestyle behavior changes including increased smoking frequency (45%) among smokers (Sidor & Rzymski, 2020), both increased and decreased alcohol consumption (Anne et al., 2020; Kim et al., 2020) self-reported weight-gain in adults (e.g. due to snacking in response to food cues, stress or little sleep) (Zachary et al., 2020) and in younger adults (Sidor & Rzymski, 2020), increased consumption of unhealthy food, uncontrolled eating, snacking between meals and overall higher number of main meals (Ammar et al., 2020; Carroll et al., 2020; Sidor & Rzymski, 2020). Furthermore, it was observed that having a higher Body Mass Index (BMI) and lower age were associated with an increase in junk food consumption (Ashby, 2020; Di Renzo et al., 2020; Sidor & Rzymski, 2020) and that children with obesity increased their snack intake and sugary drinks during lockdown (Pietrobelli et al., 2020). In contrast, a Spanish study indicated that the lockdown measures led to the adoption of a healthier diet in an adult study population (Rodríguez-Pérez et al., 2020).
Whereas prior studies revealed mixed effects of the COVID-19 lockdown on eating behaviors, the impact on individual food purchase behaviors, including meal delivery, have been less frequently investigated. Zhao and colleagues indicated that most individuals in main land China continued purchasing food products (e.g. 80.1% of fruits and 77.2% of vegetables) via in-person grocery shopping (Zhao et al., 2020) and it was observed that online food shopping increased in Taiwan; every additional confirmed case of COVID-19 increased online sales by 5.7% and the number of customers by 4.9%. (Chang & Meyerhoefer, 2020). Italian insights indicated that the minority of participants used online delivery during lockdown (9%) although it was not observed how this changed compared to pre-lockdown (Di Renzo et al., 2020). Moreover, food purchasing trends indicated that households are stocking up energy dense, ultra-processed groceries (e.g. nielsen.com). However, less research is conducted on individual level changes and socio-demographic differences in food purchases during the lockdown.
To add to the literature and better understand the impact of the lockdown on changes in dietary behaviors and individual differences, the aim of this study was to examine self-reported eating behavior and food purchases during five weeks into the COVID-19 lockdown among a representative adult Dutch sample, and to assess socio-demographic differences in eating and food purchase behaviors.
In the present paper, secondary data analyses were conducted using cross-sectional online panel data collected by a panel agency (Flycatcher.eu) that has been performed in accordance with the declaration of Helsinki. The initial study was commissioned by the Netherlands Nutrition Centre, an independent organization funded by the Ministry of Economic Affairs and the Ministry of Public Health, Welfare & Sport. Descriptive outcomes (in Dutch) have been reported previously (Flycatcher, 2020). Members of the Flycatcher Panel registered voluntarily and gave explicit consent to be included in the Flycatcher Panel. Their participation in any survey is voluntary and panel members may terminate their panel membership at any time. After explaining the study details, participants could participate in the online survey which was not invasive and anonymous.
A nationwide representative sample living across the Netherlands was recruited by the panel agency. Based on the budget available while allowing a representative study sample at the same time, the aim was to reach a minimum sample size of 1000 respondents. Taken into account an expected response rate of 60–65%, an initial sample of 1598 respondents were randomly selected from the participant database of the panel agency (based on socio-demographic representativeness, e.g. age, sex, educational level) and invited by e-mail to take part in the survey. This email message included detailed information about the purpose of the study (e.g. aim, client, estimated time required for completion, number of points awarded upon completion of the entire questionnaire, information about anonymity). Respondents were invited between April 22–28, 2020 and were given seven days to complete the survey. A reminder email was sent to non-responders two days after the initial invitation. Inclusion criteria were being aged 18 years or older and currently living in the Netherlands. A final number of 1030 respondents completed the survey (response rate = 64%).
Age, sex, highest level of education, weight and height were assessed. Based on the Dutch educational system (Statistics Netherlands, 2018) three educational levels were defined high (university, college, higher vocational, general secondary, and intermediate vocational education), middle (general intermediate, and lower vocational education), and low (elementary education or less). Based on height and weight, BMI (weight (kg)/height (m)2) and weight-status (healthy weight (BMI=<25), overweight (BMI = 25 < 30), obesity (BMI=>30)) were calculated.
First, we assessed if participants indicated to eat healthy pre-lockdown on a five-point Likert scale (fully agree - full disagree). By means of three multiple choice questions, we assessed 1) if individuals found it easier or more difficult than usual to make healthy food choices, 2) if they ate healthier or less healthy than usual and 3) if they ate less or more than usual, during lockdown. Individuals could also indicate if they had not changed their eating behavior during lockdown in respect of these topics.
Among those participants that indicated to eat healthier or less healthy than usual, reasons for eating either healthier or less healthy during lockdown were assessed by asking participants to indicate the two most important reasons from a pre-defined list (e.g., fewer temptations, being bored, see Table 2 for full list). Participants were also asked to indicate if they ate in a different way than usual during lockdown (with more awareness, taking more time, during different occasions, more often and snacking more frequently) using a five-point Likert scale, ranging from fully disagree (1) to fully agree (5). We calculated the number of participants that (fully) agreed on each of the items (score 4 or 5).
First, we asked participants if they did the groceries for their household (being the gatekeeper) in the past weeks. If not at all (n = 156, 15.1%), participants were excluded from the analyses concerning food purchase behavior. Second, by means of a multiple-choice question we assessed if participants did groceries more often or less often than usual or if they did not change this frequency compared to pre-lockdown. We also assessed if participants ordered groceries online more frequently (yes/no) compared to pre-lockdown. Third, we assessed if participants more frequently purchased (yes/no) shelf-stable (e.g. preserved); frozen or ready-to-eat products compared to pre-lockdown. Also, it was assessed if participants changed the type of foods purchased by examining if they purchased less or more fruit, vegetables, fish, pastry/cake, candy/chocolate, chips/snacks, non-alcoholic drinks and alcoholic drinks during lockdown or if this was as usual. Lastly we assessed if participants used meal delivery services more often (yes/no) compared to pre-lockdown (including take-a-way), and if so, which products were ordered more often than usual deep-fried food (e.g., fries, deep-fried snacks); pizza; salad; sushi/poke bowl, wok-meals (e.g. rice, noodles), hamburgers or meals (unspecified) from local restaurants (yes/no).
Descriptive statistics were used to describe socio-demographic characteristics and eating and food purchase behavior. Multivariate multinomial logistic regression models were used to assess socio-demographic differences in eating and purchasing behavior were ‘no change in eating or purchase behavior’ was included as reference category. Multivariate binary logistic regression models were used to assess differences in meals ordered for delivery. Odds Ratio's (OR) and their 95% confidence intervals were presented. Age, sex (male/female), educational level (low, mid, high) and weight-status (healthy-weight, overweight, obesity) were included as covariates in all models. Analyses were conducted using SPSS V 26.0. Statistical significance was defined as a two-tailed P < 0.05.
Participants that completed the online survey (n = 1030) were on average 49.9 (SD 17.0) years old (range = 18-87y), almost half of the participants were men (49.5%) and the majority had a middle educational level (41.8%). In total 44.4% of the participants had a healthy weight and 55.6% of the participants had either overweight or obesity (Table 1
).
Most of the participants (82.7%) indicated that they did not find it more difficult or easier than usual to make healthier choices during lockdown, although a total of 111 participants (10.8%) indicated that they found it more difficult than usual to make healthy choices. Participants with overweight (OR = 2.13, 95%CI = 1.31–3.47) and obesity (OR = 3.23, 95%CI = 1.80–5.81) were more likely to indicate that they found it more difficult than usual to make healthy food choices during lockdown compared to those with a normal weight, Fig. 1
. Also women were more likely to indicate to find it more difficult than usual to make healthy choices during lockdown (OR = 2.07, 95%CI = 1.33–3.23) compared to men. Older participants were more likely to indicate to experience no differences compared to those of younger age, that were more likely to indicate that they found it easier than usual (OR = 1.06, 95%CI = 1.04–1.08) as well as more difficult than usual (OR = 1.04, 95%CI = 1.03–1.06) to make healthy choices during lockdown than those of older age. No differences for educational level were observed.
Most participants indicated that they did not change their diet during lockdown (83.3%) whereas 7.1% of the participants indicated that they ate more unhealthily during lockdown. Facing more unhealthy temptations at home (35.6%), more leisure time (31.5%) and being bored (21.9%) were the most frequently mentioned reasons for eating unhealthier than usual during lockdown. A total of 99 (9.6%) participants indicated that they ate healthier during lockdown. Most frequently mentioned reasons for eating healthier than usual during lockdown were a need to improve resistance (30.3%), more time/head space to prepare a healthy meal (30.3%) and more time/head space to be conscious about healthy nutrition (26.3%), Table 2
.
Participants with overweight (OR = 2.26, 95%CI = 1.24–4.11) and obesity (OR = 4.21, 95%CI = 2.13–8.32) were more likely to indicate to eat unhealthier than usual during lockdown compared to participants with a healthy weight. However, participants with overweight were also more likely to indicate that they ate healthier than usual during lockdown (OR = 1,77, 95%CI = 1.09 = 2.86) compared to those with a healthy weight, Fig. 1.
Older participants were more likely to indicate to experience no differences compared to those of younger age, who were more likely to indicate that they ate healthier than usual (OR = 1.03, 95%CI = 1.01–1.04) as well as unhealthier than usual (OR = 1.04, 95%CI = 1.02–1.06) during lockdown.
Those with a high educational level (OR = 2.25, 95%-CI = 1.03–4.93) were more likely to indicate to eat unhealthier than usual during lockdown compared to those with a low educational level. Yet, participants with a high educational level (OR = 1.68, 95%CI = 1.02–2.74) were more likely to indicate that they ate healthier than usual during lockdown compared to those with a middle educational level. No differences between men and women were observed.
Most of the participants (82.9%) did not change the amount of food they consumed during lockdown, whereas 92 (8.9%) indicated to eat more than usual during lockdown. Participants with overweight (OR = 2.24, 95%CI = 1.34–3.76) and obesity (OR = 2.73, 95%CI = 1.45–5.15) were more likely to indicate that they ate more than usual during lockdown compared to participants with a healthy weight, Fig. 1. Older participants were more likely to indicate to experience no differences in the amount they ate during lockdown compared to younger participants, whereas those of younger age were more likely to indicate that they ate more than usual (OR = 1.61, 95%CI = 1.01–2.57) as well as less than usual (OR = 1.02, 95%CI = 1.01–1.04) during lockdown. Women (OR = 1.61, 95%CI = 1.01–2.57) also were more likely to indicate to eat more than usual during lockdown compared to men. Lastly, those with a lower educational level (OR = 2.17, 95%CI = 1.08–4.36) were more likely to indicate to eat less than usual during lockdown compared to those with a high educational level.
A total number of 874 (84.9%) participants indicated to get groceries either in-store or online during lockdown and were included in the analyses. Of those participants, the majority indicated to get groceries less often than usual during lockdown (n = 440, 50.3%), Table 1. Younger participants (OR = 1.03, 95%CI = 1.00–1.05) were slightly more likely to get groceries more often than usual during lockdown than those being older. Women (OR = 1.45, 95%CI = 1.09–1.93) were more likely to indicate to get groceries less often than usual during lockdown than men. Participants with a high educational level were more likely to do groceries less frequent than usual during lockdown compared to those with a low (OR = 1.77, 95%CI = 1.17–2.67) and middle educational level (OR = 1.83, 95%CI = 1.30–2.58). No significant differences in the frequency of getting groceries for weight-status were observed. Only a small number of participants (n = 59, 6.8%) indicated that they got online groceries more often than usual, but no socio-demographic differences were observed.
Most participants indicated that they did not change the purchases of fruit, vegetables and fish during lockdown (Table 3). Yet, 15% of the participants indicated to purchase more fruit than usual during lockdown, whereas this was lower for vegetables (9.6%) and fish (6.3%). We observed no socio-demographic differences in fruit and vegetable purchases during lockdown. For fish purchases we observed that those of older age were more likely to indicate to purchase more fish than usual during lockdown (OR = 1.03, 95%CI = 1.01–1.05) compared to those that were younger. Those with a low (OR = 2.37, 95%CI = 1.11–5.04) and middle (OR = 2.35, 95%CI = 1.22–4.53) educational level were more likely to indicate to purchase less fish than usual during lockdown compared to those with a high educational level.
Most participants did not change the purchases of sweets, snacks and beverages during lockdown (Table 3). Among those that did, participants with a high (OR = 2.93, 95%CI = 1.13–7.57) and middle educational level (OR = 3.33, 95%CI = 1.40–7.94)) were more likely to indicate to purchase more pastry/cake than usual compared those with a low educational level during lockdown. In line, participants with a high (OR = 4.83, 95%CI = 1.99–11.73) and middle (OR = 3.22, 95%CI = 1.37–7.58) educational level were also more likely to indicate to purchase more sweets/chocolate than usual compared to those with a low educational level during lockdown. Those with a middle educational level were more likely to indicate to purchase less nonalcoholic beverages than usual during lockdown (OR = 2.40, 95%CI = 1.06–5.41) compared to those with a high educational level. Those with a high educational level indicated more often to purchase more alcoholic beverages than usual (OR = 2.01, 95%CI = 1.01–3.99) during lockdown compared to those with a middle educational level whereas those with a middle educational level were more likely to indicate to purchase less alcoholic beverages than usual (OR = 2.37, 95%CI = 1.39–4.06) during lockdown compared to those with a high educational level. Younger participants were more likely to indicate to purchase more non-alcoholic beverages (OR = 1.02, 95%CI = 1.00–1.04) and alcoholic beverages (OR = 1.04, 95%CI = 1.01–1.06) during lockdown than usual compared those of older age. Women were more likely to indicate to purchase more pastry/cake than usual during lockdown (OR = 2.05, 95%CI = 1.16–3.63) than men. Men were more likely to indicate (OR = 1.53, 95%CI = 1.01–2.31) that they bought less alcoholic beverages during lockdown compared to women. Participants with obesity were more likely to indicate to purchase more chips/snacks (OR = 2.79, 95%CI = 1.43–5.45) and more nonalcoholic beverages than usual (OR = 2.74, 95%CI = 1.36–5.50) during lockdown in comparison with those with a healthy weight. Participants with overweight were also more likely to indicate to purchase more nonalcoholic beverages (OR = 2.09, 95%CI = 1.16–3.77) as well as more alcoholic beverages than usual (OR = 2.05, 95%CI = 1.02–4.11) during lockdown compared to those with a healthy weight.
A total of 362 participants (41.4%) never used meal delivery pre-lockdown (incl. take-a-way) nor did during lockdown. Of those that used meal delivery services pre-lockdown, 174 (29.5%) indicated to use meal delivery services more frequently than usual during lockdown, whereas 122 (20.7%) used it less frequently than usual during lockdown. Most participants (n = 293, 49.7%) used meal-delivery services as usual during lockdown. Participants with a high educational level were more likely to indicate to use meal delivery more frequently than usual during lockdown (OR = 2.51, 95%CI = 1.34–4.67) than those with a lower educational level. Also, those of younger age were more likely to indicate to used meal delivery more often than usual than those participants of older age (OR = 1.02, 95%CI = 1.00–1.04). Further, no socio-demographic differences in meal delivery were observed.
Of the 174 participants that indicated to use meal delivery services more frequently, meals from local restaurants (n = 104, 59.8%) were most often ordered, followed by pizza (n = 61, 35.0%, Table 3). Participants with overweight (OR = 5.23, 95%CI = 1.82–15.0) and a healthy weight (OR = 3.57, 95%CI = 1.28–9.91) were more likely to indicate to order meals from a local restaurant more often than usual during lockdown than those with obesity. Participants with obesity were more likely to indicate to order pizza (OR = 2.88, 95%CI = 1.09–7.60) as well as deep-fried food (OR = 3.29, 95%CI = 1.15–9.46) more often than usual compared to those with a healthy weight. Younger participants (OR = 1.03, 95%CI = 1.00–1.06) were more likely to indicate to order deep-fried food more often than usual compared to older participants whereas older participants were more likely to indicate to order a meal from a local restaurant more often than usual (1.04, 95%CI = 1.02–1.07) than the younger participants. Participants with a low (OR = 7.55, 95%CI = 2.26–25.2) and middle (OR = 2.47, 95%CI = 1.04–5.87) educational level were more likely to indicate to order deep-fried food more often than usual compared to those with a high educational level. Women were more likely to indicate to order meals from a local restaurant more often than usual than men (OR = 2.38, 95%CI = 1.15–4.93). No socio-demographic differences were observed in the frequency of the delivery of sushi/poke-bowl and wok-meals. (Salad and hamburgers excluded from analyses due to small numbers, Table 3).
Most participants did not indicate to have changed their eating behaviors and food purchases five weeks into the COVID-19 lockdown. This stresses the perseverance of dietary routines (healthy or unhealthy) that are hard to change. Prior research showed that habits are strong predictors of eating behavior (van't Riet et al., 2011; Verhoeven et al., 2012) and can explain approximately 20% of the variation in dietary behaviors (Gardner et al., 2011). The current study shows that despite the changes in daily life and pandemic stressors, most people retained their routinized dietary behaviors. Also, earlier studies showed limited effects of individual attempts (e.g., educational interventions) to change dietary behavior (de Ridder et al., 2017). In the current study sample, the pandemic ‘only’ encouraged 30 participants (2.9%) to eat healthier during lockdown to improve their resilience, and 6 participants (0.60%) to eat healthier due to the relationship between overweight and COVID-19 complications. Yet, despite the finding that most participants did not change their behavior, general population level intake of high-processed energy dense products is still too high and the intake of fresh nutritious foods too low (National Institute for Public Health and the Environment, 2016). To illustrate, the average Dutch population currently consumes 113 g fruit and 131 g vegetables instead of the recommended 200 g and 250 g successively, per day (Netherlands Nutrition Centre, 2017). Also, approximately half of the Dutch adult population is overweight or obese (National Institute for Public Health and the Environment, 2019). As diet-related conditions like obesity are a major risk factor for being hospitalized for COVID-19, changing dietary patterns would benefit the resilience of the population in future. Attempts supporting individuals to eat healthier as well as wider food system changes to promote healthy diets are urgently needed (Swinburn et al., 2019).
A considerable number of participnats changed their eating behavior and food purchases during lockdown. To illustrate, 7.1% of the participants indicated to eat less healthy during the lockdown. Translating this figure to a nation-wide sample of 18–87 year in the Netherlands (Statistics Netherlands, 2020), this would result in 950.000 adults eating less healthy because of the lockdown. This would have severe potential public health consequences including weight gain and increased risk for non-communicable diseases like diabetes type 2 or cardiovascular diseases. It should however be acknowledged that a slightly larger part of the participants indicated to improve their food intake during the lockdown (9.6%) which would have positive public health consequences. Nevertheless, predominantly among those that ate less healthy during lockdown, substantial socio-demographic differences were observed.
Approximately 7% of the sample that was responsible for doing groceries indicated to that they ordered their groceries more frequently online than usual. This is slightly lower than the figure observed in Italy (9%) (Di Renzo et al., 2020) but much lower than the online food ordering figures during the pandemic observed in Asia (Chang & Meyerhoefer, 2020; Zhao et al., 2020). These increases in online food ordering may on the one hand related with the request to stay at home as much as possible (for which food delivery is extremely suitable) but it may also be related with fears for being infected in places like shops (Gerhold, 2020). While globally online shopping grew extensively, future trends will show how the current pandemic will change our way of shopping permanently.
We observed that eating behaviors of older participants were less likely to be impacted by the lockdown compared to younger participants, which is in line with earlier observations during the COVID-19 pandemic (Di Renzo et al., 2020). Since 23% of the participants was 65 years and older (up to 87 years old) it is reasonable to assume that their daily routines during lockdown were less divergent than usual compared those in the studying or working age group (The Netherlands Institute for Social Research, 2019). A recent study in the Netherlands indicated that 80% reduced outdoor activities and 44% worked from home during the lockdown (de Haas et al., 2020). Those in the studying and working age group (18–65) suddenly had to combine work activities with homeschooling or other caring task (e.g., causing time-stress, risk for parental burn-out (Griffith, 2020)), were faced with job losses (e.g., causing financial insecurity and mental stress), were not able to go to school/university whereas some of the working group also obtained more leisure time (e.g. inability to work, no commuting time), all of which deviates from usual routines. We observed that 17% of the participants ate at different times and 14% indicated to eat more frequently, demonstrating some participants also differentiate their daily dietary routines during lockdown. Such deviations from daily routines are also a common during vacation and holidays, which have been found related to weight gain in adults (Cooper & Tokar, 2016; Stevenson et al., 2013).
Most noticeable was that participants with overweight and obesity were more likely to indicate to find it more difficult to make healthy choices, ate unhealthier, ate more and purchased or ordered more unhealthy products and meals than usual during lockdown, compared to those with a healthy weight. To illustrate, participants with obesity were more likely to indicate to purchase chips and snacks, non-alcoholic beverages and ordered pizza or deep-fried foods more often than usual compared to those with a healthy weight. Our findings are in line with other research during the COVID-19 pandemic that found a positive relationship between obesity and weight gain after one month of self-quarantine (Pellegrini et al., 2020). A psychological explanation for the association between obesity and unhealthy eating during lockdown could be that it is moderated by stress. Indeed, stress is a common psychological reaction to the pandemic (Rajkumar, 2020). Stress is also associated with obesity, and the neurobiology of stress overlaps significantly with that of appetite and energy regulation (Sinha & Jastreboff, 2013). Moreover, people with obesity are more prone to stress-induced eating, compared to healthy controls (Cotter & Kelly, 2018). Elevated stress levels due to the pandemic may therefore translate into more unhealthy eating engagement among this group. It could also be speculated that people with overweight and obesity are more concerned about their dietary intake due to overweight preoccupation (Annis et al., 2004) and therefore be more sensitive to notice changes in their eating behavior than those with a healthy weight and be quicker to self-report to find it more difficult to eat healthy due to changed daily routines.
However, it was also observed that a group of participants with overweight were significantly more likely to indicate to eat healthier during lockdown than those with a healthy weight. Although one could speculate that improving resilience or the attention on the relationship between overweight and COVID-19 and complications could explain these outcomes, we could not support this based on additional explorative analyses; 33.3% of individuals with a healthy weight indicated to eat healthier to improve resilience, whereas this was 27.3% of those with overweight. Yet, facing less food temptations at work (58.8% vs 29.4%), on-the-go (53.3% vs. 33.3%) and at social events (60.0% vs. 36.0%) were more often indicated as one of the two main reason for eating healthier during lockdown by this group of participants with overweight. These assumptions should however be interpreted with caution and follow-up studies are needed to better understand underlying mechanisms why some individuals with overweight eat healthier while some others unhealthier under lockdown circumstances.
It was noticeable that those with a high educational level more frequently reported to eat less healthy and to purchase more sweet snacks (pastries, chocolate) during lockdown compared to those with a low educational level, and to purchase more alcoholic beverages during lockdown compared to those with a middle educational level. In general, those with a higher educational level eat healthier and drink more alcoholic beverages than individuals with a lower educational level (Dijkstra et al., 2018). A recent cluster-analysis study from France indicated that participants with a high educational level were more likely to work from home as a result of the lockdown and were more likely to change their eating behaviors (Deschasaux-Tanguy et al., 2020) whereas those that kept working outside of their home (including less qualified jobs) or those with no professional activity were less likely to change their dietary behaviors. We observed a similar pattern in our sample (data not reported), where approximately 9% of the participants with both a high and low educational level worked ‘(almost) always from home’ pre-lockdown, whereas this proportion increased to 56.5% for those with a high educational level and to 13.9% for those with a low educational level during lockdown. Therefore, the likelihood of eating unhealthier due to changed daily routines (as outlined in 4.3) is higher for those with a high educational level than for participants with a low educational level.
Those with a high educational also indicated to use meal delivery services more frequently during lockdown than those with a low educational level. As those with a higher educational level are more likely to go out for dinner usually (Lachat et al., 2012), the lockdown might have reinforced to get the restaurant “at home”, especially due to online campaigns supporting local restaurants and food services during the lockdown. Yet, when using meal delivery services, participants with a higher educational level were less likely than those with a low and middle educational level to order more deep-fried food during lockdown.
Those with a low educational level were more likely to indicate to eat less than usual compared to participants with a high educational level. Prior research indicates that food-insecurity increased since the corona crisis (Loopstra, 2020; Wolfson & Leung, 2020). A UK study found that especially those with a drop in income were more likely to experience food insecurity during the corona crisis (Loopstra, 2020) which includes eating less by skipping meals or not eating for a whole day. As individuals with low educational levels are more likely to experience larger employment losses due to the corona crisis than those with high educational levels (Cho & Winters, 2020), this could be a potential mechanism explaining this outcome.
Compared to other countries, the Dutch lockdown was less constraining. For example, in comparison with the Italy where individual movement was restricted except for the necessity, health or work, Dutch citizens were requested to stay at home as much as possible, but were able to go out for a walk or run (Dutch Government, Approach and measures against the coronavirus, 2020; Italian Government, Coronavirus Covid-19 Italy, 2020). In an Italian study, Di Renzo et al. indicated that 46.1% of the participants not changed their lifestyle behaviors and 37.4% and 35.8% of the Italian participants declared to eat more or less healthy food (Di Renzo et al., 2020). These figures are much higher than the observations in our Dutch sample, with for example 15.0% and 4.5% of the participants indicating to eat more or less fruits, subsequently. In addition, where we observed that the majority of Dutch participants did not eat (un)healthier or more during lockdown, over half of the participants in a Canadian study indicated to change their eating behavior; e.g. 57% of woman indicated to eat more during lockdown and 67% women indicated to eat more snack foods (Carroll et al., 2020). Sidor and Rzymski indicated that over 43% and more than 50% of participants in Poland reported to eat and snack more. These figures are also higher than that we observed in our Dutch sample (e.g. 8.9% indicated to eat more). Ruiz-Roso and colleagues observed that adolescents in Spain Chile Colombia and Brazil increased fruit (+7.7 percent point (pp)) and vegetable (+7.8 pp) intake as well as increased fried (1.4 pp) and sweet food intake (+6.7 pp). While we did not include adolescents, we observed that 15% indicated to have purchased more fruit, 9.5% more vegetables, 9.5% more candy/chocolate. 23% indicated to order deep-fried food more often. These figures are slightly more in line with our findings than those of the Italian, Canadian and Polish study findings. Nevertheless, our observation that the lockdown was more likely to take a toll on healthy dietary choices of participants with obesity has been observed in a variety of international studies (Ashby, 2020; Di Renzo et al., 2020; Sidor & Rzymski, 2020). All together these findings suggest that different lockdown strategies implemented in different countries have influenced eating behaviors differently. Further research should unravel how different lockdown measures impacted these supposed differences, taking both socio-cultural factors and the severity of the coronavirus in the country of concern into account.
Strengths of the study include the large study sample, generalizability of the study sample, the included survey items explicitly asking for differences in eating and purchase behavior as compared to pre-lockdown and that the study was timed in week five of the lockdown (and thus not retrospective). Limitations of the study include the cross-sectional character and the use of unvalidated measures to assess eating and food purchasing behavior. Also, all outcome measures were self-reported. This may have caused bias by expressing participants’ ideas rather than their actual behavior. For example, the participants may have had different perceptions of healthy food and a healthy diet rather than their actual behavior, which may have caused bias as well. While 81% of the participants of this study indicated that they ate rather healthy pre-lockdown, national studies into food consumption using 24h recalls indicate that this percentage is much lower (e.g. only 6% of the population meats daily vegetable recommendations (Institute for Health and Environment, Food consumption compared to the wheel of five 2012/14–2016, 2017). Moreover, using self-reported BMI as proxy for weight status may have bias the outcomes (Dekkers et al., 2008). This is however a common limitation in the field of behavioral nutrition research which uses surveys that measures dietary behavior and will be common in comparable COVID-19 related studies that predominantly relied on self-reported survey studies.
Parallel to fighting the coronavirus and eliminating the COVID-19 pandemic it is important to implement actions and interventions encouraging a healthy diet to support individuals to get into a healthy lifestyle routine, especially among vulnerable groups (e.g. individuals with obesity). Not only are diet related non-communicable diseases like obesity associated with increased risk for severe illness or death from COVID-19, our study also indicates a higher risk for unhealthy eating behavior for the same group under lockdown circumstances. Besides, the pandemic has confronted us with the fragility of the food system (e.g. disruptions of the global food chains and empty supermarket shelves) (Hobbs, 2020). Supporting a healthy diet should be approached from a socio-ecological perspective by not only encouraging individuals to eat well-balanced meals but also improving the food system on the global, national and community level, also addressed in the multi-level framework of action to support nutrition and food security during the COVID-19 pandemic (Naja & Hamadeh, 2020). For example, the COVID-19 pandemic provides urban planners with the opportunity to support the development of rebalanced and healthier local food systems, reducing reliance on national supermarkets (Cummins et al., 2020). The increase upsurge of online food purchases during the pandemic also observed in the current study may reassure retailers to improve web shops to encourage customers to get healthier groceries (Jilcott Pitts et al., 2018) or boost local restaurants to offer healthier meal delivery options, especially since the current meal delivery scape is not supportive in this (Poelman et al., 2020). Such community environmental improvements, together with global, national and individual efforts could support healthy eating behaviours needed to improve resilience of the population during the current crisis, but also in the future. In the upcoming months or years (depending on the course of the virus and its impact on society) it is important to monitor the consequences of the virus and the lockdown on peoples’ eating and food behaviors as well as health status, especially among the most vulnerable groups. In addition, underlying mechanisms of the impact of the lockdown on diet should be further understood. At last, actions that support a sustained and healthier food system and environmentshould be studied and implemented.
Most participants did not change their eating behavior or food purchases during lockdown, confirming the persistence of dietary routines. However, profound socio-demographic differences were observed for those that did report changes. Especially for individuals with overweight and obesity, the lockdown has taken its toll on healthy dietary choices. Because diet-related conditions are a major risk factor for being hospitalized for COVID-19, this study indicates that the pandemic may even further challenge public health. More research should unravel underlying mechanisms for these observations while at the same time sustained and healthier food systems are needed to improve resilience of the population in the current and future pandemics.
MP analysed the data and wrote the manuscript. FM, ED, PA designed the online survey and ED and PA collected the data. All authors read and provided input and critical feedback on the manuscript before approving.
The data collection was funded by an institutional subsidy (‘instellingssubsidie’) of the 10.13039/100009647Ministry of Health Welfare and Sport and by the 10.13039/501100013890Ministry of Agriculture, Nature and Food Quality of the Dutch Government.
As this study involved secondary data analyses of data that was initially collected by the Netherlands Nutrition Centre, no approval from an ethics committee prior to the reported study was obtained. However, the data collection was not invasive (online survey about eating behavior) and is in line with the ethical standards of the involved universities. Therefore, we report the following in the manuscript:
Data collection has been performed in accordance with the declaration of Helsinki. After explaining the study details, participants could participate in the online survey which was not invasive and anonymous, but signed informed consent was not obtained.
None.",Appetite
PMC7787058,"Comparing actual and forecasted numbers of unique patients dispensed select medications for opioid use disorder, opioid overdose reversal, and mental health, during the COVID-19 pandemic, United States, January 2019 to May 2020","Implementation of community mitigation measures such as stay-at-home orders to slow the spread of SARS-CoV-2, the virus that causes the 2019 novel coronavirus disease (COVID-19), has been widespread in the United States (Gostin and Wiley, 2020). Collateral consequences of these mitigation measures (e.g., economic stress, social isolation), coupled with fear of virus transmission, have raised concerns about worsening mental health and substance use-related harms such as opioid use disorder and overdose (Henry et al., 2020; Volkow, 2020). A recent survey found that 1-in-7 U.S. adults reported serious psychological distress in April 2020, during peak use of community mitigation measures (McGinty et al., 2020). A subsequent survey of adults in the U.S. reported that 13.3 % of adults had started or increased substance use to cope with pandemic-related stress or emotions, 30.9 % had symptoms of anxiety or depressive disorders, 26.3 % had symptoms of a trauma and stress-related disorder, and 10.7 % had seriously considered suicide in the past 30 days (Czeisler et al., 2020). In addition, emerging data indicate that drug overdoses have increased during the same time period as peak community mitigation measures (Alter and Yeager, 2020).
Further, as a result of community mitigation measures, access to medical treatment, including medications used to treat opioid use disorder, opioid overdose, and mental health conditions, may have been limited due to clinician office closures, discontinuation of in-person treatment and recovery support services, and delays in seeking care due to concerns about exposure to COVID-19 during medical visits (Henry et al., 2020; Volkow, 2020). Analysis of pharmacy dispensing data is one approach to examine if access to medications changed during community mitigation measures; yet, to date, such analyses are lacking. To address this research gap, this study used nationally representative data to assess dispensing patterns of selected substance use and mental health medications from January 2019 through May 2020 in the United States.
In this time series analysis, data from the IQVIA Total Patient Tracker database, which captures 92 % of prescriptions dispensed from U.S. retail pharmacies, were used to calculate the number of unique patients (all ages) dispensed the following medications by month from January 2019 to May 2020: medications for opioid use disorder treatment, buprenorphine (single entity and buprenorphine-naloxone combinations), extended-release (ER) intramuscular naltrexone; the overdose-reversal medication naloxone, including those issued under a standing order in retail pharmacies; selective serotonin reuptake inhibitor or serotonin-norepinephrine reuptake inhibitor antidepressants; benzodiazepines; and for comparison purposes, two chronic disease medications, HMG-CoA reductase inhibitors (statins) used in the treatment of hyperlipidemia and angiotensin receptor blockers (ARBs) used in the treatment of hypertension and other cardiovascular conditions. Buprenorphine formulations approved for the treatment of pain (i.e., Butrans, Belbuca, Buprenex) were excluded from the analysis. In addition, oral naltrexone formulations were not included as they are not generally recommended in the treatment of opioid use disorder (American Society of Addiction Medicine, 2020; Substance Use and Mental Health Services Administration, 2020a).
To assess changes in the number of unique patients dispensed medications during the time of COVID-19 mitigation measures, March 2020 to May 2020, we used the exponential triple smoothing statistical forecasting function in Microsoft Excel (Seattle, Washington) to generate monthly forecasted estimates and 95 % confidence intervals (CIs) for each drug or drug class examined. This statistical forecasting method predicts future values based on historical data by utilizing the additive error, additive trend, and additive seasonality (AAA) exponential triple smoothing algorithm; a method well suited for data with seasonality or other cyclical patterns over time (Microsoft, 2015; Makridakis et al., 1998). Once forecasted estimates and 95 % CIs were estimated, we then compared the forecasted estimates with the actual number of unique patients dispensed each medication by month for March 2020 to May 2020. The actual number of unique patients dispensed the medication were considered statistically significantly different than forecasted estimates if the actual number of unique patients in a particular month fell outside the forecasted estimates and associated 95 % CIs. When this occurred, the actual number of unique patients dispensed the medication was considered to be higher or lower than what would have been expected based on prior trends in the data for that medication. All analyses were conducted with Microsoft Excel (Seattle, Washington) and Stata V15.1 (College Station, Texas). This study was a secondary analysis of de-identified data and was therefore exempt from institutional review board approval.
From January 2019 to February 2020, the monthly number of unique patients dispensed antidepressants (mean = 13,888,901 [SD = 337,357]; range = 12,696,855 to 13,844,201) as well as benzodiazepines (mean = 4,781,043 [SD = 166,850]; range = 4,478,448 to 5,011,279) was relatively stable; however in March 2020, the number of unique patients dispensed antidepressants (14,330,662) and benzodiazepines (5,128,721) was statistically significantly higher than forecasted estimates (Fig. 1
). In March 2020, an estimated additional 977,063 (95 % CI: 351,384 to 1,602,743) unique patients and 450,074 (95 % CI:189,999 to 710,149) unique patients were dispensed antidepressants and benzodiazepines, respectively, compared to forecasted estimates. The numbers of unique patients dispensed antidepressants and benzodiazepines in April 2020 and May 2020 were within forecasted estimates. The patterns of dispensing in March 2020 to May 2020 for the two comparison chronic disease medications, statins and ARBs, were similar to those for antidepressants and benzodiazepines during this time.
The number of unique patients dispensed buprenorphine products approved to treat opioid use disorder increased from 713,778 in January 2019 to 814,019 in May 2020 (Fig. 2
A). Between March 2020 to May 2020, the number of unique patients dispensed buprenorphine products was within forecasted estimates. The number of unique patients dispensed ER intramuscular naltrexone fell statistically significantly below forecasted estimates in each month, March 2020 to May 2020. In March 2020, an estimated -1039 (95 % CI: -1528 to -550) fewer patients were dispensed ER intramuscular naltrexone compared to forecasted estimates, followed by -2139 (95 %CI: -2629 to -1650) fewer patients in April 2020, and -2498 (95 % CI: -2987 to -2009) fewer patients in May 2020 (Fig. 2B). The numbers of unique patients dispensed naloxone fluctuated during the study period (mean = 73,573 [SD = 3768]; range 67,294 to 81,323) but were within forecasted estimates for March 2020 to May 2020.
This study is subject to limitations. First, our data do not include information on whether prescriptions were used by patients, the patient-specific clinical indication for the medication, or whether these were new prescriptions or refills. Second, sociodemographic characteristics that could affect treatment access were not included in the data. Third, although our data reflect unique patients receiving medications at given points in time, we were not able to examine individual patients over time. Fourth, naloxone administered by emergency medical services personnel or first responders and naloxone distributed by community-based organizations outside of retail pharmacies are not included in the IQVIA data used in this study. Fifth, our data did not include geographic identifiers; thus we were not able to assess differential impacts on unique patients dispensed medications across geographic areas. Finally, we were not able to assess use of non-medication-based treatments for mental health or substance use conditions or receipt of medications outside of U.S. retail pharmacies, including methadone for opioid use disorder treatment provided through opioid treatment programs as well as extended-release naltrexone provided through clinician offices.
This study is the first to provide national estimates of access to select addiction, overdose reversal, and mental health medications during the COVID-19 pandemic and time of peak community mitigation measures. Importantly, we found that prescription dispensing for most medications examined fell above or within forecasted levels. However, ongoing concerns about the prolonged effects of the COVID-19 pandemic and related stressors on mental health and substance use (Henry et al., 2020; McGinty et al., 2020; Alter and Yeager, 2020; Volkow, 2020) underscore the importance of implementing innovative strategies to facilitate continued access to treatment, recovery, and harm reduction services.
The findings and conclusions in this report are those of the authors and do not necessarily represent the official position of the Centers for Disease Control and Prevention/the Agency for Toxic Substances and Disease Registry.
Drs. Jones and Guy conceived of the study. Drs. Jones and Guy conducted the data analysis and Dr. Jones drafted the manuscript. Drs. Guy and Board provided critical review and revisions to the manuscript.
The authors report no declarations of interest.",Drug Alcohol Depend
PMC7558232,Food choice motives and the nutritional quality of diet during the COVID-19 lockdown in France,"The world is currently facing the COVID-19 pandemic. To avoid fast-growing transmission of the virus, governmental authorities have had to impose nationwide lockdowns. In France, between March 17th and May 10th, 2020, most of the population was asked to stay home. In order to limit drastically any human contact, the French were allowed to leave their home only for grocery shopping, medical care, legal obligations and physical activity within a 1 km radius; except for workers from essential sectors (e.g., healthcare, food factories and shops). During this period, all businesses that sold food remained open to the public. However, major disruptions in daily routines caused by the lockdown (e.g., home-working, restaurant closures) were likely to alter food consumption habits in the French population. Moreover, closed borders led to changes in the distribution and availability of food products (Morel, Stroobants, Bran, Iwaniuk, & Hauteville, 2020; Oxfam France, 2020).
A large part of humans’ eating behaviours are habits, i.e., automatic associations between specific context cues and responses, which have history of repetition and reward. Habits form as people pursue goals by repeating the same responses in given contexts, and become automatic and hard to change (Wood & Runger, 2016). Because food choices are performed every day and usually in the same context, they likely result from a habitual response; notably, food choices have been shown to be very stable in adulthood (Borland, Robinson, Crozier, & Inskip, 2008; Hu et al., 1999; Khani, Ye, Terry, & Wolk, 2004; Weismayer, Anderson, & Wolk, 2006). However, when people are undergoing changes in their environment, their habits are vulnerable to change as they engage in a new non-automatic process of decision making (Verplanken & Wood, 2006). We thus hypothesised that the unusual lockdown period may have caused discontinuities in food choice habits.
In a constructionist perspective, food choice decisions result from one's personal food values that are shaped by life course events, personal and social factors (Furst, Connors, Bisogni, Sobal, & Falk, 1996; Sobal & Bisogni, 2009). Food values are computed by integrating a set of attributes (food choice motives) based on their importance or salience for an individual at the point of choice (Rangel, 2013). A change in food choice motives may thus lead to a change in food choice decisions. The most important food choice motives have been shown to be taste, cost, nutrition and convenience with a large interindividual variability (Glanz, Basil, Maibach, Goldberg, & Snyder, 1998). We hypothesised that people engaging in a new process of food choice decision making during the lockdown period may have caused changes in food choice motives associated with changes in food choice habits, resulting in modification of the nutritional quality of diet.
The present study aimed to examine the extent of changes in food choice motives during the lockdown and how it related to changes in nutritional quality of diet. We hypothesised that food choice motives and nutritional quality of diet changed during the first month of lockdown (from March 17th to April 16th, 2020) compared to the month just before the lockdown (from February 17th to March 16th, 2020). We also hypothesised that changes in food choice motives were associated with changes in nutritional quality. Because poor nutritional quality diet is one of the main risk factors for non-communicable diseases (Afshin et al., 2019), it is of importance to examine the effect of the lockdown on nutritional quality to help anticipating health consequences at a population level. Moreover, this unique nationwide disruption in daily life gives the opportunity to investigate how changes in food choice motives may influence the nutritional quality of diet at an individual level. The results may inform future public health actions that aim at tackling diet related non-communicable diseases by identifying which food choice motives changes may increase or decrease the nutritional quality of diet.
This was a cross-sectional, pre-registered online experiment conducted in Qualtrics survey platform (www.qualtrics.com). Participants were recruited by emailing individuals from a population registered in the Chemosens Platform's PanelSens database at Centre des Sciences du Goût et de l’Alimentation (Dijon). This database was declared to the relevant authority (Commission Nationale Informatique et Libertés; CNIL; n°1,148,039). Eligible participants were aged over 18, had been residing in France at least since February 17th, 2020 (i.e., one month before the lockdown) and had access to a computer or tablet with an internet connection. Eligible participants who completed the study received compensation in return for their participation (15€ Amazon voucher). The study was approved by the ethical evaluation committee for research of INSERM (reference: n°20–683, delivered on April 27th, 2020). All participants were informed that the purpose of the study was to investigate food choices during the lockdown and provided consent for their participation. Data were collected on April 30th and May 1st, 2020. Three attention check questions (e.g., ‘How many times have you visited the planet Mars?‘) were included in various parts of the questionnaire.
Participants’ characteristics assessment included demographic questions (age, gender, employment status, highest educational qualification, professional situation during the lockdown, living area, type of housing, household composition, financial situation) and food-related behaviours questions (out-of-home eating habits before the lockdown, grocery shopping frequency and time spent cooking during the lockdown, changes in eating habits during the lockdown, dietary restrictions, dieting status, weight and height at the time of the study). Participants also answered questions about their consumption of organic and local food products (not reported here). As participants were recruited during the COVID-19 pandemic, they were asked if they suspected having or having had COVID-19 and how worried they were about their health. We also asked for current levels of stress, depression, and loneliness (3 individual items) on a continuous scale from 0 to 100.
Food choice motives were assessed using a French version of the Food Choice Questionnaire developed in English by (Steptoe, Pollard, & Wardle, 1995) and adapted by (Cottet, Ferrandi, Lichtlé, & Plichon, 2017). The French version included 24 items and nine subscales: health (3 items), convenience (3 items), sensory appeal (3 items), natural content (3 items), ethical concern (2 items), weight control (3 items), mood (3 items), familiarity (2 items), and price (2 items). See Additional file – section 1 for the items in French and in English. Instructions were adapted to assess food choice motives during the month before the lockdown and during the first month of the lockdown simultaneously. For each subscale, two scores were computed by averaging ratings for individual items before and during the lockdown, respectively. The scores ranged from 1 to 4: 1 = Not at all important; 2 = A little important; 3 = Moderately important; 4 = Very important. Δ motives were calculated as the difference of the score for each of the nine subscales during and before the lockdown. Δ motives > 0 indicated higher importance of the motives during the lockdown compared to before.
Food consumption was retrospectively assessed for the month before the lockdown and the first month of the lockdown simultaneously using a validated food frequency questionnaire including 110 foods, 12 non-alcoholic drinks and 4 alcoholic drinks with frequency assessed by a 6-item scale from “Never” to “Several times a day” (Kadawathagedara et al., 2017). Usual portion sizes before and during the lockdown were estimated with photos for different food types on a 5-level scale, derived from the SU.VI.MAX portion book (Hercberg, Deheeger, & Preziosi, 2002), for 72 commonly eaten food items, and by the intermediate portion size for the 38 remaining food items. Participants were also asked the size of the glass or cup they used before and during the lockdown for each non-alcoholic beverage and standard servings were used to estimate alcoholic beverage amounts. Consumption frequency of each item before and during the lockdown was transformed into daily frequency, and daily intake was calculated by multiplying the daily frequency by the estimated portion size. Individual nutrients intakes were calculated before and during the lockdown by multiplying the daily intake of each food item by its nutritional values from the SU.VI.MAX nutrient composition database (Hercberg, 2006).
Adherence to the French dietary recommendations was evaluated during the month before the lockdown and during the first month of the lockdown using the simplified PNNS-GS2 (sPNNS-GS2), an index previously designed to reflect the 2017 French main dietary recommendations (Chaltiel et al., 2019). The sPNNS-GS2 builds on the distinction between malus components (less healthy food groups which consumption should be limited, carrying a negative score, i.e., red meat, processed meat, sugary foods, sweet-tasting beverages, alcoholic beverages, salt) and bonus components (healthier food groups carrying a positive score, i.e., fruits and vegetables, nuts, legumes, whole-grain food, milk and dairy products, fish and seafood). The sPNNS-GS2 calculation has been previously described by Chaltiel et al., 2019. A weight for each component is defined according to the level of evidence of the association between food groups consumption and health status. sPNNS-GS2 were computed for each participant before and during the lockdown (range: 17 to 11.5). Slight modifications were brought to the calculation of the score. The sPNNS-GS2 originally included bonus points for added fat below 16% of energy intake (Chaltiel et al., 2019). The food frequency questionnaire did not make it possible to calculate the percentage of energy intake accounted for added fat and this component was excluded from the score calculation. However, a modified version of the sPNNS-GS2 including an added fat component based on the ratio of plant over animal fat was also calculated. The main analysis was replicated on this indicator and results were similar (see Additional file – section 2). In addition, the only whole grain food included in the food frequency questionnaire was whole grain bread. To obtain an estimation of other whole grain foods consumption frequency as required by the sPNNS-GS2 calculation, we calculated the ratio whole grain bread/(whole grain bread + white bread) and multiplied the consumption frequency of other grains (pasta, rice and semolina) by this ratio.
The primary outcome, Δ quality, was the difference in nutritional quality of diet (sPNNS-GS2) between during and before the lockdown. Δ quality > 0 indicated better nutritional quality during the lockdown compared to before.
Hypotheses were specified before the data were collected and we followed an analytic plan that was pre-registered before data analysis (https://osf.io/gwfdb/). Only participants who completed the study were included in the analyses. Participants who failed at least one attention check were excluded. We analysed data from participants who reported plausible energy intake, i.e. ≥ 500 kcal/day and ≤3500 kcal/day for women, and ≥800 kcal/day and ≤4000 kcal/day for men (Banna, McCrory, Fialkowski, & Boushey, 2017; Willett, 2013).
For descriptive purposes, we compared food choice motives scores and sPNNGS-2 components before and during the lockdown using paired T-tests. As exploratory analyses, we also examined whether changes in food choice motives or nutritional quality during the lockdown compared to before differed across population subgroups using one-way ANOVAs: people who are younger vs. older, male vs. female, normal-weight vs. overweight, lower vs. higher educational level, facing financial difficulties vs. people who were not, living alone during the lockdown vs. with others, living in a city vs. in the countryside, usually having meal out of home at least four times a week vs. less than 4 times a week, infected by the corona virus vs. not infected. We then examined the influence of changes in food choice motives during and before the lockdown on the difference in nutritional quality of diet by running a multiple linear regression including the nine Δ motives as predictors and Δ quality as the dependant variable (main model). Sensitivity analyses were conducted to examine whether the pattern of results from the main model differed: 1/ including age, gender, highest educational level and declared BMI as covariates (adjusted model), 2/ excluding participants who declared that they did not make any noticeable change in their diet during the lockdown, 3/ excluding participants who declared that they often did not find in store what they wanted to buy during the lockdown, as change in diet quality could be due more to external constraints than to personal motives, 4/ excluding participants who declared that they went to work as normal during the lockdown. As an additional exploratory analysis, we also adjusted the main model for the variables with significant effects on Δ motives or Δ quality in the exploratory one-way ANOVAs.
All statistical analyses were performed using SAS version 9.3 (SAS Institute, Inc. 2012 SAS® 9.3. Cary, NC). The level of significance was set at p < 0.05 applying Bonferroni correction for multiple comparisons where appropriate.
We aimed to recruit a sample size of 1000 participants to detect small differences in food choice motives scores and sPNNS-GS2 before and during the lockdown using paired t-tests (d = 0.1) and small effects of Δ motives on Δ quality in a multiple linear regression including nine predictors (f2 = 0.016) at power 0.80 and level of significance 0.05 (GPower 3.1).
A total of 1353 participants consented to participate. Participants who were not eligible (n = 110), did not complete the study (n = 121), failed at least one attention check (n = 84) or reported implausible energy intake (n = 100) were excluded and data from 938 participants were analysed. Participants’ characteristics are presented Table 1
. Eighteen participants declared that they suspected having COVID-19 when they completed the study and 59 declared that they suspected having had COVID-19 before. Six hundred participants (64%) declared being slightly to very worried about their health. On average levels of stress, depression, and loneliness were 26 (SD 28), 23 (SD 25), and 34 (SD 28) respectively on a scale from 0 to 100.
Food choice motives changed significantly during the lockdown compared to before (Table 2
). In particular, 48% of the participants declared that mood was more important in their food choices during the lockdown compared to before and 48% declared that convenience was less important. Health and weight control were more important during the lockdown compared to before for 26 and 29% of the participants, respectively.
On average, the participants consumed 1700 kcal/day (SD 596) during the month before the lockdown and 1935 kcal/day (SD 656) during the first month of lockdown and this increase was statistically significant (paired t-test: t(937) = 13.57, p < 0.001). Overall, the nutritional quality of diet significantly decreased during the first month of the lockdown compared to the month before (Table 3
). Despite an increase in fruit and vegetables, pulses, fish and seafood consumption, the sharp increase in processed meat, sweet-tasting beverages and alcoholic beverages consumption negatively affected the sPNNS-GS2.
We explored whether changes in food choice motives and nutritional quality during the lockdown compared to before differed across population subgroups and found relatively few significant differences (see Additional file – section 3).
When examining the influence of changes in food choice motives on changes of the nutritional quality of diet during the lockdown compared to before, we found that increased importance of weight control motives was associated with increased nutritional quality and that increased importance of mood motives was associated with decreased nutritional quality in both raw and adjusted multiple linear regressions (Table 4
). Changes in other food choice motives were not associated with changes in the nutritional quality of diet. In the other three multiple linear regressions testing the influence of changes in food choice motives on changes of the nutritional quality conducted as sensitivity analyses (i.e., excluding participants who declared that they did not have made any noticeable change in their diet during the lockdown, excluding participants who declared that they often did not find in store what they wanted to buy during the lockdown, excluding participants who declared that they went to work as normal during the lockdown), Δ weight control and Δ mood remained significant or marginally significant predictors of Δ quality (see Additional file – section 4). In addition, the exploratory adjusted model, including the variables from exploratory analyses for which we found differences in Δ motives or Δ quality at alpha level = 0.05, also led to similar results (see Additional file – section 4).
To our knowledge, this is the first study that investigated changes in food choice motives associated with nutritional changes during the lockdown in France. Significant changes in food choice motives during the lockdown were observed with an increase in the importance of mood, weight control, health, ethical concern, natural content and sensory appeal, and a significant decrease in the importance of convenience, familiarity, and price. The participants reported a 14% increase in energy intake and a decrease in nutritional quality of their diet during the lockdown compared to before. An increase in the importance of weight control during the lockdown was associated with increased nutritional quality, whereas an increase in the importance of mood was associated with decreased nutritional quality. Changes in the importance of other food choice motives were not associated with changes in nutritional quality of diet.
Increase in energy intake and unhealthier dietary patterns during the lockdown compared to before were also described in a study conducted among 37,252 French adults from the web-based NutriNet-Santé cohort (Deschasaux-Tanguy et al., 2020). The authors found an energy intake of 1942 kcal/day during the lockdown, which is similar to the reported energy intake reported during the lockdown in the present study (1935 kcal/day on average). The authors highlighted weight gain for 35% of the sample and increased consumption of sweets, biscuits, and cakes. Consistently, despite the fact that the participants of the present study increased their intake of fruit and vegetables, pulses, fish and seafood, they also increased their consumption of processed meat, sugary foods, sweet-tasting beverages and alcoholic beverages leading to a decrease in the nutritional quality of their diet on average. These changes in food consumption patterns echo studies showing increased snacking during the lockdown (Deschasaux-Tanguy et al., 2020; Sanchez & Moreno, 2020), as fatty-sweet products and sweet-tasting beverages (including fruit juices) are usually consumed during snacking episodes by French adults (Si Hassen et al., 2018). In addition, a survey on 3000 French adults reported that 42% declared having pre-meal drinks (“apéritif”) more often during than before the lockdown (Darwin Nutrition & IFOP, 2020). Pre-meal drinks are usually the first part of a meal, opening a social eating time and are often accompanied by finger foods (Danesi, 2018). The deterioration of nutritional quality during the lockdown may be partly due to increased number of social and festive eating occasions within the home, associated with consumption of low-nutritional-quality foods (e.g., sweet-tasting beverages and alcoholic beverages, processed meat, sugary foods). Changes in health, ethical concern, natural content, sensory appeal, and price food choice motives during the lockdown are in line with the results of a survey conducted among a representative sample of 1005 French adults where the participants declared changes in their perception of the ecological (49%), social (47%) and economical (57%) values of the food during the lockdown (YouGov, 2020). The decrease in the importance of convenience for 48% of our sample mirrored that 83% declared that they increased their time spent cooking during the lockdown. Collectively, these changes in food choice motives may reflect a growing awareness of the importance of the sustainability of food choices where preserving health and pleasure from eating, protecting the environment and guaranteeing decent wages to farmers are equally important (FAO & WHO, 2019).
Increase in the importance of mood (48% of the participants) and weight control (29% of the participants) food choice motives were prominent and associated with opposite changes in nutritional quality of diet. Stress, feeling of emptiness and boredom management by eating were common behaviours in the French population during the lockdown with 63%, 63%, and 57% prevalence in a 1092 sample of French adults, respectively (Cherikh et al., 2020). Occasional emotion regulation by eating is associated with the consumption of sweet foods (De Lauzon et al., 2004; Macht & Simmons, 2011) which may explain the negative relationship between changes in mood food choice motive and nutritional quality of diet. On the contrary, increased importance of weight control led to increased nutritional quality, suggesting that participants engaging in weight management behaviour successfully stuck with their goal by managing their food intake during the first month of the lockdown. In line with our results, a study investigating eating behaviour during the lockdown in 2364 UK adults showed that 35% of the participants declared eating a more healthy and balanced diet during the lockdown compared to before (Robinson et al., 2020). It is worth noticing that in the present study increased importance of health as a food choice motive was not significantly correlated with increased nutritional quality; whereas people more motivated by health were reported to adopt healthier diet than people less motivated by health (Konttinen, Sarlio-Lähteenkorva, Silventoinen, Männistö, & Haukkala, 2012; Naughton, McCarthy, & McCarthy, 2015). Moreover, we would have expected an increase in nutritional quality when price became less important because of the positive association between price and nutritional quality across individual food items (Andrieu, Darmon, & Drewnowski, 2006; Marty et al., 2015; Rehm, Monsivais, & Drewnowski, 2011), but this is not supported by these data. Similarly, we would have expected an increase in nutritional quality when convenience became less important because the degree of food processing and convenience were shown to be negatively associated with nutritional quality (Martínez Steele, Popkin, Swinburn, & Monteiro, 2017; Poti, Mendez, Ng, & Popkin, 2015). Our results suggest that choosing more expensive and less convenient foods (i.e., requiring more effort and time to prepare) did not necessarily translate into better nutritional quality of diet. Overall, the difference in the measured food choice motives only explained 5.7% of the variance of the change in the nutritional quality during compared to before the lockdown. Nutritional quality is multidimensional by nature; food choices are complex decisions and various other variables may have influenced what people chose to eat and the resulting nutritional quality of their diet during the lockdown, for instance the availability of food products.
We were able to collect detailed information about food consumption during the month before the lockdown and during the first month of the lockdown in a large sample of French adults. Our study was timely as the data were collected two weeks after the end of the first month of the lockdown. However, the participants retrospectively reported their food consumption which is a clear limitation of this study. We could not anticipate the lockdown and organise a measurement point before the lockdown. Participants were asked to report simultaneously for each food item their consumption before and during the lockdown which made it easier reporting differences in consumption frequency, even if a recall bias could have affected the responses for the period before the lockdown. In other respects, due to this exceptional situation, we compared food consumption in March (before the lockdown, end of winter) and in April (during the lockdown, beginning of spring). We could have expected a season effect in our data, with an improvement of the nutritional quality of diet in April compared to March due to increased availability of fresh fruit and vegetables, although access to fresh product may have been limited by the lockdown (Oxfam France, 2020). Finally, due to unexpectedly high numbers of participants who failed an attention check or reported implausible energy intake (16.4% of the eligible participants who completed the study), we did not reach the sample size of 1000 participants we aimed for. However, a sample size of 938 participants still allowed to detect small effects of Δ motives on Δ quality in a multiple linear regression including nine predictors (f2 = 0.017) at power 0.80 and level of significance 0.05 (GPower 3.1). A limitation of this study is that the sample was not representative of the French population and included more women and individuals with higher educational level. This is often the case in studies with volunteers on this topic (Deschasaux-Tanguy et al., 2020). In addition, the participants were recruited from a population registered in the Chemosens Platform's PanelSens database, gathering individuals who agreed to be contacted to take part in research studies exploring eating behaviours. Thus, it is likely that our sample was biased towards individuals with an interest in food. However, this can also be viewed as a strength as these individuals were more likely to have paid attention to what they ate before and during the lockdown and consequently to have cautiously reported their food consumption.
In a follow-up study, it would be interesting to investigate whether changes in food choice motives and nutritional quality remain stable overtime. Moreover, we analysed the nutritional quality, but the lockdown may also have influenced other characteristics of diet (e.g., proportion of organic and local products). A secondary objective of this online survey was to compare consumption of organic and locally produced food before and during the lockdown and to examine how it related to nutritional quality of diet. The collected data about consumption of organic and local food products before and during the lockdown will be analysed separately. An unanswered question is how diet of more disadvantaged populations was modified during the lockdown and specific studies are needed to describe food choices and eating behaviours among these populations. Finally, only increased weight control food choice motive significantly predicted a better nutritional quality of diet. The increase in health food choice motive did not translate into better nutritional quality of diet. Yet, numbers of public health actions aim at increasing motivation towards health to encourage the individuals to make healthier food choices (Capewell & Capewell, 2017; Frieden, 2010). Our results suggest that increasing the importance of health as a food choice motive might not be sufficient to increase the nutritional quality of diet, maybe because of a lack of nutritional knowledge. From this perspective, making nutritional information easy to understand and directly accessible by consumers at the point of choice should be prioritised, e.g., the front-of-pack nutrition label Nutriscore (Egnell et al., 2018).
The lockdown period in France was related to a decrease in the nutritional quality of diet on average which could be partly explained by changes in food choice motives. The lockdown was indeed related to modification of food choice motives in this sample, notably with an increase of mood as a food choice motive. Moreover, the importance of convenience and price motives decreased whilstthe importance of health, natural content and ethic motives increased, suggesting a growing awareness of the importance of sustainable food choices.
The study was approved by the ethical evaluation committee for research of INSERM (reference: n°20–683, delivered on April 27th, 2020). All participants were informed that the purpose of the study was to investigate food choices during the lockdown and provided consent for their participation.",Appetite
PMC7473012,"Importance of meteorology in air pollution events during the city lockdown for COVID-19 in Hubei Province, Central China","Urban agglomerations over the North China Plain (NCP), Yangtze River Middle Reaches, Yangtze River Delta (YRD), and Pearl River Delta (PRD) have been generated with rapid economic development and urbanization in China, which has resulted in air pollution problems during the past few decades (Zhang et al., 2012; Han et al., 2016; Gui et al., 2019). Haze pollution in the ambient atmosphere induced by high aerosol concentrations, especially anthropogenic fine particles with aerodynamic diameters less than or equal to 2.5 μm (PM2.5) (Li et al., 2017), has been the most prevalent atmospheric pollution phenomenon in China (Guo et al., 2014; An et al., 2019). Considerable attention has been paid to PM2.5 particles because of their important roles in air quality and climate change (Tao et al., 2012; Wang et al., 2018; Zheng et al., 2015; Rosenfeld et al., 2014).
Generally, heavy haze events occur in four source regions in China: the NCP in North China, the YRD in East China, the PRD in South China, and the Sichuan Basin (SB) in Southwest China (Xu et al., 2016; Zhang et al., 2013). Governed by atmospheric circulation, the regional transport of PM2.5 emitted from these source regions can deteriorate air quality in the downwind receptor regions, leading to regional haze pollution in a large area across Central-Eastern China (CEC) (Li et al., 2013; Jiang et al., 2015; Bei et al., 2016; Chen et al., 2019; Wang et al., 2019). Haze pollution events in the NCP have been observed to mainly result from air pollutant accumulation under stable weather conditions in winter (Zhao et al., 2013; Gao et al., 2015; Zhang et al., 2016). The southward movement of cold fronts during the East Asian winter monsoon season, which is usually conducive to the rapid removal of atmospheric pollutants in the NCP (Zhao et al., 2013; Gao et al., 2016), can induce long-range transport of air pollutants from upwind regions to downwind regions in China (Hsu et al., 2010; Kang et al., 2019). Hubei Province in Central China, which has a distinct sub-basin terrain, is geographically located between the four haze pollution regions of the NCP, YRD, PRD, and SB, as shown in Fig. 1
. As such, it may be pivotal for the regional transport of air pollutants in China driven by East Asian monsoonal winds. However, the regional transport of air pollutants across CEC forced by meteorological drivers remains to be poorly understood.
Recently, Hubei has increasingly suffered from haze pollution (Wang et al., 2014; Tan et al., 2015; Xu et al., 2017; Gao et al., 2019). Several studies concerning the air pollution in this region have been conducted (Zhang et al., 2015; Zheng et al., 2019; Bai et al., 2020). Generally, the changes of air pollutants are highly dependent on their emissions and meteorological conditions (Tie et al., 2017; Xu et al., 2016; An et al., 2019). If the regional amount of emitted air pollutants is roughly stable in a particular period, meteorological conditions may be the determining factor for the occurrence of air pollution (Kan et al., 2012). To control the spread of the 2019 novel coronavirus (COVID-19), China launched a level-I response to this public health emergency in 30 provinces, autonomous regions, and municipalities as early as January 25, and was the first country to shut down commercial activities, restrict travel, and require its people to stay home (Tian et al., 2020; Wang et al., 2020a, Wang et al., 2020b). From January 24, 2020, Hubei was the first province in China to implement these restrictions, which are believed to have caused large reductions in air pollutant emissions over large regions in China (Huang et al., 2020; Chang et al., 2020; Shi and Brasseur, 2020). Such anomalies in air pollutants (PM2.5, NO2, and O3) diminished near the end of February 2020, when restrictions related to COVID-19 began to be eased and people outside of Hubei province started to return to work (Huang et al., 2020; Wang et al., 2020a). However, there were still several air pollution episodes in North China (Le et al., 2020), East China (Huang et al., 2020), and especially Hubei Province of Central China, which had the strictest city lockdown measures. Thus, using comprehensive measurements of ground-based data, satellite observations, and reanalysis data, as well as model simulations, we first assess the extent of wintertime aerosol changes over CEC during the city lockdown for COVID-19 (January 24–February 29, 2020) by comparing aerosol optical depth (AOD) and Angstrom exponent (AE) values during the same period over 2000–2020, and further investigate the importance of meteorology in driving regional transport and accumulation of air pollutants with respect to air quality change in Hubei under the rare low emissions of anthropogenic pollutants over a large region in China.
The Moderate Resolution Imaging Spectroradiometer (MODIS) is a sensor aboard NASA's TERRA satellite with 36 bands from 0.4 to 14.4 μm, a relatively fine spatial resolution between 250 and 1000 m, and a wide range of ~2330 km. This sensor can act as a feasible means of land aerosol remote-sensing (Chu et al., 2002). This study used Terra MODIS C6.1 Level 2 aerosol products (MOD04_L2) at 10 km spatial resolution from 2000 to 2020. All data were downloaded from NASA Level 1 and the Atmosphere Archive and Distribution System (https://ladsweb.nascom.nasa.gov/data/search.html). The Dark Target merged AOD data at 550 nm (hereafter referred to as AOD) were principally used in this study. The AE provided information about the dominant particle size in the atmospheric column, which was calculated using the linear fit of AOD against λ on a logarithmic scale; thus, the AE between 470 and 660 nm (AE470
–
660) product was used to study the dominance of fine-mode particles over CEC.
Hourly PM2.5 concentrations used in this study were derived from the public data of the Ministry of Ecology and Environment of China (http://106.37.208.233:20035/), including more than 1600 ambient air quality monitoring stations across China. The PM2.5 concentrations were measured by the micro-oscillating balance method and the β absorption method, following the China Environmental Protection Standards HJ 93-2013 and HJ 655-2013 (http://www.cnemc.cn/jcgf/dqhj/201711/P020181010540081577412.pdf). Smooth PM2.5 concentration maps were further obtained by gridding these point data with the Cressman interpolation method (An et al., 2020; Shen et al., 2020). The regional averages of PM2.5 mass concentrations obtained from the total monitoring sites over Hubei, China, were chosen for the PM2.5 pollution analysis. The chemical components in PM2.5 were determined using on-line instruments at an environmental monitoring supersite in Wuhan (114.38°E, 30.52°N).
The reanalysis data for 2000–2019 used to calculate the climatological wind field were provided by the National Center for Environmental Prediction (NCEP, https://www.ncep.noaa.gov/), with a horizontal resolution of 1° × 1°. Horizontal and vertical meteorological data of air temperature and wind speed during the pollution episodes were obtained from the MERRA-2 reanalysis dataset with a horizontal resolution of 0.5° × 0.625° (https://disc.gsfc.nasa.gov/datasets?project=MERRA-2). Observational data of meteorology including hourly surface air temperature, relative humidity (RH), precipitation, and near-surface wind speed and direction in Hubei were obtained from the national weather monitoring network of the China Meteorological Administration.
The WRF model provides the fine meteorological fields driving the FLEXPART model during pollution events. In this study, the WRF model was configured with two nested domains, coarse and fine. The coarse domain covered the entirety of Asia with a 30 × 30 km horizontal resolution, and the nested fine domain included most of China and its surrounding regions with a 10 × 10 km horizontal resolution. The physical parameterizations used in WRF modeling were the Morrison microphysics scheme (Morrison et al., 2009), Rapid Radiative Transfer Model (RRTM) scheme for long- and short-wave radiation (Mlawer et al., 1997), Yonsei University (YSU) boundary layer scheme (Hong et al., 2006), Grell 3D cumulus parameterization, and Noah land surface scheme (Grell et al., 2005). Using the reanalysis meteorological data in the horizontal resolution of 1° × 1° obtained from the NCEP for initial and boundary meteorological conditions, the WRF simulation ran for 12 h each time, where the first 6 h of simulations constituted spin-up time.
A Lagrangian particle dispersion model, FLEXPART-WRF version 3.1 (Brioude et al., 2013; Stohl et al., 2005; Fast and Easter, 2006), was used to determine the origin and transport pathways of particles arriving at the receptor site. In this model, the trajectories of a large number of particles released from a source are simulated, considering the processes of tracer transport, turbulent diffusion, and wet and dry deposition in the atmosphere (Brioude et al., 2013); thus, it simulates the transport and dispersion of tracers by calculating the backward trajectories of multitudinous particles, which are termed plume backward trajectories, reflecting the distribution of potential source regions that may have impacts on a target point or receptor region (Chen et al., 2017; Seibert and Frank, 2004; Zhai et al., 2016).
To improve the accuracy of the trajectory calculation, we used high-resolution WRF simulation domain 2 outputs as the input meteorological conditions for the FLEXPART model, which has been widely used to investigate the potential sources of air pollutants in relation to environmental change (Stohl, 2003; Gadhavi et al., 2015; Sauvage et al., 2017; Zhu et al., 2018). In this study, the FLEXPART-WRF simulation was conducted for a 24-hour backward trajectory with the release of 10,000 air particles in the first hour from Xiangyang (XY, 32.0°N, 112.1°E), Wuhan (WH, 30.6°N, 114.3°E), and Jingzhou (JZ, 30.3°N, 112.2°E), respectively, for six pollution events during the lockdown. The output domain in FLEXPART-WRF was set up with six vertical levels (10, 100, 500, 1000, 2000, and 4000 m) with a 10–1000 km release height and a horizontal resolution of 0.1° × 0.1°.
High AOD values exceeding 0.5 existed over CEC, revealing regional aerosol pollution during 2000–2020 (Fig. 2a). In particular, higher AOD values (>0.9) were observed over the lower flatland of Hubei and Hunan provinces, based on comparisons of Fig. 1, Fig. 2a, which highlighted an area of aerosol pollution in Central China (Shen et al., 2020). Comparison of AOD and AE between the averages during the lockdown and the 21-year climatological mean over the same period during 2000–2020 presented distinct anomalous changes over CEC (Fig. 2). A large scale of negative anomalies for AOD during the lockdown was noted (Fig. 2b), revealing great impacts of the lockdown policy on the reduction in aerosol loads over CEC. However, several positive anomalies of AOD were still observed in North China, which were mostly related to the formation of severe haze caused by unfavorable meteorological conditions, invigorated heterogeneous chemistry, and enhanced secondary aerosol formation (Le et al., 2020). As satellite retrieval data, the AOD is related to surface particles as well as other factors, such as moisture content in the air (Shen et al., 2020), which may result in contrast increase of AOD values in dot areas, such as Dongting Lake in Hunan Province, Poyang Lake in Jiangxi Province, and Chaohu Lake in Anhui Province (Fig. 2b, c). Compared with the averages during 2000–2020, AOD values decreased noticeably over CEC, mostly exceeding 20% (Fig. 2c); Hubei Province and the urban site of Wuhan had greater AOD reductions by 39.2% and 31.0%, respectively, during the lockdown, which confirms the significant reductions in atmospheric aerosols.
AE can provide qualitative information on aerosol size; high values of AE indicate the dominance of fine-mode particles. Combined with the topographic data in Fig. 1, AE values exceeding 1.2 were identified in mountain areas over CEC, indicating dominant fine-mode particles in clean air regions (Shen et al., 2020). AE anomalies during the lockdown exhibited an opposite distribution compared with AOD anomalies (Fig. 2e); positive anomalies of AE in most regions of CEC indicated an enhanced contribution of fine-mode particles in the air. Overall, AE values increased by more than 15% in CEC during the lockdown compared with the climatological mean (Fig. 2f), and were enhanced by 29.4% and 45.3% in Hubei and Wuhan, respectively. Such inverse change reflected the reduction of total aerosols in the air and the increase in the contribution of fine-mode particles during the lockdown.

Fig. 4
shows that the PM2.5 concentration in Hubei during the lockdown ranged from 9.5 to 99.3 μg·m−3 with an average of 46.6 μg·m−3, much lower than the average level during same period in 2019 (74.2 μg·m−3). Although there were significant reductions in aerosol loads and surface PM2.5 concentrations during the lockdown (Zheng et al., 2020), several PM2.5 pollution episodes still occurred in Hubei, as shown in Fig. 4. Six PM2.5 pollution events had hourly concentrations larger than 75 μg·m−3, and PM2.5 reached maximum concentrations of 94.1, 81.2, 88.1, 89.2, 99.3, and 84.8 μg·m−3 at 06:00 January 25, 02:00 February 1, 02:00 February 2, 23:00 February 3, 12:00 February 5, and 22:00 February 25, 2020, respectively, which were 2.0, 1.7, 1.9, 1.9, 2.1, and 1.8 times higher than the average during the lockdown.
Based on the synoptic conditions on these six pollution events with the NCEP reanalysis data of meteorology, similar configurations of atmospheric circulation conditions occurred over CEC during the pollution episodes of P1, P5, and P6, and conditions over CEC, especially Hubei Province in Central China, were controlled by a high pressure system after the passage of a cold front, with relatively large pressure gradients and prevailing strong northerly winds, which could drive the regional transport of air pollutants from North China to Hubei Province (Fig. S1). In contrast, the pollution processes of P2, P3, and P4 generally occurred when a uniform air pressure field existed over CEC with a weak surface pressure gradient and low wind speeds (Fig. S1), which could induce air pollutant accumulation in Hubei Province.
During the lockdown period, the near-surface meteorological factors varied greatly (Fig. 5
). The wind speed had an average value of 2.1 m·s−1, ranging from 0.8 m·s−1 to 6.4 m·s−1. The RH and air temperature fluctuated in the ranges of 24.8–98.2% and −0.4 °C–20.7 °C with averages of 78.1% and 8.0 °C, respectively. In contrast to the pollution events of P1, P5, and P6, scarce precipitation was observed for P2, P3, and P4. Notably, the wind speeds showed distinguishing changes during the six episodes, with higher speeds exceeding 3.4 m·s−1 during P1, P5, and P6 but lower speeds below 2.6 m·s−1 for P2, P3, and P4. Compared with the twenty-year climatology (2000–2019), anomalous northerly/easterly winds at 10 m prevailed in the lower flatland of Hubei during P1, P5, and P6 (Fig. S2). Generally, strong winds favor the purging of air pollutants (Wei et al., 2015; Yang et al., 2015). However, PM2.5 pollution persisted over Hubei, highlighting the possibility of the transport of PM2.5 from upwind regions to Hubei, given the strong northerly wind. In contrast with episodes P1, P5, and P6, negative anomalies of wind speeds were noted for P2, P3, and P4, indicating a distinct pollution pattern for these three events. Therefore, the six pollution episodes were divided into type I (including P1, P5, and P6) and type II (P2, P3, and P4) for the following discussion.
Although all the provinces in CEC went into lockdown during the same time period, the regional meteorological conditions led to accumulation of PM2.5 air pollution over the northern region of CEC (Fig. 6
). From the observation data, it is apparent that the upwind regions of Hubei were the most polluted areas with high PM2.5 concentrations (>120 μg·m−3) 24 h before the type I pollution occurred (Fig. 6a, b, c); these pollution parcels moved southward with the northerly winds (Fig. 6d, e, f) and finally reached Hubei (Fig. 6g, h, i), where the PM2.5 concentration increased significantly with time. These upstream regions therefore were likely the main contributor to the regional PM2.5 pollution over Hubei for type I episodes.
The FLEXPART-WRF model simulated the explicit particle trajectories for this pollution type, which were characterized by long-range transport patterns for XY, WH, and JZ (Fig. 6j, k, l, Fig. S3). The three receptor sites were located in northwestern, eastern, and southwestern Hubei, respectively, which can roughly reflect the transport pattern of particles in the lower flatland of Hubei, and XY was the most polluted site. The same potential source regions were found for the three sites. The regional transport of air pollutants was centered along a northeastern route from Hebei in North China and the YRD in East China during P1 (Fig. 6j, Figs. S3a, d). The YRD emission sources of air pollutants exerted a considerable impact on P2 through regional transport of PM2.5 across Eastern China to Hubei (Fig. 6k, Figs. S3b,e). During P6, the regional transport pathways of PM2.5 from the NCP regions contributed to the elevated PM2.5 concentrations (Fig. 6l, Figs. S3c, f). The transport height was limited to a low level with an average at around 400 m for P1. In contrast to P1, P6 had higher transport heights, with averages of 544, 625, and 947 m for XY, WH, and JZ, respectively, accompanied by notable sinking motions. However, the air particles were transported at lower heights (~360 m) for XY and greater heights (~730 m) for WH and JZ during P5. The discrepancy in transport heights for different sites in Hubei may have resulted from terrain effects, which should be investigated in future studies. Driven by northerly winds of the East Asian winter monsoon over CEC, the long-range transport of PM2.5 from the upstream northern region to downwind in Hubei Province played a key role in the formation of type I air pollution episodes. The exceptional importance of meteorology was noted in the PM2.5 accumulations over the northern region of CEC and the regional transport of PM2.5 over CEC.
In contrast with the type I episodes, the type II episodes were associated with weak wind speeds and scarce rainfall when the pollution occurred (Fig. 5, Fig. 7a–c), revealing the likely role of local PM2.5 accumulation over Hubei. Short plumes of tracer particles and higher traveling heights (averaging 550–1193 m) compared with type I were also shown for type II by the FLEXPART-WRF model (Fig. 7d–f, Fig. S4). Given the comparatively low PM2.5 concentrations in southern Hubei (Fig. 3, Fig. 7a–c), the prevailing southerly plumes for this pollution type revealed the impacts of local PM2.5 pollution over Hubei. Therefore, the stagnant conditions that caused these episodes had to cover areas in Hubei and neighboring Hunan Province, where human activities were likely shut down during the city lockdown for COVID-19 in China. Additionally, areas within 380 km from the center of XY, WH, and JZ can cover most of Hubei and Hunan provinces in Central China; therefore, a threshold of 380 km was set to distinguish local and long-range transport of pollution, based on a previous study (Hu et al., 2018). Particle plumes associated with type II were basically smaller than this threshold. Therefore, local air pollutants were dominant for type II, with tracer particles traveling at comparatively greater heights and descending obviously when the receptor sites were reached.
The increased contribution of fine-mode particles during the lockdown may have been responsible for local pollution. The major chemical components of PM2.5 in WH varied significantly during the two pollution types (Fig. S5). Compared with the averages during the lockdown, the concentrations of secondary inorganic matter (SO4
2−, NO3
−, and NH4
+) were increased by 85.9–152.4% and 76.1–114.2% during type I and type II pollution episodes, respectively, and organic carbon concentrations increased by 0.7–103.4% and 28.0–102.8%, respectively, which confirmed the enhanced formation of secondary PM2.5 during the local pollution events, separate from the regional transport processes (Chang et al., 2020). Static weather conditions and scarce rainfall in Hubei were the main drivers of secondary pollution during type II episodes. A related study also found increased amounts of sulfate, organic carbon, and secondary inorganic aerosols in WH during the lockdown (Zheng et al., 2020). Huang et al. (2020) revealed that haze events during the COVID-19 lockdown in East China were driven by increases in atmospheric oxidizing capacity, which in turn facilitated secondary pollution.
It is worth noting that the inversion layer of air temperature did not exist during clean and type I periods (Fig. 8
), whereas the type II periods had temperature inversion below 975 hPa, revealing stable weather conditions near the surface that inhibited the vertical diffusion of air pollutants. Compared with the clean air period, the type I pollution episodes were characterized by stronger winds, which increased sharply to a maximum of 12.1 m·s−1 at 975 hPa and then decreased with increasing altitude at 975–775 hPa. Based on previous criteria for low-level jets (LLJs) given by Bonner (1968) and Wei et al. (2013), a LLJ in this study required Vmax ≥ 10 m·s−1 and a corresponding falloff ΔV (Vmax − Vmin) ≥ Vmax/2 in the lowest 3000 m. Such vertical structures of horizontal winds with LLJs occurring during type I episodes could induce the downward mixing of regionally transported air pollutants. In contrast with type I, the type II pollution episodes had much weaker wind speeds compared with the clean periods, which were favorable to the local accumulation of air pollutants accompanied by the inversion layer. In addition, wind convergence for the two pollution types, especially type I with greater convergence in a thicker layer (Fig. 8), promoted the accumulation of PM2.5 near the surface of Hubei with elevated ambient PM2.5 concentrations, thus contributing to air pollution.
Based on comparisons of the average concentrations during the lockdown and the two pollution types, positive anomalies of PM2.5 were identified in the lower flatland of Hubei during type I episodes (Fig. S6), whereas the upstream regions generally featured negative anomalies of PM2.5 concentrations, affirming the regional transport of PM2.5 from the upstream CEC source regions to the downstream Hubei receptor region. However, type II was characterized by positive anomalous PM2.5 concentrations across CEC centered in Hubei, reflecting the impact of stagnant meteorological conditions on the local pollution, especially in the sub-basin of Hubei, during type II events (Fig. 7, Figs. S1, S2 and S6). By dividing the air pollution anomalies by the lockdown averages of PM2.5 concentrations observed in Hubei, it was estimated that the PM2.5 concentrations increased by 79.8–96.1% and 75.5–82.6% during type I and type II episodes, respectively; therefore, the long-range transport of air pollutants contributed more to PM2.5 pollution in Hubei.
This study demonstrated the impacts of regional transport vs. local emission sources by examining an unprecedented period when human activities were largely shut down in Hubei Province, Central China. Compared with the 21-year climatological mean over the same period during 2000–2020, the AOD and AE values during the city lockdown for COVID-19 decreased and increased, respectively; in most regions of CEC, AOD (AE) values decreased (increased) by 39.2% (29.4%) and 31.0% (45.3%) in Hubei and Wuhan, respectively, because of the rigorous restrictions. Such inverse changes reflected the reduction of total aerosols in the air and the contribution of the increase in fine-mode particles during the lockdown.
Although large reductions in aerosols were observed during the lockdown, the surface PM2.5 had a distinct spatial distribution over CEC, with high PM2.5 concentrations in North China and East China. In particular, relatively high PM2.5 concentrations were notable in the lower flatlands of Hubei in Central China, where six exceptional PM2.5 pollution events were detected with hourly concentrations higher than 75 μg·m−3. Anomalous northerly/easterly winds at 10 m prevailed during P1, P5, and P6, representing type I pollution, whereas negative anomalies of wind speed were noted for P2, P3, and P4, which were classified as type II pollution. Type I was characterized by the long-range transport of air pollutants from upstream CEC source regions, which then converged in the downstream Hubei receptor region, whereas local air pollutants were dominant for type II because of stagnant meteorological conditions despite large reductions in primary pollutants. It was calculated that the PM2.5 concentrations increased by 79.8–96.1% and 75.5–82.6% during type I and type II pollution episodes, respectively, compared with the averages in Hubei during the lockdown; therefore, the long-range transport of air pollutants contributed more to PM2.5 pollution in Hubei.
This study revealed the exceptional importance of meteorological drivers for air quality change under the rare low emissions of anthropogenic pollutants during the COVID-19 lockdown over a large region in China; these results imply the difficulty of air pollution mitigation under the anomalous changes of meteorology over the Asian monsoon regions.
Lijuan Shen, Tianliang Zhao, Honglei Wang and Jane Liu conceived and designed the experiments as well as wrote the article; Yongqing Bai, Shaofei Kong, Huang Zheng, Yan Zhu and Zhuozhi Shu involved in the discussions and helped in the data analysis.
We declare that we have no financial and personal relationships with other people or organizations that can inappropriately influence our work, there is no professional or other personal interest of any nature or kind in any product, service and/or company that could be construed as influencing the position presented in, or the review of, the manuscript entitled “Exceptional importance of meteorology in air pollution events during the city lockdown of COVID-19 over Hubei Province of Central China”.",Sci Total Environ
PMC7486612,An investigation of the effect of temperature on the oxidation processes of metallic diesel engine fuel system materials and B100 biodiesel from used cooking oil in exposure testing,"The International Energy Agency (IEA) has predicted that global CO2 emissions are expected to decline by 8%, or almost 2.6 gigatonnes (Gt) as a result of the 2020 SARS-CoV-2 global health crisis [1]. In particular, diesel demand has fallen by 1.5 million barrels per day (mb/d) because of lower economic activity and restrictions to rail and bus transport and is expected to remain lower by 7% until the end of 2020 (2mb/d) [1]. However, diesel fuel continues to be the main fuel for the majority of heavy-duty vehicles such as ships and trucks as well as in countless agricultural and industrial vehicles. The efficiency and durability of diesel engines have made them the ideal power plants for these vehicles. There is therefore an ongoing need to address the way in which emissions from these types of engines can be decreased to address the need to globally reduce temperature changes owing to climate change for the future sustainability of the planet. Biodiesel is thus increasingly being used as a means of reducing CO2 emissions from the vehicle fleet with the EU, the USA and the UK setting targets for the use of biodiesel blends of 10 (by 2020), 25 (2022) and 12.4% (by 2032) respectively.
King [2] noted that biofuels offer potential advantages over conventional fuels for the medium term, as biofuels have the potential to work with existing diesel engine technology and they can be introduced as blends to conventional diesel fuel. Biofuels reduce the overall carbon dioxide generated and are said to decarbonize the fuel, either through fuel switching and/or by reducing the amount of CO2 involved in the production of fuels. Thus, using biofuels can result in reduced greenhouse gas emissions compared to fossil fuels [3], [4], [5], [6]. Future vehicle technologies may develop solutions for decreasing emissions that rely on alternative fuels, such as hydrogen, and because of this, electric vehicles will become increasingly prevalent. In the medium term however, liquid hydrocarbons will continue to be used for transport applications [5], [7]. Pereira [8] compared the use of B100 with diesel on a fleet of buses over an 18 month period. The lubricating oil was monitored for Al, Pb, Fe and Cu content and showed that Al, Pb and Fe engine components showed decreased wear due to increased lubricity of B100 over diesel but increased wear of Cu components due to increased reactivity Cu with B100 over diesel. The decreased viscosity of the lubricating oil with time led to reduced service times for B100 buses to ~⅔ that of diesel buses. In addition to the use of biofuels, water-blended diesel emulsions have shown potential to improve engine performance and also reduce levels of particulate matter (PM) and nitrogen oxide emissions (NOx) from diesel engines [9], [10], [11], [12] and gives an alternative approach for future vehicles with lower emissions.
Biodiesels are fatty acid alkyl esters that are derived from a range of different sources, such as palm, canola, corn, rapeseed and sunflower oils. The advantage of biodiesel is that it is close in fuel properties such as flash point, fire point, calorific value, viscosity, density and cetane number to petroleum diesel. In some literature it has been shown to reduce both CO2 and NOx emissions [9], [13] whilst maintaining or improving engine performance [14], [15], [16]. There are also challenges in the use of biodiesel in that it can lead to increased corrosion and oxidation of metallic engine components[17], [18], [19], [20] including fuel injection systems [21]. Additionally, biodiesel can have problems at low temperatures, where it can gel, although this can be avoided by the use of appropriate anti-gelling agents [22]. Chandran[23], Fazal et al
[24] and Zuleta et al
[25] have provided comprehensive critical reviews of the way in which biodiesel interacts with diesel engine materials and showed that the proportion of biodiesel in the blend, the total acid number (TAN) and presence of water all affect biodiesel oxidation.
Another challenge with biodiesel is that it oxidises more rapidly than conventional diesel. The oxidation reactions transform the esters in biodiesel to alcohols, ketones, ethers, alkanes, organic acids, aldehydes and oligomers. The different reaction pathways are described in detail by Zuleta et al and Bannister et al
[26], [27]. The oxidation reactions result in increased viscosity of the fuel and degraded performance. The oxidation rates are affected by a range of factors, including the chemistry of the biodiesel itself, the temperature and the metallic components in the fuel system (as well as the way in which fuels are stored and transported before use in the engine) [28], [29], [30], [31].
In an automotive engine, fuel comes into contact with many different components. Biodiesel is known to cause enhanced corrosion due to the water and free fatty acids contained within the fuel [18], [20]. Copper components in particular are known to suffer enhanced corrosion in biodiesel [19]. The purpose of the current work is to provide data on rate of reaction of common metals and alloys with B100 diesel and explore the mechanisms involved in the onset of the corrosion process for samples fully submerged in B100. Furthermore, the fully submerged position of specimens in biodiesel was designed to simulate the exposure of components within an engine exposed to biodiesel for extended periods at different temperatures.
In this work we have focused on looking at the way in which corrosion initiates and the corrosion rate for a number of different metal alloys across a wide range of temperatures. Other studies have looked predominantly at biodiesel and biodiesel blends produced straight from crops and by comparison the B100 biofuel we have used was based on recycled used cooking oils. In addition, we have investigated the link between the metallic alloy corrosion and the details of the oxidation mechanism of the fuel.
Corrosion characterisation tests were carried out on metal coupons of copper, brass, aluminium Al1050 alloy, aluminium Al7075 alloy and steel when in contact with biodiesel B100 at 25 °C, 80 °C, 90 °C, 100 °C, 110 °C and 120 °C for 270 h. During the tests, fuel temperature was maintained and monitored. The samples used for the tests were brass Cu30Zn (51 mm X 30 mm X 1.6 mm), copper (51 mm X 25 mm X 2 mm) with the composition of 100% Cu, mild steel (50 mm X 30 mm X 2 mm) with the composition of 0.1% C, Al1050 alloy (51 mm X 20 mm X 1.5 mm) with the composition of 99.5% Al and Al7075 (51 mm X 20 mm X 1.5 mm) with the composition of Al, Mg, Cu and Zn. One 5 mm diameter hole was drilled at the corner of each metal sample and nylon fishing line used for hanging the samples in the fuels, so that they were not in contact with the walls of the vessel. Before starting the immersion corrosion tests, all metallic samples were prepared using the process outlined below:
All samples were prepared in accordance with ASTM G31 [32] by wet grinding with silicon carbide abrasive papers (400 to 1200 grade) and then polishing to a 6 µm diamond finish on all faces and edges. The samples were then washed with water and methanol and then ultrasonically cleaned in acetone for 20 min before being dried by a heater. The samples were dried to constant weight.
After the allotted time the samples were removed from the B100, washed with detergent and water with light brushing using a soft nylon bristled brush and then rinsing with methanol and then acetone to remove the testing fuels from the surfaces and dried in hot air. To avoid damaging any potentially corroded surfaces, the samples were not subjected to ultrasonic cleaning. The samples were repeatedly cleaned and dried to constant weight in accordance with ASTM G1 [33].
Before and after the immersion corrosion tests, all metal samples were weighed by an electronic balance accurate to 0.0001 g. One sample from each metal was used at 25 °C, 80 °C, 90 °C, 100 °C, 110 °C and 120 °C. The weight loss for each sample was recorded. This allowed the corrosion behaviour of the metal samples when in contact with biodiesel and diesel fuel to be observed through measurement of their corrosion rates and studying the morphology surface changes for them. The average weight loss for each sample was converted to corrosion rate by using the equation [32]:CorrosionRate(mmyear-1)=WρAtwhere: Corrosion rate is calculated in mm year−1, W = weight loss in grammes, either by weight loss of the coupon or calculated from the concentration of metal in solution, ρ = density in g cm−3, A = surface area in contact of fuels in mm2 and t = test duration in years.
Fuel samples were analysed before and during corrosion immersion tests by Gas Chromatography Mass Spectroscopy (GCMS) (Perkin Elmer TurboMass GCMS, Perkin Elmer Seer Green, UK) in the chemistry department at the University of Leicester. Samples of 2 ml were removed by pipette. GCMS was performed on dilutions of 5 vol% and 0.5 vol% in carbon tetrachloride using 0.1 ml aliquots. Both fuel compositional changes and the presence of metal species were investigated to an accuracy of ± 0.5 ppm by Inductively Coupled Plasma Atomic Emission Spectroscopy (ICP-AES) on an Agilent 5110 (Stockport, UK). Fuel samples were sent to Oil Check Laboratory Ltd (Doncaster, UK) for this analysis and each sample was analysed 3 times. Each sample consisted of 0.5 ml of fuel diluted in 4.5 ml kerosene containing 10 ppm Co as standard.
The B100 biodiesel used in these experiments was processed from Used Cooking Oils (UCO) and purchased from Biofuel Refineries Ltd (High Wycombe, UK). It had a density of 0.881 g cm−3, a viscosity of 3.1 cSt at 40 °C and a Total Acid Number (TAN) of 0.23 mg KOH g−1. The Oxidation Stability of the B100 was not supplied and is unavailable, however fuels of similar origin and composition typically show a range from 1.2 to 9 h at 110 °C [25].
The unreacted biodiesel was analysed by GCMS and consisted of four main Fatty Acid Methyl Ester (FAME) components. These were identified using the NIST database software as 16.0, 18.2, 18.1 and 18.0 methyl esters as shown in Table 1
. The relative quantities of these constituents were calculated for B100 from relative chromatogram areas, as is standard practice for GCMS.
The physical and chemical behaviour of the alloys before and after immersion tests were characterised by optical microscope (Olympus GX53, Southend-on-Sea, UK) and SEM (Sirion 200 FEGSEM (FEI, Eindhoven, Netherlands)) with Princeton Gamma Technology Spirit EDX.
The colour change of the fuel was also noted. Each glass jar contained one specimen of the alloys samples and each specimen was removed for visual inspection and surface analysis after 270 h. Temperatures were controlled using a thermocouple and hot plate stirrer. The thermocouple was isolated from the biodiesel by a glass sheath.
SEM studies on both Al1050, Fig. 7
, and Al7075, Fig. 8
, showed evidence of small, localised and infrequent pits e.g. Fig. 7g shows a pit in Al1050 at 90 °C. The corrosion products on the surface contain C, O and Al and are consistent with salt formation with fatty acids. Fig. 8g
shows a similar pit and corrosion products for Al7075 at 110 °C.
With steel coupons, ICP identified no significant amounts of Fe in solution at any temperature. For the steel coupons, there was no mass loss, rather there was a mass gain, and, in fact, all mild steel samples gained slightly in mass during exposure to B100. Hence the corrosion rate reported was zero by mass method in Fig. 5. SEM studies of mild steel samples, Fig. 9
, showed more isolated pits, which also contain C and O, by elemental mapping. An example of steel pit is seen in Fig. 9g
at 90 °C. Again, the reaction products are ascribed to insoluble fatty acid formation, hence the slight increase in mass for all steel samples. The mass loss in our experiments was too low to provide realistic corrosion rates for mild steel even though we used higher temperature exposures than those used by Fazal et al [18] which reflects the low corrosion rates of mild steel on exposure to biodiesel.
For Cu and brass samples, Fig. 10, Fig. 11
show significant evidence of metal oxidation in SEM images. For brass, pitting is evident at 100 °C and extensive above this temperature.
In all cases, C and O are present in the reaction products, which fill these pits. The sample at 120 °C showed a more heavily pitted region shown in Fig. 10g which is believed to be due to the flow of B100 across the sample due to stirring. For Cu, pitting occurs at all temperatures and a large pit was observed at 100 °C (Fig. 11
g and 11h) filled with reaction products rich in C and O.
In fact, corrosion products rich in C and O were observed for all Cu samples across the surface, but in higher amounts in the pits. At 110 °C and 120 °C, pitting no longer dominates for Cu, and a more uniform corrosion reaction occurs across the whole surface. This implies that any copper oxide passivation layers are entirely unstable at these temperatures, with respect to reaction with methyl esters to form the acid and formic acid according to:

However, the Cu samples showed a much reduced TAN and there is no evidence of free acid or formic acid in the GCMS, so it is reasonable to assume that any acid formed will be in the vicinity of the copper metal, where it reacts readily to form formic acid and fatty acid salts which have been observed in SEM by EDX. The mass loss for Cu matched closely with the ICP results, indicating solubility of Cu salts in B100. Other researchers [37], [38], [39], [40], [41], [42] have already shown that Cu is a strong catalyst for double bond oxidation reactions, even at 25 °C, and can form allylic alcohols and epoxy groups, both of which have been detected in GCMS.
The experiments have shown that brass and copper are highly reactive towards B100 and both showed significant corrosion compared to the lower reactivity metals; mild steel Al7075 and Al1050 alloys. For brass, the reaction proceeds via a pitting mechanism at all temperatures and produces a reaction product rich in C and O, which is identified as metal salts of fatty acids. The reaction products vary in size and thickness so the EDX results are qualitative. With Cu, pitting occurs at low temperature, but at higher temperatures a uniform corrosion mechanism dominates and the oxide layer is completely unstable.
For the lower reactivity metals, all showed a tendency to pit and produce fatty acid salts, with a greater tendency to behave like this at higher temperatures.
The corrosion rates calculated are relatively low compared to those from the literature and this is attributable to the short timescale of the study. The initial stages of the corrosion process involve the breakdown of the oxide film on the surface resulting in pit formation. Once a pit has formed, oxidation processes accelerate.
The reaction products from all samples were identified by GC/MS. Without a metal sample present, the B100 underwent auto oxidation and the most reactive species present was shown to be 18.2. With Al1050 and Al7075 present, the reaction products were similar to the blank control experiment, indicating very little interaction of these metals with the oxidative process. However, with mild steel present, it is possible to see evidence of cyclisation of oxidised reaction products and this behaviour is promoted by the presence of Cu and brass metal coupons.
Significant colour changes were observed in biodiesel samples as a result of their contact with brass, copper and steel at temperatures higher than 80 °C. These changes in colour and brightness were related to the presence of metal species in the fuel composition. The colour changes in the fuel resulted from the production of different copper fatty acid salts, or zinc fatty acid salts. There was no evidence for Al, or Fe in B100 from ICP results and it was concluded that, if formed, as indicated by abundance for C and O at pit sites, then these salts are insoluble.
Immersion tests for Al7075, Al1050, brass, copper and mild steel at temperatures ranging from 25 to 120 °C in a used cooking oil derived B100 biodiesel showed that:●Brass (<0.0075 mm y-1) and copper (<0.08 mm y-1) corroded at a faster rate than either of the aluminum alloys (<0.0012 mm y-1) or mild steel (<0.00004 mm y-1).●Brass and copper caused chain scission of the biodiesel identified by GCMS analysis to cause changes to the fatty acid methyl ester composition as a function of time. Greater changes were found with higher temperature exposure.●Pitting corrosion of Al1050 and Al7075 were detected by mass loss but ICP was only capable of detecting alloying elements from Al7075.●No appreciable corrosion was found on the steel alloys by ICP or mass loss.●SEM analysis showed that corrosion was initiated by a pitting mechanism except for Cu at high temperature which displayed uniform corrosion.●By mass loss, the activation energies for Cu, Brass, Al7075 and Al1050 were calculated to be −47.9 kJ mol−1, −85.4 kJ mol−1, −90 kJ mol−1 and −60 kJ mol−1, respectively.●The activation energies for Cu, Brass, and Al7075 from ICP analysis were calculated to be −57.9 kJ mol−1, −87.2 kJ mol−1 and −140 kJ mol−1, respectively.


M. Matbouei: Investigation, Data curation, Writing - original draft. D.P. Weston: Conceptualization, Methodology, Investigation, Visualization, Writing - review & editing. Xingzhong Liang: Investigation, Data curation. S.V. Hainsworth: Conceptualization, Writing - review & editing.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Fuel (Lond)
PMC7604061,Count regression models for COVID-19,"The novel coronavirus disease (COVID-19) first identified in Wuhan, the capital of Hubei, China in October 2019, is a severe acute respiratory disease that has now become a worldwide pandemic. Fig. 1 shows the extreme extent to which this pandemic has spread across the world, with the total number of confirmed global cases exceeding 700,000 as of 30th March 2020 and is still increasing exponentially. The total number of cases worldwide has already surpassed the number due to the severe acute respiratory syndrome (SARS) in the early 2000s. Many reports have suggested that this new virus is becoming comparable to the Spanish flu pandemic from 1918.
The most common symptoms of COVID-19 are almost identical to those of the flu - e.g. high fever, fatigue, cough and shortness of breath. Individuals have been required to self-isolate if they believe that they are exhibiting these symptoms. The most severe symptoms have been linked to pneumonia, multi-organ failure, and death. Other symptoms of COVID-19 include the loss of sense of smell (anosmia) and in some cases individuals may display no symptoms at all, but will still be carrying the virus.
The global effects of COVID-19 have led to many countries locking down their international borders, cities and towns for extended periods. For example, in China, UK, Italy, Spain, France and many others. Hence, many are fearful that another global recession is on the horizon. On the contrary, after a two month national lock-down, China has shown the world that a strict lock-down has contributed to a reduction in the number of new cases and deaths from COVID-19, with the number of new cases recently decreasing to zero.

The current literature relating to COVID-19 is limited and the majority of the known work focuses exclusively on China, where the first major outbreaks occurred. The existing research has focused on topics such as determining the population who are most at risk, the factors increasing the risk of infection, the medical properties of those who become infected, the factors that can improve clinical outcomes and reduce the spread of the virus, the biological properties of the virus, and many others. See for example [1], [2], [3], [4], [5], [6], [7], and [8].
More specifically, the literature relating to COVID-19 analysis outside of China has been limited. Since these countries are lagging behind China in terms of the overall spread of the disease, much of the literature has been focused on modelling and predicting the disease in the early stages of the outbreak — particularly the daily incidence (number of new confirmed cases per day) and the basic reproductive number. For example, in Italy [9], [10], in France [11], and in Japan [12], [13], [14]; to name but a few.
Thus far, a wide range of statistical and predictive methods have already been applied to the analysis of COVID-19 in China, for example traditional epidemic models, such as the SIR model [15], [16] and the basic reproductive number [17]; neural networks [18]; regression models [19], [20]; experimental frameworks [21]; correlation analysis [22].
From the literature, it is evident that the majority of the analyses on COVID-19 are limited to China, and a limited number of countries in Asia and Europe. These are arguably the countries that first identified known cases of COVID-19. However, we should note that since this is an ongoing situation, new research is being published daily and therefore the literature is being updated continuously. Hence, our main motivation is to provide a statistical analysis in modelling and analysing the number of confirmed cases of COVID-19 in eighteen countries around the world. The main contributions of this paper are: (i) to provide a statistical analysis of COVID-19 worldwide; (ii) to investigate whether it is possible to utilise count regression models for fitting and predicting the number of daily confirmed cases due to COVID-19 globally.
The contents of this paper are organised as follows. Section 2 describes the data used in our analysis. In Section 3, we detail the methodology and models used. Section 4 outlines the results, and provides a discussion of these results. Section 5 provides a conclusion and summary of our results.
The data we analyse consists of the historical daily new cases due to the COVID-19 Coronavirus confirmed from eighteen different countries worldwide (China, Denmark, Estonia, France, Germany, Italy, Malaysia, Philippines, Qatar, South Korea, Sri Lanka, Sweden, Taiwan, Thailand, UAE, UK, USA, Vietnam), listed on the EU Open Data Portal from 31st December 2019 to 25th March 2020. These countries were chosen because they were the earliest countries to detect COVID infections.
The data were downloaded from the website “European Centre for Disease Prevention and Control” (ECDC) which sources its data from the WHO, and our analysis is limited to the data available at the time of writing. The eighteen countries were chosen based on their ranking in terms of the highest numbers of cases, thus we believe that the data obtained gives a satisfactory representation of the main countries affected by the virus at these times.
In epidemiology and the study of infectious diseases, count-based data related to incidence are commonplace. In particular, data such as the daily incidence (number of cases) relating to an infectious disease can be modelled and predicted using a wide variety of methods, including compartmental (or deterministic) models such as the SIR and SEIR models, and stochastic models such as discrete time and continuous time Markov chains, and stochastic differential equations. In this study, we apply discrete time count regression models with the aim of modelling and predicting the daily incidence of COVID-19 across the world. Such models are preferred because they provide an appropriate, rich, and flexible modelling environment for non-negative integers. In addition, the models are robust for estimating constant relative policy effects and when implemented to policy evaluations, such models can move beyond the consideration of mean effects and determine the effect on the entire distribution of outcomes instead [23]. Poisson count regression models are part of the family of generalised linear models that are commonly used in epidemiological studies [24]. The Poisson and negative binomial regression models are widely used for modelling discrete count data where the count takes a non-negative integer with no upper limit, while the data is highly skewed. The negative binomial regression has the added advantage of being able to deal with the problem of overdispersion [25].
The four models below are due to Christou and Fokianos [26], [27], Fokianos and Fried [28], Fokianos et al. [29] and Fokianos and Tjostheim [30]. The models due to Christou and Fokianos [26] are based on the negative binomial distribution. The models due to the others are based on the Poisson distribution. Both Poisson and negative binomial distributions are commonly implemented when dealing with count data and observations occurring at a specific rate.
Let Zt= denote the number of newly confirmed cases in a country on day t, t=1,…,T. In other words, Zt= the change in the cumulative confirmed cases from day t−1 to t. For each of the eighteen countries selected, the following four regression models were fitted to the corresponding daily incidence data:

•
Zt∣Ft−1∼Poissonα+βt, with link function = ‘identity’ and distribution = ‘Poisson’.•
Zt∣Ft−1∼Poissonexpα+βt, with link function = ‘log’ and distribution = ‘Poisson’.•
Zt∣Ft−1∼NegativeBinomialα+βt,ϕ, with link function = ‘identity’ and distribution = ‘negative binomial’.•
Zt∣Ft−1∼NegativeBinomialexpα+βt,ϕ, with link function = ‘log’ and distribution ‘negative binomial’.

where Ft−1 denotes the history up to day t−1, α represents the intercept parameter, and β is the slope parameter.
Each of the four models was fitted by the method of maximum likelihood. That is, by maximising L1(α,β)=∏t=1Tα+βtZtZt!exp−α−βt,
L2(α,β)=∏t=1Texpα+βtZtZt!exp−expα+βt,
L3(α,β,ϕ)=∏t=1TZt+α+βt−1Zt(1−ϕ)α+βtϕZt,and L4(α,β,ϕ)=∏t=1TZt+expα+βt−1Zt(1−ϕ)expα+βtϕZt,respectively, with respect to α, β and ϕ. We shall denote the maximum likelihood estimates by α^, β^ and ϕ^, respectively. For a more in-depth discussion of the four regression models we refer the readers to the literature cited above. The models were fitted using the command tsglm in the R package tscount
[31].
For each of the fitted models, we computed the Akaike information criterion (AIC), Bayesian information criterion (BIC) and associated p-values obtained by re-sampling. The AIC for the four models were computed as AIC=4−2logL1α^,β^,
AIC=4−2logL2α^,β^,
AIC=6−2logL3α^,β^,ϕ^,and AIC=6−2logL4α^,β^,ϕ^.The BIC for the four models were computed as BIC=2logT−2logL1α^,β^,
BIC=2logT−2logL2α^,β^,
BIC=3logT−2logL3α^,β^,ϕ^,and BIC=3logT−2logL4α^,β^,ϕ^.The values are given in Table 1. According to AIC and BIC values, the best model out of the four is the negative binomial model with a logarithmic link function. Table 2 gives the estimates of the intercept and slope parameters along with their corresponding standard errors for this model. Also given in Table 2 are the p-values quantifying the significance of the slope parameter. In line with standard significance levels, if the p-value is less than 0.05 then the slope estimate is deemed to be significant.
We applied the models specified in Section 3 and fitted them to our data on the number of new daily cases of individuals infected with COVID-19 from eighteen different countries worldwide. According to Table 2, the majority of p-values corresponding to the best fitting model (negative binomial model with a logarithmic link function) for each country’s data are smaller than 0.05 — indicating significance of the slope coefficient estimates at the 5 percent significance. However, a particular exception is that of China, whose p-value is significantly greater than 0.05. This result is, perhaps, not surprising as China was the first country to be majorly affected by COVID-19 and by the time most other countries started to see significant increases in new numbers of cases its numbers had already peaked and new cases in China were being confirmed at a slower rate.

Among the countries where the model appears to show a reasonable fit, the slope estimate was positive in all cases indicating the expected number of new cases confirmed each day is expected to increase with respect to time. In particular, the UK and Vietnam have the largest and smallest slope estimates, respectively, hence the rate of increase in new daily COVID-19 cases with time is the highest for the UK and lowest for Vietnam.

Fig. 2, Fig. 3 provide the predicted values of Zt, their median and 95 percent confidence intervals for the 10 days immediately following the period that our data covers (starting from 26 March 2020). Also plotted in the figures are the actual number of newly reported cases for these 10 days. Fig. 4, Fig. 5 plot the same for four of the eighteen countries for, respectively, 7 days ahead and 15 days ahead. We have chosen four countries for limitations of space and for not being repetitive. The y axes of Fig. 2, Fig. 3, Fig. 4, Fig. 5 are plotted in log scale. Because log0 is undefined, we have left out zeros while plotting in log scale. This means some of the plots in Fig. 2, Fig. 3, Fig. 4, Fig. 5 have fewer than five curves.
The predicted Zt values time at t were computed as ϕ^1−ϕ^−1expα^+β^t. The predicted median at time t, say M(t), was computed as the solution of ∑k=0M(t)k+expα^+β^t−1k1−ϕ^expα^+β^tϕ^k=0.5.The predicted 95 percent confidence interval at time t, say L(t),U(t), was computed as the solutions of ∑k=0L(t)k+expα^+β^t−1k1−ϕ^expα^+β^tϕ^k=0.025and ∑k=0U(t)k+expα^+β^t−1k1−ϕ^expα^+β^tϕ^k=0.975.


The actual number of new cases falls within the 95 percent confidence intervals for each of the eighteen countries (for 7 days, 10 days and 15 days), suggesting that the fitted model is robust in spite of being simple. For some countries, such as Denmark, Malaysia, and the Philippines, the actual and predicted values are reasonably close. On the other hand, for many countries the predicted values overestimate the actual number of new cases (Estonia, France, Germany, Italy, etc.). However, in a few instances - e.g. Qatar and United Arab Emirates, the actual number of new daily cases starts to outgrow the predicted values in the latter half of the 10 days (same was observed for 7 days and 15 days). Note that these countries do not appear to share a common connection. Although the regression model accounts for the historical number of daily cases (and the average rate of new daily cases), a possible explanation why it may under or overestimates the true number of new daily cases is due to the fact that it does not take into account many other factors that can influence the spread of infectious diseases, such as the behaviour of individuals (e.g. social, travel, etc.), government action, and economic policies.
Whilst this method has its advantages of being simple, straightforward and yet robust, the results should be interpreted with caution. They allow us to capture the general trend of the new daily cases in each country and generate some basic predictions in the short term. However, arguably, this approach misses key factors that are accounted for in other types of available models. Therefore, it would not be wise to purely use the results presented here to make policy decisions, but rather these results should be used in conjunction with those from other analyses, which can help to support or contradict.
Furthermore, we do not consider here the historical daily mortality due to COVID-19 as there exist many dependent factors that should be considered when modelling these numbers. Examples include available treatments, susceptible population, hospital capacity, transmission rate, location and elevation risk, socio-economic factors and many more. This data can often be limited or hard to obtain due to restrictions such as data privacy or unreliable reporting. For further information we refer the readers to Booth and Tickle [32].

Finally, we check robustness of the (log, negative binomial) model. We fitted all four models ((identity, Poisson), (log, Poisson), (identity, negative binomial) and (log, negative binomial)) to the two halves of the data set. The first half was taken as the data from 31 December 2019 to 11 February 2020. The second half was taken as the data from 12 February 2020 to 25 March 2020. The values of AIC and BIC for the four models for each half are given in Table 3, Table 4. We see that the (log, negative binomial) model gives the smallest values for each country and for each half.
We have provided a statistical study on the modelling and analysis of the daily incidence of COVID-19 in eighteen countries around the world. In particular, we have investigated whether it is possible to fit count regression models to the number of daily new cases of COVID-19 in various countries and make short term predictions of these numbers. The results suggest that the biggest advantage of these methods is that they are simplistic and straightforward allowing us to obtain preliminary results and an overall picture of the trends in the daily confirmed cases of COVID-19 in different countries.
The best fitting count regression model for modelling the number of new daily COVID-19 cases of all countries was shown to be a negative binomial distribution with log link function. The best fitted model was robust in that the 95 percent confidence intervals for prediction contained the actual number of new cases for each country. However, the model was not able to predict the trends of new daily cases well for China. We believe that this could be related to fact that China was the first country to be significantly affected, and by the time other countries started to be affected by COVID-19, China had already reached its peak in confirmed cases and their confirmed cases dramatically declined. Given these results, this suggests that this model may be more useful for modelling the early stages of an outbreak, when the number of new cases is increasing, and, more specifically, this suggests that a count regression model is better suited for modelling new daily cases when the trend is increasing linearly, semi-exponentially, or exponentially. Among the countries that fit well with this model, the slope estimate was positive in all cases, indicating that the expected number of new cases being confirmed each day is expected to increase with respect to time. The UK and Vietnam have the largest and smallest slope estimates, respectively, hence the rate of the daily increase in COVID-19 cases is highest for the UK and lowest for Vietnam. The model is beneficial for short term predictions in order to see the short term trend and the rate of growth of new cases, when no intervention measures are taken. In addition, the results could be useful in contributing to making health policy decisions or government intervention, but more importantly, these results should be used in conjunction with the results from other mathematical models that are more specific to epidemiology.
Nevertheless, direct extensions to the current work could include modelling the daily mortality due to COVID-19. Such models could incorporate dependent factors that influence mortality rate such as available treatments, susceptible population, hospital capacity, transmission rate, location and elevation risk, socio-economic factors and many more. A further extension is to seek models that are theoretically motivated for COVID data.

Stephen Chan: Introduction, Motivation, Data. Jeffrey Chu: Analysis, Discussion. Yuanyuan Zhang: Analysis, Discussion. Saralees Nadarajah: Methods, Fitting.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Physica A
PMC7482617,New global dynamical results and application of several SVEIS epidemic models with temporary immunity,"Immunization is believed to be one of the most successful and cost-effective public health interventions [1], for instance in worldwide eradication of small-pox and sharp reduction in the annual morbidity of most other vaccine-preventable diseases, such as polio, measles, hepatitis B, yellow fever [2], cholera [3], mumps [4] and influenza [5], [6], [7], [8]. Currently, immunization saves 2–3 million lives yearly and prevents debilitating illness, disability and death from the diseases. However, it is estimated that 19.4 million infants failed to be reached with routine immunization services in 2018 [1]. Due to low vaccination rate, the 2017–2018 seasonal influenza caused estimated 45 million illnesses, 21 million medical visits, 810,000 hospitalizations and 61,000 deaths in the United States [9], and now burden is not optimistic. Fortunately, timely vaccination programme played a core part in mitigating the pandemic (H1N1) 2009 [8] (pH1N1). Take Hong Kong China for instance: the subsequent potential waves of the pandemic [10] might be effectively mitigated with the launch of the pH1N1 vaccination programme for several priority groups [11], although the first wave failed to be timely contained due to the unavailability of the vaccine against the novel influenza strain [12] (see Fig. 1
).
Admittedly, immunization may not be once and for all because vaccine-induced immunity is generally temporary, and so are disease-acquired and natural immunity, which becomes one of major obstacles eliminating such these infectious diseases. Vaccines rarely provide the recipients with almost life-long immunity against re-infection. After being infected, susceptible individuals first become exposed but not infectious and then become infectious. The successfully recovered individuals acquire disease-induced immunity. Additionally, by virtue of natural immunity [13], [14], [15], a part of exposed individuals fail to develop disease but acquire temporary immunity. For example, the efficient innate immunity protects more than 90% of individuals infected with Mycobacterium tuberculosis
[14]. A recent study [15] has showed that, similar to seasonal influenza, most infection (up to 75%) of the pandemic H1N1 strain was asymptomatic and gave the infected individuals temporary immunity.
The nonlinear epidemic dynamical models incorporating both temporary immunity and latency such as SEIRS, SVEIS models in [16], [17], [18], [19], have been developed to better understand the transmission dynamical behaviors of infectious diseases qualitatively and quantitatively. The exploitation of their global asymptotic stability has been of great interest and challenging to researchers in infectious disease modelling aimed at finding out the effective control interventions, seeing [16], [17], [18], [19]. While the Lyapunov function methods may become unsuitable to prove their global stability, the classical geometric approach for nonlinear autonomous differential equations based on additive compound matrix theory developed by Li and Muldowney [20], [21], [22] has been succeed in applying to these epidemic models [16], [17], [20], [21], [22]. For example, Cai and Li [16] proposed the following nonlinear SEIV epidemic model with temporary immunity:(1.1){dSdt=(1−p)Π−βSIφ(I)−μS+ωV,dEdt=βSIφ(I)−(μ+σ)E,dIdt=σE−(μ+γ)I,dVdt=pΠ+γI−(μ+ω)V,where the total population N consists of susceptible (S), latent (E), infectious (I) and vaccinated-recovered (V) classes. The nonlinear incidence βSI/φ(I), with φ(0)=1 and φ′(I) ≥ 0, generalizes saturated incidence βSI/(1+κI) and nonmonotone incidence capturing psychological effect βSI/(1+κI2)
[23], [24]. Along the work of [16], Sahu and Dhar [17] further developed a nonlinear SVEIS model with partial temporary immunity as follows:(1.2){dSdt=Π−αS−βSI1+κI−μS+ωV+(1−q)γI,dVdt=αS+qγI+ξE−(μ+ω)V,dEdt=βSI1+κI−(μ+σ+ξ)E,dIdt=σE−(μ+γ)I,where susceptible class are vaccinated with certain vaccine at constant rate α, different from model (1.1) with a fraction of vaccinated newborns (denoted by p). We always assume that the same parameter represents the identical biological meaning throughout this paper, and the detailed biological descriptions of the parameters for model (1.2) are demonstrated in Table 1
. Note that [16], [17] applied the geometric approach based on the second additive compound matrix theory of [20] to the responding limiting systems and achieved global stability of the unique endemic equilibrium (EE) under the vaccination reproduction number Rv>1 and some additional restrictions. More recently, Lu and Lu [18], [19] improved the classical geometric approach of [20], [21], [22] and generalized the geometric criterion on global-stability problem and applied it to several nonlinear SEIRS models, successfully removing some restrict conditions on global stability of their EE.
Borrowing the ideas of [16], [17], [23], [24], we establish the following SVEIS epidemic model with general nonlinear incidence:(1.3){dSdt=(1−p)Π−Sg(I)−μS+ωV,dVdt=pΠ+γI+ξE−(μ+ω)V,dEdt=Sg(I)−(μ+σ+ξ)E,dIdt=σE−(μ+γ)I,in which, it is assumed that vaccine-induced, disease-acquired and natural immunity may last the nearly same time for some diseases like influenza, and the differential infectious force function g possesses the following properties reflecting some biological significances:

(P1)
g∈C:R+→R+, satisfies g(0)=0,
g(I) > 0 for I > 0.

(P2)
g(I)/I∈C is monotonously nonincreasing for I > 0, and limI→0+(g(I)/I):=β<+∞.

(P3)
I|g′(I)| ≤ g(I) for I > 0.
It is worth highlighting that saturated and nonmonotone incidences in [23], [24], βSln(1+κI)
[29] and βSI/(1+κI+1+2κI)
[30], but not confined to them, fulfill (P1)-(P3), thus we lift restrictions on monotonicity of g(I) in spite of the introduction of (P3). With this geometric criterion in [18], we shall thoroughly address global threshold dynamics of models (1.3) and (1.2), characterized by their vaccination reproduction numbers. Incidentally, the unnecessary restrictions both in Theorem 4 in [16] and Theorem 5.5 in [17] are completely removed since model (1.3) reduces to model (1.1) if g(I)=βI/φ(I) and ξ=0. Of particular note is that we achieve global asymptotic stability for model (1.1) of [16] with nonmonotone incidence reflecting psychological effect, which also reserves threshold dynamics.
Furthermore, as an application of model (1.2), the reported pH1N1 case data of Hong Kong China [12] are utilized to estimate its parameters, aimed at accounting for the avoidance of the subsequent potential waves of the pandemic in 2010 (as predicted by WHO [10]) with the pH1N1 vaccination programme. Meanwhile, several disease-control measures are evaluated in terms of global sensitivity analysis for the vaccination reproduction number. In particular, this study arrives at a conclusion that joint usage of multiple control measures such as isolation, vaccination and treatment, can more effectively cut down the peak of the waves and dramatically delay the arrival of the second wave at the same time.
The outline of this paper is summarized as follows. In Section 2, we offer insight into global threshold dynamics for model (1.3), including the existence, local and global asymptotic stability of its equilibria. Section 3 completely addresses the global dynamics of model (1.2). Section 4 performs parameter estimation and global sensitivity analysis for the vaccination reproduction number of model (1.2) with the purpose of seeking for effective control measures. Finally, we close the paper with a conclusion and discussion section.
For model (1.3), one can easily obtain that the biologically feasible regionΩ={(S,V,E,I)∈R+4:N=S+V+E+I≤Πμ},is the positively invariant set by similar arguments in [16]. Apparently, the disease-free equilibrium (DFE) P0=(S0,V0,0,0) of model (1.3) always exists, where S0=[(1−p)μ+ω]Π/[μ(μ+ω)],
V0=pΠ/(μ+ω). Thus, by application of the next generation matrix approach in [31], the vaccination reproduction number (e.g., seeing [32], [33]) is calculated as(2.1)Rv=σg′(0)S0(μ+γ)(μ+σ+ξ)=σβΠ[(1−p)μ+ω]μ(μ+ω)(μ+γ)(μ+σ+ξ),clearly remaining the same with the model in [16] when ξ=0.
By some direct but tedious algebra operations, it can be deduced that the I* component in the EE P*=(S*,V*,E*,I*) is determined by the following equation(2.2)G(I):=(S0−aI)g(I)−bI=0,forI∈[0,S0/a],wherea:=(μ+γ)(μ+σ+ξ+ω)+σωσ(μ+ω),b:=(μ+γ)(μ+σ+ξ)σ.In what follows, we are going to focus mainly on analyzing the positive real solution of Eq. (2.2). A simple induction then shows(2.3)G′(I):=(S0−aI)g′(I)−ag(I)−b.It deduces from (P2) that G′(0)=S0g′(0)−b=b(Rv−1).
In the case of Rv>1, together with G′(0) > 0, G(0)=0 and G(S0/a)=−bS0/a<0, it can be revealed that G(I) > 0 as I is sufficiently small, guaranteeing the existence of positive real root for Eq. (2.2) from Fig. 2
, denoted by I*. And its uniqueness is verified by reduction to absurdity as follows. Provided that another positive solution I
* of (2.2) nearest to I*, if it exists, must satisfy G′(I
*) ≥ 0 owing to the continuity of G(I). Actually, together with g′(I
*) ≤ g(I
*)/I
* deduced from (P3), we arrive at(2.4)G′(I*):=S*g′(I*)−ag(I*)−S*g(I*)I*=−ag(I*)+S*(g′(I*)−g(I*)I*)<0,where one utilizes the equality b=S*g(I*)/I* derived by the equations that the EE satisfies. An obvious contradiction exists as shown in Fig. 2. Thus, the positive solution I* is unique, which can lead to the uniqueness of S*, V*, E* from the analysis above.
In the case of Rv≤1,
Eq. (2.2) must admit no positive solution. Otherwise, let I
⋆ be its smallest one. Combining G(0)=0 and G′(0) ≤ 0 yields that G(I) ≤ 0 for sufficiently small I. Since the function G(I) continuously increases to 0 from the non-positive value, it is clear to see that G′(I
⋆) ≥ 0, which contradicts with G′(I
⋆) < 0 in (2.4).
To sum up, model (1.3) has a unique EE P* if and only if (iff) Rv>1.Theorem 2.1
For model
(1.3)
, a DFE P
0
always exists and the EE P* exists uniquely iff
Rv>1
.



Theorem 2.2(i) The DFE P
0
is local asymptotically stable (LAS) if
Rv<1,
but becomes unstable if
Rv>1
; (ii) The EE P* is LAS iff
Rv>1
.

ProofThe Jacobian matrix of model (1.3) takes the following form of(2.5)J=[−(μ+g(I))ω0−Sg′(I)0−(μ+ω)ξγg(I)0−(μ+σ+ξ)Sg′(I)00σ−(μ+γ)].(i) The characteristic equation at P
0 is(2.6)(λ+μ)(λ+μ+ω)[λ2+(2μ+γ+σ+ξ)λ+(μ+γ)(μ+σ+ξ)(1−Rv)]=0.Obviously, its all eigenvalues possess negative real parts when Rv<1, that is, P
0 is LAS. If Rv>1, there exists a positive root, so the DFE becomes unstable.(ii) Calculating the characteristic equation at P*, one reaches(2.7)(λ+μ)[(λ+a1)(λ+a2)(λ+a3)+ωg(I*)(λ+a4)−σS*g′(I*)(λ+a5)]=0,where a1:=μ+γ,
a2:=μ+σ+ξ,
a3:=μ+ω+g(I*),
a4:=μ+γ+σ,
a5:=μ+ω. Clearly, λ1=−μ<0.
Case I. Let g′(I*) > 0. One asserts that all eigenvalues of the following equation(2.8)(λ+a1)(λ+a2)(λ+a3)+ωg(I*)(λ+a4)=σS*g′(I*)(λ+a5)satisfy Reλ < 0. Suppose, for contradiction, that there exists one eigenvalue λ˜ with Reλ˜≥0. From (2.8) and (P3), the following contradiction is attaineda1a2<|(λ˜+a1)(λ˜+a2)(1+g(I*)λ˜+a5)+ωg(I*)(λ˜+a4)λ˜+a5|=σS*g′(I*)≤σS*g(I*)I*=a1a2.
Case II. Let g′(I*) ≤ 0. Equality (2.8) is recast as λ3+A1λ2+A2λ+A3=0. For i,j=1,2,3, the Routh-Hurwitz conditions can be ensured byA1=a1+a2+a3>0,A2=a1a2+a2a3+a1a3+ωg(I*)−σS*g’(I*)>0,A3=a1a2a3+ωg(I*)a4−σS*g’(I*)a5>0,A1A2−A3=(a1+a2+a3)(a1a2+a2a3+a1a3)−a1a2a3+ωg(I*)(2μ+ξ+ω+g(I*))−σS*g’(I*)(a1+a2+g(I*))>0.We thus infer that all eigenvalues obey Reλ < 0. Combining Cases I and II leads to local stability of P* for Rv>1. □


Theorem 2.3
The DFE P
0
of model
(1.3)
is GAS in Ω if
Rv≤1
.

ProofBy the first equation of (1.3) and S+V+E+I≤Π/μ, it is easy to ascertain thatdSdt≤(1−p)Π−μS+ωV≤(1−p)Π−μS+ω(Πμ−S−E−I)≤[(1−p)μ+ω]Πμ−(μ+ω)S=(μ+ω)(S0−S),which asserts that S ≤ S
0 (similar to [4]). Otherwise, let us suppose that S > S
0, thus dS/dt < 0. It follows that S ≤ S
0 when S(0) ≤ S
0, which is absurd as our assumption. Hence, our claim S ≤ S
0 is valid. Observe that g(I)/I ≤ β for I > 0 can be ensured by (P3) (seeing, e.g., [34]). Construct Lyapunov function W(t)=E+(μ+σ+ξ)I/σ, and its time derivative of W(t) along the solutions of model (1.3) is estimated asdW(t)dt=dEdt+μ+σ+ξσdIdt=I(Sg(I)I−b)≤I(βS0−b)=bI(Rv−1)≤0provided that Rv≤1. From the LaSalle’s Invariance Principle [35] and local stability of P
0 in Theorem 2.2, we can derive its global asymptotic stability for Rv≤1. □

In the sequel, we shall employ the general criterion for global stability for autonomous differential equations developed by [18] to establish global stability of the EE P* of model (1.3). A brief outline on this geometrical approach [18], [20], [21], [22] is presented as follows.
Let us consider the nonlinear autonomous dynamical system:(2.9)dxdt=f(x),x∈Q⊂Rn,where the function f(x)∈C:Q→Rn and Q is an open set. For (2.9), the solution with x(0,x0)=x0 is defined as x(t, x
0) and its equilibrium as x*. Moreover, let us assign M(x)∈C2:Q→Rn, satisfying dim(∂M/∂x)=m when M(x)=0. We assume that system (2.9) admits a n−m dimensional invariant manifold defined by Γ={x∈Rn|M(x)=0}.
The following three hypotheses are satisfied:

(H1) Γ is simply connected.

(H2) There is a compact absorbing set D ⊂ Q ⊂ Γ.

(H3) System (2.9) admits a unique equilibrium x* in Γ.
The general geometric criterion of Lu and Lu is recapped as follows.Lemma 2.1
(see Theorem 2.6 in
[18]
). The unique equilibrium x* of
(2.9)
is globally asymptotically stable (GAS) in Γ provided that (H1)-(H3) and the following condition (C) hold.

(C) For the coefficient matrix B(x(0, x
0)) of system
(2.9)
, there are a matrix C(t), a sufficiently large τ
1 > 0 and constants
ρ1,ρ2,…,ρn>0
such that
(2.10)bii(t)+∑i≠jρjρi|bij(t)|≤cii(t)+ρjρi|cij(t)|,for∀t≥τ1,∀x0∈D,
and
(2.11)limt→∞1t∫0t(cii(t)+ρjρi|cij(t)|)ds=c¯i<0,
where bij(t) and cij stand for entries of matrices B(x(0, x
0)) and C(t), respectively.


Denote the interior, the boundary of Ω by Ω˚ and ∂Ω, respectively. Uniform persistence in Ω˚ of model (1.3) for Rv>1 can be deduced from the instability of P
0 and P
0 ∈ ∂Ω.Theorem 2.4
Model
(1.3)
is uniform persistent in
Ω˚
if
Rv>1
.

Theorem 2.5
The EE P* of model
(1.3)
is GAS in
Ω˚
if
Rv>1
.

ProofThe third additive compound matrix of J
[22] for model (1.3) acquires the formJ[3](x)=[−(ω+σ+ξ)Sg′(I)−γ−Sg′(I)σ−(ω+γ)ξ000−(σ+ξ+γ)ω0−g(I)0−(ω+σ+ξ+γ)]+Θ1,where Θ1:=diag{−(3μ+g(I)),−(3μ+g(I)),−(3μ+g(I)),−3μ}.Assign M(x)=S+V+E+I−Π/μ with x=(S,V,E,I)∈R+4. The invariant manifold for (1.3) is Γ={x∈R+4|M(x)=0}. Following [22], it turns out to be N(x)=ν(x)=−μ and m=dim(∂M/∂x)=1. In the sequel, let P(x)=diag{I,E,V,S} and I4×4 be the 4 × 4 identity matrix. Then the coefficient matrix B(t)=PfP−1+PJ[3](x)P−1−νI4×4 readsB(t)=[−(ω+σ+ξ)SIg′(I)E−γIV−Ig′(I)σEI−(ω+γ)ξEV000−(σ+ξ+γ)ωVS0−Sg(I)E0−(ω+σ+ξ+γ)]+Θ2,where Θ2=diag{−(2μ+g(I))+I′/I,−(2μ+g(I))+E′/E,−(2μ+g(I))+V′/V,−2μ+S′/S}.Meanwhile, model (1.3) can be recast into(2.12)ωVS=S’S+g(I)+μ−(1−p)ΠS,γIV=V’V+μ+ω−pΠV−ξEV,Sg(I)E=E’E+μ+σ+ξ,σEI=I’I+μ+γ.
Note that Theorem 2.4 implies that there is a constant π
0 > 0 such that π
0 ≤ S, V, E, I ≤ Π/μ. It follows from (P1) that there are constants l, L > 0 such that l ≤ g(I) ≤ L. Assign π ≔ μπ
0/Π. By I|g′(I)| ≤ g(I) in (P3) and (2.12), ci(t) are respectively estimated asc1(t)=b11(t)+∑i=24|bij(t)|=−(2μ+ω+σ+ξ+g(I))+I’I+SI|g’(I)|E+γIV+I|g’(I)|≤−(2μ+ω+σ+ξ+g(I))+I’I+Sg(I)E+γIV+g(I)≤−(2μ+ω+σ+ξ+g(I))+I’I+(E’E+μ+σ+ξ)+(V’V+μ+ω−pΠV−ξEV)+g(I)≤V’V+E’E+I’I−(pμ+ξπ)≜c¯1(t),c2(t)=b22(t)+∑i≠2|bij(t)|=−(2μ+ω+γ+g(I))+E’E+σEI+ξEV≤−(2μ+ω+γ+g(I))+E’E+(I’I+μ+γ)+(V’V+μ+ω−pΠV−γIV)≤V’V+E’E+I’I−(l+pμ+γπ)≜c¯2(t),c3(t)=b33(t)+∑i≠3|bij(t)|=−(2μ+σ+γ+ξ+g(I))+V’V+ωVS≤−(2μ+σ+γ+ξ+g(I))+V’V+(S’S+g(I)+μ−(1−p)ΠS)≤S’S+V’V−[σ+γ+ξ+(2−p)μ]≜c¯3(t),c4(t)=b44(t)+∑i≠4|bij(t)|=−(2μ+σ+γ+ω+ξ)+S’S+Sg(I)E≤−(2μ+σ+γ+ω+ξ)+S’S+(E’E+μ+σ+ξ)≤S’S+E’E−(μ+ω+γ)≜c¯4(t).Choose the matrix C(t) in Lemma 2.1 as C(t)=diag{c1(t),c2(t),c3(t),c4(t)}. It is easy to check that limt→∞∫0tc¯i(s)ds/t=c¯i<0, where c¯1=−(pμ+ξπ),
c¯2=−(l+pμ+γπ),
c¯3=−[σ+γ+ξ+(2−p)μ],
c¯4=−(μ+ω+γ). By Lemma 2.1, the EE is GAS in Ω˚. □
Remark 2.1Let ξ=0 and g(I)=βI/(1+κI), then model (1.3) reduces to the model with saturated incidence of [16], which retains global threshold dynamics from Theorem 2.5, improving Theorem 4 in [16]. More importantly, the sharp threshold dynamics result is extended to the model with nonmonotone incidence capturing psychological effect of [16].

In this section, for simplicity, we take g(I):=βI/(1+κI), satisfying (P1), (P2) and

(P3)′
Ig′(I) ≤ g(I) for I > 0.
Following the same reasoning as the proof of Theorems 2.1–2.2 in Subsections 2.1–2.2, one easily draws the following conclusions on the existence, local stability of the DFE P˜0=(S˜0,V˜0,0,0) and the EE P˜*=(S˜*,V˜*,E˜*,I˜*) for model (1.2), where S˜0=(μ+ω)Π/[μ(μ+α+ω)],
V˜0=αΠ/[μ(μ+α+ω)].Theorem 3.1
Model
(1.2)
always has a DFE
P˜0
and the EE
P˜*
is unique if the vaccination reproduction number
(3.1)R˜v=σg′(0)S˜0(μ+γ)(μ+σ+ξ)=σβΠ(μ+ω)μ(μ+α+ω)(μ+γ)(μ+σ+ξ)>1.

Theorem 3.2
The DFE
P˜0
is LAS when
R˜v≤1,
and it is unstable but the EE
P˜*
is LAS when
R˜v>1
.


In what follows, we make a thorough inquiry into global stability of model (1.2). Using the similar arguments as the analysis of Theorems 2.3-2.4 in Subsection 2.3 can lead to global stability of the DFE and persistence of model (1.2) as follows.Theorem 3.3
If
R˜v≤1,
the DFE
P˜0
is GAS in Ω.

Theorem 3.4
If
R˜v>1,
model
(1.2)
is uniform persistent in
Ω˚
.


In order to achieve global stability of the EE, we focus mainly on the significant differences and skip the repeated parts with the proof of Theorem 2.3 in Subsection 2.3. The coefficient matrix B(t) for model (1.2) is calculated asB(t)=[−(α+ω+σ+ξ)SIg′(I)E−qγIV−Ig′(I)+(1−q)γISσEI−(α+ω+γ)ξEV000−(α+σ+ξ+γ)ωVS0−Sg(I)EαSV−(ω+σ+ξ+γ)]+Θ˜2,where Θ˜2=diag{−(2μ+g(I))+I′/I,−(2μ+g(I))+E′/E,−(2μ+g(I))+V′/V,−2μ+S′/S}. And model (1.2) can be transformed into(3.2)ωVS=S’S+g(I)+μ+α−ΠS−(1−q)γIS,qγIV=V’V+μ+ω−αSV−ξEV,Sg(I)E=E’E+μ+σ+ξ,σEI=I’I+μ+γ.

Clearly, g(I) meets (P1), (P2) and (P3)′, and g′(I) > 0 for I > 0. Uniform persistence ensures that there exists positive constants π
0, l, L such that π
0 ≤ S, V, E, I ≤ Π/μ, and l ≤ g(I) ≤ L. Let π ≔ μπ
0/Π. Two cases will be considered to estimate c
1(t).

Case 1. g′(I)−(1−q)γ/S≥0. Employing (3.2), g′(I) > 0 and (P3)′ results inc1(t)=−(2μ+α+ω+σ+ξ+g(I))+I’I+SI|g’(I)|E+qγIV+|Ig’(I)−(1−q)γIS|≤−(2μ+α+ω+σ+ξ+g(I))+I’I+(E’E+μ+σ+ξ)+(V’V+μ+ω−αSV−ξEV)+g(I)≤V’V+E’E+I’I−(α+απ+ξπ)≜c¯1(t).
Case 2. g′(I)−(1−q)γ/S<0. Similar proof in Theorem 2.3 gives S ≤ S
0, being equivalent to μ+α−Π/S≤αω/(μ+ω). By g′(I) > 0, we can arrive atc1(t)≤−(2μ+α+ω+σ+ξ+g(I))+I’I+Sg(I)E+qγIV+(1−q)γIS−Ig’(I)≤−(2μ+α+ω+σ+ξ+g(I))+I’I+(E’E+μ+σ+ξ)+(V’V+μ+ω−αSV−ξEV)+(S’S+g(I)+μ+α−ΠS−ωVS)≤S’S+V’V+E’E+I’I−(μαμ+ω+(α+ξ+ω)π)≜c¯1(t).

We can similarly infer thatc2(t)=−(2μ+α+ω+γ+g(I))+E’E+σEI+ξEV=−(2μ+α+ω+γ+g(I))+E’E+(I’I+μ+γ)+(V’V+μ+ω−αSV−qγIV)≤V’V+E’E+I’I−(α+απ+qγπ)≜c¯2(t),c3(t)=−(2μ+α+σ+γ+ξ+g(I))+V’V+ωVS=−(2μ+α+σ+γ+ξ+g(I))+V’V+(S’S+g(I)+μ+α−ΠS−(1−q)γIS)≤S’S+V’V−(2μ+σ+γ+ξ+(1−q)γπ+μαμ+ω)≜c¯3(t),c4(t)=−(2μ+σ+γ+ω+ξ)+S’S+αSV+Sg(I)E=−(2μ+σ+γ+ω+ξ)+S’S+(V’V+μ+ω−qγIV−ξEV)+(E’E+μ+σ+ξ)≤S’S+V’V+E’E−(γ+qγπ+ξπ)≜c¯4(t).By applying Lemma 2.1, the above is concisely stated into Theorem 3.5.Theorem 3.5
The EE
P˜*
of model
(1.2)
is GAS in
Ω˚
if
R˜v>1
.

Remark 3.1An immediate consequence of Theorem 3.5 yields global threshold dynamics of model (1.2), getting rid of the unnecessary restrictions in Theorem 5.5 from [17]. Additionally, model (1.2) with the incidence satisfying (P1),(P2) and (P3)′, e.g., βSln(1+κI)
[29], βSI/(1+κI+1+2κI)
[30], also reserves global threshold stability by the same proof.
Remark 3.2From the analysis in Sections 2 and 3, it can be similarly verified that the following SVEIS model with temporary immunity and nonlinear incidence satisfying (P1)-(P3) is a sharp threshold system characterized by its vaccination reproduction number,(3.3){dSdt=Π−αS−Sg(I)−μS+ωV,dVdt=αS+γI+ξE−(μ+ω)V,dEdt=Sg(I)−(μ+σ+ξ)E,dIdt=σE−(μ+γ)I.


At the end of every month from May 2009 to October 2010, the pH1N1 case data of Hong Kong were released by official website of Center for Health Protection, Hong Kong China (available at https://www.chp.gov.hk/sc/statistics/data/10/26/43/416.html
[12]), and the data from May 2009 to June 2010 are chosen to fit the parameter values of model (1.2) owing to its high smooth degree (see Fig. 1). Indeed, the prevalence level of from July to October 2010 showed the small fluctuations and kept low (also seeing [8]). The first wave of the pandemic failed to be avoided (see Fig. 1) since there was no available vaccine against the novel influenza strain before 21 December 2009. It was on that day, the pH1N1 vaccination programme for five priority groups was launched and started [11] to minimize any potential second wave and 4182 doses of pH1N1 vaccine were administered [36]. Notice that the vaccine recipients will develop immunity in about 15 days [7] (delayed vaccination, e.g.,[2]), so the start time of generating vaccine-induced immunity can be approximated as 1 January 2010 as shown in Fig. 3
(a).
The intervals or values of parameters and initial condition of model (1.2) are estimated (as shown in Table 1) and explained as follows.(a)According to Subsection 4.1, we set vaccination rate α=0 during the 2009 pandemic, but α in (0,1] during the 2010 pandemic from [5]. The vaccine effectiveness is up to 99% [37], thus the vaccine is considered to be perfect.(b)Since life expectancy is about 83.74 years in Hong Kong in 2010 [25], natural death rate μ=30/(83.74×365)=9.8150×10−4 per month (m−1).(c)Following [5], [26], [27], [28] and [6], [7], the infectious duration varies from 4 to 10 days and the immunity period changes in the scope of 180 days to 2 years, respectively, so 1/γ∈[4/30,10/30]=[0.1333,0.3333] and 1/ω ∈ [6, 24.3333]. Let us take the infectious duration and the immunity period as 7 days [27], [28] and 1 years [6], respectively, then 1/γ=0.2333 m and 1/ω=12.1655 m.(d)The latent period (1/σ) ranges from 1 day to 5 days according to Refs[5], [26], [27], [28]., then 1/σ ∈ [0.0333, 0.1667]. From [5], [26], [28], it may be realistic for the influenza A(H1N1) to consider that exposed individuals recover after 1–10 days due to natural immunity, namely, ξ in [3,30]. It is not hard to obtain that the values of parameters q, β and κ belong to [0,1] based on some existing works (e.g., [17], [23]).(e)The number of births of Hong Kong in 2009 [38] was 8.21 × 104 per year, namely, 6748 m−1. Considering that vast majority of newborns were taken protective measures, about 2% of the number of births is chosen as recruitment rate of S class, so Π=6748×2%=130 m−1. The number of total population of Hong Kong during 2009–2010 [38]) was about 7.0 × 106, thus N(0)=S(0)+V(0)+E(0)+I(0)≤7×106. Together with the case data [12], the initial value I(0)=23 is fixed. And we assume that E(0)=10.

Above all, the values of the remaining parameters β, ξ, σ, q, κ and the initial values S(0), V(0) are estimated (seeing Table 1) with the 8 cases data from May to December 2019 by the DEDiscover simulation tool [39], where we choose the method of Hybrid DESQP Optimization Algorithm, combining global differential evolution and local sequential quadratic programming. From the parameter estimation results above, the values of κ=1.3458×10−13,
q=0.9287 tend to 0 and 1, respectively. This entails that several standard model selection criteria are employed to evaluate the superiority of models fitting the data [40], including Akaike information criterion (AIC) and Bayesian information criterion (BIC), and their variations such as AICc, with their smaller values corresponding to a better model. It can be observed from Table 2
that model (1.2) with κ=0 and q=0.9287 is selected as the best model by the criteria above, and its simulation results are presented in Fig. 3(a). This suggests that the simple mass action incidence βSI may appropriately reflect the short-term transmission process of the emerging influenza A(H1N1) virus and partial temporary immunity should be incorporated into the influenza models. Furthermore, we analyze the error of fitting to evaluate the performances and reliability of model (1.2) with κ=0 and q=0.9287, and MAPE (the mean absolute percentage error) and RMSPE (the root mean square percentage error) are computed as MAPE =37.36%, RMSPE =6.76%, respectively. Based on the criteria of MAPE and RMSPE in [41], [42], our model can yield reasonable forecasting results. Lastly, from Table 1 it can be checked that the latent period 1/σ=0.1116m=3.3482days and 1/ξ=1/(4.2857m−1)=7days are in agreement with the reality.
The results of parameter estimation above yield that the vaccination reproduction number of 2009 is computed into R˜v=1.4675>1, which is consistent with the conclusion in [28], [43] (ranging from 1.2 to 2.3). From Theorems 3.4 and 3.5, the disease may be persistent and become endemic. Without vaccination, as forecasted by WHO [10], the second wave is indeed observed through simulation using the estimated parameter values (see Fig. 3(b)), thus vaccination is imperative if the vaccine is available. Furthermore, vaccination rate α=0.3527 is estimated with the case data from January to June 2010 (other parameter values remain the same with Table 1, and initial condition (93492,312020,627,1287) is the simulation result in December 2009, corresponding to R˜v=0.2801<1, such that the pandemic was contained quickly, as proved in Theorem 3.3 and shown in Fig. 3(a).
The vaccination reproduction number R˜v of model (1.2), measuring the average number of secondary cases that are caused when one index case is introduced into a disease-free population [32], [33] in which a vaccination programme is carried out, may determine the transmissibility, severity and outcome of the pandemic. In order to seek for effective disease-control measures, we therefore shall be concerned with the effects of input parameters ω, β, α, γ, ξ on R˜v. Based on Latin Hypercube Sampling (LHS) and partial rank correlation coefficients (PRCCs) [44], global uncertainty and sensitivity analysis for R˜v is conducted to reveal the influence degree on model outcomes. These interesting parameters are considered to obey normal distributions with means coming from baseline values given in Table 1. And their PRCC values are computed through 5000 simulations per run and demonstrated in Fig. 4
(a) and Table 3
.
Finally, numerical simulations are carried out to evaluate the effectiveness of disease-control measures. In Table 3, input parameters β, α, ω, γ, ξ are ranked in descending order according to their influences on new infections. In fact, it seems difficult to prolong immunity duration related to the parameter ω. For this reason, we only consider the impacts of parameters β, α and γ. In detail, β has positive impact on R˜v and α, γ have negative impacts on it. Thus, we decrease the value of β by 10% and increase the value of γ by 10%, respectively. As discussed above, vaccination was such an effective health intervention, that the H1N1 pandemic was successfully curbed in 2010. In consideration of frequent outbreaks of current seasonal flu (including influenza A(H1N1), B and C) epidemics in many countries, such as the United States [9] and China with low vaccination rate, it may be interesting and significant to assume that the vaccine is available and vaccination is carried out at the begin of the pandemic. 10% and 20% of vaccination rate α=0.3527 are used to study the effect of vaccination on the pandemic. And the other parameter values and initial values of Table 1 are fixed. Simulation results are presented in Fig. 4 (b)-(d).
Undoubtedly, reducing the disease transmission coefficient β, such as epidemic propaganda, isolation, sterilization and wearing a mask, cuts down the peak of the first wave and delays the arrival of the second wave, but its two peak values fail to decrease obviously even though parameter β is the first sensitive, seeing Fig. 4 (b). On the other hand, increasing vaccination rate α and shortening the disease course of disease γ (e.g., antiviral therapy) lower more dramatically the peak values of the first and second waves than reducing β, but the peak of the second wave arrives much earlier than reducing β (as shown in Fig. 4 (c) and (d)). Therefore, it is possible for policymaker to use multiple control measures jointly during the influenza pandemic. It is also acknowledged that timely vaccination is particularly effective at reducing the outbreak peaks than the other two measures.
Immunization has been bringing mankind great success to prevent the disease transmission every year [2], [3], [4], [5], [6], [7], [8], [1], and a long latent period of infectious disease may generate dramatically different model prediction and thus allows of no to neglect [26]. What’s more, nonlinear incidence can reproduce the inhibition effect from behavioral changes of individuals and the impact of other factors like severity and stage of the infection [16], [17], [45]. The current work formulates an SVEIS model with vaccination, latency, nonlinear incidence and temporary immunity and establishes its global threshold stability by a novel geometric criterion in [18]. Most pointedly, the open questions on global threshold stability of their EE for two nonlinear SVEIS models with saturated incidence in [16], [17] are also well addressed. Inspired by [18], the introduction of the property (P3) on the infectious force function g(I) leads us to successfully achieve global threshold dynamics for the SVEIS models with nonmonotone incidence reflecting psychological effect. Furthermore, let g(I)=βI/φ(I), then an application of Theorem 2.5 yields that model (1.1) is a sharp threshold system provided that φ(I) meets φ(0)=1 and 0 ≤ Iφ′(I) ≤ 2φ(I), such as φ(I)=1+κIr for 0 < r ≤ 2.
In 2009, the novel influenza A(H1N1) virus caused the first pandemic of 21st century. We apply model (1.2) to illuminate the avoidance of the potential second wave of the pandemic (H1N1) 2009 in Hong Kong, China (as predicted by [10]) with the pH1N1 vaccination programme, and it is revealed that timely vaccination is more effective at lowering the outbreak peaks than other measures. This offers solid support for implementation of immunization strategy to cope with current global seasonal influenza burden, measles cases surge and COVID-19 pandemic if the vaccines are available.
This research is also subject to several limitations as follows. In details, observe that HBV vaccine is administered to both newborns and susceptible individuals, so both two vaccination ways can be incorporated into these SVEIS models, which, together with [4] we guess, can still preserve the threshold dynamics since insights provided by several SVEIS models studied above, can inform us that vaccination for either newborns or susceptible individuals and temporary immunity fail to change their threshold stability (see Theorems 2.5, 3.5 and Remark 3.2). Additionally, we just consider the nonlinearity of incidence rate on I, perfect vaccines, constant total population and postulate that vaccine-induced and disease-acquired immunity last the same time. It would be interesting to introduce more general incidence S
ϱ
f(I) (ϱ > 0), distinct vaccinated class (V) and recovered class (R), incomplete vaccination and varying total population size (e.g., [4], [18], [19], [21], [45]) to improve the accuracy of model prediction. Certainly, more analytical techniques are needed, and these issues are left as future investigations.",Appl Math Comput
PMC7754882,The role of NO in COVID-19 and potential therapeutic strategies,"Coronaviruses (CoVs) are a family of single-stranded positive-sense RNA viruses that mainly infect mammals and birds. They usually contain a ~30 kilobase (kb) genome and are named after their protruding crown-like spikes on the virus surface [1]. Outside of the human coronaviruses (e.g., types 229E, NL63, OC43, and HKU1) [2,3], CoVs that are found in other species do not infect humans directly from their natural hosts, but they trigger acute respiratory syndromes in humans after overcoming species barriers, such as the severe acute respiratory syndrome (SARS or SARS-CoV-1) in 2002, the Middle East respiratory syndrome (MERS or MERS-CoV) in 2012 and COVID-19 caused by SARS-CoV-2 in 2019 [4]. As of December 1, 2020, the total number of confirmed infected cases worldwide stood at 63.3 million, with a death toll of 1.47 million (from Johns Hopkins Center for Systems Science and Engineering) [5]. The fatality rate has varied greatly by region and age groups. Although many COVID-19 patients may be asymptomatic, those with symptoms include fever, dry cough, shortness of breath and myalgia. Death is mostly due to acute lung injury (ALI), acute respiratory distress syndrome (ARDS) and sepsis, which are caused by viral infection and very similar to the pathological features of SARS and MERS [6]. According to genomic and proteomic analyses, the similarity between total nucleoside sequences of SARS-CoV-2 and SARS-CoV-1 is about 79.5%, and the similarity of amino acid sequences between seven conserved replicate domains in the open reading frame 1ab (ORF1ab) is as high as 94.4% [7,8]. These indicate that SARS-CoV-2 belongs to the β-line coronavirus family and is a member of the SARS-CoV species [7,8]. It has been confirmed that SARS-CoV-2 and SARS-CoV-1 invade cells via a similar mechanism, i.e. binding to human type I trans-membrane receptor angiotensin converting enzyme 2 (ACE-2) through the S-protein. The receptor-binding ability of SARS-CoV-2 is about 4 times that of SARS-CoV-1 [9], which explains the higher infectivity of SARS-CoV-2. Due to the overlap of the genetic structures and pathological features between them, known facts about SARS-CoV-1 indeed have provided hints for our understanding of SARS-CoV-2.
Nitric oxide (NO) is a key player in both the cardiopulmonary and immune systems. The role of NO depends on its site of production and concentration. Abnormal levels of NO in vivo are usually closely related to the occurrence and development of diseases, such as viral infection. To date, there is no comprehensive report on the role, potential mechanism and therapeutic application of NO in COVID-19. In this review, NO in COVID-19 was systematically examined from the perspectives of its general features, six known pathways in lungs, possible roles in COVID-19 etiology, and clinical use in COVID-19 prevention and therapy.
Determination of nitrate and nitrite (metabolites of NO, abbreviated as NOx) by the Griess assay in the blood of patients with severe COVID-19 revealed that the production of NO was significantly higher than that of healthy individuals (as a control group) [10]. This may be compatible with macrophage activation, which is common during inflammatory immune responses. Inducible nitric oxide synthase (iNOS) in macrophages can be 2–3 fold higher following inflammation, which releases a large amount of NO leading to local and systemic increases of nitrate or nitrite [11]. However, one original clinical report from Canada showed that, through thrombotic factor profiling with immunoassays and in vitro experiments on human pulmonary microvascular endothelial cells, exaggerated and persistent injury to endothelium in severe COVID-19 patients was clearly found [12]. In addition, diffuse lymphocytic endotheliitis and apoptotic bodies were also observed in autopsy and surgical tissue specimens [13], which showed significantly decreased endothelial NO in patients with COVID-19 or related complications [14], and was suggested to be closely related to lung injury and an imbalance of NO and ROS [15]. Different findings about iNOS and eNOS suggested multiple pathways of NO during infection. Four potential pathways during SARS-CoV-2 infection have been described as below (Fig. 1
).
Although SARS-CoV-2 mainly infects bronchial ciliated epithelial cells and pulmonary type II cells, residual viral particles in endothelial cells were also found by electron microscopy. This observation confirmed that SARS-CoV-2, like SARS-CoV-1 and MERS-CoV, could directly infect endothelial cells, leading to cell apoptosis and a decrease of endothelial NO (Fig. 1, Pathway 1) [16]. In addition, decreased NO production is also along the progression of viral infection. SARS-CoV-2 invades host cells through its surface stimulating glycoprotein-S protein binding to angiotensin converting enzyme 2 (ACE2), and then down-regulates expression of ACE2 [17]. It is known that ACE converts angiotensin I (AngI) into the pro-inflammatory peptide angiotensin II (AngII), and ACE2 metabolizes AngII to produce angiotensin-(1–7) ((Ang-(1–7))) and Ang-(1–7) promotes endothelial cells to produce NO. Due to down-regulation of ACE2, suppression of ACE and its downstream product AngII is alleviated. ACE inhibits NO production, and promotes ROS production and inflammation. Furthermore, as a pro-inflammatory peptide, AngII itself activates macrophages to produce pro-inflammatory cytokines and ROS [18,19], leading to excessive inflammatory responses and NO/ROS imbalance (Fig. 1, Pathway 2). Inflammation is the normal response of the human immune system to injuries and attacks. Analysis of peripheral blood indicated that viral infection often caused a significant increase in pro-inflammatory cytokines and chemokines, and developed into a strong cytokine storm [20,21]. When high inflammation persists for a long time, it causes damage to multiple tissues and organs. In addition, high inflammation causes a severe imbalance of NO/ROS in body, which in turn leads to oxidative stress (Fig. 1, Pathway 3) [22]. A large number of activated pro-inflammatory cytokines and chemokines were found in serum of patients with severe COVID-19, including IL-2, IL-6, IL-10, TNF-α, GSCF and MCP-1 [23]. By blocking mitochondrial oxidative phosphorylation and adenosine triphosphate production, pro-inflammatory cytokines promote production of excessive ROS in the mitochondria, and lead to increased membrane permeability and changed dynamics, resulting in mitochondrial dysfunction and apoptosis [24]. Mitochondria are the main source of ROS. When excessive ROS are present, endothelial injury is aggravated by cell apoptosis, activation of transcription factors (NF-kB, AP-1), and overexpression of inflammatory cytokines and adhesion molecules (ICAM-1, VCAM-1, E-selectin), which then significantly reduce the production of NO (Fig. 1, Pathway 3). In addition, ROS changes vascular tones by increasing intracellular calcium concentration and reducing the bioavailability of NO (Fig. 1, Pathway 4) [25].
How NO level and bioavailability impacted COVID-19 patients is closely related to its unique features. In the following section, the general biochemical properties of NO would be described, in order to understand its role in COVID-19.
NO is a highly reactive heteronuclear diatomic gas molecule with one single electron in the 2p-π anti-bonding orbital (π*2p). It reacts with various reagents and regulates multiple signaling pathways. NO can directly bind to target molecules including metal centers, DNA and lipid free radicals, and also reacts with oxygen (O2) or superoxide free radicals (O2
-) to form corresponding nitrogen oxide compounds, which then attack target molecules. There are two main synthetic pathways of NO in vivo: the aerobic oxidation of l-arginine (L-Arg) catalyzed by nitric oxide synthase (NOS), and the anaerobic or hypoxic reduction of nitrite catalyzed by nitrite reductase. NO also gets produced through nitrite disproportionation, or via release from dinitrosyl iron complex (DNIC) in vivo (Fig. 2
).
Under normoxia, NO can be generated from three types of NOSs encoded by different genes: endothelial nitric oxide synthase (eNOS), neuronal nitric oxide synthase (nNOS) and iNOS (Fig. 2). Among them, eNOS and nNOS are constitutive nitric oxide synthases that are found in endothelial, epithelial, smooth muscle and nerve cells. eNOS and nNOS are regulated by intracellular calcium and calmodulin. iNOS is mainly found in macrophages, monocytes and muscle cells, and does not depend on the regulation of calcium ions [26,27]. Depending on its source and concentration, NO has a Janus face in a variety of pathophysiological processes, participating in the regulation of blood circulation, immune response and nervous system signaling [28].
Around three decades ago, researchers found that NO promoted vasodilation, improving oxygenation and reducing pulmonary vascular resistance. Ever since, NO has been used to treat pulmonary dysfunction [34]. At vasoconstriction (general physiological contraction, inflammation or vascular injury), NO effectively relaxes smooth muscle cells and dilates blood vessels, therefore modulating vascular tension and local blood flow.
It has been generally accepted that NO binds to the heme center of its typical receptor, soluble guanylate cyclase (sGC), to form a NO-ferrous heme adduct (Heme-NO), thus activating sGC, and resulting in tremendous production of intracellular cyclic guanosine monophosphate (cGMP). cGMP is a second messenger that activates Ca2+ATPase, a P-type ATPase enzyme, which reduces intracellular Ca2+ concentration and relaxes smooth muscle cells. Kinase-G also promotes phosphorylation of protein G in smooth muscle cells, which connects seven regions of transmembrane receptors and phospholipases. It then thereby inhibits ligand-receptor interaction and contractile signal transmission, enhancing relaxation of smooth muscle cells and promoting local blood flow [35,36]. In addition, NO is also involved in the metabolic pathways of nitrosothiol (RSNO). RSNO is relatively stable, with a half-life of 40 min in an oxygen-rich environment (anaerobic half-life of NO is only 1–5 s, oxygen-rich <3 s). It has a strong bronchiectasis effect independent of the cGMP pathway, which effectively improves airway tension and increases oxygen intake [37].
Hypertension, diabetes, and cardiovascular diseases often associate with vascular dysfunction and decreased endothelial NO production or bioavailability [38]. Compared to other chronic conditions, these three diseases have become the most frequent comorbidities in COVID-19 patients who require hospitalization. In a meta-analysis that included six Chinese studies and 1527 COVID-19 patients, the overall prevalence of hypertension, cardiovascular and cerebrovascular diseases and diabetes were 17.1%, 16.4% and 9.7%, respectively. Another pooled analysis included seven studies published from Jan 1, 2019 to Feb 25, 2020 in PubMed, EMBASE, and the Web of Science databases, and showed that hypertension and a history of cardiovascular disease conferred 2.4 (95% confidence interval [CI] 1.5–3.8) and 3.4 (95% CI 1.9–6.2) times higher risk of severe COVID-19 disease [39], which suggest an important role for NO in COVID-19 etiology.
Endothelial cells produce anticoagulants, including heparin, prostaglandin and NO [40]. NO inhibits blood clotting and excessive activation of platelets. Under normoxia, NO is produced by l-arginine catalyzed by calmodulin-dependent NOS. It maintains physiological vascular homeostasis in tissue and protects blood vessels from damage by platelets and circulating cells. Pathological changes start following endothelial cell dysfunction, including decreased or ceased release of NO depending on the degree of injury. It leads to accumulation of free Ca2+ in vascular smooth muscle cells, continuous vasoconstriction, and subsequently a blood hypercoagulable state. Platelets contain vascular growth factors and release a variety of pro-inflammatory mediators. When blood vessels are damaged, platelets quickly gather to the injured site to form platelet clots and a complex with plasma factor VIIa, whose subsequent interaction with extravascular tissue factor initiates the action of thrombin (via conversion of inactive protease factor X into the active protease factor Xa). Thrombin then converts soluble fibrin into insoluble fibrin, which makes the platelet clot entangled with blood cells to form a thrombus. Therefore, a decrease of endothelial NO production is a sign of endothelial dysfunction and thrombotic events [41].
Abnormal coagulation has been reported in critically ill patients with SARS and MERS, and is closely related to poor prognosis. Autopsy reports on SARS patients indicated thrombosis in lungs, bronchi and small pulmonary veins [42,43]. Recent studies showed that a hypercoagulable state was one of the main pathological events in COVID-1944. Pulmonary and distal thrombotic complications were one important reason for high mortality in COVID-19 patients [44]. Early coagulation disorders in patients with COVID-19 were characterized by a significant increase in D-dimer and fibrin/fibrinogen degradation products, which developed into disseminated intravascular coagulation (DIC) in severe cases [45]. A clinical report on 99 patients diagnosed with COVID-19 at Jinyintan Hospital in Wuhan showed that about 36% patients had a significant increase of D-dimer during hospitalization (>1.0 μg/mL) [[46], [47], [48]]. Activated partial thromboplastin time (APTT) (21–37 s) and prothrombin time (PT) (9.2–15 s) also increased significantly [[46], [47], [48]], suggesting that these infected patients had the risk of thrombosis. Excessive platelet activation and platelet-monocyte aggregation caused by high blood coagulation were observed in 49 patients with severe COVID-19 treated by the Oswaldo Cruz Institute in Brazil, which was not observed in patients with mild cases [44], and suggested the pathological inflammatory activation of thrombus formation in severe patients.
Inflammation is one major defensive mechanism to inactivate pathogens, remove irritants, and lay the foundation for tissue repairs [49]. However, excessive inflammation causes injury. Studies have shown that NO promotes or inhibits almost every stage of inflammation [50]. Low concentrations of NO produced by eNOS reduce vascular permeability and inhibit inflammatory exudation, but high NO produced by iNOS has the opposite effect [51]. When pathogens invade the body, immune cells recognize them and their pattern molecules through germline-encoded pattern recognition receptors (PRRs). When PRRs sense the presence of pathogen-associated molecular patterns (PAMPs), including exogenous pathogen cell wall components, flagellin, and nucleic acid, they immediately activate the NF-κB and MAPK pathways. The transcription factors NF-κB and activator protein (AP-1) induces expression of iNOS, leading to an increase in NO concentration. The bactericidal effect of NO involves DNA damage, protein modification, inhibition of the mitochondrial electron transport chain or other metabolic pathway enzymes. These biochemical reactions produce cytotoxicity to pathogens and inhibit their further invasion. Because immune cells are the main effector cells of iNOS expression, the bactericidal effect of NO produced by iNOS is mainly aimed at microorganisms in the cytoplasm. Additionally, due to the membrane permeability of NO, it can also kill extracellular pathogens through diffusion [52].
Moreover, NO is also involved in the regulation of vascular inflammation through ameliorating vascular dysfunction and preventing complications, such as tissue edema caused by vascular leakage and respiratory failure. NO reduces vascular damage caused by inflammation [53]. Furthermore, NO inhibits proliferation of immune cells in inflammatory responses. It inhibits production of a large number of cytokines in lymphocytes, eosinophils, monocytes and other immune cells, including key cytokines in the inflammatory response [26]. Therefore, extreme inflammatory effects, such as the cytokine storm, are diminished, and uncontrolled body injury is avoided by NO [54].
In 2004, a Swedish group studied the inhibitory effect of NO donors on SARS-CoV-1 infection in VeroE6 cells [60]. Cells were treated with SNAP and another non-NO donor compound (as control) at various concentrations (0, 50, 100, 200, 400 μM) at 1 h after infection. The 50% tissue culture infection dose (TCID50) was determined after 24 h. The results showed that SNAP significantly inhibited the replication cycle of SARS-CoV-1 at both RNA and cellular levels in a dose-dependent manner. Besides, iNOS expression was found to accompany decreased offspring viruses by 82% [60]. Two NO-mediated antiviral mechanisms were proposed, which were later experimentally verified: (1) NO affected one or two replication-related cysteine proteases encoded by SARS-CoV-1 ORF1a, which directly inhibited viral RNA replication, and (2) NO decreased the palmitoylation level of S protein and inhibited the membrane fusion of offspring virus S protein binding to host cell receptor ACE261.
Replication of SARS-CoV-1 was mediated by the nonstructural proteins nsp1-nsp16, and the later contain two cysteine proteases, which would be discussed in further details below [62,63]. Cysteine protease cleaves pp1ab replicase polyproteins with varied efficiency. Upon treatment with SNAP, two new high-molecular weight peptides were found. It was suggested that NO changed the original cutting mode of cysteine proteases, thereby affecting production of the non-structural proteins, and terminating the replication process of viral RNA [61,64].
The effect of NO on S protein was also investigated. VeroE6 cells infected with recombinant vaccinia virus carrying S gene (rVV-L-S) were treated with 400 μM SNAP, which was labeled with [3H] palmitic acid. After immune-precipitation of the S protein, it was found that SNAP treatment significantly reduced the number of palmitoylated S protein. The intercellular fusion was significantly decreased due to the low expression of S protein after SNAP-treated rVV-L-S was mixed with CHO-ACE2 cells (a cell model that stably expresses ACE2 on the cell surface). The results showed that the entry efficiency of the pseudotyped virus was significantly lower after SNAP treatment, and the virus infection rate decreased by about 70% [61]. O2
- is also produced during viral infection, which reacts with NO readily to produce peroxynitrite (ONOO-) [65], a viral inhibitor. In order to clarify whether ONOO- contributed to this effect, the ONOO- donor SIN-1 was used to treat cells infected with SARS-CoV-1. ONOO- did not show inhibitory effect on SARS-CoV-1 replication, which ruled out the contribution of peroxynitrite in this case [61].
SARS-CoV-2 and SARS-CoV-1 share a similar infection process: they both rely on the membrane fusion mediated by the viral S protein with the host cell receptor ACE2 to promote the injection of viral genetic material [66]. At present, the 3D atomic map of the SARS-CoV-2 S protein has been successfully constructed by cryogenic electron microscopy. The SARS-CoV-2 S protein is a trimer protein with a large number of glycosylation modifications, and its protein sequence is very similar to the S protein of SARS-CoV-1 [67]: although the S2 region (mediated membrane fusion) is highly homologous (99%), there is a difference in amino acid residues of the S protein receptor region (RBD). This difference has been shown to promote the cell entry mechanism of SARS-CoV-2 [68,69]. In addition, the SARS-CoV-2 genome is divided into six main functional open reading frames, including ORF1ab, spinous (S), envelope (E), membrane glycoprotein (M), nucleocapsid (N) and helper gene [70]. The replicase protein pp1ab, formed by ORF1ab, is cleaved into 16 non-structural proteins (nsp) involved in virus replication by papain-like (PLPro) and 3C-like (3CLPro) proteases encoded by SARS-CoV-2. In addition, the homology between the SARS-CoV-2-encoded 3CLPro and that of SARS-CoV-1 is as high as 96%, and their structures are basically similar [71,72].
Therefore, the inhibition of SARS-CoV-2 by NO may be similar to that of SARS-CoV-1. NO also inhibits viral replication by affecting one or two cysteine proteases encoded by the SARS-CoV-2 ORF1a and reducing the palmitoylation level of the S protein [73]. However, the mechanism of NO in SARS-CoV-2 remains unclear. Researchers have recommended NO together with clinically recommended antiviral drugs as an effective strategy for the treatment of COVID-19 [71,74].
The main format of NO used in therapy is its precursors, such as sodium nitroprusside (SNP). SNP is usually administered intravenously and releases NO immediately after entering the bloodstream. It is widely prescribed as a vasodilator for the treatment of acute hypertension. However, intravenous administration of this type of drugs may lead to systemic vasodilation and arterial hypotension [75], and alternative medicines have therefore attracted much interest.
NOS is expressed in healthy paranasal sinus epithelial cells and produces high-level NO gas continuously [76]. Through respiration, NO then reaches deep regions of lungs at a lower concentration, promoting dilation of bronchi and blood vessels, as well as increasing oxygen intake in the lungs [77,78]. Upon reaching the bloodstream, NO may immediately get scavenged by hemoglobin (Hb), thereby preventing systemic vasodilatation [79]. Therefore, researchers have tested the effect of inhaled NO (iNO) as a selective pulmonary vasodilator as a potential treatment for respiratory failure caused by lung diseases [80]. Currently, iNO has been used in the treatment of ARDS, pulmonary bacterial infections and persistent pulmonary hypertension of the newborn (PPHN), and was approved by the FDA as a clinical adjuvant therapy for PPHN in 1999 [81,82]. iNO was also known to benefit therapy in other diseases, including myocardial or cerebral ischemia, sickle cell disease, cerebral malaria and ischemia-reperfusion injury. iNO may be used in surgery or organ transplants according to animal experiments. Although there were no obvious side effects after iNO treatment, it is necessary to continuously monitor the levels of met-myoglobin and nitrogen dioxide (NO2), as well as changes in blood clotting [81,83].
Coronavirus mainly infects humans through the respiratory tract. In severe cases, it causes complications, such as respiratory failure and irreversible damage to the lungs. Based on the above therapeutic features, iNO had been studied by researchers as an adjuvant therapy for respiratory failure caused by coronaviruses.
The global mortality rate of SARS patients was 10.5%, with around 20% patients developed ARDS, accompanied by severe lung infiltration and extensive consolidation [[84], [85], [86]]. Corticosteroids and ribavirin were widely used to reduce pulmonary infection in patients, but extensive use of these drugs had serious side effects, including osteonecrosis of femoral heads [87]. The optimal treatment strategy for SARS had not been released yet. Appropriate preventive measures were certainly needed to slow down aggravation of this disease.
During May–July 2003, one rescue trial of SARS suggested that exogenous inhaled NO could effectively improve arterial oxygenation in severe patients and inhibit the virus [85]. This trial involved 14 SARS patients (8 females and 6 males, ages 19–63) who were treated in the intensive care units (ICU) of Chao Yang Hospital and China-Japan Friendship Hospital. Patients were divided into two groups, one treatment group (6 subjects) and one control group (8 subjects). These six subjects received iNO for at least 3 days, decreasing dose day by day from 30 ppm, 20 ppm–10 ppm, and then to 0 ppm on the 4th day. After that, the subjects continued to inhale 10 ppm NO if arterial oxygenation deteriorated. Blood oxygen saturation (SpO2) was continuously monitored and the inhaled oxygen fraction (FiO2) was measured intermittently in 4 patients in the treatment group and 5 in the control group. Results showed that after iNO treatment, the average SpO2 increased from 93% to 99%, and the oxygen supply decreased from 6 L/min to 2 L/min. The ratio of PaO2 (the partial pressure of oxygen)/FiO2 monitored (4 subjects) increased from 97 mmHg to 260 mmHg. Also, continuous positive airway pressure (CPAP) and bilevel mask positive airway pressure (BiPAP) ventilation were reduced and even discontinued in all 4 subjects. In addition, SpO2 remained at a high level after stopping NO inhalation. The density of pulmonary infiltration in 5 patients also decreased significantly, and chest radiography showed a decreased spread or decreased density of the lung infiltrates in 5 of the 6 patients. In the control group, two patients died, with the other six patients recovering and leaving the hospital within 8 weeks after the end of the study. Taken together, these results showed the great potential of iNO for SARS treatment [85].
During the MERS outbreak in 2012, noninvasive ventilation (NIV) was commonly used for patients who had related acute hypoxemic respiratory failure (AHRF), although the overall effectiveness remained controversial [88]. Analysis on a multicenter retrospective cohort of severe MERS patients from 14 participating tertiary care hospitals in 5 cities in Saudi Arabia admitted between September 2012 and October 2015 were reported on August 9, 2018. This analysis included 302 MERS patients. 105 (35%) patients initially used NIV, whereas 197 (65%) patients were only managed with invasive mechanical ventilation (MV). Through the Mann-Whitney U or Student's t tests, the main interventions for patients initially managed with NIV were compared to those managed only with invasive MV. Results showed that patients managed initially with NIV were more likely to subsequently require iNO compared to invasive MV patients [20.0% vs 11.7%, P = 0.05], and suggested the important role of iNO as an adjunctive therapy in the treatment of MERS [89].
According to the above promising outcomes among SARS and MERS patients, investigations of iNO therapy are warranted for the treatment of COVID-19, and have been put into practice for a number of clinical trials as discussed below.
Studies have shown that about 26% of COVID-19 patients needed ICU treatment, out of whom 61% developed ARDS [90,91]. Once ARDS occurs in patients with hypoxemia, invasive therapy has been shown to be indispensable [92]. Moreover, there is no other treatment that could replace oxygen ventilation support in critically ill patients. As such, iNO has been studied as an alternative rescue method in COVID-1993.
In March 2020, one multicenter clinical trial was organized by Harvard University and Air Force Medical University (China) to investigate whether continuous inhalation of NO could be used as a rescue therapy to effectively improve oxygenation and the survival rate of COVID-19 patients. Exclusion criteria included a history of intubation less than 72 h before treatment, lung malignant tumors, brain function damages, etc. 200 patients were recruited and randomly divided into the iNO-treatment and control groups. The treatment group first received 80 ppm NO, and then 40 ppm until symptoms of hypoxia completely disappeared. Once PaO2/FiO2 was >300 mmHg within 24 h, patients could be weaned from iNO step by step. Levels of NO2 (<2 ppm) and methemoglobin (non-invasive combined oximeter, <5%) were closely monitored throughout the study to ensure the steady progress of the experiment (Table 1
, NCT04306393) [94]. Outcomes of this trial have not been released yet.
University Health Network submitted a clinical trial in May 2020 on whether the use of high dose iNO (≥160 ppm, high medical dose) was safe and could reverse virus burden and respiratory failure in COVID-19 patients on mechanical ventilation. It was expected to recruit 20 patients, each of whom would be given 160 ppm iNO for 6 h, once per day for two days. The primary outcome measured COVID-19 PCR status at completion of treatment (day 7) from tracheal aspirate (Table 1, NCT04383002)95. Similar trials were carried out, including EUCTR2020-001329-30-AT [96], which focused on iNO therapy in patients with pulmonary failure (Table 1, all underway).
In the same month, Tufts Medical Center carried out a pilot randomized-controlled (2:1) open label investigation of iNO to prevent progression to more advanced disease among 42 COVID-19 patients with dyspnea. Subjects received NO using one an iNO pulse device with a dose of 125 mcg/kg IBW/hr (equivalent to approximately 20 ppm). The primary outcome of this study is to determine whether iNO treatment slows down progressive systemic hypoxia within 28 days (Table 1, NCT04388683) [95]. A similar trial including NCT03331445, which focuses on patients with respiratory distress, is being carried out by Nitric Solutions-Mobile Unit (Table 1, all underway) [95].
On August 26, 2020, a clinical trial of iNO in severe pregnant patients with COVID-19 in Massachusetts General Hospital was reported. Six pregnant women with severe COVID-19 from April to June 2020 were admitted and received iNO therapy. They were treated with high-dose NO (160–200 ppm) via mask twice a day, and a total of 39 treatments was administered. An improvement in cardiopulmonary function was observed after commencing NO gas, as evidenced by an increase in systemic oxygenation in each administration session among those with evidence of baseline hypoxemia, and reduction of tachypnea in all patients in each session. Three patients delivered a total of four neonates during hospitalization and they were home after 28 days with their newborns in good condition. Five of six patients had two negative test results by nasopharyngeal swab for SARS-CoV-2 within 28 days from admission. The result of the study showed that 160–200 ppm iNO appeared to be well tolerated, and might benefit pregnant patients with hypoxic respiratory failure (Table 1) [97].
In addition to the treatment of moderate or severe COVID-19 patients, iNO was also applied to treat patients with a mild form of the disease.
In April 2020, a clinical trial on mild COVID-19 patients (defined by a positive RT-PCR test for SARS-CoV-2) was carried out at Massachusetts General Hospital. This trial was expected to recruit 420 patients with mild COVID-19 (210 subjects, and the other 210 as a control group) and the iNO treatment would be administered at 140–300 ppm for 20–30 min. The primary goal was to prevent the deterioration of mild COVID-19 patients, which was defined as whether patients needed to return to the emergency department or be intubated (Table 1, NCT04338828)95. Similar trials include NCT04305457 (Massachusetts General Hospital) and NCT04443868 (Sanotize Research and Development Corp) (Table 1, all underway) [95].
In May 2020, Xijing Hospital and Massachusetts General Hospital also designed a joint trial on early-stage COVID-19 patients, who still breathed on their own, in order to determine whether high-dose iNO treatment could safely slow down or prevent the deterioration of this disease. 240 patients with mild symptoms such as fever and cough were recruited. They were treated with 140 ppm iNO twice daily and the number of patients who needed endotracheal intubation within 28 days was recorded (Table 1, underway) [98]. Similar trials include NCT04476992 (Safety Study on the Use of Intermittent Versus Continuous Inhalation of NO in Spontaneous Breathing COVID-19 Patients) carried out in Research Institute of Cardiology (Table 1, underway) [95].
The combined use of NO and other medicines were also studied. Boston University conducted a small clinical trial on the therapeutic effect of iNO in patients with COVID-19 spontaneous respiration. In this study, 39 COVID-19 patients with an average age of 61 years, who could breathe on their own, were treated with iNO for an average course of 2.1 days. The initial dose of iNO was 30 ppm (increased or decreased according to the course of disease in the later stage), and SpO2/FiO2 was used to evaluate the oxygenation status during ventilation. During this period, patients were treated with IL-6 receptor antagonists (34 cases, 87.2%), hydroxychloroquine (24 cases, 61.5%), azithromycin (21 cases, 53.9%) and autologous immunomodulators (23 cases, 59%). After SASv9.4 analysis, the results showed that a total of 21 patients (53.9%) did not need follow-up invasive mechanical ventilation after iNO treatment, of which 20 cases were successfully discharged from the hospital, with 1 case resulting in death. The median ratio of SpO2/FiO2 (IQR) decreased from 108 (96–118) to 54.9 (30–86.1) (Table 1) [99].
Inhaled NO has not been widely promoted for the treatment of COVID-19. To date, no outcomes from large-scale clinical trials have been released. Besides the trials mentioned above, there was a single case involving one patient who significantly improved after treatment with only iNO. This female patient had idiopathic pulmonary artery hypertension (IPAH) before being diagnosed with COVID-19, and had symptoms such as progressive dyspnea and fatigue that might have aggravated into pulmonary hypertension before treatment. She was evaluated with a non-canister iNO system, GENOSYL, which is commonly used to treat PPHN in newborns. The patient was first treated with 20 ppm NO plus 2 LPM intranasal supplementation of O2 for 12–14 h during the daytime, and the dose was gradually reduced at night (10, 5, 0 ppm) for 2–3 h. After 6 days of inhalation treatment, the above symptoms were improved, and completely disappeared within only 10 days after the dose was gradually reduced (Table 1) [100]. Although it was unclear whether she was completely recovered from COVID-19, her treatment was carried out entirely at home and did not require any emergency care or hospitalization. Certainly this single case is not representative of most COVID-19 patients, or even similar co-infection patients. However, it does indicate the potential of a portable NO inhalation system for treating mild COVID-19 patients at home to improve dyspnea and other symptoms [33], in order to achieve the effect of shunt treatment.
With the COVID-19 pandemic infecting tens of millions worldwide, identifying safe and effective preventive measures to stop the spread of the disease has become paramount. NO has been known to prevent viral transmission, and promote viral clearance and host recovery. Therefore, researchers speculated that exogenous NO might be effective for SARS-CoV-2 infection prevention, and recently iNO has been put into clinical trials for this purpose [101].
One randomized clinical trial of iNO (160 ppm) was conducted to prevent COVID-19 infection among healthcare workers at Massachusetts General Hospital. It was aimed at helping healthcare workers who were in close contact with COVID-19 patients. 470 people (235 in the iNO group) were expected to be recruited and given 160 ppm NO inhalation administration for 30 min twice daily. The incidence of COVID-19 was compared between the iNO and control groups. Based on the clinical data available in China and Italy, iNO inhalation was expected to reduce the incidence to 5% (previously 15%). In addition, a portable NO inhalation device was invented for this study. The device was small in size and easy to carry, with a gas storage capacity of 3 L. It also minimized the production of NO2, which facilitates wide clinical application of iNO (Table 1, NCT04312243, underway) [101]. A similar trial, NCT04337918, is also underway (Sanotize Research and Development Corp, Table 1) [95].
During the SARS outbreak in China, an interesting phenomenon observed was that only 8% of smokers (mostly male) have been infected with SARS-CoV-1 [102]. In this COVID-19 pandemic, less than 10% of smokers have been infected, much lower than the percentage of male smokers among the whole male population (~52%) [103]. In addition, there were similar reports in France, the United States and Italy, where smokers infected with SARS-CoV-2 were only 5–6% when the reference number was 25.4%, 13.7% and 14.9%, respectively [93]. With a range of 250–1350 ppm, NO is the main nitrogen oxide in cigarette smoke (the concentration of NO2 is very low or undetectable), and is much higher than the medical use of iNO, which is generally no more than 80–160 ppm. It appears that high concentrations of NO may have a preventative effect on COVID-19. In view of existing iNO experiments, intermittent high concentrations of NO administration may be tested using a NO inhalation system independent of gas tank supply [93]. A similar medical device (GENOSYL DS®) has been approved by the US FDA, and has been used for the treatment of PPHN with good outcomes.
Inhaled NO has been suggested as an alternative rescue method before invasive treatment, especially for the relief of hypoxemia. However, according to recent clinical trials in Italy, NO appears unable to reverse oxygenation in patients with extensive mechanical ventilation who had developed persistent hypoxemia [104,105]. Since the targeted effectors of NO in the vascular system and immune system were usually cells or viruses, the inefficacy of NO in the treatment of patients with severe mechanical ventilation might be explained by damage from effectors and excessive viral infection. It also suggests that oxygenation treatment for critically ill COVID-19 patients should instead focus on more effective antiviral drugs, instead of ordinary ventilation support. Therefore, the treatment of iNO in critically ill patients should be evaluated comprehensively with multiple factors.
Although a large number of studies have been carried out focusing on the therapeutic effects of iNO in COVID-19, the safe and effective dose for iNO is still uncertain. Therapeutic doses for COVID-19 patients have ranged from 20 to 300 ppm. Only a few investigations examined the safety and effectiveness of 80,150 and 160 ppm iNO (Table 1, NCT04456088, NCT04397692, NCT04383002) [95]. The results of these trials have not been published yet. Among those clinical devices available for iNO use, including GENOSYL, LungFit Delivery System and INOpulse, only few trials have verified their feasibility or safety in the treatment of COVID-19 (Table 1, NCT04421508, EUCTR2020-002394-94-BE) [95].
NO level and bioavailability decreased in patients with COVID-19, which indicated exogenous supplementation of NO might help prevent infection or treat patients. Here, we covered the general features and potential mechanisms of how NO functions in COVID-19 etiology, as well as its potential clinical applications. Inhaled NO might participate in multiple stages of COVID-19 prevention or therapy, including prevention of infection, intervention of mild patients, alternative rescue treatment of moderate and severe patients, and adjuvant treatment of mechanically ventilated patients. Although promising, the safety and effectiveness of iNO needs comprehensive and careful evaluation.

Department of Education of Hubei Province, China, 337/370, 6101/12267.",Free Radic Biol Med
PMC7484627,Prospective impact of Corona virus disease (COVID-19) related lockdown on shrimp aquaculture sector in India – a sectoral assessment,"The outbreak of coronavirus disease 2019 (COVID-19) first reported from Wuhan, China (Wang et al., 2020) in December 2019 has been declared as a Public Health Emergency of International Concern (PHEIC) and the virus has spread to almost all the countries (Johns Hopkins Coronavirus Resource Center (JHU), 2020). It has infected approximately 22.86 million people worldwide and about 0.78 million people lost their lives as on 20th August 2020 (https://www.worldometers.info/coronavirus/). In India, around 2.77 million people were diagnosed positive for COVID-19 and 53,000 people lost their lives by the end of June 2020 (https://www.mohfw.gov.in/). India had imposed a countrywide lockdown from 25 March to 20 August 2020 in different phases restricting the movement of people, closing down transport networks and all the economic activities except a few essential and medical services. Due to the highly contagious nature of the virus which till date does not have a specific treatment or vaccine, many countries have enforced complete lockdown/shutdown in their respective territories to contain the spread of the virus. COVID-19-induced restrictions exert a symmetric, but asynchronous shock on the global and national food systems from primary supply to processing, exports to trade as well as national and international logistics systems (Schmidhuber et al., 2020; Torero, 2020). A paradox of unemployment due to close down of activities in manufacturing and service sectors in one side as well as labour shortage in primary food production systems due to social and movement restrictions might cause severe economic consequences that can result in global economic recession as bad as the great depression (International Monetary Fund (IMF), 2020). Moreover, export restrictions across the countries might limit global farm-food trade and market access (Laborde, 2020; IFPRI, 2020) and the reduced freight capacity on commercial flights for agricultural goods led to global supply chain disruptions (FAO, 2020a; Ivanov, 2020). Further, the declaration of lockdown without preparedness impacted all the operations across the food system value chain (FAO, 2020b; Stephens et al., 2020).
Shrimp aquaculture is a vibrant agri-business sector in India with a production of 0.7 Million Tonnes (MT), most of which (90%) is exported to the United States of America (USA), South East Asia, European Union (EU), China and Japan earning a substantial amount of foreign exchange to the tune of 5 billion USD (MPEDA, 2019). Nearly 70,000 t of shrimps were consumed domestically. India is also the third largest producer of farmed shrimp globally with extensive farming regions distributed in the east and west coasts of the country. About 1.2 million people are employed directly or indirectly in the shrimp supply chain which encompasses seed production and supply, farming, production and supply of feeds and other inputs, harvest, post-harvest handling and marketing (Geetha et al., 2019). Shrimp farming is practiced in about 0.15 million ha spreading across nine coastal states with an average productivity of 6 t/ ha mostly by small and medium scale farms (MPEDA, 2019). However, major critical inputs such as seed, feed, pond supplements and shrimp health care products are produced mostly in two southern states: Andhra Pradesh and Tamil Nadu and transported to all the other states. The processing factories are spread across the maritime states. Therefore, interstate and intrastate movement of inputs and farmed shrimp are of utmost importance for the sector. Since 2010, Pacific white shrimp (Penaeus vannamei) has been the main species and hatcheries rely on Specific Pathogen Free (SPF) brood stocks imported from the USA, Madagascar and Mexico for seed production. The SPF shrimp brood stock imported from overseas suppliers are quarantined in a government-owned Aquaculture Quarantine Facility (AQF) (http://www.rgca.org.in/aqf.php) located at Chennai, Tamil Nadu to ascertain them that they are free of OIE listed pathogens before entering the hatcheries.
The short and long-term effects of COVID-19 risks marginalise coastal communities who are already vulnerable to many social and environmental changes (Bennett et al., 2020). FAO (2020b) in its initial assessment on COVID-19 indicated that shrimp farming gets disrupted as supply chains are broken, labour shortage emerges and market access gets affected. Therefore, it is important to investigate the immediate and long-term consequences of this pandemic for the global network of agricultural and food systems (Bennett et al., 2020; Stephens et al., 2020). Under these circumstances, the present study was undertaken to study the impact of COVID-19 related lockdown and restrictions and their cascading effect on the shrimp value chain, from the perspective of stakeholders. This study intends to bring out suggestions for interventions that could contribute to developing mitigation measures and policy responses for the resilience of the shrimp farming sector in India.
Garrett's ranking technique was employed to find out the critical constraints faced by the shrimp hatcheries and processors. It was calculated as percentage score and the scale value was obtained by applying Scale Conversion Table given by Garret and Woodworth (1969). The percentage score is calculated using the following formula:Percentage score=−100Rij–0.5Njwhere,
Rij = Rank given for ith item by jth individual.
Nj = Number of items ranked by jth individual.
For each constraint, the scores of individual respondents were added and divided by the total number of respondents. These mean scores for all the constraints were ranked in order to identify the critical constraints.
The constraints experienced by shrimp farmers and the overall critical impact of COVID-19 lockdown on the sector as a whole were analyzed using the Rank Based Quotient (RBQ) analysis to explain the order of severity. The important constraints reported were ranked as per their severity and the RBQ for each constraint was calculated using the formula proposed by Sabarathnam and Vennila (1996) which is widely adopted in agriculture and allied sectors (Katole et al., 2015; Bandara et al., 2016; Rimiki et al., 2017).RBQ=−ΣFin+1−iNn×100where in
Fi = Number of respondents reporting a particular problem under ith rank.
N = Number of Respondents.
i = Number of ranks.
n = Number of constraints identified.
The impact of COVID-19 lock down on shrimp hatcheries is given in the form of Garret ranking mean score in Fig. 2
. Manpower shortage (65.33) and non-availability of skilled technicians (48.11) at shrimp hatcheries due to restrictions in the movement were ranked as severe constraints followed by insufficient SPF brood stock availability (46.78) and lack of transport facilities to distribute the seed across the farming regions which together adversely affected the hatcheries. Similar views were reported in other media (https://www.undercurrentnews.com/2020/04/02/indian-hatcheries-hit-by-virus-lockdown/). It was reported that quarantine measures were severely affecting the labour availability for critical farming operations and the timing of labour needs is often inflexible for seasonally produced foods (Stephens et al., 2020).
There were two scenarios extracted based on the data collected and validated with key informants. In the first scenario, wherein, the seed produced by the shrimp hatcheries prior to the lockdown which should have been ideally sold to farmers during the first week post- lockdown could not be sold due to total disruption in transportation, uncertainty and non-availability of workforce. Since holding ready to sale shrimp post larvae (PL) for longer periods was uneconomical for the hatchery and with anticipated no improvement in demand, transportation and future prospects, most of the shrimp hatcheries discarded the available seed stock. Most importantly, a section of farmers being aware of the pandemic situation in other countries during the beginning of the year itself and anticipating a fall in prices due to weakening export demand in these countries, were not keen on stocking shrimp even prior to lockdown. Further, the farmers in the northern states (Odisha, Gujarat and West Bengal) and 30% of farmers in Andhra Pradesh and Tamil Nadu states where stocking of shrimp seed was scheduled for the end of March to mid-April did not do so. This was owing to the uncertainties in the availability of other inputs, manpower and expected slump in shrimp prices due to forecast of poor demand in the international markets by trading houses.
In the second scenario, farmers who had a standing stock during the lockdown resorted to ‘panic harvesting’ of small-sized shrimps and sold them for lower prices to avoid the massive financial losses. This interruption in the staggered harvesting and restocking might lead to a spike in seed demand immediately after the relaxation of the lockdown. However, due to disruption in international air cargo movement, the import of SPF brood stock was temporarily suspended, and the hatcheries did not have adequate brood stock to meet the increasing demand for seed. During the initial days of this crisis in India, most of the airlines had stopped their operations and even the commercial cargo flights had vastly decreased their freight capacity for agricultural goods, which had caused disruptions in the global supply chain. Ivanov (2020) reported that the agri-food sector is highly connected internationally. Hence the reduction in international cargos can severely disrupt the shrimp value chain across the world. Therefore, the reduced local demand and lack of SPF brood stocks for sustaining seed production severely impacted the shrimp hatcheries. Further, the exodus of the migrant labour employed as technical hands in the large-scale hatcheries, coupled with the inability to source new labour due to movement restrictions, severely affected the performance of the hatcheries resulted drop in seed production (Fig. 2).
Shrimp farming has two major seasons in India viz., summer crop (March–April to June–July) and the winter crop (July–August to November–December). The summer crop happens to be the major contributor (60%) to the Indian shrimp production and unfortunately the lockdown coincided with the main cropping season. The farming scenario during lockdown revealed a mixed picture. About 27% of farmers who had prepared their ponds for stocking did not do so because of the difficulty in obtaining quality seed, uncertainty over continuous supply of other inputs and the unpredictable market conditions. About 25% of the farms were in Phase-I with less than 30 days of culture (DoC), 34% were in phase-II with 30 to 80 DoC, and about 14% were in the category above 80 DoC (Phase-III). The DoC reflected the financial impact on the farmer, wherein farmers in phase I and II may not, realize their investment, while those in phase III, could make break even or get small profits albeit with production risks and increased expenditure as highlighted by the FAO (2020a).
The constraints experienced by the shrimp farmers during the lockdown are detailed in Table 1
. Access to processors for marketing and transportation of harvested shrimp were flagged as severe constraints with RBQ scores of 86.31 and 82.86, respectively. Similarly, access to diagnostic labs (80.71) and post-harvest handling materials (78.45) were the other major constraints. Anticipating a further drop in prices and worsening market conditions, around 50% of the farmers who had a standing crop with small and medium-sized shrimps decided for harvest and make a “distress sale” (forced to sell for lower price). But they even couldn't do that due to inadequate access to insulated trucks, skilled workforce, ice and seafood processors at the right time, which all were reported to be the major constraints faced by farmers. Bennett et al. (2020) reported such a similar scenario that farmers experienced as ‘twin disaster’, which was characterized by reduced demand and attendant collapse of prices during the pandemic.
Screening of water and soil samples at weekly intervals is a vital prerequisite to manage the parameters optimum and this has a direct bearing on the health of the farmed shrimp. Access to the diagnostic laboratories for such regular screening was a severe constraint due to movement restriction. In case of feed production and supply, barring the minor glitches during the first week of the lockdown the feed mills resumed their production. However, the issues related to labour and logistics hindered the timely supply of feed. Feed production was driven by the demand from farming operations. Therefore, a significant reduction in the farming area led to the scaling down of feed production.
Though the Government relaxed the restriction on the movement of aquaculture inputs and services for farming activities by classifying it under “essential activity”, the access to machinery and their parts required for farming operations were severely affected. Shrimp farms in Gujarat, Maharashtra and Andhra Pradesh states were mostly manned by migrant labourers from eastern parts of India hence the reverse migration of these labourers to their home states created a labour vacuum affecting the farming operations. Schmidhuber et al. (2020) reported that labour availability for agricultural supply chains has become a near ubiquitous problem, such deficits are caused by domestic labour supply disruptions, as well as by shortages of seasonal and migrant workers. Taking a cue from the evolving market conditions, when farmers from these states eventually planned for stocking, availability of migrant labourers were a major constraint due to the nationwide lockdown.
The challenges faced by the shrimp processors are given in the Fig. 3
. Shortage of manpower was reported as the major constraint by 75% of the processors. The majority of the skilled workers employed in processing plants are migrant workers who went back to their native places during the initial days of the lockdown and did not return to work. Social distancing and movement restrictions by the community are severely affecting labour availability for key time critical operations (Stephens et al., 2020) and shortages of seasonal and migrant workers (FAO, 2020b; Schmidhuber et al., 2020). Harvesting and post-harvest handling of shrimps was usually done by skilled fishers, and their absence led to poor handling of shrimps at farms and a drop in the quality of shrimps harvested. Similar situations have been reported from the agriculture and animal husbandry sector, where agricultural production, meat and dairy products have been adversely affected by the pandemic induced labour shortages (FAO, 2020b). To provide policy support to the farmers, the state Government of Andhra Pradesh negotiated with the Seafood Exporters Association of India and assured a minimum procurement price for different sizes of the harvested shrimps (Table 2
) (Undercurrent News Dt. 1/5/2020, 2020). However, 67% of the respondents reported that the processors refused to pay the price fixed by the Government, citing the poor quality of harvested shrimp.
Inadequate quantity of raw material (harvested shrimp) to run the processing facility, non-availability of desired size quality shrimp, lack of export orders and insufficient storage facility with small scale buyers were constraints reported by 65, 56, 54 and 31% respectively of the processor respondents. Moreover, processors were battling a period of low demand due to weakening economic situations in the importing countries, resulting in accumulation of unsold inventory filling the cold storage limits, thus hampering further procurement. Closure of local markets due to lock down and absence of cold storage space with local buyers further strained the marketing and distribution system. The sudden nature and severity of the lockdown left little scope for identifying suitable domestic substitutes in the short term but may spur less reliance on global agri-food value chains in the future (FAO, 2020b; Stephens et al., 2020; Schmidhuber et al., 2020).
The overall impact and economic loss were estimated based on the responses of the stakeholders irrespective of their affiliation. The results related disruptions adversely affected the shrimp aquaculture sector to the extent of 30–40% in economic terms (Fig. 4
). Most of the respondents (85%) opined that the expected decline in shrimp export performance to the major importing nations whose economies were also severely affected was a major impact. This may be due to the reduction of farming area and production, as expressed by 81% of respondents. Therefore, it is expected that farmed shrimp production and export could decline by 40% compared to the previous year (Fig. 5
). About 75% of the respondents predicted that the shrimp market price in the current season would be reduced by more than 35%. The loss of employment for the workers during the season was 30–40%, as reported by 67% of the respondents. The shrimp supply chain is heavily dependent on diversely skilled labour. It offers wide range of jobs opportunities, such as farm management, technical help at hatcheries, farms and processing units, personnel for manufacturing and marketing of inputs, wholesale and retail businesses, workers to operate farm machinery, vehicles, civil works, plumbing, mechanical and electrical equipment.
Labourers from the local villages also could not attend work due to movement restrictions and in-house migrant workers went home due to fear of infection and lack of salary assurance and subsistence from the employers. The aquaculture labourers were non-organized and with the loss of their employment do not have social protections as reported elsewhere (Harper et al., 2020). The sealing of state and district borders and restrictions on day to day movement of people affected their access to work places causing huge loss of employment and income. Similar views were expressed by international organizations and institutions (Bennett et al., 2020; FAO, 2020b; International Monetary Fund (IMF), 2020; Schmidhuber et al., 2020; Stephens et al., 2020). As a whole, this study estimated a probable loss of about 40% to the Indian shrimp sector in each component, the total loss in value terms being 1.50 billion USD (Table 3
). However, the impact in each component as well as the overall economic loss would be much higher than that projected, if the lockdown and other restrictions continue in the next cropping season.
The Governments both at the national and state levels took instant remedial measures like notifying aquaculture as an essential activity thereby easing the restrictions for the movement of inputs and people, fixing a minimum procurement price for the farmed shrimp and opening departmental retail outlets etc. However, the implementation of these mitigation measures at the ground level need additional efforts and follow-up using the government mechanism. In addition, the Government of India has announced a major scheme, the Prime Minister Fisheries Development Scheme (Pradhan Mantri Matsya Sampada Yojana-PMMSY) for facilitating a ‘Blue Revolution’ by leapfrogging aquaculture production. The PMMSY envisages harnessing the fisheries potential through various measures such as strengthening value chain, measures for doubling the income, employment generation, economic and social security for fish farmers adhering to sustainability principles. The outlay for the scheme is Rs.20,050 crores (approx.267 Million USD) with a plan to implement it over a five year period from 2020–21 to 2024–25 in all the States/Union Territories of India. Further, based on the results of the present study, short and medium-term measures have been suggested to minimize the adverse impact of the pandemic and similar unforeseen risks in future (Table 4
). It is important that stakeholders of different segments need to communicate frequently and work together with the government departments to develop essential policies to ensure sustainable shrimp aquaculture in the country.
This sectoral assessment has clearly indicated that COVID-19 lockdown and subsequent disruptions in the supply chain movements adversely impacted the activities in shrimp aquaculture sector and led to a direct economic loss to its different stakeholders. India's dependence on the exotic SPF vannamei brood stock from overseas suppliers will lead to a long-term impact if the embargo on international cargo movements continues. Further, restrictions which forced the skilled and farmworkers to be confined at home and in-house migratory workers to leave for their homes, negatively affected all the components of the sector and their livelihood. The Indian shrimp industry would incur an approximate economic loss to the tune of 1.50 billion USD for this year alone. Farmers and hatchery operators are looking for massive relief packages from the government to minimize the negative economic impact and sustain this dynamic agribusiness sector which earned a foreign exchange of 5.0 billion USD for the country last year. This investigation has provided an initial assessment of the pandemic based on the stakeholder's perspective. However, the situation is dynamic and further follow-up assessments at the state and national levels may be required to fully understand the impact that this pandemic has had on Indian shrimp aquaculture sector.
I have revised the manuscript as per the comments of the reviewers and responses to the reviewers' comments are also enclosed. The revised manuscript alongwith the enclosures is submitted herewith for your kind consideration.

Mohan, 2020


Undercurrent News Dt. 2/4/2020, 2020

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Aquaculture
PMC7800136,Management of Cardiogenic Shock During COVID-19: The IHVI Experience,"In 2017, the Inova Heart and Vascular Institute (IHVI) in Falls Church, Virginia implemented a systemwide cardiogenic shock (CS) initiative using a “one-call” activation and management system (1). Our program has emphasized early CS recognition and has used a standardized treatment algorithm, multidisciplinary decision making, and selective use of mechanical circulatory support (MCS) tailored to shock severity and phenotype. This approach improved access to care and has been associated with increased survival for patients presenting at our hospital and at 34 regional transferring facilities (1). From its inception, our policy has been to accept all CS transfers in the absence of compelling contraindications.
The recent coronavirus disease 2019 (COVID-19) pandemic significantly affected our CS team’s care processes. Anticipating a strain on finite resources, we recalibrated our program to optimize outcomes while ensuring patient and staff safety and managing resource capacity (2). The following 5 measures were enacted: 1) universal rapid testing to identify COVID-19–positive patients with CS at the time of index presentation to the health care system; 2) real-time intensive care unit (ICU), ventilator, and MCS capacity dashboards; 3) standardized donning and doffing protocols for personal protective equipment (PPE) according to the recommendations of the Centers for Disease Control and Prevention; 4) daily systemwide dissemination of resource availability; and 5) modification of our CS transfer policy to be more restrictive toward accepting patients when critical care resources were limited.
To expedite the cohorting of patients with COVID-19 in our rapidly expanded negative-pressure ICU beds, COVID-19 status was determined, whenever possible, during the initial CS activation call. An ICU capacity dashboard provided updates on the number and location of available ICU beds, negative-pressure–ventilated rooms, mechanical ventilators, MCS devices, and ICU staffing. All CS activations were reviewed by our multidisciplinary team, and decisions were rendered on a case-by-case basis, taking into consideration IHVI resources, medical futility, and the perceived ability to provide care at the current location (with ongoing support from IHVI). At the pandemic’s peak, this resulted in fewer transfers being accepted, with transferring centers forced to manage more patients with CS within their own facilities. To support our referral centers, our CS team provided enhanced remote consultative support with more frequent communication and technical guidance.
From March 1 to June 30, 2020, 7,809 patients were tested for suspected COVID-19 at our hospital. Of these, 3,096 patients tested positive for the virus, and 1,468 required hospitalization at IHVI. To the best of our knowledge, there were no cases of transmission from patients to health care providers. Compared with the same period in 2019 (Table 1
), there were fewer CS activations (67 vs. 93) and a higher proportion of transfer patients declined (42% vs. 11%; p < 0.001). The in-hospital survival of declined transfer patients was numerically less than those accepted for transfer (47% vs. 67%; p < 0.098). In addition, patients with CS who were treated during the pandemic presented with greater hemometabolic acuity (Table 1). Despite this, MCS use and in-hospital survival were comparable to the previous year. Consistent with national and international trends (3,4), we experienced a significant decline (∼25%) in the number of patients treated for ST-segment elevation myocardial infarction and an increase in mechanical complications resulting from late presentations (4 acute ventricular septal defects in 2020 vs. 1 in 2019). Data were obtained by retrospective review of electronic medical records under previously obtained internal Institutional Review Board approval.
In summary, the COVID-19 pandemic substantially disrupted IHVI’s established regional system of care delivery for CS. Acute shortages in resources resulted in fewer accepted transfers. We also noted a shift toward higher patient acuity during this time. Although IHVI’s CS survival rates remained favorable, mortality was high for those patients declined for transfer. Our PPE policy appeared to be effective at preventing patient-to-staff virus transmission. The 5 key interventions noted earlier were instrumental in allowing our program to assess, adjust, and adapt in real time to the crisis. Although primarily descriptive, these observations may inform future strategies aimed at optimizing access, resources, and outcomes for patients with CS who are treated within regional systems of care affected by a worldwide pandemic.",J Am Coll Cardiol
PMC7800141,Cardiovascular Deaths During the COVID-19 Pandemic in the United States,"Weekly death data were obtained from the National Center for Health Statistics (Centers for Disease Control and Prevention) for January through June 2020, as well as for the same weeks during the preceding year (2019) (10). International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10) codes were then used to identify underlying causes of death caused by ischemic heart disease (I20–I25), heart failure (I50), hypertensive diseases (I10–I15), cerebrovascular disease (I60–I69), and other disease of the circulatory system (I00–I09, I26–I49, I51, I52, I70–I99) (11). As we sought to examine the potential indirect effect of the pandemic, deaths with an underlying cause of COVID-19 were excluded from the analysis (10). Data on state populations from the 2018 American Community Survey files were used to calculate mortality rates.
Our initial analysis included all states (and District of Columbia) in the United States. We then focused on areas that experienced early surges in COVID-19 cases: New York (excluding New York City), New York City, New Jersey, Massachusetts, Louisiana, Michigan, and Illinois. We considered the “pre-pandemic” period to be the first 11 weeks in 2020 (January 1 to March 17), and the “pandemic” period to be the subsequent 11 weeks of 2020 (March 18 to June 2). The start of the pandemic period was determined based on when states began to experience rapid rises in reported cases of COVID-19 and issued stay-at-home orders (over the third and fourth weeks of March). We constructed corresponding periods of an identical duration from January to June in 2019 to serve as a historical control.
For each state/city, we calculated weekly death rates (per 100,000 population) for each cardiovascular cause of death for January through June 2020 (pandemic year), as well as for the corresponding weeks in 2019 (nonpandemic “control” year). Next, we fit a Poisson regression model to compare death rates during the 11-week pandemic period to the 11-week pre-pandemic period in 2020. We used a similar approach to compare mortality rates during the same 11-week periods in 2019. We then calculated the ratio of the relative change in death rates in 2020 versus the relative change in death rates 2019. This approach allowed us to estimate the increase in deaths due to cardiovascular causes that were attributable to the pandemic, compared with a historical baseline, while accounting for seasonal variation in deaths. The 95% confidence interval (CI) for all values was constructed with the dispersion parameter estimated by deviance.
Statistical analyses were performed using SAS 9.4 (SAS Inc., Cary, North Carolina) and figures were created using R version 4.0.2 (R Foundation, Vienna, Austria). Institutional review board approval from Beth Israel Deaconess Medical Center was not sought because of the use of publicly available deidentified data, per usual institutional policy.
In the United States, there was a total of 397,042 deaths caused by ischemic heart disease, heart failure, hypertensive disease, cerebrovascular disease, and other diseases of the circulatory system through June 2, 2020. Of these, 199,311 occurred during the pre-pandemic period (January 1, 2020, to March 17, 2020), and 197,731 occurred during the pandemic period (March 18, 2020, to June 2, 2020). Across the 6 most affected states, there was a total of 85,262 deaths, 39,053 of which occurred during the pre-pandemic period and 46,209 of which occurred during the pandemic period. Weekly mortality rates (per 100,000 population) by cause of death in the United States in 2020, compared with the same period in 2019, are shown in the Central Illustration
and Supplemental Table 1. Weekly mortality rates by cause of death for each of the seven jurisdictions are shown in Figure 1
and Supplemental Table 2.
There was a nationwide increase in deaths caused by ischemic heart disease after the onset of the pandemic in 2020, compared with changes over the same period in 2019 (ratio of the relative change in deaths per 100,000 in 2020 vs. the relative change in 2019: 1.11; 95% CI: 1.04 to 1.18) (Table 1
). A similar increase was observed for deaths caused by hypertensive disease (1.17; 95% CI: 1.09 to 1.26) but not for heart failure (0.97; 95% CI: 0.92 to 1.01), cerebrovascular disease (1.03; 95% CI: 0.99 to 1.07), or other diseases of the circulatory system (0.99; 95% CI: 0.95 to 1.04).
New York City experienced the largest relative increase in deaths caused by ischemic heart disease (ratio of the relative change in deaths per 100,000 in 2020 vs. the relative change in 2019: 2.39; 95% CI: 1.39 to 4.09) during the pandemic, compared with baseline changes in 2019 (Table 2
). A more modest increase in deaths caused by ischemic heart disease was seen in the remainder of New York State (1.44; 95% CI: 1.16 to 1.79), New Jersey (1.45; 95% CI: 1.22 to 1.73), Michigan (1.23; 95% CI: 1.07 to 1.41), and Illinois (1.11; 95% CI: 1.04 to 1.19) but not in Massachusetts or Louisiana. There were also relative increases in deaths caused by hypertensive diseases after the onset of the pandemic in New York City (2.64; 95% CI: 1.52 to 4.56), the remainder of New York State (1.28; 95% CI: 1.06 to 1.55), New Jersey (1.88; 95% CI: 1.38 to 2.57), Michigan (1.16; 95% CI: 1.00 to 1.35), and Illinois (1.30; 95% CI: 1.12 to 1.51). New Jersey was the only state that experienced a rise in deaths caused by cerebrovascular disease (1.28; 95% CI: 1.09 to 1.51), and New York City was the only jurisdiction where there was a rise in deaths caused by other diseases of the circulatory system (1.65; 95% CI: 1.20 to 2.27). In contrast, deaths caused by heart failure did not increase in any state.
First, our analysis was based on provisional data from the Centers for Disease control and Prevention (CDC), which may be incomplete in recent weeks owing to reporting delays. We only analyzed data through June 2, to minimize the effect of reporting delays. Second, our analysis only included underlying causes of death caused by cardiovascular diseases, but it is possible that COVID-19 may have been a contributing cause of death. However, the CDC reports that for the majority of deaths (95%) for which COVID-19 is reported on the death certificate, COVID-19 is selected as an underlying cause (11); these deaths were excluded from our analysis. Third, we lacked a contemporaneous control group, but used data during corresponding weeks of the most recent year (2019) as a historical control to quantify increases in deaths attributable to the onset of the pandemic in the United States. Fourth, individual-level demographic data for cardiovascular deaths were not made publicly available by the CDC and require further study, particularly given evidence of significant racial/ethnic and socioeconomic disparities in deaths during the pandemic (25, 26, 27).
Deaths caused by ischemic heart disease and hypertensive diseases increased during the COVID-19 pandemic, particularly in areas that experienced the initial surge of cases in the United States. Our findings suggest that the pandemic may have had an indirect toll on patients with cardiovascular disease, possibly owing to the avoidance of hospitals because of concerns about exposure to the virus, increased strain on health care systems, and deferred outpatient and procedural care. These patterns may also, in part, reflect the cardiovascular sequelae of undiagnosed COVID-19. Further study is needed to clarify the relative extent to which these different mechanisms have contributed to the rise in cardiovascular deaths. As COVID-19 cases surge in different regions of the United States, public health officials and policymakers should improve public health messaging to encourage patients with acute conditions to seek medical care and expand health care system resources to mitigate the indirect effects of the pandemic.Perspectives
COMPETENCY IN MEDICAL KNOWLEDGE: During the COVID-19 pandemic in the United States, there has been a marked increase in deaths caused by ischemic heart disease and hypertensive diseases.
TRANSLATIONAL OUTLOOK: Further study is needed to clarify the extent to which avoidance of hospital-based treatment because of concern about exposure to the virus, deferred outpatient and procedural care, strain imposed on health care systems, and the cardiovascular sequelae of undiagnosed COVID-19 contributed to the rise in cardiovascular deaths.

Dr. Wadhera has received research support from the National Heart, Lung, and Blood Institute (grant K23HL148525-1) at the National Institutes of Health; and has previously served as a consultant for Regeneron, outside the submitted work. Dr. Yeh has received research support from the National Heart, Lung, and Blood Institute (R01HL136708) and the Richard A. and Susan F. Smith Center for Outcomes Research in Cardiology; has received personal fees from Biosense Webster; and has received grants and personal fees from Abbott Vascular, AstraZeneca, Boston Scientific, and Medtronic, outside the submitted work. All other authors have reported that they have no relationships relevant to the contents of this paper to disclose.",J Am Coll Cardiol
PMC7774554,Aspergillosis Complicating Severe Coronavirus Disease,"Cases of CAPA were identified during March–June 2020 at Johns Hopkins University (Baltimore, MD, USA) and Hospital Clinic of Barcelona (Barcelona, Spain) by review of microbiologic and infectious diseases consult data, with approval of the institutional review boards of both institutions. Cases were defined as recovery of Aspergillus species from respiratory fluids (tracheobronchial secretions, sputum, bronchoalveolar lavage [BAL]) or positive (index ≥1) serum or BAL markers, identified with work-up for possible secondary pneumonia, typically clinically indicated with new fever or respiratory decompensation with new focal infiltrates on chest radiograph or computed tomography (CT) scan. Results for a Fungitell β-d Glucan Assay (https://www.fungitell.com) were reported when available but did not suffice to establish case diagnosis; 60 pg/mL was considered intermediate and ≥80 pg/mL was considered positive. Neither center used PCR-based testing for fungal infections during this period. Charts were reviewed to summarize demographic, clinical, and outcomes data, including day of hospitalization and ICU admission relative to reported onset of symptoms. World Health Organization (WHO) ordinal scale scores (0–8) at diagnosis of CAPA were estimated (46).
We calculated descriptive statistics for all data. These values are shown as frequencies, means (±SD), medians (with ranges), and proportions.
Patient-level data were compiled in cases recognized before June 2020 at Johns Hopkins Medical Center and Hospital Clinic of Barcelona (Table). Demographics mirrored those described for poor overall outcomes; advanced age and underlying diseases of hypertension and pulmonary disease predominated. Two patients had an underlying immunosuppressive disease. The most common immunosuppressing agents associated with CAPA included systemic or inhaled steroids, most frequently for adjunctive management of COVID-19 related inflammatory disease. CAPA was recognized a median of 11 days after symptom onset and 9 days after ICU admission. Most of these patients were hospitalized during stages characterized by inflammation or acute respiratory distress syndrome or afterwards, with lung injury, in the ICU and required respiratory support. Thus, WHO ordinal classifications at CAPA diagnoses were ≥5 (46).
In cases for which CT scans were performed, radiographic reports generally described a mixture of findings attributable to the virus (ground glass opacities and crazy-paving), findings consistent with airway inflammation and mucous plugging (bronchiectasis, airway wall thickening and irregularity, bronchiectasis), and radiographic findings consistent with airway-invasive disease (consolidations, tree-in-bud nodules) (Table; Figure 1). In some cases, larger nodules with necrosis and cavitation were noted. Although nodular necrosis with cavitation was described, no radiographic reports highlighted findings that are classically associated with angioinvasive disease (ground glass attenuation described as halos) (47).
Bronchoscopy was rare, and diagnosis was most frequently supported by tracheal aspirate culture; few patients had positive serum biomarkers. Seventeen (85%) cases were identified by positive culture; most (12/17, 71%) were identified by detection of A. fumigatus. Although rarely used, results of Fungitell β-d glucan assays were more frequently positive compared with serum galactomannan assays. All but 2 patients were given intravenous antifungal drugs, which included voriconazole, posaconazole, or liposomal amphotericin B. One patient (#2) was not treated for findings of a nodule and positive serum galactomannan result, was extubated, and survived. Another patient (#12) had diagnosis of CAPA established 1 day before death and never received antifungal therapy.
Evidence of secondary aspergillosis developing in persons infected with severe acute respiratory syndrome coronavirus 2 was first evident in China but emphasized more clearly by case series from Europe. We provide a timeline of studies describing secondary aspergillosis occurring in persons with COVID-19, an entity that has become referred to CAPA (Figure 2) (23–45). Early reports from China noted frequent CT findings suggestive of invasive aspergillosis but provided few microbiologic or clinical details. Although without specific citation, a US Department of Defense document on COVID-19 noted that there were anecdotal communications of invasive aspergillosis documented in postmortem examinations in China (23). Use of empirical antifungal drugs was frequent; in a large study evaluating risk factors for death, »50% of persons had secondary infections, and antifungal therapy was administered in 22% (21,22). Radiographic descriptions were suggestive of invasive disease; in a study describing radiography in 51 patients, 11 (22%) had nodules with halos or reverse halos (20). Without manifestations of patient-specific data, these cohort studies nonetheless indicated that there were substantial issues with secondary fungal infections in persons who had WHO stage II–III disease. In a study from China that evaluated outcomes of persons who had increased levels of serum interleukin 6, mixed fungal infections occurred in 27.1% of 48 critically ill patients (24). In another study from China, Aspergillus species were recovered from respiratory fluids in 14% of COVID-19 patients (24).
Patient-level descriptions emerged quickly in small case series from Europe. In the first case series from Europe for COVID-19, a total of 1 of 5 patients had alveolar infiltrates on chest radiograph and Aspergillus spp. cultured from tracheal aspirate (25). Thereafter, rapid reports from centers in Austria, Belgium, France, Germany, the Netherlands, and Italy emerged (Figure 2). Differences in diagnostic methods and case definitions generated a wide degree of variability, and incidences ranged from 3.8% to 34% of persons admitted to ICUs (24–45). One center in China reported rates based on the denominator of persons hospitalized because of COVID-19 and that CAPA developed in 7% of 104 patients who had CAPA (33). Bronchoscopy was variably and infrequently performed, but frequent positive results for lavage culture, galactomannan, and Aspergillus PCR were observed, and there was visual presence of thick mucoid secretions, sometimes with evidence of bronchial inflammation, such as ulcers (33). Using multivariable analysis, Wang et al. reported that advanced age, chronic lung disease, previous positive results for the β-d glucan assay, antimicrobial drug exposure, and mechanical ventilation to be risks for CAPA in persons who had COVID-19 (33). Histopathologic evidence of fungal invasion has been noted in some, but not all, patients who met CAPA definitions by airway culture or lavage galactomannan and underwent lung biopsy or autopsy (32,38,42). CAPA caused by an azole-resistant A. fumigatus isolate was first described in the Netherlands and then in the United Kingdom and France (34–36).
Results of 3 studies that used a prospective design provided the most accurate estimates of incidence, timing, and clinical usefulness. A prospective, multicenter study that used screening with serum biomarkers and bronchoscopy for 108 mechanically ventilated patients in Italy reported that 30 (27.7%) persons met CAPA criteria (median of 4 days after ICU admission and 14 days after COVID-19 diagnosis) (38). Higher mortality rates were noted for CAPA patients than for controls; there were trends to improved survival and decreased follow-up galactomannan levels after antifungal therapy. Another study from the Netherlands applied nondirected BAL by using a closed-circuit suction catheter at a median of 2 days (range 0–8 days) after mechanical ventilation and reported 9/42 (21.4%) patients met criteria for CAPA on the basis of culture or galactomannan BAL positivity; patients with CAPA had longer duration of ICU admission (41). Finally, another prospective study that used enhanced screening with blood and respiratory samples, antigen assays (galactomannan enzyme immunoassay [GM EIA] and β-d glucan assay), and an Aspergillus PCR reported that 19/135 patients met diagnostic criteria for CAPA when concurrent radiographic abnormalities were considered (45).
Despite decades of case reporting and large cohort studies, many clinicians still fail to recognize that Aspergillus species can cause destructive inflammatory and invasive pathology in persons who have severe influenza, mistakenly ascribing culture results to benign airway colonization (18,19). With this in mind, the rapid recognition of CAPA, as described by reports from multiple centers (Figure 2), probably reflects previous learning and heightened awareness in centers in Europe and the clinical diligence that arises when encountering a new and unknown entity. We add 20 cases to the accumulating literature describing CAPA. Multiple pathophysiologic, clinical, and diagnostic considerations have emerged from observations reported to date.
First, pathophysiology of disease is distinct in this context, and not necessarily similar to invasive aspergillosis that occurs in classically immunosuppressed persons. Although it is broadly understood that Aspergillus species cause allergic manifestations, such as allergic bronchopulmonary aspergillosis, and a severe invasive pneumonia with potential angioinvasion, forms of chronic necrotizing or semiinvasive Aspergillus pulmonary disease are less well understood. These types of infections occur in persons who have more chronic immunosuppression, especially that related to prolonged steroids and chronic obstructive pulmonary disease. Common pathophysiology of these syndromes involves poor clearance of conidia, enabling bronchial inflammation and invasion, manifesting with distinct radiographic and clinical findings characteristic of airway invasion with slower development of necrosis, and exuberant and chronic tracheobronchitis, frequently with lack of angioinvasion, which limits performance of serum-based diagnostics (48). Mounting evidence suggests that severe respiratory virus infections, especially influenza and infection with severe acute respiratory syndrome coronavirus 2, can be complicated by Aspergillus airway overgrowth with pulmonary infection similarly characterized by mixed airway inflammation and bronchial invasion (Figure 3).
Distinguishing between benign airway colonization and potential disease caused by Aspergillus spp. has always been difficult because conidia are common inhabitants of airways and do not always cause inflammatory or invasive disease. To improve the process of obtaining information about what constitutes disease, early efforts have been directed toward standardizing diagnostics and definitions by using a similar approach, as for IAA, which eliminates the classic immunocompromising host criteria and relies on BAL and serum antigen results to define certainty of disease (49–51). Cases reported in this study would be considered probable CAPA if tracheal aspirate or sputum cultures met microbiologic criteria. Although more efforts are required to clarify definitions, clinicians should understand that definitions are not meant to provide clinical guidance, but to support a metric to compare epidemiology and clinical trial data. Three prospective cohort studies suggest that treatment with antifungal drugs might improve clinical outcomes (38,41,45), but definitive evidence of clinical usefulness necessitates larger comparative studies that use antifungal drugs for prevention or early therapy.
Most published studies suggest that CAPA occurs in »20%–30% of the most severely ill, mechanically ventilated COVID-19 patients (24–45). Perhaps the most accurate estimates of incidence emerged from 3 studies that deployed enhanced prospective screening and provided incidence estimates of 14%–20% and poor outcomes that might potentially be improved by use of antifungal therapy (38,41,45). Another study reported a particularly low rate of CAPA (3.8%) (40). Diagnostic differences probably contribute to variability in estimates.
Performance of diagnostic testing is variable depending on immunopathogenesis of disease. Persons who have extensive invasion into and beyond airways show positive serum GM EIA results more frequently than persons who had disease restricted to the endobronchial lumen. For this reason, sensitivity of the serum GM EIA assay is highest in hematology/oncology patients, ranging from 60% to 80%, but lower in ICU patients, estimated to be 30%–50% (48–52). In CAPA cases, serum GM EIAs have been infrequently positive. In our case series, results of β-d glucan assays were more frequently positive, but false-positive results would be anticipated because of to cross-reactivity (52). A prospective study reported a relatively large proportion of cases with positive results for β-d glucan assays for patients who had candidiasis (38). When applied to BAL, results for GM EIA appear positive more frequently, and some investigators reported potential utility of quantitative PCR or GM lateral flow tests in lavage (24–45). However, because none of these tests were developed and optimized for the nonhematology context, performance could be variable with different cutoff values.
Despite diagnostic limitations, several studies point to utility in routine use of fungal biomarkers and early screening in persons who have COVID-19, especially directed toward BAL. Lei et al. examined residual serum samples by using a β-d glucan assay and GM in 181 COVID-19 patients who had oxygen saturation <94% or respiratory rates >29 breaths/min, and reported positive results in the β-d glucan assay for 32 (17.7%) of 181 patients and positive results in the GM EIA for 14 (7.7%) of 181 patients sampled (53). In that study, most positive results occurred after 14 days of COVID-19 symptoms, which is consistent with the timing of recognized CAPA. Although their retrospective study was limited by lack of clinical and outcomes data, findings suggest that at least some cases might be identified by more aggressive use of a biomarker screening strategy. This suggestion was shown more definitively in prospective studies that evaluated BAL or lavage from a close-circuit system, with antifungal therapy applied for lavage GM EIA positivity potentially leading to improved outcomes (38,41,45). Deploying such a strategy might be limited in some centers by complexity of assays and difficulties in obtaining bronchoscopy because of viral infectivity.
Radiographic manifestations might be best understood when one considers that CAPA can be a constellation of mixed airway and invasive diseases. In our series and other reports, radiographic appearance varied from early evidence of airway inflammation and invasion (irregular airways to centrilobular nodules) to airway necrosis; this necrosis was most frequently characterized by cavitary nodules and progressive consolidation (33). Corresponding histopathology can be varied, including diffuse alveolar damage, with or without clear fungal invasion (32,43).
Although many questions linger, emerging evidence supports the conclusion that Aspergillus species cause mixed pathology in COVID-19 patients, ranging from airway inflammation to semiacute or acute bronchial invasion, similar, in most part, to that observed with severe influenza infections. Increased efforts are needed to determine the best ways to prevent, diagnose, and treat Aspergillus disease associated with COVID-19.",Emerg Infect Dis
PMC7781000,Electronic-Cigarette Use Alters Nasal Mucosal Immune Response to Live-attenuated Influenza Virus. A Clinical Trial,"We inoculated human volunteers with LAIV to examine the innate immune response to influenza infection. Participants recruited were healthy, young adults of 18–40 years of age and were categorized as nonsmokers, cigarette smokers, and e-cigarette users on the basis of self-reported tobacco-product use, smoking or vaping diaries, and biomarkers of exposure to nicotine and tobacco products (Table 1). Exclusion criteria included a history of allergic rhinitis, asthma, and use of immunosuppressive drugs, including corticosteroids, to reduce the possibility of confounders affecting the nasal mucosa. A sample size of ∼16 per group was targeted on the basis of power calculations using previous studies observing differences in smokers and nonsmokers (26, 27, 31). Inclusion criteria for the exposure categories were as follows: 1) nonsmokers were never-smokers, 2) cigarette smokers smoked at least three cigarettes per day on average, 3) e-cigarette users vaped at least 18 puffs per day on average and smoked fewer than five cigarettes per week. Most of the e-cigarette users recruited were former smokers and used mostly second- and third-generation devices. Participants entered into our protocol as shown in Figures 1 and 2.
During the initial screening visit, participants consented, were examined by a physician, and reported their health history, including tobacco-product use. If participants were cigarette smokers or e-cigarette users, they were given a smoking or vaping diary to complete for 3–4 weeks, after which they returned for their baseline visit, during which diaries were collected. At the baseline visit, participants were first examined by a physician, and then nasal lavage fluid (NLF), nasal epithelial-lining fluid (NELF), a nasal-scrape biopsy specimen obtained via nasal curettage (39), serum, and urine were collected. After baseline sample collection, participants were inoculated with a standard dose of the 2015–2016 or 2016–2017 LAIV vaccine (FluMist; MedImmune, AstraZeneca) within the standard influenza season, as described previously (31, 40, 41). Viral strains in the 2015–2016 vaccine included A/California/7/2009 (H1N1), A/Switzerland/9715293/2013 (H3N2), B/Phuket/3073/2013, and B/Brisbane/60/2008. Virus strains in the 2016–2017 vaccine included A/California/7/2009 (H1N1), A/Hong Kong/4801/2014 (H3N2), B/Brisbane/60/2008 (B/Victoria lineage), and B/Phuket/3073/2013 (B/Yamagata lineage). Participants returned on Days 1, 2, and 8 after inoculation, at which point NLF, NELF, and nasal-scrape biopsy specimens were again collected, as shown in Figure 2. The protocol was approved by the University of North Carolina at Chapel Hill Biomedical Institutional Review Board (13-2246), and all methods were performed in accordance with relevant guidelines and regulations. This study was also registered at clincaltrials.gov (NCT 02019745).
Levels of influenza-specific IgA in the NLF were measured using a direct-sandwich ELISA (see data supplement). Virus-specific IgA levels were determined against the IgA standard curve and normalized to total IgA levels (45). After normalization, the change in the antibody level was determined by using the relative percentage of the baseline level, in which the virus-specific antibody concentration post-LAIV inoculation was divided by pre-LAIV inoculation levels and multiplied by 100.
NLF analyses were completed after Shapiro-Wilk normality testing. A mixed-effects analysis with Fisher Least Significant Difference (LSD) was used for NLF cell markers of influenza viral-load analyses, a paired two-way ANOVA with Fisher LSD post hoc test was used for the influenza-specific IgA analysis, and a Kruskal-Wallis test with a Dunn post hoc test was used for the NELF analyses. A Brown-Forsythe and Welsh ANOVA were used for cytokine and chemokine NELF and NLF analyses. Analyses were completed in GraphPad Prism, and significance was determined to be present when P was less than 0.1, which was based on the use of clinical data with a relatively small N (41, 46).
Baseline effects of tobacco-product exposure were first determined by using linear regression comparing gene expression among tobacco-product exposure groups (e-cigarette users and cigarette users) and control subjects (healthy nonsmokers and nonusers).
Similar to the authors of previous studies measuring the effect of the LAIV and exposure to environmental toxicants (31, 41), we completed an a priori analysis of the dependent variable (LAIV response) calculated from the area under the curve (AUC) by using the pracma package in R (R Foundation for Statistical Computing; https://cran.r-project.org/web/packages/pracma/pracma.pdf) over the days of the study. Linear-regression analysis was then used to determine the relationship between LAIV response and tobacco-product exposure using the baseline-corrected AUC. Baseline correction was used because of significant variability in baseline gene expression among the comparison groups. Demographic covariates were included in a multiple regression as a secondary analysis, in which we identified an interaction of sex and tobacco-product exposure. All analyses were conducted using R (47). For all gene-expression analyses, statistical significance was determined to be present when P was less than 0.05 and the fold change was greater than |1.5| for baseline effects or when the percentage of change was greater than |150%| for effects of the baseline-corrected AUC.
The heatmap was created using the R pheatmap package (47, 48). Interaction networks and pathway-enrichment analyses were performed using STRING (STRING Consortium) (49). Interactions were determined using a confidence score ≥ 0.7. A Markov cluster algorithm was used to cluster genes significant for interaction with an inflation parameter of 1.5.
Subject demographics, cigarette use, and tobacco- and nicotine-specific biomarker data are described in Table 1. There were no differences among groups in terms of body mass index or age. As expected on the basis of results from the prescreening recruitment questionnaire, the number of cigarettes smoked per day was greater in cigarette smokers than in e-cigarette users; cigarette smokers also had higher tobacco-specific nitrosamine levels (NNAL/creatinine) in urine than nonsmokers and e-cigarette users, indicating little to no dual use in the e-cigarette group. Both cigarette smokers and e-cigarette users had higher serum cotinine levels than nonsmokers, as expected.
In an approach similar to that of our previous study (16), we analyzed the effect of tobacco use compared with nonuse on samples at baseline. We found 38 genes to be differentially expressed in the cigarette-smoking group and 3 genes to be differentially expressed in the e-cigarette group, with two genes (USP9Y, CD1A) common to both cigarette smokers and e-cigarette users and changed in the same direction (see Table E1 in the data supplement).
Influenza subunit genes from NLF cells were compared among exposure groups for differential expression but showed no significant effects of the tobacco-exposure group on viral load (Figure 3A). This result differs from those of our previous reports (31), which may be the result of a lower pack-year history or lower numbers of cigarettes smoked per day in our cohort compared with the ones previously studied.
Previous studies have shown that serum antibody levels are a poor measure of LAIV vaccine efficacy (50). In contrast, nasal mucosal secretory IgA, the predominant immunoglobulin produced in response to infection of the nasal mucosa, has been shown to be a much better indicator of LAIV-induced antibody responses (reviewed in Reference 45). We developed an anti–LAIV-IgA ELISA to determine the effects of cigarette smoking and e-cigarette use on antibody production and found that LAIV-specific IgA levels increased as expected in nonsmokers after LAIV inoculation but did not increase in e-cigarette users and cigarette smokers (Figure 3B). These results suggest an impaired humoral response to LAIV-induced IgA secretion in e-cigarette users.
Using nasal-scrape biopsy specimens obtained at baseline and on Day 1 and Day 8 after LAIV inoculation, we examined the effects of tobacco-product use on LAIV-induced gene-expression changes. Changes in LAIV-induced gene expression were assessed by calculating the AUC over the three analysis days and subtracting the baseline expression to adjust for interindividual variability. There were 191 differentially expressed genes in the e-cigarette–user group as compared with nonsmoker control subjects; 31 genes were upregulated, and 160 genes were downregulated (Figures 4A and 4B and Table E2). The top five upregulated genes in the e-cigarette exposure group by the percentage of change from nonsmokers included CD19, CKLF, BST1, GPI, and AKT3. The top five downregulated genes by the percentage of change from nonsmokers included MR1, NT5E, HRAS, CD55, and IL5RA. Eighty genes were differentially expressed in the cigarette-smoker group as compared with control subjects, 4 were upregulated, and 76 were downregulated. The upregulated genes included GPI, ANP32B, LAMP1, and MAVS. The top five downregulated genes by the percentage of change from nonsmokers included SMPD3, NOS2A, KLRB1, APP, and CXCL1. Fifty-two of the genes in both tobacco-exposure groups overlapped (Figure 4C), with all genes in both exposure groups being differentially expressed in the same direction, 50 genes being downregulated, and 2 genes being upregulated. GPI is one of the overlapping genes that was also one of the top differentially expressed genes in both the e-cigarette and cigarette exposure groups; in both cases, it was upregulated by over 4,000%.
Using NELF collected by using nasosorption, we measured cytokine levels at baseline and on Days 1, 2, and 8 after LAIV inoculation (Table E3). Similar to changes in gene expression, LAIV-induced changes in mediator levels were determined by calculating the AUC of the 4 analysis days. Chemokines regulating the recruitment and activation of monocytes (MCP-1, MIP-1β) were increased in cigarette smokers as compared with nonsmokers (Figures 5A and 5B). In contrast, cytokines regulating antiviral host-defense responses (IFNγ, IL-6, IL-12p40) were reduced in e-cigarette users but were not reduced in cigarette smokers, as compared with nonsmokers (Figures 5D–5F). Interestingly, IL-2, IL-1α, and VEGF were increased in e-cigarette users as compared with nonsmokers (Figures 5G–5I).
In our covariate analysis, we identified interactions between tobacco-use group and sex. One hundred and nineteen genes displayed an interaction between sex and tobacco-use group in response to LAIV (Table E4). A variety of pathways from the Kyoto Encyclopedia of Genes and Genomes were significantly enriched in this gene set, including cytokine–cytokine-receptor interaction, TLR (Toll-like receptor) signaling, inflammatory and infectious diseases, TNF signaling, and cell-adhesion–molecule pathways (the top 25 enriched pathways are reported in Table E5). Predictive clustering (Figure 6 and Table E6) resulted in five main clusters: IFN regulation–associated genes, including IFNL1, IFNAR1, IFIT2, IFI27, IRF2, and IRF5; chemokines and immune-signaling genes that are involved in chemotaxis and chemoattraction, including CX3CR1, CCL5, CCL20, CXCL12, CXCL1, CCL25, CCL28, and CXCL13; TNF regulation– and adaptive immunity–associated genes (T cell– and B cell–related genes), including TICAM1, TNFRSF11A, TNFRSF13C, TRAF3, TFRC, CD3D, CD86, CD1D, and CDK1; B cell– and B-cell antigen–related genes, including CD19, CD9, CD79A, and CD79B; and cell-death regulation genes, including BAX, BCL2L1, and BID. Because of the small N within sex, we were underpowered to complete sex-stratified analyses.
The purpose of this study was to test the hypothesis that e-cigarette use alters respiratory antiviral host-defense responses in humans. To test this hypothesis, we used our well-established model of influenza infection, nasal inoculation with LAIV, and compared host-defense responses in groups of e-cigarette users, cigarette smokers, and healthy nonsmoking and nonusing control subjects. Our results demonstrate that e-cigarette use did not appear to affect the markers of viral load tested but was associated with significantly altered LAIV-induced nasal mucosal immune-gene expression, immune-mediator release, and nasal LAIV-specific IgA levels. Similar to findings of our previous studies (16), changes in the expression of nasal immune genes were more abundant and greater in magnitude in e-cigarette users than in cigarette smokers. Furthermore, sex was a significant modifier of LAIV-induced immune-gene expression (Figure 6), suggesting that genes involved in IFN signaling and adaptive immune function (T- and B-cell function), are differentially modified in male and female e-cigarette users. Together, these data suggest that e-cigarette use alters nasal mucosal antibody production, gene expression, and protein production and thereby might alter respiratory antiviral host-defense function and immune memory. Demonstrations of causality would require longer-term studies of immunity and infection rates.
Although NLF for secretory IgA analysis was not collected at an ideal time point (8–9 d after infection rather than 14–21 d after infection), differences in production of LAIV-specific IgA were observed between groups. Nonsmoker LAIV-specific IgA levels increased after LAIV inoculation, whereas e-cigarette–user and cigarette-smoker levels did not, adding potential consequences for long-term memory responses. This identifies a potential effect of e-cigarette use on downstream immunity to infectious diseases and immune memory, which should be further explored. Considering that e-cigarette use is prevalent among teenagers who are recommended for complete immunization schedules, understanding whether and how vaping could modify vaccination-conferred immunity is an unexplored field. Secretory IgA is the principal antibody isotype present in nasal secretions (45) and neutralizes pathogens, like influenza, at the site of infection before they attach, enter, and replicate in the host cell (45). Although conventional intramuscularly administered influenza vaccines generate a serum IgG-antibody response, protection conferred by LAIV vaccination is believed to be derived by its ability to generate a robust and sustained nasal mucosal IgA response (51). Hence, although viral load was not affected by e-cigarette use, suggesting no difference in susceptibility to influenza viral infections, sustained immune-memory response and protection against reinfection may be suppressed by using e-cigarettes. Although it is unclear what levels of pathogen-specific IgA are needed in the nasal mucosa to indicate protection against subsequent infection, these data indicate that e-cigarette use suppresses the nasal mucosal antibody response.
The differential response to LAIV infection as a result of tobacco-product use was substantial, with a total of 219 genes differentially expressed in the nasal epithelium of e-cigarette users and cigarette smokers as compared with nonsmokers. Common in both e-cigarette users and cigarette smokers was the overwhelming downregulation of immune genes in response to LAIV. In addition, e-cigarette use was associated with a greater number of immune-gene expression changes than cigarette smoking when compared with nonsmokers in response to LAIV, suggesting a broader potential for disruption of host-defense functions in e-cigarette users than in cigarette smokers. Interestingly, 52 differentially expressed genes overlapped in both groups, altered in the same direction, indicating some common effects between groups. However, when compared on a gene-by-gene basis, e-cigarette users showed greater suppression of a majority of these genes (Figure 4C). Hence, e-cigarette use was associated with a greater number of immune-gene expression changes, and genes differentially expressed in both e-cigarette users and cigarette smokers showed greater suppression in e-cigarette users. These observations are similar to those of our previous study demonstrating that baseline immune-gene expression in the nasal epithelium of e-cigarette users indicated an overall immunosuppressive phenotype, which was marked by a greater number of differentially expressed genes than that shown in smokers (16).
Among the most downregulated genes in both e-cigarette users and cigarette smokers were APP, NUP107, and ITGB1, which have previously been identified as host factors regulating influenza viral infections (52). For example, APP encodes the Amyloid precursor protein, which can be broken down into smaller fragments, such as β-Amyloid, which in turn has been shown to inhibit influenza viral replication (53). Among the most upregulated genes in e-cigarette users after LAIV inoculation was CKLF, which encodes chemokine-like factor, a potent chemoattractant for neutrophils, monocytes, and lymphocytes, that has been associated with infiltration of inflammatory cells and pulmonary damage (54). One of the most downregulated genes in e-cigarette users after LAIV infection is NT5E, which encodes CD73, a surface ecto-5′-nucleotidase. Knockout mice demonstrate that lack of CD73 does not alter influenza-induced acute lung injury but is necessary for a proper innate antiviral immune response (55). In addition to broad, differential gene-expression changes in response to LAIV, cigarette smokers, e-cigarette users, and nonsmokers also differed significantly in their cytokine responses. Of the 28 cytokines analyzed, 9 were modified by tobacco-product exposure. Interestingly, chemokines regulating the recruitment and activation of monocytes were enhanced in cigarette smokers. In contrast, the cytokines IFNγ, IL-6, and IL-12p40, with known critical function during antiviral host-defense responses (56), including inducing immune memory (57), were decreased in e-cigarette users. Together, these biomarkers of immune response in the nasal epithelium after inoculation with LAIV suggest that e-cigarette use is associated with disrupted normal mucosal host-defense function.
A unique finding of this study is that sex and tobacco-product exposure interact to influence the host-defense response to LAIV, impacting 119 genes in our data set. Sex has been demonstrated as a significant modifier of viral infection and tobacco-product use individually but had yet to be shown as having an interactive effect. Sex is a known and substantial modifier of the response to viral infection because of physiological and anatomical differences between males and females (58). These differences affect antibody responses, viral clearance, vaccine efficacy, and levels of virus-induced inflammation, generally resulting in a more protective response to viral infection in females than in males (58–62). Interestingly, a similar interactive effect was observed in our previous study on wood-smoke exposure, emphasizing that sex and inhaled pollutants can more broadly interact to influence host-defense responses against viral infections (41). The five clusters significantly enriched in the sex–tobacco-exposure interactome include IFN regulation–associated genes (IFNL1, IL18, IFNAR1, IRF2, IRF5, IFI27, IFIT2), chemokine genes involved in attraction and activation of cells involved in immune memory (CXCL12, CXCL13, CCL28, CCL20), and genes involved in responses to pathogens (CD40, TICAM1, TLR7). The altered IFN-related genes are critical to the response to viral infection. Alteration of many of these innate immune genes likely affect recruitment and activation of pathways critical for mounting an adaptive response to a virus, especially by altering type 1 IFN, shown to induce B-cell activation and appropriate antibody responses (63). Similarly, alteration of the expression of genes actively involved in response to pathogens has been shown to impair outcomes of influenza and other viruses. For example, TLR7, which is a key pathogen-recognition receptor, has been shown to mediate natural-killer–cell activation and necessary IFNγ production after influenza infection (64). Altered expression of these critical host-defense genes were dependent on both sex and tobacco-exposure group, indicating that susceptibility to influenza differs by both factors. Although our N was not sufficient to complete sex-stratified analyses, this should be a strong focus of future work, especially because of recent male-biased susceptibility to emerging viral infections and further links to lifestyle factors such as smoking and vaping (65–67).
Previous research into the effects of e-cigarettes on immune function may give us insights into the role of specific e-cigarette components on the impaired host-defense response to LAIV infection observed here. We have previously demonstrated that e-cigarettes can suppress immune-gene expression and, particularly, that flavoring compounds can alter critical host-defense responses such as macrophage, neutrophil, and natural-killer–cell function; airway epithelial-cell ciliary motility; and mucin secretion (4, 5, 16–18, 68). Specifically, reactive flavoring chemicals, such as aldehydic flavoring chemicals, were shown to alter immune-cell functions critical to the response to pathogenic infection, such as phagocytosis and natural-killer–cell function (5, 17), and to compromise induction of adaptive immune responses via suppression of key innate immune-cell functions (69–71). Additional studies of chronic nicotine exposure and exposure to the e-cigarette components propylene glycol and vegetable glycerin have shown that these exposures affect the immune system and response to viral infections (72, 73). Although the number of participants in this study limited our ability to stratify by popular flavoring profiles, nicotine content, or other e-cigarette components to investigate their role in viral infection, uncovering how specific e-cigarette components modify antiviral host-defense function should be a target of future investigation.
This study, although novel and informative, does include limitations. This study was conducted from 2015 to 2017 and is thus most informative about the response to LAIV inoculation when use of second- and third-generation e-cigarette devices were most prominent and may not fully inform potential responses to newer devices or e-cigarette formulations (74–76). How the differences in devices, e-cigarette liquid formulations, and changes in aerosol deliveries affect the antiviral host-defense responses described here needs to be examined in future studies. Similarly, because of the time period in which this study was conducted, our e-cigarette–user participants were also mostly former smokers; thus, changes seen in this group may differ from the effects in younger e-cigarette users who are predominantly nonsmokers. However, based on our inclusion of both biomarkers of nicotine use (cotinine) and combusted tobacco (NNAL), our recruited e-cigarette users are not likely to have been substantial dual users. Specifically, in our study population, e-cigarette users had elevated levels of cotinine but not of NNAL, and smokers had elevated levels of both metabolites, indicating that e-cigarette users were not likely to have been dual users of e-cigarettes and conventional cigarettes. These results are consistent with previous findings in cohorts of e-cigarette users and cigarette smokers around the same timeframe (4, 16). Our sample-collection timeframe also limited our ability to analyze the ideal time for virus-specific secretory IgA, missing the class-switching peak by several days. Despite this limitation, we were able to detect increased LAIV-specific IgA levels in the NLF of nonsmokers, which was absent in both the e-cigarette–user and cigarette-smoker groups. Finally, although our analysis demonstrated a significant interaction between sex and tobacco-user group (Figure 6), our study was not sufficiently powered to stratify the different user groups by sex.
Overall, this study demonstrates that e-cigarette use is associated with significant suppression of host-defense responses in the context of experimental respiratory viral infections. Similar to data from previous studies published by us and others, our data further support the notion that e-cigarette use is associated with different effects on markers of mucosal immune responses as compared with smoking cigarettes and that e-cigarette use is not without harm (34, 77). These data also build on rodent work that demonstrated a connection between e-cigarette exposure and influenza-induced inflammation and tissue injury (73). However, population-based studies are needed to determine whether and to what extent the observations shown here are applicable to community-acquired respiratory infections. The data generated in this study suggest that e-cigarette use could increase the risk of suppressed host-defense functions in the context of respiratory viral infections. If so, this has important public health implications, especially during influenza season and respiratory-virus pandemics.",Am J Respir Cell Mol Biol
PMC7774536,Cellular Immunity in COVID-19 Convalescents with PCR-Confirmed Infection but with Undetectable SARS-CoV-2–Specific IgG,"We used a questionnaire to look for potential plasma donors who recovered from SARS-CoV-2 infection. The questionnaire addressed characteristics and additional parameters determining suitability as blood donor (Table). We received >550 questionnaires; 310 volunteers had had PCR-confirmed SARS-CoV-2 infection. We selected 78 volunteers (54 male, 24 female) who had PCR-confirmed SARS-CoV-2 infection as participants. Their median age was 47 years (19–66) years. We preferred donors who tested negative by a second SARS-CoV-2 PCR and had experience donating blood; we especially sought donors with the blood type AB (because they are universal plasma donors) and donors with a body weight >60 kg (because they can donate 3 units of convalescent plasma). We preferentially recruited those living in close vicinity to University Hospital Essen. Because we observed antibodies against human leukocyte antigens and human neutrophil antigens, which prohibited blood donation, mainly in female patients (n = 4), we preferred male donors, of whom 1 had these leukocyte antibodies. Only 4 of the participants received oxygen supplementation and none ventilator treatment. Of note, 39/78 participants were infected during skiing holidays. Unfortunately, radiograph and computed tomography data were not available; they are usually performed only for critically ill patients in Germany. Thus, our cohort is unique because it is biased toward especially healthy male blood donors with mild courses of COVID-19. We tested donor serum samples for IgG against the S1 protein of SARS-CoV-2 by ELISA. Furthermore, results of a standard neutralization assay were available in donors with negative or borderline antibody ratios.
In the negative control group we included 22 healthy participants (6 male, 16 female) who had no symptoms of SARS-CoV-2 infection and no household contact with infected patients since January 2020. Their median age was 48 years (range 28–60 years).
We determined IgG antibodies by a CE-marked Anti-SARS-CoV-2 IgG semiquantitative ELISA (Euroimmun, https://www.euroimmun.com), according to the manufacturer’s instructions. The ELISA plates were coated with recombinant SARS-CoV-2 spike protein (S1 domain). Serum samples were analyzed automatically at 1:100 dilution, using the Immunomat (Virion\Serion, https://www.virion-serion.de). Results are given as the ratio of patient sample/control sample). An antibody ratio of >1.1 was considered positive, of ≥0.8 to <1.1 borderline, and of <0.8 negative.
Vero E6 cells (ATCC CRL-1586, https://www.atcc.org) and SARS-CoV-2 virus were cultured as described by Heilingloh et al. (7). Neutralization capacity of serum samples was determined by endpoint dilution assay, expressed as 50% tissue culture infective dose (TCID50)/mL. Serial dilutions (1:20–1:2560) of serum samples were incubated with 100 TCID50 of SARS-CoV-2 for 1 h at 37°C and added afterwards to confluent Vero E6 cells cultured in 96-well microtiter plates. On day 3 after infection, the cells were stained with crystal violet (Roth, https://www.carlroth.com) and dissolved in 20% methanol (Merck, https://www.merck.com); we analyzed the appearance of cytopathic effects (CPE) by light microscopy. The neutralizing titer was defined as the reciprocal of the highest serum dilution at which no CPE breakthrough in any of the triplicate cultures was observed.
ELISpot stripes containing PVDF membranes (MilliporeSigma MultiScreen HTS; Fisher Scientific, https://www.fishersci.com) were activated with 50 µL of 35% ethanol for 10 s and washed with distilled water. Plates were then coated for 3 h with 60 µL of monoclonal antibodies against IFN-γ (10 µg/mL of clone 1-D1K; Mabtech, https://www.mabtech.com). Thereafter, ELISpot plates were washed and then blocked with 150 µL AIM-V (Thermo Fisher Scientific, https://www.thermofisher.com). After 30 min at 37°C, AIM-V was discarded and duplicates of 250,000 peripheral blood mononuclear cells (PBMC) were grown in the presence or absence of either PepTivator SARS-CoV-2 protein S1/S2 or membrane (M) protein (600 pmol/mL of each peptide; Miltenyi Biotec, https://www.miltenyibiotec.com) or an S1 protein (4 µg/mL; Sino Biologic, https://www.sinobiological.com) in 150 µL of AIM-V. The peptide mix (PepTivator) of the S1/S2 protein covered the immunodominant domains, the peptide mix of the M protein the complete sequence of the glycoprotein. The S1 protein was a recombinant protein expressed in (human) HEK293 cells (Appendix Figure 1). After 19 h incubation at 37°C, the ELISpot plates were washed and captured IFN-γ was detected by incubation for 1 h with 50 µL of the alkaline phosphatase-conjugated monoclonal antibody against IFN-γ (clone 7-B6–1, Mabtech), diluted 1:200 with phosphate-buffered saline plus 0.5% bovine serum album. After further washing, 50 µL of nitro blue tetrazolium/5-bromo-4-chloro-3-indolyl-phosphate was added; purple spots appeared within 7 min. Spot numbers were analyzed by an ELISpot reader (AID Fluorospot, Autoimmun Diagnostika GmbH, https://www.aid-diagnostika.com). Mean values of duplicate cell cultures were considered. We determined SARS-CoV-2–specific spots by spot increment, defined as stimulated minus nonstimulated values. Stimulated spot numbers >3-fold higher than negative (unstimulated) controls combined with an increment value of >3 to any of the 3 antigens were considered positive. Of note, the negative controls reached a mean value of 0.27 spots and an SD of 0.48 (Appendix).
We performed statistical analysis using GraphPad Prism version 8.0.1 (https://www.graphpad.com) and IBM SPSS Statistics 23 (https://www.ibm.com/spss/statistics) software. We used linear regression analysis for numerical variables. The analysis of categorical variables was performed by Mann-Whitney test or 1-way analysis of variance (Kruskal-Wallis test) with Dunn’s correction for multiple comparisons, as appropriate. Two-sided p values <0.05 were considered significant.
In 78 potential convalescent plasma donors with PCR-confirmed SARS-CoV-2 infection, the median interval between onset of symptoms and first blood sampling was 60 days (range 22–112 days) (Figure 1). Thirteen out of 78 (17%) donors had either borderline or negative results (ratio <1.1) to the Anti-SARS-CoV-2 IgG ELISA (Euroimmun). Altogether, 28 CP donors were tested again at later time points, a median of 75 days (24–154 days) after onset of symptoms. Retesting in 10 participants with a ratio of <1.1 showed that most antibody results (9/10) remained similar. The median interval between both blood samplings in this group was 25 days (range 10–61 days). In 1 volunteer with a borderline ratio, the value increased over time and became positive. In donors with higher antibody ratios, the values also remained at a similar level. In all participants with an antibody ratio <0.8, no neutralizing antibodies could be found; in those with a ratio of 0.8–1.1, the titer was 1:20–1:40.
We compared the characteristics of participants with undetectable antibodies to those with intermediate (1.1–3.0) or high antibody ratio (>3) (Table). Of note, in the total cohort of 78 potential blood donors, the median antibody ratio was 3.37; we chose a ratio of 3 as our internal cutoff for convalescent plasma donations. None of the parameters, including age, sex, body mass index, interval to onset of symptoms, risk exposure, symptoms of SARS-CoV-2 infection, need for oxygen or antibiotic treatment, or blood group, differed significantly. However, female participants tended to be overrepresented in the group with undetectable antibodies (p = 0.1 by Kruskal-Wallis test). One of the 78 potential CP donors did not report any symptoms of SARS-CoV-2 infection in the questionnaire. This participant showed an antibody ratio of 3.9.
Cellular immunity was determined from day 24 to day 154 after the onset of COVID-19 symptoms, parallel to antibody testing (Appendix Figure 2). Immunity was followed up as a control in participants with undetectable or low antibodies (irrespective of a triggering event) or when plasma was donated. We established an IFN-γ ELISpot assay separately for each of various stimuli, peptide pools of the S1/S2 and the M protein, and an S1 protein antigen of SARS-CoV-2 (Figures 2, 3). None of the ELISpot responses differed significantly between 9 participants with undetectable antibody responses (ratio <1.1) and 15 with high antibody responses (ratio >3) (Figure 2). However, ELISpot responses to all stimuli were substantially higher than in the negative controls. Nevertheless, the strength of responses toward the S1 protein tended to be higher in the group with a ratio of >3 versus <1.1 (Figure 2, panel A); whereas it was only marginally higher toward the S1/S2 peptides (Figure 2 panel B) and similar toward M peptides (Figure 2, panel C). The strength of responses toward S1/S2 peptides tended to be higher overall than the S1 protein alone. CP donors with an antibody ratio <1.1 showed a median frequency of 3 spots per 250,000 PBMC for stimulation with S1 protein, 6 with S1/S2 peptides, and 11 with M peptides. CP donors with an antibody ratio >3 showed a median frequency of 7 spots per 250,000 PBMC with S1 protein, 10 with S1/S2 peptides, and 13 with M peptides.
To analyze a possible interrelationship between T cell responses against different SARS-CoV-2 antigens and between T- and B-cell responses, we plotted results of various assays (Figure 3; Appendix Figure 3). We observed that patients whose antibody ratio was <1.1 showed robust ELISpot responses mainly directed against the M protein, whereas patients who had a ratio >3 had responses similarly directed against S1/S2 or S1 protein and M protein (Figure 3). We furthermore found that cellular responses against S1/S2 or S1 protein were all low (maximum of 13 spots increment against S1/S2 and 5 against S1 protein) in participants with an antibody ratio <1.1. In contrast, participants with a ratio >3 reached maximum values of 85 (S1/S2 protein) and 32 (S1 protein) spots increment. Maximum responses toward M peptides were more similar: 39 spots increment in CP donors with a ratio of <1.1 or 57 in those with ratio >3.
Cellular immunity toward any of the SARS-CoV-2 antigens was detectable in 7/9 (78%) participants who had an antibody ratio <1.1. In comparison, 12/15 (80%) donors with an antibody ratio of >3 had detectable cellular immunity. Considering all potential CP donors with PCR-confirmed SARS-CoV-2 infection (also those with a ratio of 1.1–3), 22/28 (79%) were classified as positive by ELISpot.
In summary, we could detect T-cell immunity against SARS-CoV-2 in most of the SARS-CoV-2 PCR-positive healthy participants with undetectable IgG antibodies against the S1 protein. In this group, T-cell immunity was more strongly directed against the M than the S1 protein.
We focused on a cohort of volunteer study participants with PCR-confirmed SARS-CoV-2 infection who did not react positive to an S1-specific SARS-CoV-2 IgG ELISA. We observed undetectable humoral response in 17% of our potential blood donors. Similar to our data, other groups reported a lack of antibody response in a subset of patients infected with SARS-CoV-2. For example, a study in China reported absence of antibodies in 10%–20% of participants (W. Tan et al., unpub. data, https://doi.org/10.1101/2020.03.24.20042382). Moreover, Cervia et al. described that, in 15%–20% of S protein–seronegative patients (IgG in the serum), S protein–specific IgA was detectable at several mucosal sites (C. Cervia et al., unpub. data, https://doi.org/10.1101/2020.05.21.108308). Previous publications demonstrated that the magnitude of the humoral response toward SARS-CoV-2 was dependent on the duration and magnitude of viral antigen exposure (8,9; C. Cervia et al.). The absence of durable systemic IgG responses may indicate mild and transient SARS-CoV-2 infection that was cleared effectively (e.g., by the innate immune system) (10). However, whether this transient immune response had led to protective immunity needs to be clarified. The detection of SARS-CoV-2–specific IgG is not considered consistently to be a correlate of virus control (11–13).
Protection of humans against reinfection can be proven definitively only by rechallenge. However, the assessment of cellular immunity can supplement the data on humoral response. The specificity of T-cell assays critically depends on the antigen used for stimulation. In this study, we chose the S protein as stimulus because of its importance as a target for neutralizing antibodies and because it contains major immunodominant epitopes. It mediates the entry of the SARS-CoV-2 virus into the host cell (14,15). The S1 subunit of the S protein acts on the cell binding, and the S2 subunit acts on the fusion of the viral membrane to the cell membrane (16; H. Wang et al., unpub. data, https://doi.org/10.1101/2020.03.26.994756). Data by Okba et al. (17) indicate that S1 is the most specific antigen for the diagnosis of COVID-19. The S2 subunit is the more conserved one, and could cross-react with the S protein of severe acute respiratory syndrome coronavirus (SARS-CoV-1) or MERS-CoV (17,18). However, the infection rate with SARS-CoV-1 or MERS-CoV appears low in Caucasian populations. We selected the M protein, another surface protein of SARS-CoV-2, as a second stimulus because it has been observed to also contain dominant T-cell epitopes (19). It plays a central role in virus assembly (20) and is more likely a target of cross-reactive T cells. Structural comparisons of SARS-CoV-1 and SARS-CoV-2 proteins showed 76% identity for the S protein and more for other structural proteins: 91% for the envelope protein, 90% for the M protein, and 95% for nucleocapsid (19). We observed that potential CP donors with undetectable antibodies against the S1 protein of SARS-CoV-2 had T-cell responses more strongly directed against the M than the S1 protein. Thus, we speculated that their T cells may preferentially target viral peptides involved in virus assembly rather than cell binding; this hypothesis needs confirmation. Responses toward the S1/S2 peptides were stronger than to the S1 protein, possibly because additional immunodominant T-cell epitopes in the S2 antigen caused the stronger response. The finding that the T-cell responses to the S1 protein, which is most specific to SARS-CoV-2, were relatively low raises the issue of potential cross-reactivity after stimulation with the S1/S2 or M peptides. Cross-reactivity has been shown for antibodies directed against SARS-CoV-1 and SARS-CoV-2 (13). 
Similarly, SARS-CoV-2 cross-reactive T cells due to contact to common coronaviruses may occur (5,21) that could interfere with the specificity of our ELISpot assays. Nevertheless, recent PCR-confirmed SARS-CoV-2 infection could have caused the frequency of reactive T cells toward SARS-CoV-2 to be higher in the current cohort of potential CP donors than those reactive toward other common coronaviruses. Furthermore, cross-reactive T cells could be protective against SARS-CoV-2 infection, especially in children and young adults with frequent social contacts (5). Using flow cytometry, Braun et al. (5) detected preexisting SARS-CoV-2 S-cross-reactive CD4+ T cells in 34% of healthy donors, and Grifoni et al. (25) in »40%–60% of unexposed persons. However, arguing against cross-reactivity interfering with our ELISpot assays, we observed negative T-cell responses in the negative control group.
Of interest, differences between participants with a ratio of <1.1 and of >3 seem to be more pronounced after stimulation with the S1 protein than the S1/S2 peptides. Thus, apart from the M protein, the S2 protein may be an additional target of T-cell responses, especially in participants with undetectable T- and B-cell responses against the S1 protein.
Chandrashekar et al. observed near-complete protection in 9 rhesus macaques after SARS-CoV-2 infection (22). After initial viral clearance, upon rechallenge, the animals showed a 5 log10 reduction in median viral loads compared with primary infection and an anamnestic humoral and cellular immune response. Moreover, Deng et al. reported that viral load remained negative in 4 rhesus macaques upon rechallenge with SARS-CoV-2 but showed a transient increase in body temperature (23). Similarly, Kirkcaldy et al. reported limited evidence of reinfection in humans with previously documented COVID-19 (24). Other studies demonstrated that SARS-CoV-2–specific T cells were detectable in the majority of recovered patients (21; N.L. Bert et al., unpub. data, https://doi.org/10.1101/2020.05.26.115832). Data on the earlier coronavirus SARS-CoV-1 indicated that cellular immunity was detectable for >17 years after infection. Similar to our findings, studies from Sweden and France recently observed T cell responses against SARS-CoV-2 in seronegative persons (6; Gallais et al.), Sekine et al. reported that 4/31 (13%) patients who recovered from mild symptoms of COVID-19 were seronegative, which is very similar to 17% of seronegative results in our cohort. Assessment of T cell immunity by flow cytometry showed a greater difference of T-cell responses toward S1/S2 and M peptide pools between seronegative and seropositive patients than our study; this difference may be attributable to several differences between the studies; that is, we here used the ELISpot method instead of flow cytometry to measure specific T cells and our seronegative CP donors were all PCR positive, whereas none of the CP donors was tested positive by SARS-CoV-2 PCR (6).
ELISpot data on other coronaviruses have been reported since 2004. The authors of these early studies used either human leukocyte antigens (HLA)–A2 restricted peptides (25) or overlapping peptide pools spanning the whole SARS-CoV-1 proteome (26). ELISpot data in patients in China who recovered from SARS-CoV-1 infection 1 month earlier showed T-cell immunity in 100% of participants (25), and in 50% of patients recovered 12 months earlier (26). Our ELISpot data determined at a median of 2 months after the onset of symptoms indicate that 79% of participants had detectable T-cell immunity, which fits well with the previous data on the structurally related coronavirus SARS-CoV-1. A study on SARS-CoV-1 from 2008 (26) showed that T cell responses were mainly directed against the S protein and that CD8+ T-cell responses were more frequent and of a greater magnitude than CD4+ T-cell responses. Furthermore, a recent study indicated that on day 14 after injection of an adenovirus-vectored COVID-19 vaccine vigorous ELISpot responses against overlapping peptides of the S protein were induced (27). Compared with our data, responses at day 14 were higher. However, compared with a recent study using mosaic surface protein consisting of exposed extracellular domains of the SARS-CoV-2 spike, envelope, and membrane proteins (28), we observed slightly stronger T-cell responses in our convalescent patients, although the assays with mosaic surface protein were performed earlier after the onset of symptoms (day 6–32). This difference could be attributable to the use of various stimuli.
As of August 2020, we face the challenge of estimating how many persons are still susceptible to SARS-CoV-2 infection. The ELISpot assay we established may help to identify patients with adaptive immunity against SARS-CoV-2 infection. The assay has the following advantages: it is applicable for routine use, measures cellular immunity within 1 day on a single cell level, determines functional cells, and is independent from HLA restriction. However, it does not allow researchers to determine which T-cell population responds upon restimulation. According to our data in volunteers with confirmed SARS-CoV-2 infection, it could be speculated that the majority of persons with undetectable systemic IgG may presumably be protected by specific T-cell immunity, which would be good news for the control of the pandemic.",Emerg Infect Dis
PMC7774538,"SARS-CoV-2 Cluster in Nursery, Poland","Despite robust research, knowledge about coronavirus disease (COVID-19) spread and effective control measures is still limited. Until recently, research has indicated that children rarely spread the infection to adults and are not the primary drivers of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) transmission (1).
We describe characteristics of the cluster of SARS-CoV-2 cases that emerged in a single nursery in Poland within 2 weeks of its reopening. We anonymized all data and collected no sensitive data. The Bioethics Committee of the Medical University of Warsaw approved the study protocol.
The nursery at issue was reopened after a nationwide lockdown on May 18, 2020. On May 31, a nursery worker reported family contact with a symptomatic SARS-CoV-2–infected person, and the nursery was closed. During the 14 days the nursery was open, a mean of 25 children attended the nursery daily. Children spent »8 hours there, divided into 3 groups, each cared for by 2 caregivers (Appendix). Neither children nor caregivers moved across multiple classes. Caregivers wore facemasks when in contact with children. Parents did not enter the building when dropping off and picking up children. Contacts between parents and nursery workers lasted <15 minutes, with facemasks on. Family members of different children did not mix.
The index case of SARS-CoV-2 infection (in a nursery worker with family contact) was confirmed on June 4. Subsequent PCR testing of nursery staff, children attending the facility, and family members (2 initial case-patients plus 104 other persons) (Appendix) revealed positive results in an additional 4 nursery workers (of whom 1 was also a parent of a child attending the facility), 3 children of the nursery workers, 8 children attending the facility, 3 siblings of those children, 8 parents, and 1 grandparent. The cluster involved a total of 29 persons; 8 were children attending the nursery, and 12 were children’s family members who did not enter the facility (Table). One child with a negative result had 2 parents with positive results. One child’s parent tested negative in this cluster but had tested positive within the previous 2 weeks, involved in another cluster.
The overall positivity rate in our cluster was 27%. COVID-19 prevalence in Poland is low. The number of tests conducted in the country was 124,194 in June, whereas the number of positive cases was 1,374, which corresponded to a positivity rate of 1% (2). Thus, local SARS-CoV-2 circulation in society is not sufficient to explain the positivity rate in our cluster. The case of the COVID-19–negative child with positive parents could have been a false-negative result or a negative result after being infected. The result might also have been a true negative, and the parents were infected from another source. However, other potential exposures could not explain infections in all parents involved in our cluster.
We depict probable chains of transmission in the Figure. Of note, physical contact between nursery workers and children’s family members who were infected was strictly limited, and the only close contacts for these groups of adults were children. Given that most COVID-19–positive persons were asymptomatic and tested on the same day, determining with certainty whether children transmitted the virus to their parents or the workers is not possible. Nevertheless, children seemed to be effective mediators of infection between adults.
Several reports concerning clusters of COVID-19 in childcare settings imply little to no SARS-CoV-2 transmission among children and from children to adults (1,3–5; A. Fontanet, unpub. data, https://doi.org/10.1101/2020.06.25.20140178; R.M. Viner, unpub. data, https://doi.org/10.1101/2020.05.20.20108126). However, such estimations are open to bias, given that most published data were obtained at the time of lockdown, when children’s social contacts were limited to family members. Another limitation of those publications is that they applied mostly to school-age children.
The high infection attack rate among children in our cluster could be explained by prolonged close contact between very young children, who are less able to adjust to control measures. Similarly, specific intimate contact between toddlers and their family members could have led to effective spread within families. This observation might be particularly important in light of novel findings that nasopharyngeal SARS-CoV-2 levels are the highest in the youngest children (6). Moreover, the airborne transmission route in the nursery rooms’ confined environment could have played an important role (7).
Our study has some potential limitations. We could not determine whether the infection in the nursery worker was the real index case because one of the children’s parents had tested positive within the previous 2 weeks and that child could also have been the primary case. Moreover, we could not verify the information we obtained from the nursery about the facility’s prevention methods.
Our report questions the role of young children in driving the COVID-19 pandemic. Of note, most children in our study were asymptomatic, and this cluster would likely not have been detected without subsequent testing of persons who had direct contact with the index case-patient. We believe further studies are needed to clarify young children’s role in the transmission of SARS-CoV-2.",Emerg Infect Dis
PMC7774544,"Superspreading Event of SARS-CoV-2 Infection at a Bar, Ho Chi Minh City, Vietnam","Superspreading events occur when a few persons infect a larger number of secondary persons with whom they have contact (1,2). For severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), an R0 of 2–3 with 6–8 secondary cases has been suggested to constitute a superspreading event (3).
Although SARS-CoV-2 is known to be transmitted through droplets and fomites, there has been growing evidence of airborne transmission (4,5). Better understanding of specific settings in which superspreading events are facilitated remains critical to inform the development and implementation of control measures to avoid future waves of the pandemic (5).
On March 18, 2020, a 43-year old man, patient 1, sought treatment at the Hospital for Tropical Diseases in Ho Chi Minh City, Vietnam, for fever, cough, muscle aches, fatigue, and headache. A sample from a nasopharyngeal throat swab specimen taken at admission tested positive for SARS-CoV-2 by reverse transcription PCR.
During the 14 days before the onset of his symptoms on March 17, he had traveled to Thailand and within Vietnam, between Hanoi and Ho Chi Minh City. From 10:00 PM on March 14 until 2:30 AM of the next day, he participated in a St. Patrick’s Day celebration at bar X in Ho Chi Minh City. The bar had 2 indoor areas for clients, an »300-m2 area downstairs and an »50-m2 area upstairs, with no mechanical ventilation. During open hours, the left and right entrances were typically kept closed to facilitate cooling with air conditioners that recycle indoor air; the middle entrance was kept open. The bar also has naturally ventilated outdoor spaces (Appendix). Patient 1 was inside the bar during the party.
After the confirmed diagnosis of COVID-19 in patient 1, we used contact tracing and testing to detect 18 additional PCR-confirmed cases. Of these, 12 (patients 2–13) were at bar X during the evening of March 14; the other 6 (patients 14–19) were contacts (Table; Appendix
Figure). Of the patients with confirmed cases attending the celebration, 4 were in close contact with patient 1: patients 2–4 went to the celebration with patient 1 and patient 6 worked as a waiter in the bar. Patients 2 and 3, who were roommates, had traveled to Malaysia and returned to Vietnam, patient 2 on March 13 and patient 3 on March 6. The other patients, except for patient 1, had no recent history of travel outside of HCMC (Table).
By exploring the epidemiologic links discovered from in-depth interviews, we identified 3 possible transmission chains involving patients who attended the March 14 celebration (Table; Figure; Appendix Figure). Of these, 2 or 3 patients (patients 5, 10, and possibly 14) were asymptomatic but transmitted SARS-CoV-2 to their contacts (Table; Figure). None of the 19 patients with confirmed cases reported that they had respiratory signs or symptoms on March 14–15. However, in addition to patient 1, a total of 5 others developed mild respiratory symptoms (patient 4 on March 16, patient 6 on March 21, patient 9 on March 25, patient 13 on March 26, and patient 17 on March 27), suggesting an incubation period of 2–12 days. Follow-up data were available for 12 patients who participated in our clinical study (Appendix). Six remained asymptomatic during follow-up (Appendix Table 1).
A total of 11 whole-genome sequences of SARS-CoV-2 were obtained from the patients in the cluster. The obtained sequences were either 100% identical or different from each other by only 1–2 nt (Appendix Table 2). Phylogenetically, they clustered together tightly but were different from sequences obtained from other cases in Ho Chi Minh City during the same period.
As of September 15, 2020, only 30 cases of locally acquired infection had been reported in Ho Chi Minh City (6), but this cluster represents the only documented superspreading event (6,7). Together with data from previous reports (3,8,9), these data suggest that closed settings are facilitators of community transmission of SARS-CoV-2. The mechanism by which infected people without symptoms spread SARS-CoV-2 to others, especially in closed settings, warrants further research, including on transmission through aerosols, which has been suggested (4,10).
The high level of genome sequence similarity between the SARS-CoV-2 genomes obtained from the patients and the tight clustering on the phylogenetic tree strengthen the epidemiologic link between the PCR-confirmed cases from this cluster. Together with contact history, these data also support transmission chains involving asymptomatic carriers (patients 5 and 14) as the sources of the ongoing infection. However, the identity of the patient in the index case from the bar could not be confirmed, in part because in-depth interview data were available from only 8 of 13 patients with confirmed cases who consented to participate in the study. In conclusion, our results emphasize that persons in crowded indoor settings with poor ventilation may be considered to be at high risk for SARS-CoV-2 transmission.",Emerg Infect Dis
PMC7774547,"Coronavirus Disease among Workers in Food Processing, Food Manufacturing, and Agriculture Workplaces","The Centers for Disease Control and Prevention (CDC) collected cumulative aggregate data from state health departments on workers in US food processing, food manufacturing, and agriculture workplaces who had laboratory-confirmed COVID-19 (5). Requested data elements included the number and type of workplaces that reported >1 COVID-19 case among workers during March 1–May 31, 2020; the number of workers in affected workplaces; the number, demographics, and symptom status of workers with COVID-19; and the number of COVID-19–related deaths among workers. CDC requested the same information for meat and poultry processing workers and published preliminary data (1). Symptom data collection varied by workplace; clinical signs and symptom severity were not requested. None of these data had personal identifying information.
Workplaces were defined by the North American Industry Classification System codes 111 (Crop Production) and 311 (Food Manufacturing) (6). Demographic and symptom status proportions were calculated after excluding missing and unknown values. Data on sex were missing for 14.8% of food manufacturing and agriculture workers with COVID-19; on age for 13.4%; on symptom status for 33.6%; and on race and ethnicity for 36.3%. Because characteristics of total worker populations in affected workplaces were not available, we compared the racial and ethnic distribution of workers with COVID-19 to the distribution of all workers in the animal slaughtering and processing industry. CDC determined the investigation to be nonresearch as defined in 45 CFR 46.102(l); Paperwork Reduction Act was waived with respect to voluntary collection of information during a public health emergency (7).
Among 50 US states, 36 (72.0%) responded to the CDC inquiry; 33 (91.7%) reported >1 laboratory-confirmed COVID-19 case among food processing, food manufacturing, or agriculture workers during March 1–May 31, 2020. States reported 8,978 cases and 55 (0.6%) deaths among workers in 742 food manufacturing and agriculture workplaces in 30 states (Table 1). Among the 30 states reporting cases, the median number of affected facilities per state was 12 (interquartile range [IQR] 4–30 facilities); among 15 states that reported worker populations in affected workplaces, 8.2% of 30,609 workers received COVID-19 diagnoses. The percentage of workers with COVID-19 ranged from 2.0%–43.5% per state.
Of cases among food manufacturing and agriculture workers with information on sex (n = 7,647) and age (n = 7,771), 4,713 (61.6%) workers were male, 2,934 (38.4%) were female, and 3,439 (44.3%) workers were 20–39 years of age (Figure 1). Among 5,721 workers with race and ethnicity reported, 4,164 (72.8%) workers were Hispanic or Latino, 963 (16.8%) were non-Hispanic White, 362 (6.3%) were non-Hispanic Black, and 232 (4.1%) were non-Hispanic Asian/Pacific Islander. Overall, 83.2% of cases occurred among racial and ethnic minority workers. Symptom status was reported for 5,957 workers; 4,957 (83.2%) workers were symptomatic and 1,000 (16.8%) were asymptomatic or presymptomatic.
States reported 28,364 cases and 132 (0.5%) deaths among workers in 382 meat and poultry processing facilities in 31 states (Table 2). Demographic characteristics and symptom status of workers with COVID-19 indicated most were symptomatic and members of racial and ethnic minority groups (Figure 2).
We describe COVID-19 among workers in US food processing, food manufacturing, and agriculture workplaces during March 1–May 31, 2020. Among all food manufacturing and agriculture workers in 28 states reporting race and ethnicity data, 36.5% of workers are Hispanic or Latino, 52.6% are non-Hispanic White, 5.9% are non-Hispanic Black, 3.5% are non-Hispanic Asian/Pacific Islander, and 1.5% are of other non-Hispanic race or ethnicity groups (4). However, among workers with COVID-19 for whom race or ethnicity data were reported, 72.8% were Hispanic or Latino, 6.3% were non-Hispanic Black, and 4.1% were non-Hispanic Asian/Pacific Islander, suggesting that Hispanic or Latino, non-Hispanic Black, and non-Hispanic Asian/Pacific Islander workers in these workplaces might be disproportionately affected by COVID-19.
The sex, age, and symptom distribution of meat and poultry processing workers with COVID-19 was similar to that observed for food manufacturing and agriculture workers. The racial and ethnic distribution of meat and poultry processing workers with COVID-19 differed slightly; a higher percentage of cases were reported among non-Hispanic Black and non-Hispanic Asian/Pacific Islander workers.
Our study supports findings from prior reports that part of the disproportionate burden of COVID-19 among some racial and ethnic minority groups is likely related to occupational risk (8,9). These findings should be considered when implementing workplace interventions to ensure communication and training are culturally and linguistically tailored for each workforce.
Reports on mass testing in US meat and poultry processing facilities revealed widespread COVID-19 outbreaks and identified high proportions of asymptomatic or presymptomatic infections (10,11). Although most food manufacturing and agriculture workers (83.2%) and meat and poultry processing workers (88.1%) in our study reported symptoms, not all workplaces performed mass testing; therefore, workers with asymptomatic or presymptomatic infections might have been missed. These findings support the need for comprehensive testing strategies, coupled with contact tracing and symptom screening, for high-density critical infrastructure workplaces to aid in identifying infections and reducing transmission within the workplace (12).
Reducing workplace exposures is critical for protecting workers in US food processing, food manufacturing, and agriculture workplaces and might help reduce health disparities among disproportionately affected populations. Adherence to workplace-specific intervention and prevention efforts, including engineered controls, such as physical distancing; administrative controls, such as proper sanitation, cleaning, and disinfection; and providing personal protective equipment likely would protect both workers and surrounding communities (13,14).
This study has several limitations. First, only 36 states reported data; these results might not be representative of all US food processing, food manufacturing, and agriculture workers and workplaces. Second, testing strategies varied by workplace, influencing the number of cases detected and reported among workers. Workers might have been hesitant to report illness or seek healthcare, which could have led to underestimating cases among workers. Delays in linking cases and deaths to workplace outbreaks likely also contributed to an underestimation. Third, demographic characteristics of total worker populations in all affected workplaces were not available, limiting the ability to quantify the degree to which some racial and ethnic minority groups might be disproportionately affected by COVID-19. Fourth, preferred language, English proficiency, and migration and immigration status of workers were not captured; culturally and linguistically appropriate public health monitoring and interventions are crucial considerations for this workforce. Finally, workers are members of their local communities; transmission of SARS-CoV-2 could have occurred both at the workplace and in the surrounding community and thus could be affected by levels of community transmission.
Comprehensive evaluations in food processing, food manufacturing, and agriculture workplaces and communities are needed to clarify and address risk factors for SARS-CoV-2 transmission among workers. The extent of control measures and timing of implementations should be evaluated to assess effectiveness of workplace interventions. Several factors at the individual-, household-, community-, and occupational-level, including long-standing health and social disparities, likely contribute to disproportionate disease incidence among racial and ethnic minority workers.",Emerg Infect Dis
PMC7774549,Susceptibility of Domestic Swine to Experimental Infection with Severe Acute Respiratory Syndrome Coronavirus 2,"We obtained 19 domestic, 8-week-old American Yorkshire crossbred pigs (Sus scrufa domesticus), 6 castrated males and 13 females, locally sourced from a high health status farm in Manitoba, Canada. We obtained animals locally, rather than from a specific pathogen–free colony, to determine the risk to farmed pigs in Canada. We oronasally challenged 16 pigs with 1 × 106 PFU/animal in a total of 3 mL Dulbecco’s Modified Eagle’s Medium (DMEM; Wisent, http://www.wisentbioproducts.com) under sedation with isoflurane. We distributed 1 mL per nostril and placed 1 mL in the distal pharynx by using a sterile, tomcat-style catheter. We confirmed the challenge dose by back-titration of the inoculum on Vero E6 cells.
We divided the 16 inoculated pigs into 2 groups of 8, and each group was housed in a separate BSL-3 cubicle. At day 10, we introduced 2 naive pigs, 1 into each cubicle with the inoculated pigs, to serve as in-room transmission controls. Animal numbers were not based on power analysis but on limitations of the containment animal room size and requirements of Canadian Council on Animal Care guidelines. Group assignments for day of euthanasia and necropsy were based on randomization at the time of permanent animal identification via ear tags.
At the time of inoculation (day 0) and every other day beginning at 3 days postinoculation (dpi) until day 15, we performed a physical examination, including collection of blood; rectal, oral, and nasal swabs; and nasal wash with sterile Delbecco’s phosphate-buffered saline (D-PBS). We began performing necropsies and post-mortem sampling starting at 3 dpi (Table 1). We sampled and necropsied 1 additional uninoculated pig to serve as a farm control providing negative control tissues. We sampled the remaining pigs at 22 dpi and 29 dpi. We collected group oral fluids from rope chews daily.
Oral, rectal, and nasal swab specimens were taken from each pig under general anesthesia by using isoflurane. Samples were placed into sterile D-PBS containing streptomycin, vancomycin, nystatin, and gentamycin. Fluid was collected from a bilateral nasal wash by using sterile D-PBS. Blood was collected in serum, sodium citrate, sodium heparin, and K3 EDTA collection tubes via jugular venipuncture.
Hematology was performed on an HM5 analyzer (Abaxis, https://www.abaxis.com) by using K3 EDTA-treated whole blood. We evaluated erythrocytes, hemoglobin, hematocrit, mean corpuscular volume, mean corpuscular hemoglobin, mean corpuscular hemoglobin concentration, red cell distribution weight, platelets, mean platelet volume, leukocytes, and absolute and percent neutrophil count, lymphocyte count, monocyte count, eosinophil count, and basophil count. Blood chemistries were evaluated on a VetScan 2 (Abaxis) with Comprehensive Diagnostic Profile rotors (Abaxis) by using serum stored at −80°C until tested. We evaluated glucose, blood urea nitrogen, creatinine, calcium, albumin, total protein, alanine aminotransferase, aspartate aminotransferase, alkaline phosphatase, amylase, potassium, sodium, phosphate, chloride, globulin, and total bilirubin. We used sodium heparin-treated blood to analyze venous blood gases by using an iSTAT Alinity V (Abaxis) instrument with a CG4+ cartridge (Abaxis) to measure lactate, pH, total carbon dioxide, partial pressure carbon dioxide, partial pressure oxygen, soluble oxygen, bicarbonate, and base excess. We used age-specific values and the instrument reference intervals to establish normal ranges (18–20).
Necropsy was performed after euthanasia via sodium pentobarbital overdose, confirmation of death, and exsanguination by femoral artery laceration. We collected tissue samples from skeletal muscle, abdominal fat, liver, spleen, pancreas, duodenum, jejunum, ileum, spiral colon, kidney, gastrohepatic and mesenteric lymph nodes, right cranial lung lobe, right middle lung lobe, right caudal lung lobe, left cranial lung lobe, left caudal lung lobe, trachea, heart, tracheobronchial lymph nodes, cervical spinal cord, meninges, cerebrum, cerebellum, brainstem, olfactory bulb, nasal turbinates, submandibular lymph nodes, tonsils, trigeminal ganglion, and the entire eye. From female animals, we collected the uterus and ovaries of the reproductive tract en bloc. We collected epiglottis and laryngeal folds from some animals. We split tissue samples between 10% neutral-buffered formalin and fresh tissue. We also collected cerebrospinal fluid, urine (when possible), vitreous, and bronchoalveolar lavage by using DMEM.
We fixed tissues in 10% neutral phosphate-buffered formalin. We routinely processed and sectioned tissue at 5 µm and stained with hematoxylin and eosin (HE) for histopathologic examination. We performed in situ hybridization on 5 μm paraffin-embedded formalin-fixed tissue sections by using RNAscope 2.5HD Detection Reagent Red kit and V-nCoV2019-S probe (Advanced Cell Diagnostics, http://rna.acdbio.com). Then, we counterstained sections with Gill’s 1 hematoxylin (Leica Biosystems, https://www.leicabiosystems.com), dried, and coverslipped.
We propagated SARS-CoV-2 isolate hCoV-19/Canada/ON-VIDO-01/2020 (GISAID accession no. EPI_ISL_425177), on Vero E6 cells in DMEM supplemented with 1% fetal bovine serum. We titrated virus by plaque assay and performed viral isolation as previously described (21,22).
Weighed, frozen tissue sections in Precellys bead mill tubes (Bertin, https://en.esbe.com) were thawed, and we added D-PBS to make 10% (w/v) tissue homogenates. We processed tubes by using a Minilys personal tissue homogenizer (Bertin, https://www.bertin-instruments.com) and clarified by centrifugation at 2,000 × g. We used TriPure Reagent (Roche, https://www.roche.com) to inactivate clarified homogenates, swab specimens, and fluids collected from experimental animals and extracted RNA in duplicate. Samples positive by semiquantitative real-time RT-PCR (qRT-PCR) samples were tested for virus isolation through standard plaque assay on Vero E6 cells by using freshly prepared homogenates of frozen tissue.
We extracted total RNA from cell culture and experimental samples, including nasal, oral, and rectal swab specimens; nasal washes; oral fluids; whole blood in sodium citrate; and tissues by using MagMax CORE Nucleic Acid Purification Kits (ThermoFisher Scientific, https://www.thermofisher.com) per manufacturer’s recommendation with the following modifications. In brief, we diluted samples in TriPure Reagent (Sigma-Aldrich, https://www.sigmaaldrich.com) at a 1:9 ratio and used this in place of the manufacturer’s lysis buffer for inactivation. We used 650 µL of TriPure-inactivated sample, 30 µL of binding beads, and 350 µL of kit-provided CORE binding buffer spiked with ARM-ENTERO (Asuragen, https://asuragen.com) enteroviral armored RNA, then single washes in both wash 1 and wash 2 buffers, and a final elution volume of 30 μL of kit-supplied elution buffer by using the automated MagMax Express 96 system running the KingFisher-96 Heated Script MaxMAX_CORE_KF-96 (ThermoFisher Scientific). The spiked enteroviral armored RNA was used as an exogenous extraction and reaction control.
We performed qRT-PCR on all extracted samples by using primers and a probe specific for SARS-CoV-2 envelope (E) gene (23), including forward primer E_SARBECO_F1 (5′-ACAGGTACGTTAATAGTTAATAGCGT-3′); reverse primer E_SARBECO_R2 (5′-ATATTGCAGCAGTACGCACACA-3′); and probe E_SARBECO-P1 (5′-ACACTAGCCATCCTTACTGCGCTTCG-3′). We prepared master mix for qRT-PCR by using TaqMan Fast Virus 1-step Master Mix (ThermoFisher Scientific) according to manufacturer’s specifications by using 0.4 µmol of each E gene primer and 0.2 µmol of probe per reaction. Reaction conditions were 50°C for 5 min, 95°C for 20 s, and 40 cycles of 95°C for 3 s then 60°C for 30 s. Runs were performed by using a 7500 Fast Real-Time PCR System (Thermofisher, ABI), and semiquantitative results were calculated based on a gBlock (Integrated DNA Technologies, https://www.idtdna.com) standard curve for SARS-CoV-2 E gene. For confirmation, we used SARS-CoV-2–specific primers targeting the spike (S) gene and the RNA-dependent RNA polymerase (RdRp) gene. For S, we used the forward primer SARS2_Spike_FOR (5′-TGATTGCCTTGGTGATATTGCT-3′); the reverse primer SARS2_Spike_REV (5′-CGCTAACAGTGCAGAAGTGTATTGA-3′); and the probe SARS2_Spike_Probe (5′-TGCCACCTTTGCTCACAGATGAAATGA-3′). For RdRp, we used forward primer RdRp_SARSr-F (5′-GTGARATGGTCATGTGTGGCGG-3′); reverse primer RdRp_SARSr-R (5′-CARATGTTAAASACACTATTAGCATA-3′); and probe RdRp_SARSr-P2 (5′-CAGGTGGAACCTCATCAGGAGATGC-3′). We tested all samples in duplicate and considered cycle threshold (Ct) <36 positive.
We were able to extract SARS-CoV-2 RNA from the submandibular lymph node of 1 pig (20–06), which was processed for high-throughput sequencing by CFIA National Centre for Foreign Animal Disease (NCFAD) Genomics Unit with enrichment for sequences for vertebrate viruses according to previously published method (24,25) and sequenced on a MiSeq (Illumina, https://www.illumina.com) using MiSeq Reagent Kit v3 (600-cycle; Illumina). Data analysis also were performed by the CFIA NCFAD Genomics Unit using nf-villumina version 2.0.0 (https://github.com/peterk87/nf-villumina), an in-house workflow developed by using Nextflow (26), which performed read quality filtering with fastp (27); Centrifuge version 1.0.4-beta (28) and Kraken2 version 2.0.8 (29) read taxonomic classification using an index of the National Center for Biotechnology Information (NCBI) nucleotide database (downloaded 2020 Feb 4); a Kraken2 index of NCBI RefSeq (https://www.ncbi.nlm.nih.gov/refseq) sequences of archaea, bacterial, viral, and human genomes GRCh38 (downloaded and built on 2019 Mar 22); removal of nonviral reads (i.e., not classified as belonging to superkingdom “Viruses” (NCBI taxonomic identification 10239) by using Kraken2 and Centrifuge taxonomic classification results; de novo metagenomics assembly of taxonomically filtered reads by Shovill version 1.0.9 (30), Unicycler version 1.0.9 (31), and Megahit version 1.2.9 (32); and nucleotide BLAST+ version 2.9.0 (33,34) search of all assembled contigs against the NCBI nucleotide BLAST database (downloaded 2020 April 10) using the “update_blastb.pl” script as part of the blast Bioconda package (35). We mapped nf-villumina taxonomically filtered reads against the top viral nucleotide BLAST match, SARS-CoV-2 isolate 2019-nCoV/USA-CA3/2020, MT027062.1, to generate a majority consensus sequence.
We determined neutralizing antibody titers in serum samples by using a plaque reduction neutralization test (PRNT) against SARS-CoV-2. Serial 5-fold dilutions of heat inactivated (30 min at 56°C) serum samples were incubated with virus for 1 h at 37°C. Each virus–serum mixture was then added to duplicate wells of Vero E6 cells in a 48-well format, incubated for 1 h at 37°C, and overlaid with 500 μL of 2.0% carboxymethylcellulose in DMEM per well. Plates were then incubated at 37°C for 72 h, fixed with 10% buffered formalin, and stained with 0.5% crystal violet. Serum dilutions with >70% reduction of plaque counts compared with virus controls were considered positive for virus neutralization. We used negative serum samples plus virus controls to estimate the percent reduction.
Detection and semiquantitation of neutralizing antibodies were determined by using SARS-CoV-2 Surrogate Virus Neutralization Test Kit (Genscript, https://www.genscript.com) according to the manufacturer’s instructions. All samples from 7–29 dpi were assessed, including archived negative serum samples and kit-supplied negative controls. We considered values above the manufacturer’s recommended cutoff of 20% positive for neutralization.
Starting at 1 dpi, a mild, bilateral ocular discharge developed in the 16 experimentally inoculated pigs; in some cases, this discharge was accompanied by serous nasal secretion. Discharge was observed for only the first 3 dpi. Temperatures among pigs remained normal throughout the study (Appendix Table 1). Overall, animals did not develop clinically observable respiratory distress; however, 1 animal (pig 20–06) had mild depression with a cough at 1 dpi, which continued through 4 dpi. This animal did not display additional clinical signs over the course of the study.
Viral shedding can occur through droplets from coughing, sneezing, oral fluids, or gastrointestinal involvement. Thus, we developed a sampling schedule to determine the incidence of viral shedding (Table 1). Starting at 3 dpi, we sampled oral, nasal, and rectal swabs every other day up to 15 dpi, in case of delayed onset (1). We extracted nucleic acid from swabs and performed qRT-PCR to identify SARS-CoV-2 by targeting the E gene, but we did not detect viral RNA in swabs from any animals over the course of the study (Table 2).
Nasal washes are a sensitive method for detection of pathogens in swine, and we routinely sampled nasal washes by using sterile D-PBS to rinse nasal passages. Two pigs (20–10 and 20–11) displayed low levels of viral RNA by qRT-PCR at 3 dpi (Table 2). We attempted recovery of live virus from PCR-positive nasal wash samples, but neither produced cytopathic effect or increased RNA detection via qRT-PCR of the cell culture supernatant.
We also used a noninvasive, group sampling method to evaluate viral shedding. A cotton rope was hung in animal pens before feeding; when pigs chewed on the rope, they deposited oral fluids. We processed fluids from ropes daily and samples from cubicle 1 had a weak positive signal for viral RNA at 3 dpi by qRT-PCR (Tables 1,3). We attempted virus isolation from this sample but were not able to isolate the virus. Of note, the positive oral fluid did not come from the same room as the 2 positive nasal washes from pig 20–10 and pig 20–11, which were housed in cubicle 2. Therefore, at least 3 animals provide evidence of viral nucleic acid in oronasal secretions from 2 independent animal rooms. In addition, we did not detect viral infection at any point from the 2 naive transmission contact pigs introduced to the infected pigs at 10 dpi.
After collecting samples, we attempted SARS-CoV-2 detection from whole blood by qRT-PCR (Table 1). Viremia, as indicated by the presence of viral RNA in the blood, was not detected in any animal during the study (Table 2). We measured blood cell counts by using the VetScan HM5 (Abaxis), blood chemistries by using VetScan 2 (Abaxis), and blood gases by using i-STAT (Abbott, https://www.abbott.com). Although some laboratory variation was observed during the study, changes were minimal and inconclusive, and profiles consistent with acute viral infection or subsequent organ damage were not observed.
To identify potential target tissues or gross lesions consistent with SARS-CoV-2, we performed necropsy on 2 animals every other day from 3 dpi through 15 dpi and necropsied an additional 2 pigs at both 22 dpi and 29 dpi (Table 1). No clinically significant pathology was observed that could be attributed directly to a viral infection. We performed qRT-PCR across all tissues and samples collected at necropsy targeting the E gene of SARS-CoV-2 (Table 4). One tissue sample, the submandibular lymph node from pig 20–06, necropsied at 13 dpi, was positive by qRT-PCR (Ct = 32) for viral RNA. The tissue sample testing was repeated in triplicate, on independent days, and generated consistent results. Further, RNA was extracted from homogenized tissue, and we recovered the full genome sequence of SARS-CoV-2 from pig 20–06.
We generated a 10% homogenate from the submandibular lymph node of pig 20–06 and used it to infect Vero E6 cells. We took aliquots from the cell culture on days 2 and 3 postinfection to monitor viral replication as indicated by an increasing quantity of RNA. On day 3, we observed mild cytopathogenic effect in the first passage with an increase in viral RNA measured by qRT-PCR targeting the E, S, and RdRp genes. The first passage supernatant was clarified by centrifugation and a second passage performed in Vero E6 cells. At day 2 postinfection of the second passage, we observed substantial cytopathogenic effect and increasing copies of SARS-CoV-2 viral RNA, confirmed by qRT-PCR. Together, these findings demonstrated the presence of live, replication-competent SARS-CoV-2 virus isolated from the submandibular lymph node of pig 20–06 (Table 2).
We monitored development of SARS-CoV-2 neutralizing antibodies over the course of study. Starting at 7 dpi, we obtained serum from individual animals for both virus neutralization test (VNT) and a surrogate VNT (sVNT) using cPass Neutralization Antibody Detection kit (Genscript, https://www.genscript.com). Serum samples first were tested by using a traditional VNT; 1 pig (20–07) generated neutralizing antibody titers, albeit weak, at a 1:5 dilution with a 70% reduction of plaques at both 13 dpi and 15 dpi (Table 5). Consequently, the sVNT assay identified the same animal, pig 20–07, as antibody-positive with 0.188 µg/mL antibody at 15 dpi. A second pig (20–14) generated antibodies at 11 dpi (0.113 µg/mL) and 13 dpi (0.224 µg/mL). We also used sVNT to identify secreted antibody in oral fluids. Of note, at 6 dpi we detected positive antibody (0.133 µg/mL) from group oral fluid collected from cubicle 1 (Table 5).
Our study found that domestic swine are susceptible to low levels of SARS-CoV-2 viral infection. Among 16 experimentally inoculated animals, 5 (31.3%) displayed some level of exposure or elicited an immune response to the virus. Only 1 pig in our study retained live virus, but 2 other animals had detectible RNA measured in nasal wash, and another 2 developed antibodies. One pig (20–06) displayed mild, nonspecific clinical signs, including coughing and depression. Then, over the 9 days between cessation of clinical signs and postmortem evaluation, we found this pig maintained the virus in the submandibular lymph node, but virus was undetected in other samples from this animal. In addition, multiple pigs demonstrated mild ocular and nasal discharge that appeared during the immediate, postinfection period. Of note, among 5 animals with potential infection, we detected only low levels of viral RNA; no live viral shedding was identified.
After detection of viral RNA in group oral fluids collected by rope chews at 3 dpi, we detected secreted antibody by using sVNT; we detected viral RNA in the same sample type at 6 dpi. The amount of antibody measured in oral fluids from swine would be considered below a protective cutoff based on comparisons to classical neutralizing titers, however the discovery of secreted antibody in oral fluids might be useful for surveillance efforts. This finding also demonstrates the possibility that human saliva should be evaluated as a less invasive method to provide accompanying evidence with serosurveillance studies for exposure to SARS-CoV-2.
The results of this study contradict previous reports indicating swine are not susceptible to SARS-CoV-2 infection (4,36). Previous studies did not detect RNA in swabs or organ samples, and no seroconversion was measured. Infectious dose, viral isolate, age, and breed or colony of swine could affect study outcomes. Of note, we used a 10-fold higher viral dose for experimental infection than was used in previous studies. Moreover, we obtained animals from a high health status farm in Manitoba, rather than a specific pathogen–free colony, to determine the risk to farmed pigs in Canada. Altogether, these findings indicate that further investigations into the susceptibility of additional domestic livestock species should be conducted to assess their risk for infection and zoonoses. Finally, we emphasize that to date no SARS-CoV-2 cases among domestic livestock have been documented by natural infection; however, the results of this study support further investigations into the role that animals might play in the maintenance and spread of SARS-CoV-2.
This article was preprinted at https://biorxiv.org/cgi/content/short/2020.09.10.288548v1.",Emerg Infect Dis
PMC7774552,"Attitudes about COVID-19 Lockdown among General Population, France, March 2020","During the spring of 2020, because of the coronavirus disease (COVID-19) pandemic, >3 billion persons worldwide lived under lockdown, and many of them were probably angry, uncertain, and distrustful of their national leaders (1). Thus, acquiring real-time information about the way populations react and comply to such stringent measures across different socio-economic groups and sociocultural contexts is crucial (2). Social acceptability is especially important in the case of France, because the general population did not adhere to governmental recommendations against the previous 2009 influenza A(H1N1) pandemic, during which only 8% of adults complied with the mass vaccination campaign promoted by health authorities (3,4).
To investigate attitudes toward the lockdown among the general population in France, we conducted a cross-sectional online survey among a nationally representative sample (N = 1,012) of residents >18 years of age (Table). The survey was administered during March 27–29, about 10 days after the nationwide lockdown was introduced. To limit selection bias, categories of persons who are less prone to participate in internet surveys (e.g., workers and older persons) were oversampled, and the invitational email did not mention the theme of the survey. In terms of response bias, self-administered questionnaires tend to yield fewer reports in the socially desirable direction than do interviewer-administered questionnaires, and online surveys might have the lowest levels of social-desirability bias (5). We computed participants’ equivalized household income per month, taking into account household size and composition. Low income refers to the bottom quartile, medium income to the second and third quartiles, and high income to the top quartile. Participants were asked to express their level of agreement toward 12 statements related to lockdown. We asked them whether they were experiencing financial difficulties because of the lockdown. We also asked for household size and housing surface area to identify participants confined in an overcrowded household.
Most participants supported the current lockdown as the only effective way to fight the epidemic and the need to maintain it for several more weeks; however, this support was significantly lower (p<0.001 by χ2 test) among low-income respondents (Table). Strong support was observed across all income groups in favor of strengthening controls to making the lockdown more effective. Only a few respondents (more frequently low-income respondents) expressed open criticisms, including statements indicating that the lockdown is “disproportionate considering the real gravity of the epidemic” (35% among low-income respondents vs. 10% among high-income respondents) and that it should be less coercive to be more acceptable (33% among low-income respondents vs. 13% among high-income respondents).
However, the consensus for the lockdown was based on the fact that it appeared a stopgap measure implemented because of a lack of alternatives: 66% of respondents agreed that the lockdown was the consequence of the lack of hospital resources, 65% agreed that mass testing could replace the lockdown, and 50% considered that the lockdown could have been “avoided by the widespread wearing of masks.” Once again, such statements were more frequent among low-income respondents. Similarly, although all socioeconomic groups acknowledged some major drawbacks (including disastrous economic consequences and family tragedies), low-income respondents were more likely than high-income respondents to state that the lockdown was causing “too much restriction on civil liberties” (58% vs. 28%). 
Social differences in attitudes toward the lockdown are probably related to practical differences in persons’ living conditions during the lockdown. After 10 days of confinement, 40% of respondents in the low-income group were already reporting financial difficulties because of the lockdown (compared with 6% among high-income respondents). In terms of housing conditions, 9% of participants were confined in an overcrowded household, but that was the case for 23% of low-income respondents (compared with 1% of high-income respondents). Overcrowded housing can impair mental health, and the lockdown made crowded situations even more unbearable because engaging in outdoor activities typically is the easiest way to cope with such situations (6,7).
In France, as in most other countries, the COVID-19 pandemic fueled contradictory information and intense controversies in traditional and social media. Our survey suggests that a social consensus has been maintained in France in favor of the national lockdown and that excessive politicization of public health has been avoided so far (8). However, this consensus remained fragile. First, opinion might have changed if the public got the impression that authorities did not promote alternatives fast enough to end the confinement period. Second, as exemplified by the lower support observed in the poorest groups, the pandemic and the lockdown both exacerbated existing social inequalities and conflicts; besides social inequalities in terms of income and housing conditions, hospital workers in France had been on strike for months during the previous year demanding more resources, and many opponents accused the government of impinging on civil liberties during the so-called “yellow vests” protest movement.
In summary, in late March, most persons in France did support the lockdown; however, such consensus remained fragile because of existing social inequalities and conflicts. Continuous monitoring of population’s attitudes and practices during the pandemic will remain key for guiding the public health response (9) and communication strategy (10).",Emerg Infect Dis
PMC7780980,Peer Support Group for Intensive Care Unit Survivors: Perceptions on Supportive Recovery in the Era of Social Distancing,"Descriptive statistics were analyzed with Stata version 16 (StataCorp LLC) (24).
The majority of participant respondents “agreed” or “strongly agreed” that the peer support group helped them to gain a greater understanding of PICS, better manage symptoms of PICS, and create relationships with others who had experienced ICU hospitalizations (Figure 1). Participants believed that the support group helped them to create meaning from their ICU experiences and feel more hopeful about the future and that it improved their quality of life.
Before adopting the entirely virtual format, 69.0% (18 of 26) of respondents participated in person. To attend the virtual peer support group, participants used a mobile phone (with or without video), tablet, or computer. The majority of participants (92.0%; 24 of 26) felt comfortable or very comfortable using their device to attend the group. Participants endorsed fewer barriers to attendance after transition to the virtual group (Figure 2).
Participant-satisfaction ratings for the virtual support group are shown in Figure 3. After transition to the virtual format, 90.0% (20 of 22) of participants stated they were likely or very likely to continue to attend the virtual group.
This brief assessment of our ICU Survivors Peer Support Group suggests that virtual peer support groups for ICU survivors are valuable, feasible, and acceptable, with patient-reported benefits including social connection and support, greater understanding of physical and emotional health, increased knowledge of illness management, and improved quality of life. There were high rates of satisfaction on comfort with technology and all measures of acceptability. Participant-satisfaction ratings for the ease of attending the group improved after the transition to the virtual format. Overall, participants reported satisfaction with the virtual support group, suggesting that this format is an acceptable alternative, potentially mitigating barriers to mental health support for ICU survivors. Although our group did not include survivors of COVID-19 who were admitted to the ICU, group benefits may be critical to these patients, who face isolation, decreased social support, economic hardship, and health-related anxiety as part of this rapidly evolving global pandemic.
Improved access to psychosocial support during an era with increasing mental health risk factors will be a necessary component of post-ICU recovery. Despite concerns that virtual groups may foster feelings of disconnection (16, 25), our group participants reported a greater degree of satisfaction with the social support provided in the all-virtual group than they reported with the hybrid group.
This study has several limitations, including its small sample size, study design and response bias, and limited generalizability. Our group uniquely incorporated virtual attendees before COVID-19. Although many in-person participants established social relationships with one another before using a virtual platform, which may have facilitated the successful transition, almost one-third of respondents never participated in person but nevertheless found the group valuable. Group members may not necessarily represent the emerging population of ICU survivors whose ICU admission was related to COVID-19, who could benefit from virtual support groups because of unifying issues of survivorship across primary diagnoses (26, 27). Our experience suggests that virtual support groups are valuable and feasible for an expanding population of ICU survivors.
Future considerations for sustaining virtual peer support groups include confidentiality, optimizing virtual therapeutic relationships, pregroup screening, and significant efforts to address health inequities and disparities that would otherwise leave vulnerable populations without access to virtual mental health services.
We share this study with urgency to increase awareness and encourage use of virtual support groups for ICU survivors. As the COVID-19 pandemic evolves, we have the responsibility to provide safe and accessible health care for ICU survivors. Undoubtedly, social isolation presents a risk to the mental health and quality of life of survivors. Virtual platforms for peer support groups are one way we can increase access to social support, maintain human connection, and lessen the mounting psychological distress experienced by survivors of critical illness.",Ann Am Thorac Soc
PMC7774555,"Limited Specificity of Serologic Tests for SARS-CoV-2 Antibody Detection, Benin","We obtained convalescent serum samples from 8 patients in Benin with RT-PCR–confirmed COVID-19 during March–April 2020. The average sampling time was 8 (range 1–10) days after RT-PCR confirmation of SARS-CoV-2 infection (Table 1). We also included 60 serum samples from patients with acute febrile illness tested as part of hemorrhagic fever surveillance during October–November 2019 as prepandemic controls (Table 2). Sampling was approved by the ethics committee of the Benin Ministry of Health (approval no. 030/MS/DC/SGM/DNSP/CJ/SA/027SGG2020).
 We tested all 68 serum samples by using commercially available ELISAs from EUROIMMUN (https://www.euroimmun.com) that rely on different antigens and antibody classes: SARS-CoV-2 nucleocapsid (N) antigen (IgG), spike 1 (S1) subunit (IgG and IgA), and Middle East respiratory syndrome coronavirus (MERS-CoV) S1 (IgG). We also used the SCoV-2 Detect IgG ELISA (InBios, https://inbios.com), an IgG-only S1 antigen-based test authorized for emergency use by the US Food and Drug Administration. Serum samples also were tested by using commercially available ELISA kits (Euroimmun) against the Zika virus (ZIKV) nonstructural protein 1 (NS1) antigen (IgG), the Epstein-Barr virus (EBV) nuclear antigen 1 (EBNA1) (IgG), and the EBV viral capsid (CA) antigen (IgM and IgG), as well as real-time PCR tests (TIB MOLBIOL, https://www.tib-molbiol.com) for all human pathogenic Plasmodium species, EBV, and cytomegalovirus (CMV). Plaque-reduction neutralization tests (PRNTs) were performed by using similar methods for SARS-CoV-2 and ZIKV as described (4,6). We used previously described recombinant S-based immunofluorescence assays (7) to test for specific antibodies to common cold betacoronavirus human coronavirus (HCoV) OC43 and HCoV-HKU1.
Among the 8 patients with RT-PCR–confirmed SARS-CoV-2 infection, seroconversion ranged from 62.5%–100% (95% CI 30.8%–100.0%), depending on the ELISA used (Figure 1, panel A), suggesting differential sensitivity of ELISAs on the basis of immunoglobulin detected and the commercial kit used. Indeed, early after infection, IgA-based tests had a higher sensitivity than most IgG-based SARS-CoV-2 ELISAs; only the InBios IgG-based kit was positive for all RT-PCR–confirmed patients (Figure 1, panel A). A total of 87.5% (7/8) of ELISA results were confirmed by a highly specific SARS-CoV-2 PRNT (Figure 1, panel B). 
When summarizing all antibody classes, antigens, and kits among the 60 prepandemic controls, we observed 25.0% (15/60; 95% CI 15.7%–37.3%) positive or borderline ELISA results (8). Different from RT-PCR–confirmed cases, ELISA reactivity in those samples contrasted with the complete lack of SARS-CoV-2–specific neutralizing antibodies, suggesting unspecific ELISA reactivity (Figure 1, panel B). 
Unspecific SARS-CoV-2 ELISA reactivity might be consistent with,but not limited to, 3 scenarios. First, antibodies elicited by common infections with endemic human coronaviruses might cross-react with SARS-CoV-2 antigens (1). However, a Fisher exact test showed no statistically significant difference in the frequency of antibody reactivity with common cold coronavirus antigens between SARS-CoV-2 ELISA-positive serum samples compared with SARS-CoV-2 ELISA-negative samples. In detail, reactivity with HCoV-OC43 was 63.6% in SARS-CoV-2 ELISA-positive samples and 70.4% in SARS-CoV-2 ELISA-negative samples (p = 0.7); reactivity with HCoV-HKU-1 was 45.7% in SARS-CoV-2 ELISA-positive samples and 74.0% in SARS-CoV-2 ELISA-negative samples (p = 0.1) (Appendix Figure 1, panel A). Similarly, a Student t-test revealed no statistically significant difference in the magnitude of antibody titers against common cold coronaviruses between SARS-CoV-2 ELISA-positive or ELISA-negative samples (p = 0.09 for HCoV-OC43 and p = 0.8 for HCoV-HKU1) (Appendix Figure 1, panel B). Of note, no serum reacted with MERS-CoV antigens, suggesting that unspecific reactivity might not apply to all coronavirus antigens and tests (Appendix Figure 2). Second, polyclonal B-cell activation can occur in infections with or reactivations of herpesviruses, such as CMV and EBV, and elicit false-positive results in serologic tests (9). However, only 2 patients had a positive CMV PCR and only 1 patient had a positive EBV PCR (Figure 2). In addition, persons with SARS-CoV-2 ELISA-positive versus ELISA-negative results did not differ in their past exposure to EBV, according to detailed serologic analyses (Figure 2; Appendix Figure 3). Finally, polyclonal B cell activation also can be caused by acute malaria, which is widespread in Africa (10). More (71.4%) persons with SARS-CoV-2–positive ELISAs than those with negative ELISAs (54.3%) were positive for Plasmodium in a highly sensitive PCR test, but the difference was not statistically significant by Fisher exact test (p = 0.35; Figure 1, panel C). However, parasite loads were statistically significantly higher among SARS-CoV-2 ELISA-positive than ELISA-negative persons by Student t-test (p = 0.035; Figure 1, panel C). In malaria, higher parasite loads are detected at early stages of infection and decrease over time, suggesting a higher proportion of acute malaria in SARS-CoV-2 ELISA–positive patients compared with likely subacute or chronic malaria in SARS-CoV-2 ELISA–negative patients (11). Thus, acute malaria is the most plausible explanation for unspecific SARS-CoV-2 ELISA reactivity in prepandemic controls. To assess the breadth of unspecific reactivity, we tested the serum samples from prepandemic controls by using a ZIKV IgG ELISA, for which unspecific reactivity has been reported in cases of acute malaria (10). We found that 57.1% of samples that elicited potentially unspecific SARS-CoV-2 ELISA results also showed ZIKV ELISA–positive results, whereas only 23.9% of samples that were SARS-CoV-2 ELISA–negative were ZIKV ELISA–positive. This difference was statistically significant by Fisher exact test (p = 0.019) (Figure 1, panel D; Appendix Figure 4). From the prepandemic controls that were SARS-CoV-2 ELISA positive, no ZIKV ELISA–positive serum samples showed ZIKV-specific neutralizing antibodies, suggesting unspecific reactivity of those samples in the ZIKV ELISA, similar to the discrepant results of SARS-CoV-2 ELISA and PRNT observed in those serum samples (Figure 1, panel E; Figure 2). 
We assessed SARS-CoV-2 antibody-based serologic diagnostics in Benin and noted unspecific reactivity in up to 25% of febrile patients, possibly due to acute malaria. Limitations of our study include the small sample size and limited patient metadata. Testing of serum samples for CMV and EBV by PCR might not have been sensitive due to lack of cell-associated viral nucleic acid; therefore, we cannot exclude potential herpesvirus reactivation affecting serologic testing. Nevertheless, our analyses point to acute malaria as the likely cause of the unspecific serologic reactivity, although we cannot exclude other coexisting conditions in the tropics, such as dengue virus, which also can affect testing (12).
Unspecific reactivity in serologic tests might affect public health interventions in tropical regions, leading to overestimates of SARS-CoV-2 circulation in regions where malaria is endemic and to misidentification of SARS-CoV-2 hotspots. In addition, due to false-positive SARS-CoV-2 results, target populations for vaccine campaigns might be missed when vaccines become available, and coexistent diseases, such as malaria, might be overlooked, leading to higher mortality rates from endemic diseases (13,14). The robustness of current and future SARS-CoV-2 serologic tests should be further assessed by multicentric seroepidemiologic studies from different tropical regions (15).",Emerg Infect Dis
PMC7703507,"Trends in deaths from road injuries during the COVID-19 pandemic in Japan, January to September 2020","The Coronavirus Disease 2019 (COVID-19) has become a worldwide pandemic. Globally, accurate figures on COVID-19 deaths are difficult to determine due to limited availability and quality of virus testing (Pulla 2020), and many countries perform ‘excess death’ monitoring to assess the mortality burden of COVID-19 (Vestergaard, Nielsen et al. 2020). Excess deaths monitoring estimates an increase in all-cause mortality that is higher than expected under normal circumstances.
In Japan, the latest estimates of excess all-cause deaths through January to July 2020 showed that the overall (direct and indirect) mortality burden from COVID-19 in Japan was relatively low compared to Europe and the United States (National Institute of Infectious Diseases, 2020a). From January to July 2020, the national excess all-cause deaths per 100,000 population was approximately 0.2 to 6.0 in Japan, including uncertainty; on the other hand, for example, in the United States, although a complete country-comparison is not always possible given the different estimation algorithms in each country, the excess all-cause deaths from March to September were about 85 per 100,000 population, and in Spain during the similar period, those were 87 per 100,000 population. (The Economist, 2020) However, consistency between the reported number of COVID-19 deaths and excess all-cause deaths was limited across prefectures, suggesting the necessity of distinguishing the direct and indirect consequences of COVID-19 by cause-specific analysis. In particular, if mortality due to causes other than COVID-19 decreases during the pandemic, the excess of direct deaths from COVID-19 may be offset by exiguous deaths—a decrease in mortality that is lower than would be expected under normal circumstances—in some other causes, making it difficult to interpret the mortality burden of COVID-19.
However, cause-specific excess deaths monitoring cannot be conducted in a timely manner in Japan because publication of vital statistics by cause of death is delayed, as is the case throughout the world (Leon et al., 2020). Instead, we used the traffic fatality data reported by the National Police Agency to examine whether deaths from road injuries actually decreased during the COVID-19 pandemic in Japan, consistent with a reduction of road transport activity connected to Japan’s state of emergency declaration. In fact, people’s mobility at transit stations and traffic volumes on major national highways in 2020 decreased from the average year, and it was particularly large in April and May after the state of emergency was declared on April 7, with a decrease of about 30% for each (Google, 2020, Ministry of Land, Infrastructure and Transport, 2020).
We obtained daily open data from 4 January 2010 to 6 September 2020 from the Institute for Traffic Accident Research and Data Analysis (ITARDA), Japan (Institute for Traffic Accident Research and Data Analysis, 2020). ITARDA gathers daily reports on the number of deaths within 24 h of a traffic accident from the National Police Agency. Daily data was converted to weekly data to ensure enough samples for analyses; the first week was from 4 to 10 January 2010 and the last week was from 31 August to 6 September 2020, based on the epidemiological week of Japan’s National Institute of Infectious Diseases’ Infectious Diseases Weekly Report (National Institute of Infectious Diseases, 2020b).
To estimate the expected number of deaths from road injuries and the associated prediction intervals, we employed the Farrington algorithm, which computes a quasi-Poisson regression model and is commonly used to study the annual and seasonal trends of the burden of disease attributable to seasonal pandemics (Vestergaard et al., 2020). The major characteristic of Farrington algorithm is to limit the data for the estimation: the expected number of deaths at a calendar week t is estimated using only the data during t − w and t + w weeks of years h − b and h − 1, where w and b are pre-fixed values and h is the year of t. In this study, we considered b = 5 and w = 3. The limited data is referred to as a reference period. In addition, to incorporate the seasonality into the model, data that is not included in the reference period is equally divided and included in the regression model as dummy variables. Then, the regression model is given by:
1\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {Y}_t\sim QPoisson\left({\mu}_t,{\phi \mu}_t\right),\log \left({\mu}_t\right)=\alpha +\beta t+{\boldsymbol{f}}^T(t){\upgamma}_{f(t)} $$\end{document}Yt∼QPoisson(μt,ϕμt),log(μt)=α+βt+fT(t)γf(t)
where QPoisson(a, b) is a quasi-Poisson distribution with expectation a and variance b, Yt is the number of deaths at a certain week t, α and β are regression parameterss, γf(t) is a regression parameter vector representing the seasonality, f(t) is a vector of dummies that equally divides the time points outside the reference period into nine periods, following the previous study (Centers for Disease Control and Prevention, 2020) and upper subscript T denotes the transpose of a vector. The parameters, including the regression coefficients and overdispersion parameter ϕ, were estimated by the quasi-likelihood approach. More details can be found in Farrington et al. (1996) and Noufaily et al. (2013) (Farrington et al., 1996, Noufaily et al., 2013).
Once the regression parameters were estimated, the expected number of deaths is predicted for the week of interest t0. The two-sided 95% prediction interval was then estimated by assuming that the data follows the negative binomial distribution as \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {Y}_{t_0}\sim NB\left(\hat{Y_{t_0}},\hat{\nu_0}\right) $$\end{document}Yt0~NBYt0^ν0^, where \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{Y_{t_0}} $$\end{document}Yt0^ is the mean of the distribution and \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\nu_0}=\hat{\frac{Y_{t_0}}{\phi -1}} $$\end{document}ν0^=Yt0ϕ−1^ is its dispersion parameter.
We set two thresholds, point estimate and lower bound of the two-sided 95% prediction interval, for exiguous deaths, and report the range of differences between the observed number of deaths and each of these thresholds as exiguous deaths. The percent deficit was defined as the number of exiguous deaths divided by the threshold.
Since January 2020, in some weeks the observed deaths from road injuries fell below the 95% lower bound, such as 6–12 April (exiguous deaths 5–21, percent deficit 2.82–38.14), 4–10 May (8–23, 21.05–43.01), 20–26 July (12–29, 30.77–51.53), and 2–9 August (3–20, 7.32–34.41) (Fig. 1 (A)). However, those less than the 95% lower bound were also observed in weeks in the previous years, particularly in 2019, such as 29 April–5 May (2–17, 4.44–27.91), 13–19 May (10–26, 23.81–44.39), and 8–14 July (3–20, 6.67–31.40). Also, in some weeks including April 5–11, 2020, the observed deaths from road injuries exceeded the 95% upper bound. Weekly exiguous deaths since January 2020 are presented in Table 1 and from 2016 to 2019 are presented in online supplementary Table 1. Similar results were obtained in a sensitivity analysis of only the seven prefectures where a state of emergency over COVID-19 was declared in 7 April 2020 (including Tokyo) (Fig. 1 (B) and Table 2 for 2020 and online supplementary Table 2 for 2016–2019).

Although the age-specific analysis, for which data were not available in this study, may yield different results, the number of road traffic fatalities for all ages during the COVID-19 pandemic has decreased slightly, but not significantly, in several weeks compared to the average year in Japan. Other limitations of this study include that it was not possible to analyse the circumstances under which the traffic accident occurred or to analyse data on deaths within 30 days of the accident, which can refer to cases where a patient died because of a shortage of intensive care unit beds due to COVID-19 and was not treated in time. Our findings suggest that the relatively small changes in excess all-cause mortality observed in Japan could not be explained simply by an offsetting reduction in traffic deaths. Considering a variety of other indirect effects, evaluating an independent, unbiased measure of COVID-19-related mortality burden could provide insight into the design of future broad-based infectious disease counter-measures and offer lessons to other countries (Vestergaard and Molbak, 2020).",Inj Epidemiol
PMC7774556,"Risk for SARS-CoV-2 Infection in Healthcare Workers, Turin, Italy","The ongoing coronavirus disease (COVID-19) pandemic is having an unprecedented impact on the worldwide population. Seroconversion for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) was described to occur 7–14 days after onset of symptoms, 100% within 19 days after clinical onset (1). Recent serologic data suggest that, in affected areas, SARS-CoV-2 infection had been acquired by more persons than what could be extrapolated by PCR analysis of nasopharyngeal swab specimens (1–3).
Large studies reported seroprevalences of 1%–6.9% (2). In February 2020, seroprevalence for 12 blood donors in Lodi, Italy, a heavily affected zone, was as high as 23% (3). Studying high-risk persons, such as healthcare workers, could be relevant for implementing preemptive and protective strategies. In Italy, 30,383 healthcare workers (of 253,619 confirmed cases; 12.0%) have been reported to be infected since the beginning of the pandemic (4).
Active healthcare workers (n = 7,457) from Azienda Sanitaria Locale Città di Torino public hospitals and outpatient services (Turin, Italy) were invited by email and printed leaflets to participate in our study. During April 17–May 20, 2020, they underwent blood withdrawal. SARS-CoV-2 antibodies were measured by using capillary electrophoresis and chemiluminescence immunoassay targeting IgGs against S1/S2 regions of spike protein (LIAISON; DiaSorin, https://www.diasorin.com). This assay has a sensitivity of 97.9% and a specificity of 98.5% and a 94.4% positive agreement with the plaque reduction neutralization test (5). SARS-CoV-2 IgG concentrations were expressed in arbitrary units/mL (AU/mL) and deemed negative if <12 AU/mL. Persons who had equivocal (12–15 AU/mL) or positive (>15 AU/mL) results provided nasopharyngeal swab specimens for SARS-CoV-2 RNA detection by using an in-house real-time reverse transcription PCR, according to Corman et al. (6).
Ethics approval was obtained, and all participants signed an informed consent form. Anonymous data were collected and analyzed by using SPSS Statistics version 26 (IBM, https://www.ibm.com) and described as number (%) or mean ± SD. Disease severity information was not collected.
We tested 5,444 (73.0%) of 7,457 healthcare workers; 4,068 (74.7%) were women. Participants had a mean ± SD age of 49.4 ± 10.6 years. S1/S2 SARS-CoV-2 antibodies were found in 377 (6.9%) participants; 176 (46.7%) had cured COVID-19, 146 (38.7%) had contacts with COVID-19 patients, and 55 (14.6%) had no known epidemiologic link. Seroprevalence was not significantly higher in men than in women (7.9% vs. 6.5%; p = 0.097 by χ2 test), and no differences were observed among age groups. Mean ± SD IgG titer was 49.2 ± 39.5 AU/mL. IgG titers were higher in older participants (Pearson r = 0.227, p<0.001 and p = 0.001 by analysis of variance; Appendix Figure) and in those previously given a diagnosis of COVID-19 (57.9 AU/mL vs. 41.6 AU/mL in those without a previous diagnosis; p<0.001 by t-test).
Detailed task information was available for 4,630 participants. Seroprevalence was highest in laboratory personnel (18/175, 10.3%), although numbers were small, followed by nurse assistants (44/520, 8.5%), nurses (150/1983, 7.6%), and doctors (55/755, 7.3%). A significantly higher seroprevalence was observed in healthcare workers working in close contact with patients versus those with limited/indirect contacts (7.5% vs. 5.2%; p = 0.013 by χ2 test; odds ratio 1.464, 95% CI 1.077–1.992) (Figure).
Among persons who had a previously diagnosed SARS-CoV-2 infection, 176 (82.6%) had S1/S2 SARS-CoV-2 antibodies. Participants without S1/S2 SARS-CoV-2 antibodies were younger (41.4 vs. 49.1 years; p<0.001) and had a shorter time since diagnosis (36 vs. 44 days; p = 0.008). When we excluded persons who previously had COVID-19, all serology-positive participants (n = 201) provided a nasopharyngeal swab specimen for detection of SARS-CoV-2 RNA; 7 (3.5%) were positive.
We found that SARS-CoV-2 infection had been acquired by 6.9% of healthcare workers in Torino, Italy. Variable seroprevalence has been described among healthcare workers in Belgium (7), Spain (8), and Germany (9) (1.6%–9.3%): no major difference in IgG prevalence was found according to job types. In our study, the highest prevalence was observed for healthcare workers in direct contact with patients and the lowest for administrative staff members. S1/S2 IgG titers were higher in older participants and in those who had a previous diagnosis of COVID-19. In an assay validation study in Boise, Idaho, USA, a seroprevalence of 1.79% was reported; older participants had the highest rates (4%, >80 years of age).
Higher titers in symptomatic patients (we presume were healthcare workers given a diagnosis of COVID-19 according to the local testing policy) have been described (https://www.cdc.gov/coronavirus/2019-ncov/lab/resources/antibody-tests-guidelines.html, https://www.who.int/docs/default-source/coronaviruse/whoinhouseassays.pdf?sfvrsn=de3a76aa_2). Although a shorter time from disease onset might explain the lack of antibodies, a lower seroprevalence in younger, previously infected healthcare workers was unexpected. A total of 3.5% of seropositive participants with no previous diagnosis of COVID-19 had positive PCR results for nasopharyngeal swab specimens; this finding might represent late-stage infections with low/no infectivity.
Our study has limitations, including incomplete coverage of healthcare workers (27% did not respond) and lack of complete job description and disease severity for all participants. Some persons did not show development of IgG after having COVID-19; thus, our study could have missed a subset of previously infected persons (10). Despite limitations, our study provides noteworthy estimates about the differential risk for acquiring SARS-CoV-2 infection by healthcare workers according to their specific job setting in a large occupational survey.",Emerg Infect Dis
PMC7774560,"Absence of SARS-CoV-2 Transmission from Children in Isolation to Guardians, South Korea","Coronavirus disease (COVID-19) in children is known to occur mainly from family clusters (1). However, children can be the only infected members in a household, especially when COVID-19 is contracted from relatives or teachers. Such situations raise concerns about isolation because little information is available on transmission of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), which causes COVID-19, during colocation of young children with their uninfected guardians. Although children generally are asymptomatic or have mild symptoms, they could be infective (1,2). We explored whether SARS-CoV-2 was transmitted from children to their uninfected guardians in a hospital isolation setting.
During February 18–June 7, 2020, we analyzed all children <19 years of age with COVID-19 and their uninfected guardians who were isolated together in 7 hospitals in South Korea. The infected children were encouraged to wear face masks. The guardians were advised to wear personal protective equipment (PPE), but the degree of PPE varied among hospitals. Adherence to PPE was monitored by the medical staff; compliance was judged as good when PPE was worn most of the time, fair for frequent adherence, and poor when PPE was worn for less than half of the observed time. Children’s isolation was lifted when 2 consecutive negative respiratory samples were obtained >24 hours apart. To ascertain secondary transmission, guardians’ respiratory samples were tested for SARS-CoV-2 if symptoms developed, before their child’s isolation was lifted, and 2 weeks after the end of isolation. This study was approved by the institutional review board of each hospital and written informed consent was waived.
Among 94 children with COVID-19 isolated in 7 hospitals, 12 children were isolated with a single uninfected guardian (Table). The median age of the patients was 6 years (range 2 months–11 years), and children were isolated for a median of 17 days (range 7–37 days). Most (7/12) children were asymptomatic, 4 had fever or respiratory symptoms, and 1 had pneumonia. Only 4 children cooperated well with wearing face masks.
The guardians included 10 mothers, 1 father, and 1 uncle; all complied with wearing PPE (Table). Most (10/12) guardians wore gloves and masks, either KF94 masks, which filter »94% of particles of 0.4 μm in size, or N95 masks which filter »95% of particles of 0.3 μm in size; 7 also wore gowns or coveralls. One guardian used a surgical mask and 1 guardian wore a KF80 mask, which filters »80% of particles of 0.6 μm, and gloves. Most (10/12) guardians had frequent close contact, but 2 children kept a distance of >1 m from their guardians during isolation. None of the guardians were SARS-CoV-2–positive during the study.
For comparison, we also analyzed 2 cases in which adults with COVID-19 were isolated with their uninfected children because no other caregivers were available (Appendix). The adult patients always wore face masks, but the 2 children never wore PPE and always had physical contact with their parents. However, the children did not become infected. The infected parents’ adherence to the use of masks likely aided in curbing SARS-CoV-2 transmission to their uninfected children by reducing virus particles in respiratory droplets (3).
Appropriate use of PPE, especially face masks, might have protected uninfected guardians in our study. Previous reports have emphasized the use of face masks to prevent SARS-CoV-2 transmission in healthcare and community settings (4). Considering the decreased risk for virus transmission noted with PPE, guardians should be counseled on the proper use of PPE when in isolation with infected children.
We did not observe SARS-CoV-2 transmission from children to guardians in isolation settings in which close proximity would seem to increase transmission risk. Recent studies have suggested that children are not the main drivers of the COVID-19 pandemic, although the reasons remain unclear (5). A large study on contacts of COVID-19 case-patients in South Korea observed that household transmission was lowest when the index case-patient was 0–9 years of age (6). Among pediatric cases, the secondary attack rate from children to household members was estimated to be only 0.5% (7). Reduced transmission from children in households was also reported in Switzerland and China and in educational settings in Australia (8–10). 
This study is limited by its small sample size, which limits the ability to generalize its results. Moreover, we did not assess the patients’ viral load, which could indirectly reflect the infectivity of the children, nor did we assess patient serology, which could further ascertain their infection status. Despite these limitations, our study provides information on SARS-CoV-2 transmission from children to guardians in isolation rooms. Additional assessments of the transmissibility of SARS-CoV-2 by children and the role of PPE in preventing infection could provide guidance during the ongoing pandemic. Nonetheless, our study adds to growing evidence that young children are less likely to contribute to the spread of COVID-19 among their adult guardians. ",Emerg Infect Dis
PMC7774565,"Nosocomial Coronavirus Disease Outbreak Containment, Hanoi, Vietnam, March–April 2020","BMH is Hanoi’s largest national tertiary general hospital, with nearly 3,000 inpatient beds and an average of 5,000 outpatients per day. The hospital has 34 clinical centers, institutes, and departments and 6 paraclinical departments, with >6,000 healthcare workers and nonclinical staff. Three affiliated national institutes are under BMH management: National Heart Institute (NHI), National Institute of Mental Health, and National Institute of Medical Expertise. The first branch of the National Hospital for Tropical Diseases (NHTD) is also located inside the BMH area, but has been a freestanding hospital since 2006. The NHTD has a second branch that was the designated hospital for COVID-19 patients in northern Vietnam, located in a suburban area of Hanoi. BMH has its own infectious disease facility, the Center for Tropical Diseases (CTD), separate from NHTD (Figure 1).
In early January 2020, BMH established 2 dedicated COVID-19 screening triage clinics for suspected cases. These clinics were located in separate areas from other departments of the hospital: the first was next to the main gate, and the second was set up near the CTD (Figure 1). Healthcare workers from the CTD operated both clinics, 1 doctor and 2 nurses working per shift. All patients were required to be screened at the clinics before they received any other services. Clinic staff performed general clinical examinations, gathered epidemiologic data, and classified whether each patient had a suspected case using general criteria issued by the Ministry of Health (MoH), including having >1 suspicious symptom (fever, cough, shortness of breath) and having a history of traveling through epidemic areas or having close contact with a patient with confirmed COVID-19 during the preceding 14 days. Before March 12, nasopharyngeal swab specimens from the suspected cases were transferred to the NIHE for SARS-CoV-2 confirmation. Beginning March 13, the specimens were processed and confirmed at BMH itself. Patients with suspected cases were transferred immediately, in dedicated vehicles, to the second branch of NHTD, even if test results had not yet been received. 
We conducted a desk review of available documents, patient records, and public data collected during March 17–April 15, 2020. We retrieved demographic data from the official COVID-19 database provided by General Department of Preventive Medicine (https://ncov.vncdc.gov.vn). Symptoms and treatment data were systematically collected from the official MoH COVID-19 database (https://ncov.moh.gov.vn) and the MoH official press release website (https://suckhoedoisong.vn).
We established different definitions of suspected cases, as well as a hierarchy of contacts, between the BMH outbreak and standards management in Vietnam in general. The MoH’s general guidelines defined a suspected case as illness in a person who had >1 suspicious symptom and had epidemiologic criteria such as travel abroad or direct contact with suspected cases. Patients with suspected cases were put in centralized quarantine for 14 days and tested for SARS-CoV-2. The contacts were categorized at 3 levels: F1 for close contacts of persons with laboratory-confirmed COVID-19 cases, F2 for close contacts of F1 persons, and F3 for close contacts of F2 persons. F1 persons were also placed in centralized quarantine and tested, whereas F2 and F3 persons were isolated and monitored at home. When a community had several confirmed cases and the index patients had multiple complicated contacts, the lockdown of a small administrative unit (usually at the commune level) was carried out.
In the outbreak at BMH, all persons who visited the hospital during March 10–March 20 were considered as the F1 group, regardless of their exposure to laboratory-confirmed cases. For contact tracing, 4 levels of contacts were followed up, from F1 to F4 (F4 comprised close contacts of F3), which is one level higher than the general guideline. F1 and F2 persons were quarantined at a centralized area, and F3 and F4 persons isolated at home (Table). Affected departments at the BMH area were isolated as soon as cases were detected, and lockdown of the entire hospital was implemented after the confirmation of 8 cases and 4 affected departments (Figure 1).
We tested all F1 persons quarantined at BMH for SARS-CoV-2 using RT-PCR in the microbiology department; persons at the CTD, NHI, and neurology department (ND) were tested 3 times to confirm the situations in these departments, and all others at BMH were tested once. Because of the requirement of >2 negative tests before a person was released from quarantine, Hanoi Center for Disease Control conducted an additional retest for all confirmed cases before the removal of lockdown. The test kits were either donated by the WHO or provided by Viet-A Corporation. In total, an estimated 15,000 tests were analyzed for quarantined persons at BMH. Each test cost »$30 USD.
F1 and F2 persons who were traced and quarantined in the community were provided >1 test by the local Center for Disease Control. The numbers of tests per person depended on the decision of the local steering committee, which considered the occurrence of symptoms and laboratory capacity.
The study was approved by the BMH ethics committee. We applied all ethics considerations needed according to MoH or by its designees.
During March 18–April 14, a total of 46 laboratory-confirmed COVID-19 cases were detected at BMH. The mean age of the patients was 44.9 years, and 80.4% were female. Ten (21.7%) patients were symptomatic; 91.3% had a history of admission to BMH or working or visiting an institute in the BMH complex, including healthcare workers (4.4%), nonclinical staff (58.7%), patients (13.0%), and family caregivers (15.2%) (Figure 2).
Case 86 was in a female nurse working at the HIV outpatient clinic of the CTD. On March 11, she had chest tightness and pain and was admitted to the NHI; her diagnosis was a clinical manifestation of preexisting hypertension illness. She had multiple contacts with CTD staff during lunch and break periods, including the patient with case 87, a 33-year-old female nurse working at the COVID-19 screening clinic who developed fever (38.5°C) and dry cough on March 18 and had a positive test for SARS-CoV-2 on the same day (Figure 2). Quarantine and mass testing were imposed for all of CTD on March 19, involving 159 healthcare workers. NHI was also put in quarantine on the same day; this quarantine included 84 persons (Figure 1).
Case 133 was in a 66-year-old woman who was admitted to Lai Chau General Hospital for stroke on February 29 and was transferred to the BMH neurology department (Figure 2). On March 22, she was transferred back to Lai Chau General Hospital because she developed fever and cough and tested positive for SARS-CoV-2. Quarantine was imposed at the neurology department on March 24 for a total of 252 persons: 162 healthcare workers, 36 patients, and 54 caregivers (Figure 1).
Of the 46 confirmed cases, 27 were from the hospital catering company (Figure 1). These persons provided food and drinks for staff and patients in the hospital and managed the hospital canteens and cleaning tasks. Thus, they moved throughout the hospital and worked close to one another. The reason for the transmission among the company staff might have been the close contact they had during their work without adequate protective equipment. Of the 91 catering company staff who worked at BMH, 28% were SARS-CoV-2 positive. Cases 174 and 184 were symptomatic, with fever and cough, but the others were asymptomatic.
On March 28, the quarantine was extended to all of BMH. A total of 7,664 persons were quarantined: 6,258 healthcare workers and other staff members, 793 inpatients, and 613 of the patients’ related family caregivers (Figure 1).
BMH stopped new admissions on March 20, except for patients with severe and critical conditions. A total of 5,113 inpatients were transferred to local provincial hospitals or other specialized hospitals in Hanoi. These patients had non–COVID-19-related illnesses and were considered safe to transfer; they were managed as F1 persons and received preventive measures from the local government and Center for Disease Control. A total of 793 patients with non–COVID-19-related illnesses required treatment at BMH because of the severity of their illness. These patients were managed with a high level of infection control, including spacing beds >2 m apart, ensuring that all healthcare workers used personal protective equipment, and having healthcare workers using N95 masks when performing aerosol-generating procedures associated with viral spread. In addition, only 1 healthcare worker at a time was allowed contact with a patient, except when a medical intervention required >1 person. Family caregivers were not permitted to have direct contact with patients. Body temperature measurement and mandatory medical reporting for all persons in and out of the hospital, enhanced room air flow, and retraining in infection prevention and control (IPC) were implemented for all the staff. Separate entryways for new emergency cases and routine dialysis patients were set. Other routine outpatients, such as patients with diabetes, hepatitis, or cardiovascular disease, were asked to delay their regular visits and go to local hospitals for care and treatment.
F1 persons were categorized into 7 groups. Four groups had registered information at BMH: healthcare workers, visiting scholars and students, nonclinical staff, and patients (both inpatients and outpatients). The other 3 groups, family, hired caregivers, and other persons who visited patients, could be found only by epidemiologic investigation, self-reported or reported in the local community. In addition, information on all cases was widely available on social media and media outlets, alerting members of the general community about potential exposure if they were at the hospital.
Healthcare workers, visiting scholars and students, severely or critically ill inpatients, and their family and hired caregivers were quarantined and managed at BMH. All other BMH cases from March 10–20 (including 5,113 transferred patients) were traced and managed by the local Hanoi steering committee. A total of 52,239 persons were followed up in the community. Among those who were traced, 27,893 F1 and F2 persons were put in quarantine (Table). Nearly 30,000 RT-PCR tests were performed on F1 and F2 persons in the community.
We describe how nosocomial transmission in a large hospital was contained through extensive testing of all possibly exposed persons, even those without any symptoms; whole hospital quarantine for >2 weeks; contact tracing in the community; and quarantine of all contacts. From the beginning of the COVID-19 pandemic, testing strategy has been an essential intervention in preventing community spread of COVID-19 in Vietnam. As of May 13, 2020, >275,000 SARS-CoV-2 RNA tests had been conducted in Vietnam; the proportion of tests per confirmed case was »950 (12). These measures were put in place to prevent a generalized epidemic and a heavy burden on the healthcare system, which generally was overloaded, with only »9 doctors and 15 nurses per 10,000 population (13). One advantage during the outbreak at BMH was the laboratory capacity and available RT-PCR test kits provided by a local company. About 15,000 tests were done for persons quarantined at the hospital. More than half of these tests were analyzed at BMH itself, which helped to greatly reduce the waiting time for detecting cases. In addition, by March 21, there were 22 licensed laboratories, including 6 provincial Center for Disease Controls, able to perform RT-PCR tests for SARS-CoV-2 across the country, which increased the local case detection capacity.
All of BMH was quarantined after 8 cases of COVID-19 were detected in 4 departments. All persons linked to the hospital, including healthcare workers, inpatients, outpatients, visitors, and close contacts of these persons within 14 days before the lockdown (27,893 persons), were considered as having suspected cases, placed in centralized quarantine, and tested. Modeling suggested that active case tracing and early testing had a major effect on reducing the community transmission of COVID-19, up to 80% (14), and the outcomes from outbreak containment at BMH could provide good empirical evidence for this result. Active case tracing has been implemented in several other countries and has shown remarkable effectiveness (15–18).
Quarantine for all the contacts was the major factor for successful outbreak containment at BMH. However, quarantine was not always an acceptable solution for many other settings because of the lack of resources, facilities, or policy support (19,20). In the case of BMH, the decision on the whole-hospital quarantine was made by considering multiple criteria. The first advantage was the hospital’s beds for transferred-out patients and the new 9-story building that could be used for the accommodation of quarantined persons. Second, the hospital contingency fund and support from the Hanoi city council were rapidly mobilized for food, drinks, and other necessities. In addition, the transmission from an unknown index case might have been the tip of an iceberg of undetected of community transmission in Hanoi that encouraged aggressive actions to prevent widespread community transmission.
Only 10 symptomatic cases were found among the 46 laboratory-confirmed COVID-19 cases in the outbreak (21.7%); 1 patient needed intensive care with mechanical ventilation (2.2%), and there were no deaths. Several large investigations with a similar approach to active case tracking efforts also showed a high rate of asymptomatic patients among persons who tested positive for SARS-CoV-2. For example, in a cohort of 829 employees who worked at Rutgers University and associated hospitals in New Jersey, USA, the prevalence of asymptomatic SARS-CoV-2 cases was 65.9% (E.S. Barrett et al., unpub. data, https://doi.org/10.1101/2020.04.20.20072470). A large population screening in Iceland showed that the positive rate among 13,080 nontargeted citizens was 0.8%, and 43% of SARS-CoV-2 positive cases were asymptomatic (21). In a homeless shelter in Boston, the asymptomatic rate among persons who tested positive for SARS-CoV-2 was 87.8% (22). These results emphasize the importance of detecting mild or asymptomatic COVID-19 cases because they may be vectors for transmission (23; D.C. Buitrago-Garcia et al., unpub. data, https://doi.org/10.1101/2020.04.25.20079103). 
The relatively low rate of transmission to healthcare workers might be the result of use of personal protective equipment and masks, as well as other IPC activities. In addition, the outbreak occurred during a generally cool time of year, so opening windows and doors was still practiced in most of areas of the hospital, which could help to lower transmission risk, compared with having to use air conditioning during the warmer season (24). Most of the cases were in nonclinical staff members, which might be the result of high frequency of exposure with lack of protective equipment as well as work in crowded conditions in the kitchen and canteen. After the first cluster was detected at the CTD, a higher level of infection control was implemented, including retraining in IPC measures for all staff. However, the compliance of nonmedical staff was inadequate, which might be the result of a lack of adequate information, training, and personal protective equipment, as well as management possibly underestimating the severity of the situation. This finding illustrates the importance for healthcare facilities to protect their nonclinical staff by providing appropriate training and adequate protective equipment, because these staff members may be both victims and vectors to other staff and patients (25,26).
The outbreak at BMH contributed to a decision to implement a social distancing campaign throughout Vietnam during April 1–April 14 and in Hanoi for an additional week after that. We found that the BMH outbreak uncovered both nosocomial and unexplained cases likely to have resulted from community transmission. The social distancing campaign might have contributed to reducing community transmission, as indicated in several other settings (27,28). In addition, experiences from the containment of the SARS outbreak in 2003 (29,30), which also occurred at BMH, helped hospital management make quarantine decisions faster. Many frontline healthcare workers who were present during the SARS outbreak 2003 were still working at BMH and contributed to the management, planning, and processing of the COVID-19 outbreak containment. Although containment in the BMH COVID-19 outbreak was successful, the index case was not found.
Our investigation is subject to several limitations. First, we could not estimate the coverage of contact tracing in the community because of the lack of information for some at-risk groups that did not register in the database (family/private caregivers and persons who visited patients). Second, because we did not interview all the patients who tested positive, the source and index cases were not fully interpreted. Finally, we did not perform a complete outbreak investigation, which reduced the validity of the containment outcomes and made it difficult to compare this study with other studies.
In conclusion, the COVID-19 outbreak containment at BMH is a noteworthy example in which a major university hospital was quarantined to prevent further community transmission. Containment of the outbreak in BMH could serve as an example for other settings that are experiencing new outbreaks of this highly transmissible disease. 
We suggest several recommendations to prevent hospital COVID-19 nosocomial outbreaks. Strict triage stations should be established at all entrances; healthcare workers, nonclinical staff, and contract workers should be monitored and those with symptoms recommended to stay home if ill; and other key IPC measures should be instituted at the hospital according to the hierarchy of IPC controls. Protective equipment should be provided to all staff, both clinical and nonclinical, as well as training in how to use it correctly. In addition, cases of severe viral pneumonia should be monitored closely, with SARS-CoV-2 testing recommended when all other possible causes have been excluded. High-risk groups, such as patients with severe acute respiratory infections, healthcare workers, and elderly patients, should also be strictly monitored.",Emerg Infect Dis
PMC7774572,Postmortem Stability of SARS-CoV-2 in Nasopharyngeal Mucosa,"Detailed analyses of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) transmission have shown the virus to be highly transmissible through droplet and contact-transmitted viral spreading; reproduction indices were 2.2–3.6 (1). Amid the coronavirus disease (COVID-19) pandemic, case-fatality rates of up to 9.26% occur in areas hard-struck by SARS-CoV-2 (2). The likelihood of virus transmission through deceased persons remains unclear. However, in recent pandemics of influenza, high and sustainable virus stability and infectivity within corpses were demonstrated (3,4), necessitating careful and conscious handling. To determine the possibility of SARS-CoV-2 transmission through deceased persons, we conducted a study of postmortem viral RNA stability.
The federal state of Hamburg, Germany, has mandated autopsies since March 2020 in accordance with the German Infection Protection Act for all patients with reverse transcription PCR (RT-PCR)–confirmed SARS-CoV-2 infection. Data and sample acquisition for the study were performed during March 22–May 1, 2020. To confirm the initial diagnosis and quantify the viral load in the corpses, nasopharyngeal swab samples (ESwab; Copan, https://products.copangroup.com) were taken at patient admission to the Department of Legal Medicine (University Medical Center Hamburg-Eppendorf). Corpses were stored at 4°C in the refrigerator. Antemortem and postmortem nasopharyngeal swab samples were taken according to recent standards (5) by trained, medically qualified personnel to ensure maximum reliability and consistent quality. Samples were analyzed for SARS-CoV-2 RNA as described previously (6).
The Ethics Committee of the Hamburg Chamber of Physicians approved the study (no. PV7311). The local clinical institutional review board, complying with the Declaration of Helsinki, also approved the study.
Antemortem nasopharyngeal swab samples (Appendix Figure) were collected by medical staff at the intensive care unit of the University Medical Center Hamburg and by general practitioners from on-call duty at a median of 6 days (range 2–14 [interquartile range (IQR) 6.3]) before death (n = 10). Using a Wilcoxon test for paired data, we did not detect any effect of the event of death on the SARS-CoV-2 RNA load (U= −5; p = 0.85). We found no correlation between the postmortem interval (time of death until cooling at 4°C; median 17.8 [range 2.7–482.6]) hours and the viral RNA loads of corpses, as indicated by Spearman correlation of 79 matched datasets (Figure, panel A).
To analyze postmortem stability of SARS-CoV-2 RNA, we selected 11 corpses with short postmortem intervals for a detailed observation over 7 days (168 hours) (Table). The median postmortem interval was 5.7 (range 2.9–32.0 [IQR 6.9]) hours. The median cycle threshold (Ct) of SARS-CoV-2 RNA in swab samples taken at admission was 29.52 (range 15.2–50.0 [IQR 22.5]) (Figure, panel A). We determined viral load in a series of 9 sequential pharyngeal swab samples (time points 0, 12, 24, 36, 48, 60, 72, 96, and 168 hours after admission). We consistently detected SARS-CoV-2 RNA at constant levels at all time points analyzed (Figure, panel B), except for patient 7 at 0, 12, and 24 hours after admission and patient 8 at admission. Because subsequent samples were positive for all corpses, we attributed those discrepancies to deviations in the sample collection. A general mixed model found no time-dependent effect on SARS-CoV-2 RNA loads (estimate −0.06, SE 0.01; p = 0.58) (7). Because of impaired interval-scaling of metric variables, we excluded negative Ct values from the statistical analysis. Intriguingly, the estimate suggests an increase of the viral load without revealing significant results (0.6%/hour).
Six patients in this study (patients 11–16) previously were part of a study in which virus growth from different tissues (including pharynx) of patients dying of RT-PCR–confirmed SARS-CoV-2 infection was investigated (S. Pfefferle, unpub. data, https://doi.org/10.1101/2020.10.10.334458) (Table). That study showed that replicating virus was detected in the throat of patients up to 35.8 hours after death. Both the detection of subgenomic RNA (sgRNA) by next-generation sequencing and virus growth could be shown in those throat samples. We also detected sgRNA by RT-PCR in throat tissue samples of these 6 previously published patients (8–10) (Figure, panel C); samples in which virus could be cultivated (S. Pfefferle, unpub. data, https://doi.org/10.1101/2020.10.10.334458) are highlighted in red.
We demonstrated maintained infectivity of SARS-CoV-2 in tissues of deceased patients. SARS-CoV-2 RNA persisted over time at constantly high titers. Taken together, our data indicate potentially high infectivity of human corpses, requiring hazard assessments in professional fields concerned and careful and conscious handling.
Our infectivity study relies on a limited number of cases and patients with severe immunosuppression. Further research should investigate viral persistence in corpses with longer postmortem intervals (>1 week) and corpses exhibiting lower initial viral loads. We recommend all work on corpses be conducted according to guidelines recently published by the World Health Organization, especially in the framework of widespread death in pandemics (https://apps.who.int/iris/rest/bitstreams/1300088/retrieve).",Emerg Infect Dis
PMC7781006,Vaping and Respiratory Viruses: The End for ENDS?,"The use of electronic cigarettes (e-cigarettes, or electronic
nicotine delivery systems [ENDS]), otherwise known as “vaping,” has been
on the rise worldwide (1). The proponents of the
e-cigarette have touted it as a “healthier” alternative, or simply a
replacement, in traditional cigarette smoking cessation attempts (1). However, the short- and long-term effects of e-cigarettes
remain poorly understood and understudied. Importantly, with the rapid rise of its use,
especially among younger generations, and also spurred by mental stresses during the
severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic, studies of its
effects on human health are ever more crucial in ensuring that users are not in fact
using a more harmful alternative (2).
As e-cigarette usage is a relatively new practice, studies to assess its effects,
especially long-term ones, on human respiratory health remains a challenge. Early
reports had shown that the use of e-cigarettes contributes to respiratory epithelium
cell death and damage, immune cell death, and altered inflammatory responses (3–5) (Figure 1). In addition, the
e-cigarette liquid has also been shown to increase inflammation and susceptibility to
viral infection in primary human airway cells (6). Currently, in the midst of the SARS-CoV-2 pandemic, there is renewed
interest in the relationship between tobacco products and susceptibility to respiratory
viruses, especially those that can cause severe diseases such as influenza viruses and
SARS-CoV-2 (7). Recent findings suggested that
e-cigarette usage may also contribute to an increase in susceptibility to viral
infection, as it alters the antiviral immune response (8). The study by Wu and colleagues found increased susceptibility of primary
human airway cells to viruses (6), but that work
was done using the liquid of e-cigarettes, and direct studies assessing the association
between e-cigarette use and viral susceptibility has been lacking.
In this issue of the Journal, Rebuli and colleagues (pp. 126–137)
begin to address this by reporting on a series of experiments comparing cigarette and
e-cigarette users with nonsmokers in terms of their responses to live attenuated
influenza virus (LAIV) vaccine, a surrogate for viral infection (9). To assess the systemic effects of e-cigarette use and
antiviral responses, the group recruited volunteers and inoculated them with the FluMist
LAIV vaccine (Figure 1). They then followed up by
collecting nasal lavage fluid (NLF), nasal biopsy samples, and nasal epithelial lining
fluid for comparison of responses between the groups. Following inoculation, they found
no change in NLF viral loads between groups, a result that differed from a previous
study possibly because of the lower average number of cigarettes smoked (10). However, the mucosal IgA levels in NLF
values did differ significantly, such that influenza-specific IgA levels were lower in
both cigarette and e-cigarette groups, an indication of impaired humoral immunity
against the virus and/or vaccine.
The group then assessed the nasal epithelial gene expression changes following LAIV
inoculation between the groups using their nasal biopsy samples. The assessment allowed
the comparison of how the e-cigarette usage group fared in terms of their antiviral
responses. The time points of Day 1 and Day 8 postinoculation allowed assessment of both
early innate and late adaptive changes in response to the LAIV vaccine. Interestingly,
the e-cigarette group was found to fare worst among the groups. Although both the
cigarette and e-cigarette groups exhibited suppressed response genes, the e-cigarette
group experienced a greater suppression. In addition, the e-cigarette group also showed
consistent suppression in their cytokine profile, in which key antiviral cytokines
including IFNγ, IL-6, and IL-12p40 were markedly reduced. The general finding from
the gene expression and cytokine profiles suggested that innate epithelial responses,
initial cross-talk between epithelium and innate immune cells, and potentially the
cell-mediated and humoral immune responses were all suppressed by e-cigarette usage.
With a blanket suppression of the antiviral responses following LAIV inoculation, it is
hence not surprising that the accompanying covariate analysis identified tobacco
products, specifically e-cigarettes in this study, to interact and influence host
antiviral defenses against LAIV. Overall, the findings from this study suggest that
e-cigarette use suppresses physiological anti-influenza responses. As responses to viral
pathogens tend to be similar, it is possible that e-cigarettes might also increase
susceptibility to other respiratory viruses, but that would need to be confirmed by
further study. Nevertheless, this study convincingly shows that protection against
influenza conferred by the LAIV vaccine was markedly reduced, as manifested by the
lowered IgA production in the e-cigarette group. This finding is important as it may
also affect efficacy of other vaccines such as the SARS-CoV-2 vaccines currently in
development and testing pipelines.
In summary, this study provides novel information regarding the effects of e-cigarette
use on antiviral responses, which is important in the context of the current SARS-CoV-2
pandemic. Findings from this study set the baseline of e-cigarette usage and respiratory
viral infections, which may be relevant to the development of public health policies
regarding e-cigarette usage. Future studies can build upon this to assess viral
susceptibility using live virus infection, as although LAIV retains the ability to
replicate, it does not possess certain virulence factors that may alter the course of
infection. Live infections can be tested in physiologically relevant models, such as the
air–liquid interface human airway epithelial cells (hAECs), which is an
established model for respiratory viral infections (11–13). The hAECs model
subjected to e-cigarette vapor followed by infection could be suitable for comparing
viral load after infection, providing a more accurate assessment of susceptibility
toward respiratory viruses. That assessment can also be extended to include a comparison
of epithelial-immune cross-talk via immune cell coculture models of hAECs (14). Susceptibility to other viruses that cause
milder infection, such as rhinoviruses (15),
can be assessed using live virus inoculation in human subjects. Finally, the authors
rightly point out the need for causative verification via longitudinal studies in
e-cigarette users to compare their frequency and severity of viral infections with
nonsmokers. These future studies will likely confirm the detrimental effects of
e-cigarettes identified in this study, thereby underscoring the public health threat
they may pose.",Am J Respir Cell Mol Biol
PMC7774575,Performance of Nucleic Acid Amplification Tests for Detection of Severe Acute Respiratory Syndrome Coronavirus 2 in Prospectively Pooled Specimens,"The Stanford Clinical Virology Laboratory receives samples from tertiary-care academic hospitals and affiliated outpatient facilities in the San Francisco Bay Area of California. Prospective pooling of consecutive nasopharyngeal or oropharyngeal swab specimens submitted for SARS-CoV-2 testing during the morning shift was conducted during June 10–19, 2020, for evaluation of a pool size of 8 and during July 6–July 23, 2020, for evaluation of a pool size of 4. Samples submitted for testing were collected from symptomatic and asymptomatic inpatients and outpatients, either for clinical care or in the context of COVID-related epidemiologic surveillance studies and drug trials at our institution. As samples from persons enrolled in these studies and trials were received daily in batches, they were randomly evenly distributed among pools on a daily basis. This distribution was conducted to preserve the independence between samples in the same pool; these samples had not been tested before receipt in our laboratory and were otherwise treated identically to nonresearch samples. Nonresearch samples were otherwise assigned to pools consecutively. Additional laboratorywide data on proportion of tests positive and cycle threshold (Ct) value distribution were obtained from all specimens (n = 74,162) tested during March 1–June 24, 2020. This study was conducted with Stanford institutional review board approval (protocol no. 48973), and individual consent was waived.
In this study, an initial pool size of 8 was selected on the basis of pilot experiments with pool sizes ranging from 4 to 10 (B.A. Pinsky, unpub. data), and the logistical consideration that pooling in multiples of 4 would be more efficient for the robotic liquid handlers in our laboratory. After review of the test performance characteristics of 8-sample pooling in conjunction with the results of an independent stochastic simulation model, additional testing was performed to evaluate a pool size of 4 to generate empiric data for further model validation. Subset analyses of first tests versus follow-up tests were conducted by retrospectively assigning pools to 1 of the 2 groups on the basis of the status of the positive sample(s) in that pool. Pools containing positive samples belonging to both groups were excluded from this analysis. To validate the performance of the model for additional pool sizes, an external in silico dataset was obtained on the basis of pool sizes of 3 and 5. The in silico analysis was performed according to US Food and Drug Administration recommendations (Appendix) (13).
Pools were constructed before nucleic acid extraction by combining 500 μL from each of the individual samples. For a pool size of 8, this resulted in a total volume of 4 mL and a dilution factor of 1:8. For a pool size of 4, this resulted in a total volume of 2 mL and a dilution factor of 1:4.
Subsequently, total nucleic acids were extracted from 500 μL taken from each pool and each individual specimen by using QIAsymphony and the QIAsymphony DSP Virus/Pathogen Midi Kit (QIAGEN, https://www.qiagen.com) and eluted into 60 μL of AVE buffer according to manufacturer’s instructions. Real-time reverse transcription PCR (rRT-PCR) was performed by using an emergency use authorization laboratory-developed test (LDT) targeting the envelope gene with the Rotor-Gene Q Instrument (QIAGEN) as described (14–16), with pooled samples tested on the same run as component individual samples. A Ct result of 40–45 was considered an indeterminate result, which was adjudicated by repeat testing and resulted as positive if reproducible with an acceptable amplification curve. Specimens were only reported as negative if the internal control human RNase P gene was detected at a Ct<35.
On the same day as QIAsymphony extraction, another 500 μL from each pool was transferred to a Hologic Panther Specimen Lysis Tube (Hologic, https://www.hologic.com) and tested by using the Panther Fusion SARS-CoV-2 Assay (Hologic) and Panther Aptima SARS-CoV-2 assay (Hologic) per the manufacturer’s recommendations (17,18). In addition to the manufacturer-set cutoff value, receiver operating characteristic (ROC) curve analysis of pooled relative light unit (RLU) values, with individual test results as the reference method, was used to determine the optimal RLU discrimination threshold. A focused electronic medical record review was conducted for all samples.
ROC curve analysis was conducted by using R package pROC (19). PPA and negative percent agreement (NPA) were calculated by using individual testing as the reference method and were reported with exact (Clopper-Pearson) 95% CIs (20). Passing-Bablok regression was used to compare Ct values of the individual LDT, pooled LDTs, and pooled Panther Fusion assays. The 95% CIs of slope, intercept, and bias were calculated by using an ordinary nonparametric bootstrap resampling method with default parameters in R package mcr. Paired t-tests were used to compare the mean differences between paired Ct values among different assays. A Student t-test was used to compare the mean difference between internal control RNase P Ct values in false-negative and true-negative pools. All comparisons were 2-sided with type I error set at 0.05. We used the laboratory-wide Ct value distribution and a separate limit of detection (LoD) experiment to develop a stochastic simulation model to estimate PPA and efficiency for a 2-stage pooled testing algorithm, which was subsequently validated by using the independent empiric pools of 8 and pools of 4 data, as well as in silico pools of 5 and pools of 3 data. We provide the methods used to develop this model (Appendix).
To evaluate a pool size of 8, a total of 112 pools from 896 samples were each tested on 3 different NAAT platforms (Table 1). Two pools were invalid, 1 by the Panther Fusion assay (0.9%), and 1 by the Panther Aptima assay (0.9%), and were excluded from subsequent analysis. All 16 individual samples in these 2 pools showed negative results. The remaining 110 pools contained 880 individual samples. Four samples were tested in duplicate in 2 different pools and showed identical results. Among the 880 individual samples, 58 (6.6%) showed positive results and a median Ct value of 31.4 (interquartile range 22.1–35.5). First-time diagnostic specimens had a higher median Ct value than specimens that underwent follow-up tests (Table 2). ROC curve analysis for the Panther Aptima showed optimal cutoff values between 343 and 393 RLUs; a cutoff value of 350 was chosen as the nearest round number (Panther Aptima-350) (Appendix Table 1, Figure 1).
Among the tested pools of 8, a total of 41.8% (46/110) contained >1 positive sample. The positive pools comprised 36 pools with 1 positive sample, 9 pools with 2 positive samples, and 1 pool with 4 positive samples (Table 3). There were 3 false-positive pools, 1 on each platform, in which each of the individual samples showed negative results. The overall PPA of pooled testing ranged from 71.7% to 82.6%, and NPA ranged from 98.4% to 100.0% (Table 4). The 14 pools containing positive first-time diagnostic samples had higher PPAs than the 28 pools containing positive follow-up test samples in an LDT (Appendix Table 3).
There were 16 total pools for which >1 method showed false-negative results. Except for the 1 pool containing 4 positive specimens, which was not detected by Panther Aptima using the manufacturer’s cutoff value (Panther Aptima-M), the remaining 15 false-negative pools each contained only 1 positive specimen. For all missed pools, the Ct value of the individual positive sample was >34 (median 36.6, interquartile range 35.5–37.7) (Figure 1). Among individual positive specimens in the dataset for pools of 8, a total of 22 (37.9%) had Ct values >34. A total of 13/22 (59.1%) were false negative for the LDT, 11/22 (50.0%) for the LDT Panther Fusion, 15/22 (68%) for the LDT Panther Aptima-M, and 8/22 (36.4%)for the LDT Panther Aptima-350. Each of these false-negative samples was collected from known symptomatic or convalescent-phase patients being monitored for viral clearance; none of these samples were initial diagnostic specimens. The pooled LDT RNase P internal control Ct values were similar in false-negative (mean 23.5, 95% CI 22.7–24.3) and true-negative (mean 23.4, 95% CI 22.7–24.1; p = 0.7) pools.
For pools containing only 1 positive sample, the pooled rRT-PCRs showed positive systematic bias when compared with the individual LDT assay, as shown by the Passing-Bablok regression intercept value being >0. Mean bias between pooled and individual Ct values was 3.4 cycles (95% limits of agreement 1.2–5.6; p<0.001) by LDT and 4.0 cycles (95% limits of agreement 0.0–8.0; p<0.001) by Panther Fusion (Figure 2). Panther Fusion showed negative proportional bias when compared with individual and pooled LDTs, as shown by Passing-Bablok regression slopes with 95% CIs that do not contain 1. This result is additionally highlighted in the Bland-Altman plots, which demonstrate that at higher Ct values, Panther Fusion outperforms the LDT.
The modeled PPA estimate is sensitive to the input parameters of proportion of positive tests, assay analytical sensitivity, and viral load distribution. The analytical sensitivity of the assay is approximated in this model by the Ct value corresponding to the probability of detecting 95% of true-positive samples, otherwise known as the 95% LoD. Specimens with Ct beyond the LoD are assigned a decreasing probability of detection on the basis of a probit regression curve, the shape of which was determined in the initial validation of the LDT (Appendix Figure 5). The viral load distribution of the tested population is approximated in this model by the proportion of samples with Ct greater than the LoD. This makes the model output independent of the actual LoD Ct value itself, enabling the model to be used across different rRT-PCRs.
If the assay analytical sensitivity is kept constant, but the tested population changes such that a greater proportion have a Ct value beyond the 95% LoD, PPA decreases (Figure 3, panel A). Conversely, if the patient population is kept constant, but assay analytical sensitivity increases (i.e., from lower Ct LoD to higher Ct LoD), PPA increases (Figure 4, panel A). However, if assay analytical sensitivity changes and the tested population shifts accordingly such that it retains the same proportion Ct >LoD, then the PPA stays constant (Appendix Figure 6). In contrast, the average expected tests per sample is almost entirely determined by pool size and prevalence, whereas analytical sensitivity (LoD Ct) and the underlying Ct distribution minimally affect efficiency because of small absolute numbers of false-positive pools (Figure 3, panel B; Figure 4, panel B). To achieve a 5% absolute difference in efficiency with an increase in LoD Ct from 32 to 40, a prevalence of 25% would be required.
Both PPA and tests per sample are highly dependent on pool size and prevalence of infection. As prevalence increases, PPA can counterintuitively increase with larger pool sizes because there is a greater likelihood of having more than 1 positive sample in a given pool, which would be expected to increase PPA. Similarly, test efficiency can decrease with larger pool sizes because the likelihood of deconvoluting a positive pool increases. Estimated PPA and average tests per sample for inputs of percentage of positive tests 0.1%–15.0% and proportion of samples with Ct value above the LoD ranging from 5% to 30% are available (Appendix Table 4).
One-way deterministic and probabilistic sensitivity analyses incorporating uncertainty in the underlying model assumptions of dilutional effect and probit regression shape demonstrate a moderate (±2% to ±7%) effect on PPA, which is more pronounced with larger pool sizes and proportion of Ct values above the LoD (Appendix Figure 7). In contrast, these parameters have a much smaller effect on testing efficiency (Appendix Figure 8). The 95% CIs for the empirically determined and modeled PPAs overlapped for most of the evaluated empiric datasets, although these values overestimated PPA for the LDT follow-up tests only subset (Figure 5). For the in silico validation data, the modeled PPA was similar for pool sizes of 5 and 3, despite in silico data analysis predicting a higher PPA for pools of 3. Modeled testing efficiency was actually slightly higher for pools of 3 than pools of 5, which was probably caused by the high prevalence of 19.1% in this dataset (Appendix Table 3).
In this study, >1,600 samples were tested in pool sizes of 8 and 4 by using 3 different SARS-CoV-2 platforms, and pooled testing showed decreased PPA relative to individual samples. False-negative results occurred exclusively in pools containing samples with low estimated viral load (Ct >34). Overlapping CIS in PPA and NPA at each pool size suggest that the lower test performance is inherent to the pooling process itself, rather than the assay. Although Panther Fusion Ct values were on average higher than those of the LDT, the negative proportional bias suggests that at low estimated viral loads (Ct >36), the Panther Fusion outperformed the LDT. This finding might be caused by the different targets of amplification (envelope gene versus open reading frame 1ab) or PCR efficiency. These subtle differences between the 2 assays highlight the method-dependent nature of test performance, a variable that cannot be anticipated, and therefore is not explicitly accounted for in most statistical models of pooled testing. Thus, method comparison studies should be performed before large-scale implementation of any pooled testing strategies, especially those that use different platforms for the pooled and individual stages of testing.
The findings of our study contrast with those of a recent study, which concluded that pooling in groups of 8 did not compromise test performance (5). This finding might be explained by differences in patient population, higher proportion of positive pools and rRT-PCR result interpretation. Another recent study of artificially constructed pools reported no major decrease in sensitivity in pools of <32 samples (3). This finding is probably explained by the relatively low starting Ct values of individual positive samples in this study; none exceeded a Ct of 30. However, this study and other experimental studies have shown empirical increases in pooled Ct values directly proportional to dilution factor, a relationship that was also observed in our study (3,4,9).
These differences highlight the effect of viral load distribution and assay analytical sensitivity on pooled test performance, both of which should be taken into account when choosing pool size and diagnostic assay. Although samples with Ct values >33 have not been reported to produce cultivable virus in convalescent phase COVID-19 patients (21), >15% of first-time diagnostic specimens in our laboratory were detected at a Ct
>35. A similar proportion of weakly positive samples that had high Ct values at a public health department virology laboratory in New York has been described (S.B. Griesemer, unpub. data). Assays with lower analytical sensitivity may miss specimens with late Ct values, for which the potential associated burden of onward transmission is currently unclear.
The stochastic model in this study demonstrated that expected PPA between pooled and individual rRT-PCRs was highly dependent on assay analytical sensitivity (represented by 95% LoD), viral load distribution of test-positive patients (represented by proportion Ct >LoD), pool size, and disease prevalence (represented by proportion of tests positive). The model outputs were not always intuitive; larger pool sizes were not always less sensitive or more efficient. With increased prevalence, larger pool sizes were more sensitive because they were more likely to contain >1 positive sample/pool. They were also less efficient because a larger proportion were positive and required deconvolution.
The model output was largely independent of the actual LoD and viral load-to-Ct value relationship of a given assay, making it generalizable across different rRT-PCRs. The only input parameters it requires are the proportion of positive test results and the proportion of samples with Ct >LoD, both of which should be readily available to any laboratories conducting clinical testing. Future studies on the sensitivity of pooled testing strategies should report these parameters.
Previous models of pooled testing strategies for SARS-CoV-2 have primarily examined the effect of pool size and prevalence on testing efficiency but have not addressed the expected decrement in assay sensitivity that accompanies a putative increase in efficiency (6,22). Those studies that have examined sensitivity did not explicitly model the effect of variable viral load distribution of test-positive patients, a parameter that can vary based on the underlying patient population (asymptomatic versus symptomatic and severe versus nonsevere), purpose of testing (diagnostic versus follow-up), and specimen type (8,23–27). In addition, previous modeling studies and in silico analyses have mostly used the Ct cutoff value of the assay, assuming 100% detection below the cutoff value, and 0% detection above it. In contrast, our model incorporates the probabilistic nature of detection at and above the LoD, which better approximates reality.
Our approach is limited by the generalizability of the probit regression shape and the equation estimating dilutional effect, as demonstrated by the variability seen on probabilistic and deterministic sensitivity analysis. Furthermore, the model assumes that the PCR is 100% efficient and that it is devoid of any proportional bias between individual and pooled tests. In addition, the model might underestimate PPA and efficiency of pooled testing if samples in each pool are not independent; placing samples with higher pretest probability in the same pool would decrease the total number of positive pools and increase the likelihood of detection. This feature could be leveraged by pooling specimens from persons in the same household or social distancing pod, such as coworkers on the same shift or students sharing a classroom. These factors, among others, might be the reasons for which the probabilistic sensitivity analysis CIs often did not contain the empiric point estimate in our validation data. These unaccounted-for factors might limit the ability of the model to provide a reliable point estimate.
The strengths of our study include its relatively large sample size, prospective rather than experimental construction of pools, and assessment of 2 different pool sizes. It also compared 3 different SARS-CoV-2 assays, 2 of which are commercially available on highly automated platforms suitable for large-scale testing. Our study was limited by its assessment of only a 2-stage pooling strategy. An additional limitation includes selection bias because the proportion of positive test results in the study specimens was higher because of the inclusion of follow-up samples from known COVID-19 patients enrolled in clinical research studies. Finally, test performance might vary depending on specimen collection medium, which we did not assess in this study (S.B. Griesemer, unpub. data).
In conclusion, a 2-stage pooled testing strategy for detection of SARS-CoV-2 by nucleic acid amplification is feasible and has the potential to strongly increase testing capacity. However, increased pool size and efficiency can compromise PPA. More studies examining early viral load kinetics and infectiousness are needed to fully evaluate the risks versus benefits of pooled testing. We provide a model to predict optimal pool size and associated expected PPA based on limit of detection, Ct value distribution, and proportion of positive test results. If this model can be externally validated, it might be useful in guiding SARS-CoV-2 pooled testing in other laboratories and as part of an adaptive risk-based strategy.",Emerg Infect Dis
PMC7780994,Rapidly Deployable Mouse Models of SARS-CoV-2 Infection Add Flexibility to the COVID-19 Toolbox,"The global severe acute respiratory syndrome coronavirus 2
(SARS-CoV-2) pandemic continues to progress quickly, with over 36 million people
infected and over 1 million deaths associated with SARS-CoV-2 by early October 2020.
Large-scale clinical trials have observed improved outcomes in some individuals with
severe coronavirus disease (COVID-19) after treatment with dexamethasone and
hydrocortisone (1, 2). However, no treatment has been identified that significantly
reduces infection or hospitalization rates. The repurposing of many antiinflammatory or
antiviral drugs has also, as yet, failed to show significant impact on disease.
Therefore, there is an urgent need to improve our understanding of SARS-CoV-2 infection
and pathogenesis and develop new therapeutic and preventative treatment strategies.
One approach to identify novel disease mechanisms and therapeutic targets has been
large-scale screening in preclinical small animal models, particularly mice. SARS-CoV-2
cell entry is mediated by binding of the viral S (Spike) protein to hACE2 (human
angiotensin-converting enzyme 2) that is broadly expressed in the respiratory, but also
the nasal and gastrointestinal, epithelium (3).
Unfortunately, mouse ACE2 shows limited binding to the SARS-CoV-2 S protein, meaning
commercially available wild-type (WT) inbred mouse strains are not useful in the study
of SARS-CoV-2 infection. In this issue of the Journal, Han and
colleagues (pp. 79–88) describe a rapid mouse model of SARS-CoV-2 infection
utilizing a recombinant human Ad5-hACE2 (adenovirus type 5–expressing hACE2) that
results in hACE2 expression and supports SARS-CoV-2 replication in the lower respiratory
tract of WT mice (4).
In Ad5-hACE2 mice, SARS-CoV-2 replication is restricted to the respiratory tract,
especially type 2 pneumocytes, and the infection is associated with mild to moderate
interstitial and perivascular inflammation localized to areas of the lungs expressing
hACE2 (4). The observation that the severity of
SARS-CoV-2 infection may be tightly linked to the cellular and anatomical tropism
provided by hACE2 distribution is supported by other SARS-CoV-2 mouse models. For
instance, hACE2 expression under the K18 (human Keratin 18) promoter
leads to expression of the protein not only in the respiratory tract but also in the
small intestine, kidneys, liver, and other organs and results in lethal disease
associated with severe pneumonia and viral dissemination (5). However, hACE2 expression under the
HFH4 (FOXJ1) promoter leads to expression in the
ciliated epithelium as well as the nervous system, resulting in neuroinvasion of
SARS-CoV-2 (6, 7). In contrast, knocking hACE2 into the murine
Ace2 promoter results in SARS-CoV-2 replication largely restricted
to the conducting airways, producing mild inflammation, as does the mouse-adapted
SARS-CoV-2 with enhanced S binding to mouse ACE2, highlighting the differential
expression pattern of ACE2 in mice compared with humans (6, 8, 9). Importantly there is evidence that the
distribution of hACE2 can be highly influential in determining the outcome SARS-CoV-2
infection in humans and tonally regulated by underlying conditions such as chronic
obstructive pulmonary disease or environmental exposures including rhinoviral infection
or smoking (10–12).
These multiple approaches to generate mouse models of COVID-19 have resulted in a diverse
range of models allowing researchers to mimic the different outcomes and features of
SARS-CoV-2 infection in humans, from asymptomatic to severe multiorgan disease. Of these
models, however, the use of adenoviral vector delivery systems has several advantages,
most prominently being the ability to rapidly establish infection in a range of animal
strains, including WT inbred mouse strains, genetically modified animals used for
mechanistic studies, and models that mimic comorbidities such as obesity and diabetes.
Caveats to this approach do exist, especially the possible antiviral immune responses
elicited by the adenoviral vectors, which could alter the responses to, and replication
of, SARS-CoV-2. There is also a risk of nonphysiological expression patterns of hACE2.
However, two other groups have used similar Ad5-hACE2 approaches to generate a
SARS-CoV-2 mouse model with similar outcomes (13, 14), indicating that the system
is robustly reproducible. In addition, another study has used different adenoviral
vectors, such as adenovirus-associated virus 9 (AAV9) hACE2 (15), highlighting the potential of this approach to modulate and
modify the expression pattern of hACE2 in the mouse.
One biological process Han and colleagues highlight from their work as a possible
determining factor of disease severity is the effects of IFNs. They find a type I IFN
transcriptional signature in the SARS-CoV-2–infected Ad5-hACE2 mice (4) similar to observations in studies using
Ad5-hACE2 mice (9) and AAV-hACE2 mice (15) and in patients with COVID-19 (16). Intriguingly, there are suggestions that
type I IFNs are not sufficiently induced in the early days of infection, resulting in
higher viral load, but that these cytokines are highly expressed later during the
infection, potentially driving the inflammatory response (16). Furthermore, a recent study shows a strong genetic
correlation of the type I IFN system with severe COVID-19 (17). This will be important to study in mouse models, as early
studies suggest that type I IFNs can influence viral load (13) and can be drivers of inflammation during SARS-CoV-2
infection (15).
In summary, different mouse models, including the one described by Han and colleagues,
are needed to aid in generating the mechanistic insight we currently lack. We do not
know how an effective anti–SARS-CoV-2 response develops or anything about the
early drivers of disease. The aim of these models is to replicate the human disease, or
aspects thereof, as closely as possible, and although none currently utilized perfectly
recapitulate either the biology or pathology of clinical infection, dependent on the
question asked, the use of several animal models should prove beneficial (as summarized
in Figure 1). For example, the rapidly deployable
Ad- or AAV-hACE2 models may be useful in screening antivirals (4, 13, 14), whereas the K18-hACE2 mouse could be more
useful in vaccine development. However, elucidating disease mechanisms is likely to
require a more specific human ACE2 knock-in model or a mouse-adapted strain of
SARS-CoV-2. The models in which more prolonged disease is observed may also prove
advantageous in following and perhaps manipulating long-term inflammatory responses and
lung tissue repair mechanisms, thereby providing insight during the puzzling
“long COVID” in individuals recovering from SARS-CoV-2 infection.",Am J Respir Cell Mol Biol
PMC7781002,Lung Expression of Human Angiotensin-Converting Enzyme 2 Sensitizes the Mouse to SARS-CoV-2 Infection,"Additional methodological details are included in the data supplement. Wild-type C57BL/6J mice were housed and bred in the animal facility of Tulane University School of Medicine. The International Care and Use Committee of Tulane University reviewed and approved all procedures for this experiment (permit number P0443). The Tulane National Primate Research Center is fully accredited by the Association for Assessment and Accreditation of Laboratory Animal Care.
We oropharyngeally transduced the mice with 1.5 × 109 plaque-forming units (PFU) of Ad5-hACE2 or Ad5-empty vectors (Vector Biosystems, Inc.) under Animal Biosafety Level 2 (ABSL2) conditions. hACE2 expression at the transcriptional level in the lungs was determined by qRT-PCR using specific primer pairs for hACE2 and hypoxanthine-guanine phosphoribosyltransferase as the internal control (Cat. No. 4331182; Thermo Fisher). Based on the profiling study, we determined the appropriate day after transduction for infecting the mice with SARS-CoV-2 intranasally by the ABSL3-trained staff with 5 × 104–2 × 105 median tissue culture infectious dose (TCID50) per nostril.
Five microliters of total RNA was added in triplicate to a 0.1-ml fast 96-well optical microtiter plate (Cat. No. 4346906; Thermo Fisher). qRT-PCR reaction (20 μl) was set using TaqPath 1-Step Multiplex Master Mix (Cat. No. A28527; Thermo Fisher) and a premix of forward and reverse primers and a FAM-labeled probe targeting the N1 amplicon of N gene (2019-nCoV RUO Kit, Cat. No. 10006713; IDT-DNA) of SARS-CoV-2 (accession MN908947), following the manufacturer’s instructions. Viral load was calculated by the linear regression function by Cq values acquired from 2019 nCoV qRT-PCR Probe Assays (27805681; Integrated DNA Technologies). The viral copy numbers from the lung samples are represented as copies/100 ng of RNA. Subgenomic mRNA (sgmRNA) encoding the E gene was quantified using a published assay (19).
Data are expressed as mean ± SEM. To compare values obtained from multiple groups over time, two-way ANOVA (Kruskal-Wallis test) was used. To compare values obtained from two groups, two-tailed unpaired student’s two-tailed unpaired Student’s t test was performed. Statistical significance was taken at the P < 0.05 level.
To transduce the expression of hACE2 in the mouse lung, we administered adenovirus 5–expressing hACE2 (Ad5-hACE2) oropharyngeally to wild-type B6 mice (Figure 1A). hACE2 was detected in the lung of Ad5-hACE2 mice at transcriptional levels at 1 day post transduction (pt), peaked at 4 days pt, and then declined and maintained a level at 7, 10, and 14 days pt comparable with the level at 1 day pt, indicating that hACE2 starts to maintain stable levels after 7 days pt (Figure 1B). We infected mice at 4 days pt with SARS-CoV-2 (intranasal delivery of 2 × 105 TCID50 per mouse) (Figure 1A). Infected Ad5-hACE2 mice had several log-fold higher SARS-CoV-2 loads in the lungs than Ad5-empty mice at 3, 6, and 12 days post infection (dpi) (Figures 1C and E1 in the data supplement). In the infected Ad5-hACE2 mice, the viral load in the lung reached the highest level at 3 dpi and gradually declined from 3 to 12 dpi to a level that was still significantly higher than infected Ad5-empty mice (Figure 1C). We did not detect any significant difference in viral loads in the livers and intestines of infected Ad5-hACE2 and Ad5-empty mice. Furthermore, using immunohistochemistry, we detected SARS-CoV-2 virus in the lungs of SARS-CoV-2–infected Ad5-hACE2 but not Ad5-empty mice at 3 dpi (Figure 2A). Similarly, infectious virus was isolated from lungs of three of four Ad5-hACE2 but not Ad5-empty mice killed at 3 dpi assessed by plaque assay (titer ranging from 0 to 1,332 PFU/ml in the Ad5-hACE2 mice) (Figure 2B) whereas the sgmRNA encoding the viral E protein was likewise amplified from lungs of three of four Ad5-hACE2 (ranging from 0 to 3.7 log viral RNA copies/100 ng of total RNA) but not Ad5-empty mice with the level of sgmRNA associated strongly with the PFU titer (Figure 2C). We also detected sgmRNA from lungs of three of four and one of four Ad5-hACE2 but not Ad5-empty mice at 6 and 12 dpi, respectively (Figure 2C). Unexpectedly, live virus was not detected in lung from one Ad5-hACE2 mouse at 3 dpi and sgmRNA was not detected in lungs from one Ad5-hACE2 mouse at 3 and 6 dpi. These data could be due to inherent variability associated with detecting live virus or viral RNA in a solid tissue sample, suboptimal storage of the samples, or another reason. Nonetheless, these results indicate that lung expression of hACE2 sensitizes the mouse to SARS-CoV-2 infection.
Infected Ad5-hACE2 mice developed more severe lesions in lungs than infected Ad5-empty mice at 3, 6, and 12 days after SARS-CoV-2 infection, namely, interstitial and perivascular inflammation associated with infiltration of large numbers of lymphocytes and macrophages (Figures 3A, 3B, and 3C). Lesion development began at 3 dpi, reached peak level at 6 dpi, and partially resolved at 12 dpi (Figure 3D). We found no histological changes in other organs including liver, kidney, intestine, heart, and brain in Ad5-hACE2 and Ad5-empty mice (Figure E2). There were no significant differences in body weight, blood cell counts, or serum chemical measurements between the two groups (Figures E3 and E4). Of note, the Ad5-hACE2 mice infected with three different doses of SARS-CoV-2 (5 × 104, 1 × 105, or 2 × 105, TCID50) also developed mild or moderate interstitial and perivascular inflammation in the lungs (Figure E5). Together, these results indicate that lung expression of hACE2 sensitized the mouse to SARS-CoV-2 infection and resulted in the development of a mild COVID-19 phenotype.
SARS-CoV-2 mainly targets and infects ACE2-expressing type 1 and 2 pneumocytes in patients, causing severe clinical disease and lung histological changes (1, 20, 21). To further characterize the COVID-19 mouse model, we used fluorescent immunohistochemistry to colocalize SARS-CoV-2 with hACE2 or with multiple cellular phenotypic markers, including CD206 for macrophages, CD3 for T cells, and Pan-cytokeratin (Pan-CK) for pneumocytes (Figures 4 and E6). We found a large number of hACE2-positive cells in the lung of SARS-CoV-2–infected Ad5-hACE2 mice at 3 dpi (Figure 4A, left panel). Interestingly, among the total SARS-CoV-2–positive regions (i.e., a group of positive cells), 75% exhibited colocalization with hACE2-positive cells (Figure 4A). The fact that the overlap was not 100% could be attributed to the downregulation of hACE2 to undetectable levels owing to the internalization of SARS-CoV-2 with its receptor hACE2 during infection (1), a notion that warrants further investigation.
We also detected T cells and macrophages in the lung of the Ad5-hACE2 but not Ad5-empty mice infected with SARS-CoV-2 at 3 dpi, resulting in moderate to severe interstitial and perivascular inflammation. However, no staining of T cells or macrophages with SARS-CoV-2 was noted (Figure E6). Interestingly, we found SARS-CoV-2–positive pneumocytes in alveolar septa with Pan-CK+ (Figure 4B). Among the total SARS-CoV-2–positive regions, we detected ∼25% that were positive and colocalized with Pan-CK–positive cells (Figure 4B, left). Extensive spike RNA was detected by RNAscope in the interstitial areas of infected Ad5-hACE2 at 3 dpi but not Ad5-empty mice at 3 and 6 dpi (Figure 5A). Specific RNA probes for spike RNA and mouse Hopx (homeobox only protein x) were used to detect SARS-CoV-2 RNA in pneumocytes (22, 23) (Figure 5B). Consistently, we also found that there were SARS-CoV-2-S RNA and Hopx RNA double-positive cells and SARS-CoV-2 RNA-positive cells in the infected Ad5-hACE2 mice at 3 dpi (Figure 5B). Taken together, these results indicate that SARS-CoV-2 can infect pneumocytes, which may contribute to the development of the interstitial and perivascular inflammation seen in SARS-CoV-2–infected Ad5-hACE2 mice. This finding is consistent with the current view that the majority of SARS-CoV-2–infected cells are pneumocytes (1, 20). However, given that only 25% of the SARS-CoV-2–infected regions were composed of pneumocytes, our data also indicate that other cell types may be susceptible to infection.
RNAseq analysis was performed at 3 dpi in Ad5-hACE2 and Ad5-empty mice. We observed a significant increase in IFN-dependent chemokine Cxcl9 (Figure 6) in Ad5-hACE2 mice. Consistently, RNAscope studies also exhibited an upregulated Cxcl9 at 3 dpi in lungs of infected Ad5-hACE2 mice (Figure 5A). We also observed an increase in Cd3 g, Cd8a, and Gzmb. This is similar to what has been reported in human BAL samples with distinct populations of CD4+, CD8+, and B cells (24) as well as the presence of Tfh cells in blood of recovered subjects (25). We observed induction of genes associated with effector T-cell populations including Il21 and Il21r (Figure 6) but did not pass the false discovery rate (FDR) filter. Pathway analysis showed that several Kyoto Encyclopedia of Genes and Genomes (KEGG) pathways were enriched in the data set (Tables 1 and E1), including cytokine–cytokine receptor interaction, the chemokine signaling pathway, the NOD-like receptor signaling pathway, the measles pathway, and the IL-17 signaling pathway.
Clinical studies (26) indicate that from the onset of COVID-19 pneumonia, the levels of T and B lymphocytes gradually increase during treatment in nonsevere patients to levels significantly higher than patients with severe disease. There are no reports yet exploring peripheral immune cell responses in mouse models. The peripheral immune response to SARS-CoV-2 infections was explored in this study by monitoring immune cells in circulation. SARS-CoV-2–infected Ad5-hACE2 mice had significantly higher levels of peripheral CD4+ and CD8+ T cells and B cells than SARS-CoV-2–infected Ad5-empty mice at 6 and 12 dpi (Figure E7).
A great strength of using the adenovirus delivery system for expressing hACE2 in mice is the immediate capability of conducting pathogenesis and preclinical studies in any given genetic background and molecularly engineered mouse strains. Specifically, this rapidly deployable COVID-19 mouse model recapitulates numerous important characteristics of COVID-19 disease to inform preclinical studies (37). Indeed, passive transfer of a neutralizing monoclonal antibody has been documented to reduce viral burden in the lung and mitigate inflammation and weight loss using a similar model (27). Ad5-hACE2–transduced mice also enabled rapid assessments of a vaccine candidate, of human convalescent plasma, and of antiviral therapies (poly I:C and remdesivir) (9). Our results showed that after SARS-CoV-2 infection, the Ad5-hACE2 mice developed histological changes and immune infiltration associated with the viral load in the lung within 6 dpi. This disease course is comparable with previously published mouse COVID-19 models (6, 8, 9, 27). Based on these reproducible results, we suggest that this rapidly deployable model can serve as an in vivo screening tool for the development of vaccines and therapeutics. Therefore, this model can be used to measure the viral load and subgenomic RNA via RT-PCR, analyze the virus in the lung with immunochemistry, and monitor histological changes and immune cell infiltration in the lung for determining the efficacy of the candidate vaccines and therapeutics. This rapidly deployable COVID-19 model should be useful for studying SARS-CoV-2–induced lung pathology. However, owing to their local and temporally limited expression of hACE2, it is conceivable that while considering and designing experiments to explore the impact of SARS-2 infection on other organs such as heart, brain, and kidney, the Ad5-hACE2 mice would be less favorable than transgenic hACE2 mice (9). Clearly, there is an urgent need for such a small rodent model for high-throughput studies testing therapeutic interventions and vaccines for SARS-CoV-2 infection of the lung.",Am J Respir Cell Mol Biol
PMC7780973,Rehabilitation Levels in Patients with COVID-19 Admitted to Intensive Care Requiring Invasive Ventilation. An Observational Study,"This was a single-center, prospective, noninterventional, observational study, conducted in patients admitted to the ICU in March and April 2020 with a confirmed diagnosis of COVID-19. Participants were followed up until acute hospital discharge. This study is reported in accordance with the STROBE (STrengthening the Reporting of OBservational studies in Epidemiology) guidelines (11) and was registered with the clinical trials.gov registry (NCT04396197).
The Queen Elizabeth Hospital Birmingham is a quaternary-level acute care hospital, with one of the largest colocated ICUs in Europe. Before the COVID-19 pandemic, the standard critical care capacity for this unit was 75 beds; however, with surge planning, the overall capacity was increased to more than 200. At the peak of the COVID-19 emergency, the ICU cared for 164 patients simultaneously (COVID-19 and non–COVID-19). This capacity was increased through a variety of measures, which included caring for two patients per bed space and reduced specialist staffing ratios. Nursing ratios were one critical care nurse to four patients, supported by three non-ICU nurses, deployed from other hospital departments. Consultant intensivist staffing was at 1:35 patients, supported by doctors in training, and deployed doctors from anesthesia, medical, and surgical specialties.
Before the pandemic, physiotherapy was provided between the hours of 8 a.m. and 5 p.m., Monday to Friday, at a ratio of one physiotherapist to seven patients, with only emergency respiratory on-call provision available outside these hours. Weekend provision was delivered by a significantly reduced service as part of normal weekend working patterns in the United Kingdom. Physiotherapists within our unit assess all patients within 24 hours of admission; delivering respiratory care often termed “chest physiotherapy” and commencing rehabilitation as indicated. To meet the increasing demand expected during the pandemic, the physiotherapy service was restructured to ensure physiotherapy was available from 8 a.m. to 8 p.m., 7 days per week, with a ratio of one physiotherapist for every 10 patients. This was achieved through the redeployment of nonspecialist critical care staff from other areas of the hospital to support the critical care physiotherapy team.
Consecutive participants were included in the analysis if they met the inclusion criteria of being adults (≥18 yr of age), having a confirmed diagnosis of COVID-19, and being mechanically ventilated for at least 24 hours. This project constituted an observation of standard care delivery with no randomization and thus met the definition of a service evaluation under the National Health Service Health research authority guidelines (12). As such, ethical approval was not required, and because all outcome measures are collected as part of routine care, the need for consent was waived.
All patients were assessed by a physiotherapist within 24 hours of admission to ICU. As there are no respiratory therapists in the United Kingdom, physiotherapists are responsible for both respiratory care and the initiation and progression of rehabilitation, where appropriate. Specifically, from a respiratory perspective, the physiotherapy team assisted with patient repositioning, including proning, and delivering chest physiotherapy to optimize secretion clearance. To support the medical and nursing teams during the pandemic, the physiotherapy team also took on increased responsibility to support management of ventilation, in accordance with lung protective ventilation guidelines. This included calculation of targets for lung protective tidal volumes, which were then displayed in the patients’ bed space, alongside twice-daily ventilation ward rounds, to ensure adherence or make the necessary adjustments to maintain these levels. As a patient’s condition stabilized, physiotherapists led and coordinated the commencement and progression of rehabilitation. Our critical care multidisciplinary team has extensive experience of delivering early and structured rehabilitation, including established safety criteria to commence mobilization, and a protocol to guide progression (10).
The primary outcome was the highest level of mobility achieved at the point of ICU discharge, as measured by the Manchester Mobility Score (MMS). The MMS is a simple seven-point mobility scale (see
Figure 1) used and validated for assessing mobility levels within critical care (13). Secondary outcomes included the number of days taken to first mobilize (defined as an MMS of 2 or higher, i.e., sitting on the edge of the bed or higher) and the location of hospital discharge, which was treated as an ordinal variable with categories of Home (No Rehabilitation), Home (With Rehabilitation), or Inpatient Rehabilitation.
Data were collected prospectively throughout the evaluation period using patient noting and electronic databases. Baseline data, including demographics, ventilation days, sedation days, renal replacement therapy using continuous venovenous hemofiltration at any point during ICU admission, tracheostomy insertion, length of stay for both ICU and the ward, and mortality, were obtained from electronic databases administered by dedicated data scientists. Other factors that may have contributed to the development of ICU-acquired weakness and therefore delays in mobilization were also collected retrospectively from patient noting. Specifically, this included data regarding aspects of critical care management, including the use of neuromuscular blocking agents, proning, and the presence of delirium, defined by a positive result on the Confusion Assessment Method ICU (CAM-ICU) at any point during the ICU stay. The presence of ICU-acquired weakness during awakening was defined as a Medical Research Council sum score of <48 (4). Rehabilitation outcomes were collected immediately after physiotherapy sessions and recorded using the MMS. Frailty scores were collected routinely as part of admission assessment using the Clinical Frailty Score (14).
Initially, the characteristics of the cohort were summarized, with continuous variables reported as means ± standard deviations where normally distributed, and medians and interquartile ranges (IQRs) reported otherwise. Comparisons between those patients who died in the ICU and those who survived to ICU discharge were then performed, using Mann-Whitney U tests for ordinal or continuous variables and Fisher’s exact tests for nominal variables. Associations between patient characteristics and physical outcomes were then assessed. MMS at ICU discharge was treated as a continuous variable in this analysis but was reported as the proportion of patients with a score of five or more points in each group, to simplify interpretation. Comparisons across nominal variables were performed using Mann-Whitney U tests or Kruskal-Wallis tests for variables with two or more than two categories, respectively. To assess associations with ordinal and continuous variables, P values were derived from Spearman’s correlation coefficients. All analyses were performed using IBM SPSS 22 (IBM Corp.), with P < 0.05 deemed to be indicative of statistical significance throughout.
During the observation period, N = 177 patients were admitted to the ICU with confirmed COVID-19 infection. Of these, 110 (62%) patients survived to ICU discharge and were included in subsequent analysis. Patients who died within the ICU were significantly older, with a higher incidence of comorbidities and higher frailty scores (Table 1).
The mean age of patients surviving to ICU discharge was 53 ± 12 years, 75% were male, and the majority were of White (48%) or Asian (35%) ethnic backgrounds (Table 1). Although there was a low incidence of frailty, the majority of the cohort was classified as overweight or obese (body mass index [BMI]: 25+ kg/m2, 87%). Chronic medical conditions were common in this critically ill population, with 45% having hypertension and 31% having diabetes mellitus; the median Charlson Comorbidity Index was 2 (IQR: 1–3).
ICU-level therapies and outcomes for the 110 ICU survivors are presented in Table 2. All patients required mechanical ventilation, with a mean duration of 19 ± 10 days (range: 2–59). A tracheostomy was inserted in 77% of patients, and 67% of patients were placed in the prone position on one or more occasion. All patients were sedated, for a mean duration of 13 ± 6 days, and 90% received neuromuscular blockade, for a median of 7 (IQR: 4–11) days. Renal failure requiring continuous venovenous hemofiltration developed in 34% of patients. A high prevalence of delirium was observed, with 69% of patients scoring positive on CAM-ICU assessment during their ICU stay. ICU-acquired weakness was present on awakening for all patients.
In total, the mean length of stay in the ICU was 22 ± 11 days. All patients were mobilized in the ICU, with a mean time to mobilization of 14 ± 7 days. At the time of ICU discharge, the median MMS was 5 (IQR: 4–6), with 50% able to step transfer or walk (MMS of 5+, Figure 1)
A single patient (1%) died in the hospital following ICU discharge, following a cardiac arrest on the ward. Two (2%) patients were readmitted to the ICU before discharge, both as a result of respiratory deterioration secondary to newly diagnosed hospital-acquired pneumonia. Patients were discharged from the hospital a median of 11 days (IQR: 6–18) after being discharged from the ICU (Table 2). Fifty-five (50%) patients were discharged home without requiring further rehabilitation, whereas 46 (42%) required further rehabilitation at home, and 8 (7%) required ongoing inpatient rehabilitation. At the time of hospital discharge, the majority of patients were able to step transfer or walk (MMS of 5+), with 83% scoring 7 points on the MMS and therefore able to walk >30 m independently. The four (4%) patients with MMS scores of less than five were all discharged for ongoing inpatient rehabilitation.
Associations between patient characteristics, namely, the time to mobilize, MMS at ICU discharge, and hospital discharge destination, were then assessed. Analysis of the latter was treated “Home (No Rehab),” “Home (With Rehab),” and “Inpatient Rehab” as an ordinal scale. The results of these analyses are reported in Tables 3 and 4.
The time taken to first mobilize was found to increase significantly with BMI (Figure 2), from a mean of 10 days to 18 days (P < 0.001) for those with BMI of 20–24 versus 40+ kg/m2. At the time of ICU discharge, MMS scores were found be significantly lower in patients with a higher frailty score at admission (P = 0.033) and in those with preexisting cardiovascular disease (P = 0.019). In those that were discharged from hospital, older patients (P = 0.012), as well as those who were frail (P = 0.031) or had a higher Charlson Comorbidity Index (P = 0.017), were significantly more likely to require further rehabilitation.
The early experience of the COVID-19 pandemic in the United Kingdom resembles the experience in other countries, with high acuity of illness and prolonged period of mechanical ventilation required for those patients admitted to the ICU. Although time to commence rehabilitation was delayed owing to this severity of illness, rehabilitation was possible within the ICU and led to increasing levels of mobility before ICU discharge. Despite the significant strain on the service, we were still able to deliver a high level of rehabilitation, even during the peak of the surge in admissions. Ongoing planning for future surges needs to consider this important aspect of care to ensure rehabilitation can still be prioritized for this patient group. Given the high degree of ICU-acquired weakness and high levels of delirium, there is likely to be a significant need for ongoing rehabilitation, both in hospital and following hospital discharge.",Ann Am Thorac Soc
PMC7790076,Year 100 of the American Journal of Tropical Medicine and Hygiene: A Remarkable Year,"Two years ago, we celebrated an anniversary of sorts, with publication of volume 100 of the American Journal of Tropical Medicine and Hygiene (AJTMH).1 That milestone was a bit artificial, as it included counting volumes of our predecessor journals, with varied numbers of volumes published per year, but it offered a chance to review progress. Now we celebrate a more precise anniversary, 100 years after publication of the first issue of the American Journal of Tropical Medicine in 1921. That journal merged in 1952 with the Journal of the National Malaria Society to form our modern journal. Please see our prior editorial for a review of how we got here.1 In this report, we discuss where we are and where we are going.
Our anniversary comes at the completion of a remarkable year. Early in 2020, we were addressing the complicated politics of a rancorous election year in the U.S. Concerns about politically motivated misunderstanding and misuse of science have been widespread in 2020, leading to a journal editorial bemoaning two landmark decisions by the U.S. administration, to cancel NIH funding for an ongoing study of coronaviruses, and to withhold support for the WHO.2 Assaults on science have been fierce and quite astounding. In these challenging times, the AJTMH will continue to serve as a forum for the leadership of the ASTMH2–4 and our colleagues5–20 concerning issues of vital importance to the international tropical medicine and public health communities.
Within the first few months of 2020, a pandemic was upon us. Initially, Americans watched in horror as the COVID-19 pandemic wreaked havoc in Asia and then Europe, but soon the pandemic proved to be a horrific problem also in the United States and nearly every country. Unlike pandemics from the past, COVID-19 has emerged in the context of modern communication and a scientific community poised for modern investigation. This has led to an explosion of scientific investigation on SARS-CoV-2 and COVID-19. Concurrently, experts have seized the opportunity to comment on every aspect of this all-too-often controversial pandemic, from clinical medicine to epidemiology to social and behavioral matters. With these trends, there has been submission and eventual publication of a remarkably large number of manuscripts on COVID-19. On December 14, 2020, a PubMed search of “COVID-19” identified 77,328 published articles. No doubt, this represents an unprecedented profusion of publications on a single new topic. With more new science on a brand new topic than ever before, we should be in the best shape possible to tackle the pandemic. Of course, it is not so simple, as the pandemic is complex, and as politicians and their proxies continue to misread scientific results to fit their political purposes. The spread of misinformation has paralleled that of high-quality scientific data.12,16,21–23 But, more light is better than less, and we should keep the faith that despite setbacks, knowledge will ultimately conquer ignorance in the fight against COVID-19.
The impact of COVID-19 on the AJTMH has been profound. After a handful of submissions related to the pandemic in the first few months of 2020, the number of submissions exploded in April (Figure 1). Soon, the journal was receiving about twice its typical volume of submissions. The excess was primarily due to articles on COVID-19. As of December 14, 2020, we have considered hundreds and published 184 articles on COVID-19, ranging from case reports and descriptive studies helping us to characterize the pandemic in its early days to early clinical trials of a range of potential therapies to perspectives addressing different aspects of COVID-19 management and policy. Submissions of non-COVID-19 manuscripts have also increased. Large numbers of submissions to the AJTMH led to a marked increase in workload for our editorial staff, our editors, and our reviewers. Happily, all have stepped up, and the journal has been able to maintain prompt reviews for most submissions (average of 24 days). Considering the urgency of the pandemic, the journal has expedited reviews of manuscripts on COVID-19 as much as possible (average of 14 days). As of this writing late in 2020, the rate of submissions on COVID-19 has slowed, but these submissions continue, and we can anticipate that however quickly the pandemic abates in the coming months, the science of this pandemic will be featured in the medical literature for years to come.
Year 100 has been a remarkable year for the AJTMH. What does the future hold? As COVID-19 slowly fades as a focus, it is hoped that some new linkages for the AJTMH will remain strong. In 2020, we have published many more papers on a range of disciplines, including clinical virology, intensive care unit medicine, and radiology, to name a few, than in past years. Although most attention in the United States has gone to COVID-19 in highly developed countries, which have been particularly hard-hit, the pandemic has also spurred the provision of advanced medical care in many low- and low-middle–income countries that typically offer such care on a very limited basis. Availability of advanced care has certainly been spotty, but we can hope that various COVID-19–inspired advances, from efficient diagnostics17,24,25 to point-of-care ultrasound26–30 and relatively low-cost means of mechanical ventilation,31,32 will remain in less developed countries as the pandemic disappears. Evaluation of the utilization of new technologies for the care of tropical diseases is a major focus of the AJTMH, and so advances facilitated by the pandemic will be featured. We can hope that these advances will improve care for a range of tropical diseases, offering a modest silver lining after the ravages of the pandemic.
As we reach the end of 2020, the future is hard to predict. But, it is a certainty that a great many tropical diseases will continue to afflict our planet. Changes will undoubtedly be seen over time, with some ailments diminishing; we expect continued good progress against many vector-borne diseases, a range of helminth infections, and diseases of poor sanitation. Progress remains challenging for some of our biggest killers, including HIV infection, tuberculosis, and malaria, and control of these diseases has taken a hit from the pandemic, but we can foresee getting back to the level of progress seen in recent years. Furthermore, as we learned so clearly in 2020, new infections will emerge, and noncommunicable diseases are on the rise. Through the slings and arrows of the modern world, from persistent endemic infectious diseases, to increasing non-communicable diseases, to pandemics, and political craziness, the AJTMH will remain a force for disseminating the latest information and recommendations on tropical medicine and public health.",Am J Trop Med Hyg
PMC7774581,"Racial and Workplace Disparities in Seroprevalence of SARS-CoV-2, Baton Rouge, Louisiana, USA","We previously reported results from a seroprevalence study conducted in New Orleans, Louisiana, USA, which was hit hard early in the coronavirus disease (COVID-19) pandemic (1). Baton Rouge is a large metropolitan area roughly 80 miles northwest of New Orleans; at the time of this study, it was in the second phase of reopening after a stay-at-home order. Although the seroprevalence in New Orleans (6.9%) (1) was similar to prevalence recorded in Spain (5%), São Paulo, Brazil (4.7%), and New York, USA (6.9%) (2,3; B.H. Tess, unpub. data, https://doi.org/10.1101/2020.06.29.20142331), Baton Rouge had only 3,427 more cases as of August 2, 2020 (17,093 cases), than New Orleans did by May 16, 2020 (13,666 cases) (4). This latest study estimated severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infections in the greater Baton Rouge area (Ascension, East Baton Rouge, Livingston, and West Baton Rouge Parishes), with additional information on potential workplace exposures.
The protocol was approved by the Ochsner institutional review board and was designed to enroll and test <2,500 participants at 13 sites throughout Baton Rouge during July 15–31. Recruitment targeted a representative sample by using a method developed by Public Democracy (https://www.publicdemocracy.io) and described elsewhere (1,5). In contrast to the New Orleans study, in which persons tested were under a stay-at-home order, Baton Rouge was in phase 2 of reopening. A randomized subset of 500,000 Baton Rouge residents were targeted with digital ads for recruitment. Of those, 3,687 volunteers were recruited and restratified according to census designations; 2,309 were invited to participate, 2,179 enrolled and completed testing, and 2,138 were included in our final analysis. A total of 38 persons were excluded because they lived in ineligible ZIP codes, and 3 withdrew consent (Appendix). All study materials were provided in English, Spanish, and Vietnamese. Participants were offered free transportation. Research staff verbally obtained consent from participants and electronically documented consent and survey responses. We then procured blood samples and nasopharyngeal swab specimens from participants.
We used US Food and Drug Administration Emergency Use Authorization–approved tests. Real-time reverse transcription PCR of nasopharyngeal swab specimens was performed by using the Abbott m2000 RealTime system (Abbott, https://www.molecular.abbott). Qualitative IgG blood tests were performed by using the ARCHITECT i2000SR (Abbott). The IgG test meets criteria established by the Centers for Disease Control and Prevention to yield high positive predictive value, which was validated by Ochsner Health laboratory and others (6,7). Study participants who tested positive on either or both tests were assessed as having been infected with SARS-CoV-2. Point estimates and corresponding 95% CIs for proportions of SARS-CoV-2 exposure (PCR+ or IgG+ tests), point prevalence (PCR+, IgG–), and seroprevalence (IgG+ tests regardless of PCR test result) were estimated for the Baton Rouge area by using raw and census-weighted counts. Unadjusted odds ratios with Firth correction were calculated for all variables.
The sample was 63.6% female and 66.9% white; average age was 48.7 years (range 18–91) and average household size 2.84 persons. The census-weighted estimate of SARS-CoV-2 infections in the sample is 6.6% (6.0%, raw), with 3.0% positive for active viral shedding without detectable antibody, which translates to 16,536 contagious persons. By race and ethnicity, seroprevalence was highest (7.5%) in Black participants, compared with White non-Hispanic (1.8%), Asian non-Hispanic (1.7%), Hispanic of any race (1.6%), and other (2.7%) participants (Table).
The point prevalence and any SARS-CoV-2 infection were mapped by ZIP codes across the greater Baton Rouge area (Appendix). Point prevalence and all infections were highly variable by ZIP code.
Marital status was associated with prevalence (p = 0.0005 by χ2 test). Single persons had the highest rate of infection (9.3%), compared with rates for married or cohabitating participants (5.0%), and were 1.9 times more likely to test positive (Figure). Work environment also affected prevalence (p = 0.01 by χ2 test); the lowest prevalence was in participants who worked from home part-time and went to a workplace part-time (3.7%). Those who worked primarily outside the home had the highest prevalence (8.2%) and were 2.3 times more likely to test positive than those who worked from home at least part-time. Infection rates varied by occupation (p = 0.01 by χ2 test); the lowest positivity was in office workers (3.0%) and increased odds of testing positive occurred in delivery, healthcare, and other public-facing jobs. However, based on seroprevalence, which also varied substantially by occupation (p = 0.03 by χ2 test), healthcare workers and public-facing workers bore the brunt of early infections, as demonstrated by higher odds of testing positive for antibodies (Figure).
We found the prevalence of SARS-CoV-2 infection in Baton Rouge to be 6.6% but with a heavy concentration of new, contagious infections (3.0%). Persons who were infected early possibly no longer had antibodies. This finding differed from our New Orleans study, which was performed after extensive lockdowns and estimated new infections at 0.9% (1). Some populations had higher rates of infection than others, including Black and Hispanic communities and public-facing workers or those who do not work from home.",Emerg Infect Dis
PMC7774526,"Impact of a Nationwide Lockdown on SARS-CoV-2 Transmissibility, Italy","We measured SARS-CoV-2 transmissibility in terms of the basic (R0) and net (Rt) reproduction numbers. These quantities represent the mean number of secondary infections generated by 1 primary infector in a fully susceptible population (R0) and in the presence of control interventions and human behavioral adaptations (Rt). When Rt decreases below the threshold of 1, the number of new infections begins to decline. Estimates were obtained through a Bayesian approach applied to case-based surveillance data collected by regional health authorities (Appendix).
To account for the geographic heterogeneity in contacts, healthcare organization, and timelines of interventions, Rt was estimated separately for different provinces and regions. We considered all 19 regions in Italy plus the 2 autonomous provinces of Trento and Bolzano. Moreover, we considered 100 of the remaining 105 provinces for which the data were sufficiently complete. The selected provinces covered 99.1% of the population of Italy and, as of May 3, 2020, accounted for 153,558 symptomatic cases (97.9% of the total recorded in the surveillance database). To evaluate the progressive decrease of transmission, we computed Rt at 3 dates: the day before lockdown (March 10) and 1 and 2 weeks after lockdown (March 18 and 25). In addition, we considered the average value of Rt over the successive 3 weeks (March 26–April 15). These choices were suggested by the trend of the national Rt (Appendix).
The R0 range was 2.83–3.10 (Figure 1) in the 8 regions for which the estimate was possible (Appendix). On March 10, Rt range was 1.79–3.36 across regions; Basilicata and Molise had an insufficient number of symptomatic cases (Figure 1). One week into lockdown, on March 18, Rt had decreased consistently, but no region or autonomous province was yet below the epidemic threshold (Figure 1). As of March 25, Rt was <1 in most regions and autonomous provinces (12/21) and <1 in the successive 3 weeks for all regions except Molise and Piedmont (Figure 1). The mean value of Rt across the regions and autonomous provinces, weighted by the number of reported cases at the corresponding date, fell from an average of 2.03 (95% CI 1.94–2.13) on March 10 to 1.28 (95% CI 1.23–1.33) on March 18, to 0.88 (95% CI 0.84–0.91) on March 25, corresponding to an overall 62.6% reduction (range across regions 45.6%–85.0%). In the 3 weeks of March 26–April 15, Rt remained stable in all regions, showing a further slight reduction at an average value of 0.76 (95% CI 0.67–0.85).
Results were consistent when analyzing estimates from the 100 selected provinces (Figure 2). As of March 10, no province had a mean estimated value of Rt <1 (n = 75; the number of symptomatic cases was insufficient for the estimate in 25 provinces). One week after lockdown, on March 18, 5/93 provinces (5.4%) had an average Rt <1, whereas on March 25 this figure increased to 49/96 provinces (51.0%). The fraction of provinces with Rt below 1 rose to 84/100 (84.0%) when considering the average over the following 3 weeks. The mean value of the reproduction number across the provinces, weighted by the province’s number of reported cases at the corresponding date, was 2.01 (95% CI 1.83–2.22) on March 10, 1.26 (95%CI 1.15–1.38) on March 18, 0.88 (95% CI 0.79–0.97) on March 25, and 0.77 (95% CI 0.63–0.95) for the period March 26–April 15.
Our results suggest that the national lockdown put in place as of March 11 to limit the spread of SARS-CoV-2 in Italy brought Rt below 1 in most regions and provinces within 2 weeks. Although Rt had been declining steeply even before the national lockdown (3) in regions with intense interventions, we estimated that the epidemic was brought under control only after the implementation of the lockdown. Lockdown was fundamental to prevent an explosion in the number of cases in other regions in which transmission had started weeks later compared with the outbreak epicenter (Lombardy, Veneto, Emilia Romagna). The range of estimates of R0 in 8 regions was 2.8–3.1, within the range of estimates obtained for other countries (4–6).
A massive and sustained scale-up of testing capacity was set up in all regions of Italy during the course of the epidemic (7); it was not accompanied by a corresponding increase of confirmed incident cases in the weeks following March 25, as indicated by the declining proportion of positive tests (Appendix). This finding suggests an increase of notification rates and thus a possible overestimation of Rt (8). To compensate for possible biases, we supplemented our results by computing alternative estimates based on the time series of hospitalized cases. Criteria for hospitalization are more homogeneous across local health systems and over time than testing criteria because they are grounded in the patient’s need for medical assistance. Furthermore, the hospitalization date is an easier piece of information to collect with respect to the symptom onset date, which requires an epidemiologic investigation and may be subject to recall bias. Results obtained with this additional method were consistent with our conclusions (Appendix).
We did not consider asymptomatic cases in our analysis. The adopted methodology is robust even in the presence of large underdetection rates, provided that these rates are constant over time or even slightly fluctuating (8,9). We did not consider imported cases either, due to the lack of data; imported cases are potential infectors, but do not contribute to the number of transmitted cases, thereby lowering estimates of reproduction numbers. In Italy, most cases were probably locally transmitted. After March 11, the ban of movement across provinces imposed by the lockdown made the role of imported cases negligible. Reproduction numbers were computed using the distribution of serial interval for Italy (10; D. Cereda et al.), which is an acceptable approximation of the generation interval (11; S. Hu et al., unpub. data, https://10.1101/2020.07.23.20160317). Both distributions are strongly influenced by country-dependent variables, such as behavior of infected persons and the adopted interventions. Estimates of the generation interval distribution are still unavailable for Italy as of October 2020.
Italy was the first country outside of Asia to impose a nationwide lockdown, rapidly followed by many countries worldwide. The effectiveness of lockdown had been proven in China, where the reproduction number was estimated to fall to »0.3 in Wuhan (12) and 0.5 in other provinces (8); Western countries had enforced a comparatively softer version of restrictions. We have shown that these measures enabled rapid reversal of the epidemic trend within 2 weeks, although probably at higher values of the reproduction number.",Emerg Infect Dis
PMC7774527,Large-Scale Isolation Facilities and Potential for Secondary Infectious Disease Outbreak,"To the Editor: Singapore has instituted large-scale isolation facilities similar to those detailed by Choi et al. (1) for patients with mild coronavirus disease. We highlight the risk for transmission of secondary infectious diseases by sharing our experience with a varicella outbreak.
Three patients, all migrant workers housed in the same isolation hall, were seen for vesicular eruptions, later laboratory confirmed as varicella, within the span of 9 days. The first patient’s symptoms were truncal erythematous-based vesicles and erosions after a prodrome of fever and headache. He was promptly transferred for further hospital isolation. As part of a ring vaccination strategy, we offered 200 close contacts postexposure vaccination. However, 2 other patients, not close contacts of the first, had similar eruptions; for the second patient, 7 days later with a rash duration of 2 days, and for the third, 8 days after, with a rash duration of 6 days (Figure). After these additional cases, vaccination was offered to all remaining patients in the isolation facility. 
All 3 patients probably contracted varicella from unidentified persons with varicella or zoster infection, given that illness onset fell short of the usual 10–21-day incubation period (2). Although varicella seroprevalence among adults in Singapore is high (88%), data on seroprevalence among migrant workers remain limited (3).
Although isolation facilities obviate the capacity constraints of hospital isolation, our experience highlights the potential for secondary outbreaks, which are disruptive and costly to investigate and control. To mitigate this risk, preentry screening inquiring about previous chickenpox infection or vaccination should be considered. Serologic screening is ideal but challenging to implement. Among patients, social distancing and face coverings should be enforced. We also recommend active surveillance for vesicular rash and fever, prompt isolation of patients with suspected cases, and vaccination of identified close contacts without previous infection, vaccination, or contraindications to vaccination, as well as temporarily halting patient flow while these measures are implemented.",Emerg Infect Dis
PMC7774579,"Intrafamilial Exposure to SARS-CoV-2 Associated with Cellular Immune Response without Seroconversion, France","We included in the study 11 couples in whom 1 of the 2 partners met clinical, epidemiologic, and laboratory criteria for a mildly symptomatic confirmed COVID-19 case. We collected blood samples from both partners of each couple during May 7–June 26, 2020. Ten healthy blood donors who had not been exposed to COVID-19 patients and who had tested negative for SARS-CoV-2 antibodies were enrolled as controls. All participants gave written informed consent for research according to protocols approved by the institutional review board of Strasbourg University Hospitals (ClinicalTrials.gov NCT 04405726). 
We performed in-house real-time reverse transcription PCR (rRT-PCR) tests for SARS-CoV-2 nucleic acid on samples from nasopharyngeal swab specimens collected during the symptomatic phase from 8 index patients and 3 contacts. Primer and probe sequences target 2 regions of the RdRp gene and are specific to SARS-CoV-2. Assay sensitivity is ≈10 copies/reaction (https://www.who.int/docs/default-source/coronaviruse/real-time-rt-pcr-assays-for-the-detection-of-sars-cov-2-institut-pasteur-paris.pdf). 
We used 3 serologic assays to detect the presence of SARS-CoV-2 antibodies. The Abbott Architect SARS-CoV-2 IgG assay (Abbott, https://www.corelaboratory.abbott) is a chemiluminescent microparticle immunoassay for detecting IgG against the SARS-CoV-2 nucleoprotein and has sensitivity and specificity close to 100% (6,7). The EUROIMMUN SARS-CoV-2 assay (EUROIMMUN, https://www.euroimmun.com) is an ELISA for detecting IgG and IgA against the SARS-CoV-2 S1 domain of the spike glycoprotein, including the immunologically relevant receptor-binding domain. This assay was reported to have a clinical specificity of 98% for IgG and 91% for IgA detection, with a maximal sensitivity reached after 28 days after symptom onset (IgG 98% and IgA 95%) (7). The Biosynex COVID-19 BSS assay (Biosynex, https://www.biosynex.com) is a lateral flow assay for detecting IgM and IgG directed against the SARS-CoV-2 receptor-binding domain of the spike glycoprotein and has a sensitivity of 95.6% and a specificity of 99.4% (8). All 3 assays were approved by the French National Agency of Medicine and Health Products Safety for their excellent analytical performances. All tests were performed according to manufacturer instructions. 
We investigated T-cell immune response against SARS-CoV-2 by performing an interferon-gamma (IFN-γ) enzyme-linked ImmunoSpot ELISPOT assay (ImmunoSpot, http://www.immunospot.com) in duplicate on fresh peripheral blood mononuclear cells (PBMC) isolated from heparin-anticoagulated blood. PBMCs were seeded at 200,000 CD3+ cells/well after dilution according to measurement of CD3+ cell frequencies by flow cytometry. They were stimulated for 20 +4 h with overlapping 15-mer peptide pools used at a final concentration of 1 µg/mL and spanning the sequences of the N-terminal portion of the SARS-CoV-2 spike glycoprotein (pool S1, amino acid residues 1–643) and the C-terminal part of the same protein (pool S2, amino acid residues 633–1273), the nucleoprotein (N), the membrane protein (M), the envelope small membrane protein (E), and the accessory proteins 3A, 7A, 8 and 9B (PepMix; JPT Peptide Technologies, https://www.jpt.com). 
To investigate the possibility of preexisting cross-reactive coronavirus-specific T cells, PBMCs were stimulated in parallel with peptide pools spanning the spike glycoprotein sequences of HCoV-229E (ES1 and ES2) and HCoV-OC43 (OS1 and OS2). Phytohemagglutinin (PHA) was used in duplicate as a positive control and culture medium in quadruplicate as a negative control. After colorimetric revelation of IFN-γ capture (UCytech, https://ucytech.com), spots were counted using an ELISPOT reader (AID, https://www.aid-diagnostika.com). For each condition, the mean number of spot-forming cells per million CD3+ cells was calculated from duplicates after subtraction of the background value obtained from negative controls to determine the frequency of antigen-specific T cells. The threshold defining T-cell reactivity for 1 antigen was set at >3 SD of the negative control background. The SARS-CoV-2-specific T-cell response was considered positive if analysis showed reactivity for >3 SARS-CoV-2 antigens. 
The median age of the 11 couples was 49 years (range 38–65 years); 11 (50%) were male (Table 1). Partners who met the confirmed case definition of COVID-19 (positive for SARS-CoV-2 by RT-PCR or serology or both) were the first to report symptoms in each couple and were considered index patients (P). Because of the lockdown from March 17 to May 11, 2020, each couple stayed in the same household during this period. Therefore, the partner of each index patient was considered a close contact (C) as defined by the US Centers for Disease Control and Prevention (CDC). 
During March 2–April 9, all index patients reported histories of >1 symptoms: 8 had fever, 6 had cough, 4 had fatigue, 8 had headache, 8 had anosmia, 7 had ageusia, 3 had dyspnea, and 3 had myalgia (Table 1). We tested 8 of these patients for SARS-CoV-2 using RT-PCR on nasopharyngeal samples; results for 7 were positive (Table 1). The duration of symptoms varied (2–21 days, median 10 days). During this symptomatic phase, all couples rigorously washed their hands, and each avoided hugs and kisses with his or her partner except couple 2. Nine of the 11 couples slept in the same bed. Only 2 index patients, P4 and P6 (i.e., the index partners from couples 4 and 6), quarantined themselves by eating and sleeping separately or wearing a mask or both for 1 day (P4) and 3 days (P6) after symptom onset. 
We performed serologic testing for SARS-CoV-2 antibodies in index patients at a median of 68 days (range 49–102 days) after symptom onset. All displayed IgG against the SARS-CoV-2 N protein, the spike glycoprotein, or both, as indicated by the 3 serologic assays (Table 2), confirming the persistence of the SARS-CoV-2 antibodies for up to 102 days after symptom onset. Results of tests for SARS-CoV-2 IgA were positive for 7 of the 11 index patients (Table 2). 
Six of the 11 contacts (C1, C2, C4, C5, C7, and C8) experienced symptoms 1–10 days after symptom onset in their partners (Table 1). We tested 3 of them for SARS-CoV-2 RNA by RT-PCR on samples from nasopharyngeal swab specimens during the symptomatic phase; results for all were negative (Table 1). Three had fever, 2 had cough, 2 had fatigue, 3 had headache, 1 had ageusia, 1 had dyspnea, and 1 had myalgia. The duration of symptoms varied (1–10 days, median 7 days) (Table 1). We performed serologic testing for SARS-CoV-2 at a median of 59 days (range 44–93 days) after symptom onset in symptomatic contacts and at the same time as their partners for asymptomatic contacts. All the contacts, including the symptomatic ones, were SARS-CoV-2 seronegative for IgM, IgA (except 1 equivocal result), and IgG (Table 2). 
To investigate the SARS-CoV-2–specific T-cell response in the 11 couples, we collected fresh PBMC samples on the same day as the serum collections. We then stimulated the samples with 4 structural and 4 accessory SARS-CoV-2 proteins followed by IFN-γ ELISPOT analysis. All index and contact patients had normal lymphocyte counts (Table 2). All index patients showed SARS-CoV-2–specific IFN-γ responses against 4–8 SARS-CoV-2 antigens (Table 2; Figure 1). All of their immune systems recognized the structural proteins S1, S2, N, and M, and 9 of them recognized >1 accessory protein (3A, 7A, 8, or 9B), showing that SARS-CoV-2–specific T-cell responses had developed (Figures 1,2; Appendix Figure 1). Blood samples were collected 49–102 days after symptom onset, which suggests that antiviral T cells are maintained for up to 102 days in patients having recovered from mild COVID-19. 
We evaluated SARS-CoV-2–specific T-cell response in contacts at a median time of 59 days (range 44–93 days) after symptom onset in symptomatic contacts and at the same time as their partner for asymptomatic contacts. Among the 6 symptomatic contacts, 4 (C1, C4, C5, and C8) displayed a positive SARS-CoV-2–specific T-cell response with a reactivity to >3 SARS-CoV-2 antigens (Figure 1, row A; Appendix Figure 1). Contact C1 exhibited T-cell reactivity against 4 SARS-CoV-2 antigens, including 1 structural protein (S1) and 3 accessory proteins; contact C5 exhibited T-cell reactivity against 2 and C8 against 3 structural proteins (N, E, and S2 for C8) and the accessory protein 9B. Contact C4 exhibited T-cell reactivity against 1 structural protein (S2) and 2 accessory proteins. Although symptomatic contact C7 exhibited T-cell SARS-CoV-2–specific response against a single antigen (structural protein S1), the frequency of IFN-γ–producing T cells was higher than that observed in his partner (mean 353 + 53 vs. 126 + 25 spot-forming units/1 million cells). Symptomatic contact C2 and asymptomatic contacts C6, C9, and C10 exhibited a low frequency of T-cell reactivity against a single antigen (S2 = 2, E = 1, 9B = 1) that was not considered here as a positive specific T-cell response to SARS-CoV-2 (Figure 1, row A and B; Figure 2; Appendix Figure 1). The asymptomatic contacts C3 and C11 showed no T-cell response against any of the SARS-CoV-2 antigens (Figure 1, row B; Appendix Figure 1). 
We included 10 unexposed HD as controls, with a mean age of 46 years (range 29–60 years). We confirmed their SARS-CoV-2 seronegative status with the 3 serologic assays. Five of them displayed low T-cell reactivity to SARS-CoV-2 against 1 or 2 antigens (S1, S2, M, 9B) (Figure 1, row C; Appendix Figure 1). 
A recent study demonstrated that several CD4 T cells reacting to SARS-CoV-2 epitopes were a result of a cross-reaction with corresponding homologous sequences from commonly circulating HCoVs including OC43 and 229E, which can cause common colds (9). To investigate if there was a correlation between T-cell responses against SARS-CoV-2 and common cold HCoVs, we tested the 11 couples and the 10 unexposed controls for reactivity against the spike glycoprotein (S1 and S2 regions) of HCoV-229E and HCoV-OC43. All but 1 HD (HD9) showed IFN-γ–producing T cells directed against these antigens (Figure 3; Appendix Figure 2). Eight index patients (P2, P3, P4, P5, P6, P7, P10, and P11), 7 contacts (C1, C2, C4, C8, C9, C10, and C11), and 7 controls displayed a positive T-cell response against both HCoV-229E and HCoV-OC43. Three index patients (P1, P8, and P9), 4 contacts (C3, C5, C6, and C7), and 2 controls displayed positive T-cell responses only against HCoV-229E. We found no correlation between the responses to S1 and S2 peptide pools of SARS-CoV-2 and HCoVs (Figure 4). 
In this study, we demonstrate that intrafamilial contacts can display a SARS-CoV-2–specific T-cell response in the absence of seroconversion, especially when they have been symptomatic. This T-cell response provides evidence that transient or anatomically contained SARS-CoV-2 infection, or both, may have occurred and that T-cell responses would be more sensitive indicators of SARS-Co-V-2 exposure than antibodies.
Each couple stayed in the same household during the COVID-19 episode and the partners were in close contact for a long time due to the lockdown. Although 5 contacts were asymptomatic, 6 exhibited symptoms a median of 7 days after symptom onset in their partners, suggesting that at least those 6 were infected. However, results from neither RT-PCR nor serology testing using 3 different assays and targeting 2 different SARS-CoV-2 structural proteins were positive in contacts. In contrast, analysis of SARS-CoV-2–specific T-cell response showed a positive response against >3 antigens, including structural proteins in 4 symptomatic contacts, strongly suggesting that they were infected with SARS-CoV-2. 
Five unexposed controls and 1 symptomatic and 3 asymptomatic contacts exhibited low frequencies of SARS-CoV-2 IFN-γ–producing T cells. Because these 4 contacts were exposed to COVID-19 patients and the unexposed controls donated blood in April and May 2020, it is unclear whether the detectable T-cell responses were the result of cross-reactivity with common cold HCoV antigens, as previously reported (10–12) or of SARS-CoV-2 infection. Although recent research provided direct evidence of cross-reactivity between SARS-CoV-2 epitopes and common cold HCoVs (9), we observed no obvious relationship between the magnitude of T-cell responses against spike glycoproteins of common cold HCoVs and SARS-CoV-2 in index patients, contacts, and unexposed HD. In parallel with our findings, another recent study (13) reported finding memory T-cell response against SARS-CoV-2 structural proteins in exposed family members and healthy persons lacking detectable circulating antibodies who donated blood during the pandemic. 
There are multiple explanations for virus-specific T cells developing without any antibody response. A study in a small cohort of patients (14) reported that 40% of asymptomatic and 12.9% of patients with mild COVID-19 no longer had antibodies 56 days after being discharged from the hospital. In our study, the serum samples were collected between 49 to 102 days after symptom onset, so it is possible that the contacts had lost their antibodies during this period. It is also possible that very low levels of antibodies that might have developed in contacts were not detected by the serologic assays we used. The lack of specific antibodies might also be because of exposure to low doses of the virus with brief and transient viral replication, to a downstream event of protective innate immune response, or to abortive replication of defective viral genomes (5).
Eventually, the presence of SARS-CoV-2-specific T-cell response, whether because of infection with SARS-CoV-2 or a cross-reaction, might explain the mild and rapidly resolved symptoms in index patients and symptomatic contacts and the resistance of other contacts to symptomatic SARS-CoV-2 infection. However, this possible explanation needs to be investigated further in a large cohort. 
Our study is subject to several limitations. First, our findings suffer from a limited sample size, although this is a unique cohort, and it was not possible to increase the sample size. Second, because of the unavailability of PBMCs collected before the pandemic, we recruited unexposed HD who donated their blood during the pandemic as controls, so we cannot exclude a potential infection by SARS-CoV-2 before the enrollment in the study. Third, although we detected high frequencies of T-cell response against diverse SARS-CoV-2 proteins in symptomatic contacts lacking circulating antibodies, it remains possible that a part of this response may be a result of cross-reaction with common cold HCoVs. 
Overall, our results indicate that persons exposed to SARS-CoV-2 may develop virus-specific T-cell responses without detectable circulating antibodies. This aspect of the immune response against SARS-CoV-2 contributes substantially to the understanding of the natural history of COVID-19. Furthermore, our data indicate that epidemiologic data relying solely on the detection of SARS-CoV-2 antibodies may lead to a substantial underestimation of prior exposure to the virus. Our data may also have implications for vaccine development and tracking the future evolution of the SARS-CoV-2 pandemic. ",Emerg Infect Dis
PMC7780968,COVID-19 Racial and Ethnic Inequities in Acute Care and Critical Illness Survivorship,"The COVID-19 pandemic highlights existing racial disparities in health care. Beyond an increased mortality, communities of color experience other disparities in clinical care such as limited access to specialty care physicians (4) and differences in rates of diagnostic testing (4). During hospitalization, language barriers may limit effective communication with patients from various ethnic backgrounds. In response to the pandemic, and without national guidelines, hospitals and state departments of health drafted plans for scarce resource allocation (Crisis Standards of Care [CSC]); the guiding principle for many plans is to “do the greatest good for the greatest number of people.” In many states, allocation of resources is based on probability of survival, which is often calculated with Sequential Organ Failure Assessment (SOFA) scores to prognosticate short-term survival and comorbidities to prognosticate 1- to 5-year survival. There are several problems with this approach. Comorbidities are often weighted equally with SOFA scores; however, most comorbidities considered in prognostication are complex, heterogeneous diseases, making prognostication on this basis questionable. In addition, rather than using well-validated comorbidity indices, such as the Charlson index, certain states have used unvalidated methods for classifying comorbidities. For example, in the Massachusetts CSC (5), comorbidities are classified as major conditions with death likely within 5 years and severe conditions with death likely within 1 year. Even if we could predict long-term survival with 100% accuracy, a low chance of 5-year survival should not dictate a change in resource allocation, as the number of accomplishments, amount of quality family time, and contributions to society can be significant in this time interval. Moreover, heavily weighing comorbidities may discriminate against minorities who have higher baseline rates of comorbidities because of social determinants of health. Finally, prediction models are meant to give probabilistic views of prognosis and are heavily dependent on the populations included in model development. A systematic review of 18 studies evaluated SOFA-based models to predict intensive care unit (ICU) mortality and reported area under the receiver operating curves to range from 0.61 to 0.88 (6); thus, even with good predictive models, ICU prognostication is imperfect.
As the medical community, we must consider how our utilitarian approach should be balanced by principles of distributive justice (7). Indeed, there are prominent historical and contemporary examples of the medical community’s contribution to propagating racial myths, inequalities, and unethical experiments. Through the lens of distributive justice, SOFA scores do not account for hundreds of years of discrimination. We advocate for several mechanisms to address this inequality. First, implementing a racial or socioeconomic correction factor may help to address these issues (7). Any such modification to existing scores must be studied and evaluated for predictive performance and to ensure there is no evidence of worsening racial disparities. Predictive models for survival in ICU patients with COVID-19 are needed and should address the influence of race/ethnicity on survival. Second, priority scoring processes may lack adequate representation of affected populations and are subject to implicit bias. Training of individuals involved in the scoring process to recognize both ethical and equity values is paramount. Lastly, hospital triage and ethics committees ought to be checks and balances for each other; the group allocating resources and the group ensuring implicit biases are not driving management (i.e., ethics) should be separate. As we examine CSCs and existing racial disparities in health care, we as a medical community need to consider how we can create a more just system.
Critically ill patients are at risk of subsequent physical, psychological, and cognitive burdens—post–intensive care syndrome—and thus may have additional ongoing care needs requiring stable access to services. Severe physical weakness was noted in over half of acute respiratory distress syndrome survivors and delirium in up to 80% of mechanically ventilated patients (8). After the acute period, it is uncertain how many patients with COVID-19 will ultimately receive a tracheostomy, but a recent Boston study reported that 21.2% underwent tracheostomy (9). Data show the average patient undergoing prolonged mechanical ventilation spent 74% of all their days alive in a hospital, in a post–acute care facility, or receiving home health and had multiple transitions of care (10). This was among patients in their mid-50s who had more than a high school education with few premorbid functional limitations or medical comorbidities. Given the disproportionate burden of severe COVID-19 among minority patients who are more likely to suffer from baseline comorbidities, their post–acute care utilization may be higher and outcomes may be worse. Per patient, post–acute care is also costly and highest among patients who require long-term acute care (10). The financial burden of post–acute care may be even more harmful for socioeconomically disadvantaged patients. Access to post–acute care facilities are largely mediated by insurance payer type, and white patients are more likely to possess the necessary insurance coverage (i.e., Medicare and commercial insurances) (11). The anticipated need for possibly high-cost post–acute care utilization by patients with COVID-19, coupled with disproportionate impact among racial/ethnic minority patients who may have more coverage limitations, is concerning for their ability to recover heightening the very disparities that may have led to an increased risk for disease.
By recognizing these challenges facing racial/ethnic minority patients, providers and systems have the opportunity to mitigate health disparities. Individual pulmonologists and intensivists can recognize personal implicit bias and engage with hospital leadership to ensure collection of demographic data and build a multidisciplinary task force charged with identifying and mitigating social determinants of health. An individual health system can fortify translator services to ensure guidance is tailored and understood by patients served in the system, partner with community health centers to expand COVID-19 testing, reduce the digital divide and limitations of telehealth access by racial/ethnic minority patients, evaluate workforce diversity (both for the advancement of racial/ethnic diversity of practitioners and to assess impact of the pandemic on staff), and consider development of coordinated post–COVID-19 recovery care which racial/ethnic minority patients with post–intensive care syndrome or chronic critical illness can access.
Although individual clinicians and healthcare systems can help address inequities for patients requiring post–acute care services, we ultimately also need health policy solutions. Current expenditure is necessarily focused on the acute hospitalization, but policies for post–acute care are critical, including funding to ensure capabilities for post–acute care facilities and rehabilitation.
Though the Coronavirus Aid, Relief, and Economic Security Act protects uninsured patients from costs to a degree, and some private insurers will waive cost sharing for treatment, it remains unclear if this will be sufficient and how long-term care expenditure will be prioritized. Proposed congressional legislation (12) focuses on collecting data with race information, creation of multiagency and clinician task forces overseeing health equity in the federal response, grant funding for community-based responses to the pandemic, a relief package that provides free testing and treatment, and policy frameworks that reduce barriers to care. The success of these measures may be modified by clinician advocacy and support.
We have had the privilege to serve patients during this crisis—patients who themselves were providers, worked in public-facing occupations, had newborns they never met, or whose loved ones never got to see them. We are inspired by care teams everywhere providing high-quality patient-centered care in the acute and post–acute care settings and are encouraged by the vision that comprehensive, systematic action to reduce inequities can be integrated into our path of recovery.",Ann Am Thorac Soc
PMC7774528,"Prevalence of SARS-CoV-2, Verona, Italy, April–May 2020","We estimated the prevalence of active or past SARS-CoV-2 infection among the population of Verona among randomly selected participants >10 years of age. This investigation was an observational, cross-sectional study approved by the Ethics Committee of Verona and Rovigo provinces on April 15, 2020 (internal protocol no. 2641CESC), in compliance with the Strengthening the Reporting of Observational Studies in Epidemiology guidelines (7).
According to Verona’s municipal register, 235,034 persons >10 years of age lived in Verona on January 1, 2020 (8). We used systematic random sampling to compile a list of potential participants. Because the prevalence of asymptomatic SARS-CoV-2 infection in Italy had previously been estimated at 10.0% (9,10), we decided to randomly sample 1,527 participants, resulting in a standard error of <1.5%. We predicted a dropout rate of 35% and accordingly mailed invitations to 2,061 potential participants. We selected the first sample using a random starting point; for subsequent samples, we used a sampling interval calculated by dividing the population size by the desired sample size (235,034/2,061 = 114).
We collected data from April 24 through May 8, 2020. We required a parent’s or guardian’s consent for participants <18 years of age. All participants gave their informed consent. Participants first completed a phone interview about COVID-19 symptoms within the previous 15 days. Specialized staff at Istituto di Ricovero e Cura a Carattere Scientifico then collected blood and nasopharyngeal swab samples from each participant. These staff extracted total RNA from nasopharyngeal swab samples using a MagnaPure LC.2 instrument and MagNA Pure LC RNA Isolation Kit (Roche Molecular Systems Inc., https://lifescience.roche.com), according to the manufacturer’s instructions. We analyzed the eluted RNA by reverse transcription PCR (RT-PCR) to detect the presence of active infections (11). We analyzed serum samples for IgG against SARS-CoV-2 by serologic assay (Abbott, https://www.abbott.com) to detect previous infections. Experienced laboratory personnel conducted each test independently and blindly.
Because neither assay has perfect sensitivity, we used latent class analysis (LCA) to estimate the prevalence of SARS-CoV-2 infection. LCA models were based on SARS-CoV-2 test results and selected clinical variables (12). We interpreted the outcomes as the probability that a given person was (or had been) infected (13). We reported all parameters and estimations with 95% CIs. We adjusted statistical models and estimations for covariates.
A total of 1,515 persons participated in the study (Figure). We found no significant difference in sex proportions between the general population (53% female) and the study sample (54% female). The mean age of all participants was 52.1 (SD = 20.0) years in the general population and 49.1 (SD = 22.2) years in the study sample. We summarized demographic and clinical data using descriptive statistics and measures of variability and precision (Table 1). Of 1,515 participants, 9 (0.6%) tested positive for SARS-CoV-2 RNA but negative for IgG against SARS-CoV-2, 40 (2.6%) tested negative for viral RNA but positive for IgG, and 1,465 (96.7%) tested negative for both indicators. Only 1 participant tested positive for RNA and IgG. Participants who tested negative for viral RNA but positive for IgG reported symptoms such as anosmia (39.5%), temperature >37.5°C (30.8%), fatigue (35.9%), and persistent cough (28.2%). Less than 2% of participants who tested negative by both tests reported symptoms.
We used a backward stepwise multinomial multivariate logistic regression model to compare selected COVID-19 symptoms (i.e., anosmia, dyspnea, diarrhea, and fever) in the RNA-positive and RNA-negative/IgG-positive groups with the RNA-negative/IgG-negative group. Fever and anosmia were each significantly associated with belonging to the RNA-negative/IgG-positive group (p<0.01) but not the RNA-positive group.
We used LCA to estimate the prevalence of infection considering the results of RT-PCR, the serologic assay, and the symptoms selected by stepwise regression. The estimated probability of belonging to class 1 (uninfected) was 0.97 and class 2 (infected) was 0.03 (Table 2).
As of May 25, 2020, Verona had 1,528 cumulative patients in whom SARS-CoV-2 infection was diagnosed, including 144 who had died, indicating a 9.4% death rate (14). Verona was the province in Veneto with the most cases and deaths caused by SARS-CoV-2 (15). Our LCA estimated a prevalence of 3.0%, suggesting 7,051 cumulative cases (4.6 times higher than the official count). These estimates suggest that 144 reported deaths would indicate a 2.0% death rate. According to the crude rates, the 50 SARS-CoV-2–positive participants in our study would account for 3.3% of the total study population. Applying this percentage to the whole population of Verona would indicate 7,756 cases and a 1.9% death rate.
Of the 10 RNA-positive participants, only 1 tested positive by serologic assay. This finding raises concerns about the current screening policy of 2-step testing, which comprises a serologic assay and, if the assay results are positive, PCR. Given the economic costs associated with testing, officials should carefully advise the public on all testing options.
Our study has a few limitations. Because participation was voluntary, our study might have been influenced by selection bias (Figure). Also, LCA might have underestimated the accuracy of both diagnostic tests. For example, considering past and active infections together might have reduced test sensitivity. Furthermore, the PCR assay did not have 100% specificity, as is usually assumed (A.N. Cohen, unpub. data, https://www.medrxiv.org/content/10.1101/2020.04.26.20080911v4). The model might have also underestimated the specificity of the serologic assay. However, the crude rates estimate a prevalence only slightly higher, and the death rate only slightly lower, than predicted by our model.
Our study estimated the prevalence of SARS-CoV-2 infection in Verona using a random sample of its population. Similar studies are currently underway on a larger scale. The results will estimate the true circulation of SARS-CoV-2, better approximate the death rate, and inform infection containment and management. Our study provides a clear picture of the circulation of SARS-CoV-2 infection in the general population of a city and an estimation of the true death rate caused by the infection. The results also suggest that 2-step testing might not detect all active infections. We are currently organizing phase 2 of our study, during which we will conduct follow-up serologic testing on all PCR-positive and PCR-negative/IgG-positive participants, enabling the evaluation of any antibody seroconversion, negativization, or change in titer.",Emerg Infect Dis
PMC7774584,"Territorywide Study of Early Coronavirus Disease Outbreak, Hong Kong, China","For this retrospective, multicenter study, we enrolled case-patients with laboratory-confirmed COVID-19 from 4 public hospital clusters managed under the Hospital Authority of Hong Kong, namely Hong Kong East Cluster, Kowloon East Cluster, Kowloon West Cluster, and New Territories West Cluster, during January 26–February 28, 2020. Sputum specimens and throat swab specimens pooled with nasopharyngeal aspirates were collected from patients who fulfilled the reporting or enhanced surveillance criteria at hospital admission (8). Laboratory-confirmed infection was defined as the detection of SARS-CoV-2 by real-time reverse transcription PCR, which amplified the envelope (E) gene and RNA-dependent RNA polymerase (RdRp) gene (9).
We obtained demographic, clinical, and microbiologic data from patients’ medical records. Epidemiologic information was retrieved from the Centre for Health Protection of the Department of Health (6) and the website https://wars.vote4.hk (7). The definitions of clinical symptoms and complications are based on World Health Organization guidance (10). We adopted the Centre for Health Protection case numbering system, which is based on the date of case confirmation. This study was approved by the Institutional Review Boards of The Hong Kong Polytechnic University (approval no. RSA20021) and the public hospitals involved (HKECREC-20200014; KCC/KEC-20200070; KWC-20200040; NTWC-20200038).
The respiratory specimens were centrifuged at 16,000 × g for 2 minutes. Total nucleic acid was extracted from supernatant using MagNA Pure 96 System (Roche, https://lifescience.roche.com) or NucliSENS easyMAG (bioMérieux, https://www.biomerieux-nordic.com) according to the manufacturers’ instructions. DNase treatment was done by using TURBO DNA-free Kit (ThermoFisher Scientific, https://www.thermofisher.com) to remove residual host DNA.
DNase-treated RNA was reverse-transcribed using random hexamers and SuperScript IV Reverse Transcriptase (ThermoFisher Scientific) as previously described (11). Viral cDNA was then amplified by using 2 PCRs containing tiled, multiplexed primers (Appendix 1 Table 1) described in the ARTIC protocol (https://artic.network/ncov-2019) (12). Details of the multiplex PCR are provided in Appendix 2.
Ligation-based 1D sequencing was carried out by using Litigation Sequencing Kit SQK-LSK109 (Oxford Nanopore Technologies, https://nanoporetech.com) according to manufacturer’s instructions. Multiplex PCR amplicons of each sample were normalized to 1 ng/µL before end-repair and native barcode ligation by using EXP-NBD104/114 (Oxford Nanopore Technologies). Barcoded samples were pooled and ligated to AMII sequencing adaptor. Sequencing was performed with Nanopore MinION device (Oxford Nanopore Technologies) by using R9.4.1 flow cell for 48 hours.
Multiplex PCR amplicons were subjected to library preparation and dual-indexing by using KAPA HyperPrep Kit and Unique Dual-Indexed Adaptor Kit (Roche) according to manufacturer’s instructions. Ligated libraries were enriched by 6-cycle PCR amplification and purification and size selection by using AMPure XP beads (Beckman Coulter, https://www.beckmancoulter.com/). The pooled library was sequenced with the MiSeq Reagent Kit V2 Nano on an Illumina MiSeq System (Illumina, https://www.illumina.com).
We analyzed nanopore sequencing data using modified Artic Network nCoV-2019 novel coronavirus bioinformatics protocol (Appendix 2) (13). Illumina sequencing reads were mapped with reference to respective consensus genome of each sample constructed from nanopore data. Variants were called by using freebayes version 1.0.0 (https://github.com/freebayes/freebayes) with haploid decoding and minimum base quality set at Q30. Consensus genomes were constructed by GATK 4.1.4.1 based on the VCF file (14). SPAdes genome assembler 3.14.0 (https://cab.spbu.ru/software/spades) and minimap2 version 2.17 (https://anaconda.org/bioconda/minimap2) were used to combine nanopore and Illumina sequencing results for de novo assembly and to identify the sequence of the unmapped gap regions. The sequences have been submitted to GenBank (accession nos. MT232662711).
To identify the amino acid change caused by each single-nucleotide polymorphism, we BLAST-searched the consensus genome of each specimen against the reference NC_045512.2 using BLASTX (https://blast.ncbi.nlm.nih.gov/Blast.cgi). Nonsynonymous mutations were identified using custom Python script (https://github.com/kenssl/Blast_mismatch_search).
Consensus genomes were aligned by Clustal Omega 1.2.4 (https://www.ebi.ac.uk/Tools/msa/clustalo). Phylogenetic tree was constructed with PhyML 3.0 (http://www.atgc-montpellier.fr/phyml/) using the maximum-likelihood algorithm. Best-fitting substitution model was selected by Akaike information criteria, in which we selected the general time-reversible model with fixed proportion of invariable sites (15). Bootstrap replicates were set at 1,000×, and maximum-likelihood phylogenetic tree was rooted on the earliest published genome (accession no. NC_045512.2). Transmission clusters were defined by clear epidemiologic and onset-time relationship. Meanwhile, we downloaded an additional 478 SARS-CoV-2 genomes from the GISAID (https://www.gisaid.org) SARS-CoV-2 data hub (16) and analyzed the phylogenetic relationships by using maximum-likelihood with bootstrap value set at 500× and rooted on SARS-CoV-2 genome NC_045512.2.
To reconstruct the evolutionary model of COVID-19 cases using the viral genomes obtained in Hong Kong, we implemented Bayesian inference through Markov Chain Monte Carlo (MCMC) framework in BEAST version 2.6.2 (17). Death rate δ (which refers to the time needed for a case-patient to become noncontagious) was determined as the lag time between date of symptom onset and date of hospital admission, because the transmission link in Hong Kong was practically stopped once the patient was hospitalized. Bayesian phylodynamic analysis was performed using strict clock and relaxed clock models with coalescent exponential growth tree priors. We ran MCMC chains for 109 generations and sampled every 500 steps. Bayesian output was analyzed after the results were visualized by Tracer version 1.7.1 (18). All parameters had an effective sample size of >200, indicating sufficient sampling.
Our investigation included 50 COVID-19 patients; 54.0% were women, and the mean age was 55.2 (range 22–96) years (Table 1). Of the case-patients, we categorized 3 cases as imported because the patients stayed in Wuhan before traveling to Hong Kong in mid-January. Four patients traveled to Japan and other provinces of China in mid-January and were hospitalized after they returned to Hong Kong, but active community transmission of COVID-19 was not officially reported in these areas during the study period, so these cases were considered possible local infections. The other 43 patients’ cases were categorized as local infection because of no recent travel history. 
Eighteen (36.0%) patients had chronic illnesses, of which cardiovascular and cerebrovascular diseases were the most common (Table 1). In total, 74.0% of the patients were experiencing cough at admission. Fever occurred in 58.0% of patients at time of admission, but that rate gradually increased to 64.0% during the course of hospitalization. Other less common symptoms were muscle aches (25.0%), sore throat (24.0%), shortness of breath (24.0%), and diarrhea (14.3%) (Table 2). Two persons (4.0%) were asymptomatic throughout the study period. On radiologic examination, 27 (54.0%) had bilateral pneumonia, 11 (22.0%) had unilateral pneumonia, and 17 (34.7%) showed multiple areas of mottling and ground-glass opacity. None of the patients were co-infected with other respiratory viruses or fungi. 
Intensive care unit admission was relatively uncommon (3/50, 6.0%) in our cohort compared with admission rates in previous studies (19–22). This difference could be attributed to underdiagnosis of milder cases during the initial COVID-19 outbreak in China. One patient’s sputum specimen was culture-positive for Klebsiella aerogenes bacteria; a second patient’s specimen was culture-positive for Ralstonia pickettii bacteria. Both had acute respiratory distress syndrome and acute respiratory injury accompanied by septic shock or acute renal injury and required admission to the intensive care unit.
Of the 50 case-patients, 42 (84.0%) could be clustered based on their epidemiologic links (Figure 1). We identified 6 transmission clusters (clusters 1–6). Cluster 1 involved a 4-member family. The father, who traveled to Guangdong, China, in late January 2020, was believed to have infected his wife and subsequently their daughter and son-in-law at a family gathering. Clusters 2 and 3 were family clusters of local infection and unknown source. Both clusters involved 3 household members with no recent travel history. Cluster 4 was attributed to a superspreading event (SSE): a barbecue and hotpot party involving 19 family members in late January. Symptom onset in these patients occurred during days 2–13 after the party. A colleague of 1 infected person, who did not attend the party, also tested positive for SARS-CoV-2. Cluster 5 initiated from a resident of a public housing estate, in whom COVID-19 was diagnosed on January 30. Eleven days later, diagnoses were made in 3 members of a household that resided in the same building (10 stories below) the index case-patient. Two household members subsequently attended a family gathering of 29 persons at a Chinese restaurant during the incubation period. COVID-19 was diagnosed consecutively in 3 persons ≈2 weeks after the gathering. In addition, a Filipino domestic aide of 1 infected family member, who did not attend the family gathering, also tested positive. For cluster 6, the first reported case was in a 70-year-old woman who visited a Buddhist worship hall during the Chinese New Year. A further 8 persons who visited the same Buddhist worship hall during this period later tested positive for SARS-CoV-2. At the data cutoff point, >4 other household members who had never been to the worship hall also tested positive. Details of the demographic and epidemiologic information on the cases and clusters are provided in Appendix 1 Tables 2–8.
Consensus genomes of all 50 cases were constructed based on nanopore sequencing and refined by Illumina sequencing. On average, 62,387 reads/genome were obtained with 550× coverage for nanopore, and 18,747 reads/genome were obtained with 132× coverage for Illumina platform. The consensus genome size was ≈29.9 kbp with GC content ≈38%. The genomes were highly conserved with the first SARS-CoV-2 genome and had an average sequence identity of 99.98% (range 99.94%–100.0%). We identified 64 nonsynonymous substitutions from all 50 genomes (Appendix 1 Table 9). Orf3a-G251V was the most frequent amino acid substitution; 44/50 (88.0%) of the samples harbored this mutation, after which Orf1ab-H3233Y (30/50, 60.0%) and S-L8V (27/50, 54.0%) were most common.
Genomewide single-nucleotide polymorphisms were used to contextualize phylogenetic placement of Hong Kong strains in SARS-CoV-2 global phylogeny (Appendix 2 Figure 1). However, because the samples were taken at the early stage of global outbreak, the genetic variability between strains was limited, resulting in several unresolved branches and marginal supporting bootstrap values. Nevertheless, when compared with SARS-CoV-2 strains isolated from other regions, Hong Kong strains tended to aggregate mainly in 2 lineages. Lineage 1 consisted of 4 Hong Kong strains that clustered with most isolates from China (n = 32). Lineage 2, which consisted of 44 Hong Kong strains, was more closely related to strains seen in South Korea (n = 7) and France (n = 5).
In examining the phylogeny of the COVID-19 outbreak in Hong Kong, we identified 2 distinctive groups (Figure 2). The first group consisted of 2 imported cases and the cases in cluster 1. The second group originated with a single robust node with bootstrap value of 94% and a common mutation Orf3a-G251V. The second group could be further separated into 3 subgroups. The first subgroup mainly consisted of the cases in cluster 5, the public housing estate–related SSE. The second subgroup included cases in cluster 4 associated with the family hotpot party, cluster 3, and 2 isolated cases (case 23 and case 43). These samples shared the same missense mutations at S-L8V and Orf1ab-H3233Y. Finally, the third subgroup included the cases from cluster 6, an SSE originating from a Buddhist worship hall, in which Orf1ab-G295V were identified.
According to Bayesian time-scaled phylodynamic analysis, strict clock and relaxed clock models estimated the time of most recent common ancestor of COVID-19 outbreak in Hong Kong as December 24, 2019 (95% Bayesian credible interval [BCI] December 11, 2019–January 5, 2020). The evolutionary rate was 3.04 × 10−3 substitutions/site/year (95% BCI 2.04–4.09 × 10−3 substitutions/site/year) (Appendix 2 Figure 2). Based on demographic data, the average time from symptom onset to hospital admission was ≈8.5 days. The estimated reproduction number was calculated at 1.84 (95% BCI 1.37–2.35).
This study provides a territorywide overview of early COVID-19 outbreak in Hong Kong, an international city with borders connecting to mainland China, by integrating demographic, clinical, epidemiologic, phylogenomic, and phylodynamic data. In Hong Kong, most cases recorded in January 2020 were imported cases. After February 1, most were local cases and close contacts of those case-patients, indicating local community transmissions. Transmission in closed settings, especially during family and religious gatherings, is a hallmark of recent cases recorded in Hong Kong. Among 6 clusters identified on the basis of epidemiologic links, 3 (clusters 4–6; Figure 1) were considered SSEs because of the larger number of persons involved (n = 8–13). We performed whole-genome sequencing on all 50 cases to investigate phylogenetic relationship and transmission link.
The SARS-CoV-2 samples in Hong Kong had 99.98% identity to the reference genome (GenBank accession no. NC_045512.2) and demonstrated no apparent major genome modification since the initial COVID-19 outbreak in Wuhan. As shown in global phylogeny, SARS-CoV-2 genomes isolated in Hong Kong could be segregated into 2 lineages. Lineage 1 was phylogenetically related to the strains isolated from China and was the cause of the cases in Cluster 1. Lineage 2 was more closely related to strains from France and South Korea. It also harbored a common mutation at Orf3a-G251V, which accounted for 88.0% of cases in this study.
Regarding the local phylogenetic analysis, clustering of samples was highly concordant to the epidemiologic link, despite the marginally supportive bootstrap value of the nodes because of the limited genetic variability. Cluster 1 demonstrated the closest genetic distance to the reference genome among all cases reported in Hong Kong (Figures 1, 2). The index case of cluster 1 (case 66) was initially defined as possible local infection because the patient traveled to Guangdong Province, which was not considered to have active community transmission at that time. However, our sequencing result demonstrated that the genome of case 66 was 100% identical to the first published SARS-CoV-2 genome, and all cases in cluster 1 did not harbor Orf3a-G251V, which was recognized as a hallmark of local cases with unknown source in our community. Therefore, instead of possible local infections, cluster 1 was more likely imported from mainland china through index case-patient 66.
Cluster 5 originated within a public housing estate, in which a family of 3 members (cases 42, 48, and 49) were suspected to have been infected through a confirmed case-patient (case 12) who lived 10 stories above them in the same building, through a potentially faulty sewage pipe setup or other environmental exposure. Based on phylogenetic analysis, viral genomes in cluster 5 shared a similar genetic distance from the reference genome and were assigned to the same branch of the tree. This finding supports a potential transmission link among these cases.
Cluster 4 was a family gathering–associated SSE during Chinese New Year. In concert with epidemiologic information, all 11 cases from cluster 4 shared 3 common missense mutations, namely S-L8V, Orf1ab-H3233Y, and Orf3a-G251V; 7 cases shared identical genomes. Considering the fast-evolving property of RNA viruses, the presence of identical genetic sequences among the strains implies that transmission occurred over a short period or even in a single event. Meanwhile, 2 isolated cases (case 23 and case 43) and 3 cases from another local cluster (case 38, case 39, and case 40) shared highly similar genomes to those of cluster 4 (Figures 1, 2). Although no apparent epidemiologic links were observed, the high degree of genomic similarity suggests that these cases might have originated in a single source. That speculation was further supported by the geographic distribution of case-patients who lived near one another and whose social circles might have overlapped (Figure 3). Our results demonstrate that the integration of epidemiologic and phylogenetic data is critical for providing more accurate information about transmission patterns.
Cluster 6 was an SSE occurring in a Buddhist worship hall. Two missense mutations, Orf1ab-G295V and Orf1ab-L3606F, were unique to this cluster. Epidemiologic investigation identified a 43-year-old monk (case 102; Figure 1), who was the abbot of the worship hall and had traveled to mainland China in early January. He was sent to a quarantine center in late February after being linked to a series of confirmed cases connected to the worship hall. He was asymptomatic throughout the study period. Phylogenetic analysis showed that this case was closest to the root of the cluster (Figure 2), suggesting that case 102 could be the index patient of cluster 6. By the time of data cutoff, the cluster involved 13 patients and spread was ongoing. This pattern demonstrates the possibility of a hidden spreader as a source of COVID-19 community outbreak. That likelihood also highlights the importance of rapid quarantine of close contacts of confirmed case-patients, regardless of the presence of symptoms, to halt community spread.
In the evolutionary clock study, the reproduction number of COVID-19 within Hong Kong as of February 28, 2020, was estimated at 1.84 (95% BCI 1.37–2.35). That value strongly indicated that the outbreak in Hong Kong was ongoing, but it was smaller than the estimated reproduction number of 2.6 in Wuhan (23,24). The smaller value is a combined outcome of reduced growth rate and increased δ. The reduced growth rate is attributed to strong public health awareness among the general public, which resulted in greatly reduced social activities and strong compliance with mask-wearing during this period (25,26). The increased δ can be attributed to robust laboratory surveillance and fast quarantine time. In addition, time of most recent common ancestor for the cases in Hong Kong was determined to be December 24, 2019, ≈25 days before the first patient in our cohort (Case 2) demonstrated symptoms on January 18, 2020 (Figure 1).
Our study has several limitations. Although we included 53.8% of the cases reported in Hong Kong as of February 28, another 43 cases, including 2 fatal cases, were not analyzed in this study. Moreover, incubation periods of cases in which the source of infection is unknown might vary widely. Studies have demonstrated that incubation periods can vary from 4.5 to 15.8 days (24) and can be longer for patients experiencing mild symptoms. However, because patients might already be infectious during the incubation period, the reproductive number in this study could be underestimated. Furthermore, our calculations were based solely on phylodynamic analysis, which could differ from calculations on the basis of epidemiologic models. Finally, ambiguous bases were observed in some of our consensus genomes. This ambiguity is mainly because whole-genome sequencing was performed on respiratory specimens instead of viral culture, in which viral load plays a critical role in the subsequent genome quality as reflected by the cycle threshold of each specimen. The paucity of viral load in specimens could affect the yield of sequencing libraries. In our study, specimens with cycle threshold <28 were usually free of ambiguous bases. Nevertheless, the uncovered area only accounted for ≈1–3% of the entire viral genome, although the remaining mapped regions had an average coverage of >100×, which should provide sufficient and accurate information for subsequent analyses (Appendix 1 Table 10).
In conclusion, phylogenomic data were consistent with epidemiologic findings that transmission in closed settings, especially during family and religious gatherings, is a hallmark of COVID-19 outbreak in Hong Kong. Social distancing and vigilant infection control measures, such as rapid isolation of suspected or confirmed case-patients and their close contacts, are crucial for containing COVID-19 in the community.",Emerg Infect Dis
PMC7774532,IgG Seroconversion and Pathophysiology in Severe Acute Respiratory Syndrome Coronavirus 2 Infection,"Development of the SARS-CoV-2 IgG ELISA is available elsewhere (E.R. Adams, unpub. data, https://www.medrxiv.org/content/10.1101/2020.04.29.20082099v1). We analyzed antibody dynamics using anonymized excess diagnostic material from patients with PCR-confirmed SARS-CoV-2 infection. The study was sponsored by St. George’s Hospital National Health Services Foundation Trust (London) and has Institutional Review Board ethics approval (Development and Assessment of Rapid Testing for SARS-CoV-2 outbreak study; Integrated Research Application System project ID: 282104; Research Ethics Committee reference: 20/SC/0171). The trial is registered at ClinicalTrials.gov under NCT04351646.
Staff at St. George’s Hospital used Sigma Virocult (MWE, https://www.mwe.co.uk) to collect nose and throat swab samples from patients with SARS-CoV-2 infection; we prepared the samples with RNA extraction kits (Roche Molecular Systems Inc., https://www.lifescience.roche.com). We confirmed infection with the RealStar SARS-CoV-2 RT-PCR Kit selective for the S and E genes (Altona Diagnostics GmbH, https://www.altona-diagnostics.com) or cobas SARS-CoV-2 Test selective for the E gene and open reading frames 1ab (Roche Molecular Systems, Inc.).
South West London Pathology (London) provides microbial diagnostic testing for the region, including St. George’s Hospital, a tertiary teaching hospital. We obtained excess diagnostic material from South West London Pathology in the form of serum samples from patients with RT-PCR confirmed SARS-CoV-2 infection. The serum samples were anonymized and stored at 4°C for <2 weeks. Patients were sampled longitudinally to assess antibody dynamics; the data comprised >30 samples per day. If samples became unavailable from 1 patient (i.e., the patient was discharged or died), we added a new patient to the cohort. Excess diagnostic material was collected from 177 persons during March 29–May 22, 2020. The study population consisted of 9.9% (177/1,785) of persons (patients and staff) who tested positive for SARS-CoV-2 infection at South West London Pathology during this period.
We obtained data from patients’ electronic medical records. We coded outcomes (as of May 22) as hospital admission, intensive care unit stay, death, or discharge. We recorded the length of hospital stay of patients who were discharged or died. We considered peaks of inflammatory markers (e.g., C-reactive protein [CRP]) to be the highest values recorded from 5 days before the first positive swab sample through the end of the study. We obtained blood values at the time of diagnosis (within 3 days after the first positive swab sample was taken).
We used the COVID-19 IgG ELISA developed by Mologic Ltd. and manufactured by Omega (Omega Diagnostics Group PLC, http://www.omegadiagnostics.com), according to the manufacturer’s instructions (Appendix 1). The assay contained the spike and nucleoprotein antigens of SARS-CoV-2. Between plate coefficients of variation were 21.0% (lower cutoff) and 16.5% (positive control; n = 16). Higher ambient temperatures in the laboratory resulted in higher optical density readings (Appendix 1).
We cross-checked and normalized raw ELISA data to enable comparison (Appendix 1). We also resolved manual handling errors (Appendix 1). We applied 2-tailed parametric and nonparametric tests as appropriate, using PRISM version 8.0 (https://www.graphpad.com) for data analysis and display. We conducted a 1-way analysis of variance to compare the effects of race and demographic information on patient outcomes. We used multivariate linear regression to determine the relationship between mean normalized optical density (NOD) and age, sex, peak CRP, number of concurrent conditions, respiratory symptoms, and race.
We acknowledge the importance of patient and public involvement in clinical studies. However, because of the rapid progression of COVID-19 and the challenges of lockdown in the United Kingdom, we did not have sufficient time to involve patients and members of the public in the development, implementation, or interpretation of this study.
We studied 177 patients who provided 645 distinct excess diagnostic material samples (Table 1). Patients were from diverse ethnic backgrounds (34% White, 35% non-White, 31% unreported; Appendix 1), and the median age was 64 years (interquartile range [IQR] 52–77 years). Fifty-seven percent were male, and 73% had >1 concurrent condition. Nineteen percent were asymptomatic and did not report respiratory symptoms at admission; these patients tested positive for SARS-CoV-2 infection while receiving treatment for other conditions. Among the 143 symptomatic patients, the median time from symptom onset to testing was 6 days (IQR 3–9 days). Of the 177 patients, 166 (94%) were hospitalized, 7 (4%) were staff, and 4 (2%) were outpatients. Of the hospitalized patients, 44 (27%) died (median time to death was 19.1 days [IQR 14.8–24.8 days]), 108 (65%) were discharged (median length of stay was 19.3 days [IQR 10.6–31.1 days]), and 14 (8%) remained hospitalized at the end of the study. Sixty-three (38%) patients were admitted to intensive care during the study.
We normalized optical densities proportional to levels of SARS-CoV-2 IgG (Figure 1, panel A). Of the 177 patients, 149 (84% [95% CI 78%–89%]) had already seroconverted at the time of the first serologic test, 13 (7.3% [95% CI 4.3%–12.1%]) seroconverted after the first serologic test, and 15 (8.5 % [95% CI 5.2–13.5%]) did not seroconvert during the entire follow-up period (Appendix 1). Of the 15 patients who did not seroconvert, samples from beyond day 20 were available for 4 patients (26%); we did not detect IgG in these samples. This finding suggests that 2.0%–8.5% of patients might not develop detectable IgG against SARS-CoV-2.
We plotted NODs by time after a patient’s first positive swab sample (Figure 1, panel B) and after symptom onset (Figure 1, panel C). NODs plateaued »12 days after PCR and »19 days after symptom onset; this time difference is consistent with the median time of 6 days between symptom onset and PCR. After seroconversion, mean NODs remained stable over the course of the study (up to »60 days after symptom onset).
We assessed whether the rate of seroconversion was associated with patient age (<70 or >70 years), sex, or respiratory symptoms. None of these variables were discernably associated with seroconversion rates (Appendix 1). NOD IgG levels were not associated with sex or the presence of respiratory symptoms. (Appendix 1).
Patients of non-White race had higher mean NODs than those of White race (1.06 vs. 0.85; F = 1.61, df = 119; p = 0.04 by unpaired Student t-test) (Appendix 1). No other differences were associated with race. We used a multivariate analysis to identify variables independently associated with NODs; the mean NOD was associated only with age, peak CRP, and race. Although age, sex, peak CRP, number of concurrent conditions, respiratory symptoms, and race were associated with patient outcome in the univariate analysis, only peak CRP was associated with poor outcome in the multivariate analysis (Appendix 1).
Persons who seroconverted were older than those who did not (median age 65.5 vs. 41.0 years; p<0.01 by Mann-Whitney test) and more likely to have >1 concurrent condition (124/130 vs. 38/47; p<0.01 by Fisher exact test). History of hypertension was associated with a higher probability of seroconversion (74/75 persons with hypertension vs. 88/102 persons without hypertension; p<0.01 by Fisher exact test). Body mass index was higher among the group who seroconverted (25.7 vs. 21.2; p = 0.03 by Mann-Whitney test).
Unlike other markers of inflammation, CRP is routinely measured in patients with COVID-19. Rising CRP levels are indicators of a poor prognosis (if other causes are excluded), and are associated with cytokine release syndrome (5; Y. Woo, unpub. data, https://osf.io/mxsvw). CRP levels were significantly higher in patients with respiratory symptoms at diagnosis than in those without symptoms (Figure 2, panel A). Patients who died or required intensive care during the study period had higher CRP levels than patients who did not die or require intensive care (Figure 2, panel B). Patients who did not seroconvert had lower CRP levels than those who did (Figure 2, panel C). Peak CRP levels had more pronounced associations with outcomes and seroconversion than did CRP levels at the time of the first positive swab sample result (Figure 2, panels D–F). CRP levels peaked a median of 12 days (IQR 8–17 days) after symptom onset and 4 days (IQR 1–11 days) after the first positive PCR result. Other inflammatory markers, such as peak D-dimer, fibrinogen, and ferritin, were also higher in patients with respiratory symptoms at diagnosis. However, these data were available for fewer patients (Table 2; Appendix 1).
Our results illustrate serologic responses over the course of SARS-CoV-2 infection. Serologic tests can enhance diagnostic capability, especially during later infection (4,6,7), when viral loads might decrease. Serologic testing might also inform surveillance, seroepidemiologic studies, and contact tracing. Our study shows that a substantial proportion of COVID-19 patients require 3–6 weeks to generate antibodies. Furthermore, 2.0%–8.5% of patients do not have detectable antibodies within 60 days after infection. Most research on antibody dynamics came from China during the early stages of the pandemic (4,6,8). Here, we describe variables that influence IgG dynamics in SARS-CoV-2 infections in diverse populations.
The performance metrics of this ELISA (Appendix 2) are comparable to other validated assays. This first-generation ELISA might confirm infection in patients without a virologic diagnosis. We applied this test to study an ethnically and clinically diverse population. In most persons who seroconverted, the conversion was relatively rapid; NODs remained stable for weeks after infection (Figure 1). The probability of seroconversion was associated with increased age and concurrent conditions such as hypertension and increased body mass index. Higher NODs were associated with non-White race, admission to hospital, and higher peaks for inflammatory markers, such as CRP. Higher antibody titers are associated with clinical severity (i.e., death or admission to intensive care during study) in our cohort, in agreement with findings from other studies (4).
CRP is a sensitive marker of elevated proinflammatory cytokines, including interleukin 6. These cytokines might play a central role in cytokine release syndrome, which is associated with increased risk for death (Y. Woo, unpub. data, https://osf.io/mxsvw). Interventions such as tocilizumab, an interleukin-6 receptor antibody, interrupt the proinflammatory cascade. Such interventions might limit disease progression and reduce risk for death (9; E. Baker, unpub. data, https://osf.io/d2nh8); they are being studied in several randomized clinical trials. In our study, a small proportion of patients did not seroconvert within 20 days after testing positive for SARS-CoV-2 infection. Several mechanisms might explain this finding. First, these patients might never seroconvert. Second, their immune responses might be confined to other antigens or mediated through T cells. Another probable explanation is that some relatively mild infections might be restricted to the mucosal cells of the respiratory tract, where antibody responses are dominated by the secretory immune system. In this scenario, the systemic immune system might produce little or no IgG.
The association of higher NODs with elevated CRPs could indicate several potential pathways. For example, antibody responses might be closely related to cytokine response syndrome, which in turn is associated with more severe disease and death. Alternatively, elevated CRPs might indicate a more pronounced innate immune response in persons already at risk for severe disease and death. This heightened innate response might be associated with a higher viral load (potentially caused by enhanced viral replication mechanisms) and genetic interactions that influence innate inflammatory pathways. Therefore, a higher viral load might lead to higher NODs for antibodies in the acquired immune response pathways. Small trials on the potential therapeutic benefits of interventions using passive antibody transfer (10) suggest that the heightened innate response hypothesis is more probable (11). Higher antibody responses are also associated with higher doses of a nonreplicating Ad5-vectored vaccine for SARS-CoV-2 (12).
Limitations of PCR include difficulties with sampling; different sample types and techniques yield varying results. Furthermore, PCR demonstrates diminishing diagnostic yield for COVID-19 as respiratory viral loads fall and symptoms subside (8,13). It might also produce false positives caused by lingering viral nucleic acid, which is not infective yet can persist for weeks after infection. Contamination could also occur during sample handling; because PCR requires amplification steps, this assay has heightened risk for contamination. Serologic testing, and the ability to detect viral antigens, may increase diagnostic accuracy for COVID-19. Our findings support early studies suggesting that physicians should consider these diagnostic modalities in conjunction, especially when a patient has negative PCR results but has symptoms of COVID-19 (6). Many COVID-19 patients experience a delay in care, a trend that emphasizes the importance of containment strategies that encourage isolation.
One limitation of our study is that it is based mainly on hospitalized patients, of whom 1 in 5 did not have COVID-19 symptoms. Further studies should document antibody dynamics of patients with less severe infections, such as healthcare workers (14), and patients with low viral loads at the time of consultation. Our findings will complement the large cross-sectional and longitudinal serologic surveys, especially as high-quality tests become more widely available. NODs were within a limited dynamic range (we could not conduct dilution studies because of small sample volumes) but nevertheless associated with clinically relevant features of COVID-19. Prospective studies are assessing the relationships between viral loads and serologic responses in patients. Regular and long-term serologic assays will be essential to monitoring the duration of the humoral response and its protective role against SARS-CoV-2.
When interpreting serologic assays of COVID-19 patients, physicians should consider factors that can influence the probability of seroconversion. Our study elucidates some of these factors. We found that less severe infections and younger age were associated with reduced probability of seroconversion. Risk factors for more severe disease, such as non-White race, increased age, and hypertension, are also associated with increased inflammatory responses, higher normalized antibody titers, and probability of seroconversion.",Emerg Infect Dis
PMC7774569,"Emerging Human Metapneumovirus Gene Duplication Variants in Patients with Severe Acute Respiratory Infection, China, 2017–2019","Luohe is a city of 2.8 million people in Henan Province, northern China. In this study, we collected throat swab specimens and clinical data from 1,021 patients with SARI admitted to Luohe Central Hospital during October 2017–June 2019. Patients were 1 month–95 (median 3) years of age; most (76.7%) of the SARI cases involved children <5 years old. All swab specimens were tested by multiplex real-time reverse transcription PCR assay using a nucleic acid diagnostic kit (Kinghawk, http://www.kinghawk828.com), which identifies HMPV, influenza types A and B, human respiratory syncytial virus (RSV), human coronaviruses, human rhinovirus and enterovirus, human adenovirus, human parainfluenza viruses, and human bocavirus.
Overall, 83.2% (849/1021) of SARI patients were positive for >1 respiratory viruses; human adenovirus was the predominant virus identified, at 22% (225/1021). HMPV was identified in 7.1% (72/1021) of SARI patients, consistent with other studies that identified HMPV in 6%–12% of SARI cases (12,13). The proportion of HMPV-positive patients with co-detected respiratory viruses was 63.9% (46/72). The rates of HMPV positivity decreased gradually with age, from 9.1% in those <2 years old to 0.9% in adults (Table 1). The epidemic season for HMPV lasted from November through May or June, with the peak number of cases occurring in March and May in 2018 and March in 2019 (Figure 1). Most (98.5%) HMPV-positive patients in this study exhibited cough or dyspnea and were diagnosed with bronchopneumonia (74.6%). No clear differences in clinical signs and symptoms were apparent among the patients infected with duplication variants compared with other HMPV viruses.
Forty-three entire coding-region sequences of the G gene were obtained from 72 HMPV-positive samples, as described elsewhere (3,5,6) (Table 2). The nucleotide sequences generated in this study were submitted to GenBank (accession nos. MN944056–97). We selected 86 subgroup A sequences (54 from GenBank and 32 from this study) and 23 subgroup B sequences (12 from GenBank and 11 from this study) to construct the phylogenetic tree by maximum-likelihood method (Figure 2). The HMPV sequences obtained in this study were clustered into 4 genotypes, including A2c, A2b, B1, and B2 (Table 2; Figure 2). Twenty-eight out of 31 A2c sequences were grouped together in 1 distinct cluster with the duplication variants, mainly detected in Spain, Japan, Croatia, and Guangzhou, China. In the sequence alignment comparison analysis, we identified 22 viruses containing 111 nt-dup variants and 6 viruses contained 180 nt-dup variants in the G gene. The 111 nt-dup variants were detected in Luohe in 2018 and continued to spread in 2019, while 180 nt-dup variants were detected during 2017 and 2018 (Table 2). The 111 nt-dup variants were separated from the 180 nt-dup variants in the phylogenetic tree, which indicates that the 2 duplication variants evolved by independent patterns in different evolutionary lineages (Figure 2, panel A). 
The twenty-two 111 nt-dup variants circulating in Luohe during 2018–2019 were closely related to the duplication-variant viruses identified in Japan, Croatia, and Guangdong, China, in 2017, with nucleotide identity of 95.7% to 100%. Six 180 nt-dup variants circulating in Luohe during 2017–2018 were clustered in 1 small cluster with high nucleotide identity at 99.1% and 100% and closely related to the duplication viruses identified in Japan, Croatia, Spain, and Beijing, China, during 2014–2017 (Figure 2, panel A). This finding indicates that the 111 nt-dup and 180 nt-dup variants have already spread and might spread extensively throughout the world.
Our findings show that 7.1% of SARI patients in the Luohe study tested positive for HMPV during 2017–2019. The rate of HMPV-positivity decreased gradually with patient age. Among the HMPV patients, 63.9% were co-infected with other respiratory viruses. Four different genotypes were cocirculating, including A2b, A2c, B1, and B2. We identified most of the A2c viruses as duplication variants, including the 111 nt-dup and 180 nt-dup variants, and found that these 2 variants were the predominant viruses circulating in Luohe during 2017–2019. 
The 111 nt-dup and 180 nt-dup variants have also been detected in different regions of the world, including in Spain, Japan, Croatia, and Guangzhou, China, in recent years (5,8–11). Similar duplications in the G gene have been reported in HRSV, another member of the family Pneumoviridae. The HRSV duplication variants of both BA9 and ON1 have rapidly spread globally, becoming the predominant viruses in many countries for many years (14,15). These findings suggest that the emerging HMPV 111 nt-dup and 180 nt-dup variants might also become predominant viruses throughout the world. 
There were some limitations in this study. The epidemic seasons were not covered for the entire 3 years, and only 1 hospital was involved in this study. Continuous surveillance will be required to determine whether these novel HMPV 111 nt-dup and 180 nt-dup variants will persist as predominant viruses and have a wider geographic distribution in the future.
Although no difference in clinical symptoms was observed between the patients infected with HMPV duplication variants and those with non–duplication-variant viruses in this study, the increased transmission frequency of the duplication variants suggests a role for duplication in the G gene in potentially expanding its transmission. Therefore, further study is needed to clarify if and how the duplications result in an evolutionary advantage for HMPV. ",Emerg Infect Dis
PMC7774535,Large-Scale Testing of Asymptomatic Healthcare Personnel for Severe Acute Respiratory Syndrome Coronavirus 2,"This study was approved by the Stanford Privacy Office, and individual consent was waived. Stanford Medicine, which comprises Stanford Health Care (SHC), Stanford Children’s Health, and Stanford School of Medicine, is located in the San Francisco Bay area, California, USA, and is staffed by >26,000 HCP. We performed a SARS-CoV-2 testing study of asymptomatic HCP during April 20–June 8, 2020. Both patient-facing and non–patient-facing SHC HCP were invited for testing on a voluntary basis through messaging across all hospital departments to encourage a safe working environment. All HCP were eligible for testing, and risk-based eligibility criteria were not enforced.
rRT-PCR of nasopharyngeal swab samples was performed by using the SHC envelope gene laboratory-developed test and a commercial assay (Panther Fusion SARS-CoV-2; Hologic Inc., https://www.hologic.com), as described (6). The distribution of cycle threshold (Ct) values of positive results with these assays ranged from 10 to 45. Plasma IgG testing was also performed by using a SHC laboratory-developed ELISA specific for the spike glycoprotein receptor-binding domain antigen (Appendix).
Demographic data were extracted from an institutional database for the entire cohort, and chart review for persons with positive SARS-CoV-2 rRT-PCR results was performed by using electronic medical records. We excluded from the study persons with a positive rRT-PCR result and an illness consistent with COVID-19 in the preceding 6 weeks. Only the first rRT-PCR result per person was included for the main analysis. Repeat rRT-PCR or IgG serologic analysis within 2 weeks was recommended to each HCP who had an initial positive rRT-PCR result. HCP were classified as asymptomatic or presymptomatic on the basis of symptoms developing consistent with COVID-19 within 2 weeks after testing.
Statistical analysis was performed by using Stata version 15.1 (https://www.stata.com) and the χ2 test or Fisher exact test for categorical variables with <5 datapoints/cell and the Mann-Whitney U test for continuous variables. Results were interpreted as significant according to a p value <0.05.
After excluding of 12 persons who had a positive rRT-PCR result and earlier illness consistent with COVID-19, we included 12,418 asymptomatic HCP in the study (Figure 1). Of these persons, 8,775 (70.7%) were female, and median age was 39.5 years (interquartile range [IQR] 32.4–50.3 years). The SARS-CoV-2 rRT-PCR positivity rate was 26/12,418 (0.2%; 95% CI 0.1%–0.3%), and IgG seropositivity rate was 111/12,373 (0.9%; 95% CI 0.7–1.1). IgG serologic results were not available for 45 persons from the part of the study population for whom only nasopharyngeal rRT-PCR was performed.
Of the 26 persons who had positive rRT-PCR results, 20 remained asymptomatic; for the remaining 6, COVID-19 subsequently developed within a median of 3 days (IQR 1–9 days) (Table; Figure 2). None of the persons who had positive rRT-PCR results were hospitalized. Of the 20 persons who remained asymptomatic, 6 were IgG positive at the time of their positive rRT-PCR result (median Ct 38.1 [IQR 36.7–38.1]), and 2 of the 15 persons retested with the IgG test seroconverted 12 days later (Ct 20.8 and 38.0).
On the basis of the assumption that these 14 persons (6 presymptomatic and 8 asymptomatic who had early or delayed positive IgG results) had true positive results, the clinical specificity of the test was estimated to be 12,392 (99.9%) of 12,404 (Appendix Table). The overall median Ct was 38.1 (IQR 37.8–38.4) and overlapped between asymptomatic and presymptomatic persons (Appendix Figure). One asymptomatic HCP had a Ct value of 20.8, consistent with high viral load.
In this cohort of >12,000 asymptomatic HCP from an area that had low COVID-19 in-hospital and community burden at the time of the study, the prevalence of SARS-CoV-2 was low (<1%) by rRT-PCR and IgG serologic analysis. The combined rRT-PCR positivity rate for symptomatic and asymptomatic persons tested during the same period in Santa Clara County was 3.2%, and the county-level proportion of hospitalizations due to COVID-19 was also 3.2% (7). Other smaller asymptomatic HCP studies have demonstrated positive rRT-PCR prevalence ranging from 1% to 7% (3; E.S. Barrett et al., unpub. data). In addition, point-of-care IgG positivity estimates for asymptomatic persons in studies from Santa Clara and Los Angeles Counties ranged from 1% to 5% (8; E. Bendavid et al., unpub. data).
There are limitations in comparability given that rRT-PCR positivity indicates active infection and potentially contagious persons, whereas IgG positivity might indicate past or active infection. However, the findings in the current study suggest that, in low-prevalence settings, HCP SARS-CoV-2 transmission risk might be driven mostly by community exposure, given the limited evidence of nosocomial transmission. In this study, there was no apparent cluster of transmission events from HCP with positive rRT-PCR results. Nonetheless, given that most persons infected with SARS-CoV-2 in this cohort were involved in direct patient care, mass testing that focuses on these persons, as well as implementation in settings lacking personal protective equipment or with a high burden of infection, might show a higher yield (E.S. Barrett et al., unpub. data).
In this study, 1 asymptomatic person was identified who showed high nasopharyngeal viral load, and 6 persons were given a diagnosis before the onset of symptoms. Despite their low frequency, these persons are examples of key groups to identify given the higher likelihood of onward transmission with high viral loads. This study confirmed the overlap in SARS-CoV-2 RNA levels between asymptomatic and presymptomatic HCP, supporting the need for testing both groups to prevent transmission (9).
There is increasing evidence from congregate settings that relying on the presence of symptoms to initiate testing is insufficient (2,4). As laboratory capacity increases, asymptomatic mass testing programs might facilitate earlier and more accurate case detection and help maintain workforce readiness, especially in high-prevalence settings (10). This testing approach was strengthened by its large scale and comprehensiveness, including tests for viral RNA and SARS-CoV-2 antibodies. Such HCP testing might help build public confidence in the safety of the hospital environment and thus limit delays in care for persons who have non–COVID-19 illnesses.
However, there are limitations to this approach. Previous symptoms were assessed by self-report, which might result in bias. In addition, although the rRT-PCR–positive results in this study could not all be confirmed as true positive results, the estimated clinical specificity of rRT-PCR was 99.9%. Finally, this approach necessitates adequate infrastructure to support intensive clinical triaging, testing, and follow-up. Sample pooling might increase testing throughput, lower cost, and enable SARS-CoV-2 detection in persons who have high viral load and represent a priority group to prevent transmission.
In summary, large-scale testing of HCP might identify asymptomatic and presymptomatic persons, including some with high viral burden. Early detection might enable prompt implementation of infection control measures to limit nosocomial spread.",Emerg Infect Dis
PMC7774577,"Etiology of Severe Acute Respiratory Infections, Bangladesh, 2017","In April 2017, the Institute of Epidemiology Disease Control and Research (IEDCR) in Bangladesh noted an 89% increase in severe acute respiratory infections (SARI) compared with April 2016 through the National Influenza Surveillance Bangladesh (NISB) at 10 tertiary-care hospitals. During April 10–June 21, 2017, we conducted a case–control study to ascertain the cause of the outbreak and its associated risk factors.
We defined a SARI case as acute respiratory illness in a patient within 10 days of onset, with history of fever and cough, and requiring hospitalization (1). We sought to enroll all adults >18 years of age who were admitted to NISB hospitals with SARI. Staff screened patients for eligibility, obtained written informed consent, surveyed participants about demographics, and took combined nasal and throat swab samples. Patients who died in hospital wards before enrollment were ineligible. Within 2 days of case-patient enrollment, staff enrolled 2 asymptomatic controls, identified by convenience from the same hospitals’ outpatient clinics, surveyed them, and took combined nasal and throat swab samples. Patients who had fever or respiratory symptoms in the previous 14 days were ineligible to serve as controls. Swab specimens from case-patients and controls were tested for viral, bacterial, and fungal nucleic acids using FTD Respiratory pathogens 33 real-time reverse transcription PCR (Fast Track Diagnostics, http://www.fast-trackdiagnostics.com)(2).
We examined the association between SARI case-status and sociodemographic characteristics, preexisting conditions, and pathogens detected through multivariate logistic regressions. The investigation was judged to be public health action by the institutional review boards of the IEDCR and US Centers for Disease Control and Prevention (approval no. IEDCR/IRB/2016/17).
We identified 79 eligible SARI case-patients and 158 eligible controls from 5 NISB hospitals (Figure). Of these, 73 (92%) eligible patients and 146 (92%) eligible controls consented to participate (Table). Case-patients were more likely than controls to be male (89% vs. 77%; p = 0.041 by Fisher exact test) and have preexisting underlying chronic conditions (47% vs. 25%; p = 0.001), including asthma (36% vs. 12%; p = 0.000) and allergies (27% vs. 10%; p = 0.003) (Table). Although 34 (47%) of case-patients were treated with antibiotics, none were treated with antiviral drugs.
Fifty-three (73%) case-patients and 92 (63%) controls tested positive for >1 pathogens (Table). Among 53 test-positive case-patients, 18 (25%) tested positive for influenza viruses (Figure), including 12 (67%) for influenza A(H1N1)pdm09, 5 (28%) for unsubtyped influenza A, and 1 (6%) for influenza C. Among 92 test-positive controls, 8 (5%) tested positive for influenza viruses (Figure), including 3 (38%) for influenza A(H1N1), 4 (50%) for unsubtyped influenza A, and 2 (25%) for influenza C, 1 of whom had a codetection of an unsubtyped influenza A virus.
Male sex (odds ratio [OR] 2.4, 95% CI 1.0−5.4), >1 preexisting conditions (OR 2.7, 95% CI 1.5−4.8), asthma (OR 4.2, 95% CI 2.1−8.4), and history of allergies (OR 3.1, 95% CI 1.5−6.6) were more common among SARI case-patients than controls (Table). Any influenza virus (OR 5.7, 95% CI 2.3−13.7), and influenza A(H1N1) specifically (OR 9.4, 95% CI 2.6−34.4), was significantly associated with SARI status. Only influenza A(H1N1) (OR 11.4, 95% CI 2.7−47.4) remained associated with case status.
The surge in SARI during April 2017 was attributable to influenza viruses. Although influenza epidemics in Bangladesh typically occur during May–September (6), our investigation suggests the 2017 season started a month early. The government of Bangladesh has purchased Northern Hemisphere formulation influenza vaccines for Hajjis (i.e., for persons entering Mecca) (7,8) but does not otherwise have a vaccination policy because its possible benefit has not been shown in Bangladesh. Influenza vaccines are sporadically available in Bangladesh’s private market but rarely used. Our findings suggest the potential utility of estimating the cost-benefit ratio of influenza vaccination among persons at high risk for SARI using Southern Hemisphere formulations, which incorporate the most current vaccine strains recommended by the World Health Organization (7) before the April–May start of the Bangladesh influenza season.
Patients with SARI were frequently prescribed antibiotics but not antiviral drugs. Whether antibiotics benefit SARI patients or solely drive antibiotic resistance is unclear; however, observational data suggest the benefit of empiric antiviral drugs to prevent influenza complications during epidemics (9). IEDCR recommended empiric treatment of patients with SARI with antiviral drugs during the 2009 pandemic but does not currently (10). Quantifiying the cost-effectiveness of empiric antiviral treatment for SARI patients during influenza epidemics could be valuable, particularly when used within 48 hours of symptom onset, when antivirals are most effective (6,9).
 This investigation had limitations. Controls were not randomly selected, and age and sex were not matched with case-patients. We limited our sample collection to the upper respiratory tract, did not have wells to identify influenza A(H3N2) RNA, and did not collect blood or other samples that would have more accurately detected bacterial infections.
Our investigation of a surge in SARI cases during April 2017 in Bangladesh suggests the value of surveillance and rapid response in identifying the etiology of outbreaks. Our findings also suggest the potential value of estimating the cost-effectiveness of influenza vaccination campaigns among groups at high risk for SARI administered as early as late March to early April and of empiric antivirals during Bangladesh’s influenza epidemics.",Emerg Infect Dis
PMC7786642,Long-term exposure to air-pollution and COVID-19 mortality in England: A hierarchical spatial analysis,"As of 30th of June 2020, COVID-19 has caused more than 500,000 deaths globally, with an estimated case fatality of 1–4% (Hauser et al. 2020). The UK is one of the countries most affected, with an estimated 57,300 more deaths in England and Wales than it would be expected from mid-February to end of May 2020 had the pandemic not taken place (Kontis et al. 2020). Established risk factors of COVID-19 mortality include age, sex and ethnicity (Wu et al. 2020). Previous studies have observed a correlation between pre-existing conditions such as stroke, hypertension and diabetes (Williamson et al., 2020, Yang et al., 2020). Long-term exposure to air-pollution has been hypothesised to worsen COVID-19 prognosis: either directly, as it can suppress early immune responses to the infection (E. Conticini et al. 2020), or indirectly, as it can increase the risk of stroke, hypertension and other pre-existing conditions (Giorgini et al., 2016, Scheers et al., 2015).
Previous studies suggested an effect of long-term exposure to air-pollution on COVID-19 mortality (Cole et al., 2020, Liang et al., 2020, Travaglio et al., 2020, Wu et al., 2020), however several methodological shortcomings limit their interpretability. They were based on data aggregated on large spatial units and thus suffer from ecological fallacy (grouped levels association do not reflect individual ones) (Wakefield 2008). Air pollution is characterised by high spatial variability, making the availability of mortality data at the same high spatial resolution crucial (Villeneuve and Goldberg 2020). In addition, a coarse geographical resolution might lead to inadequate adjustment for confounders, when these are available at higher resolution (Villeneuve and Goldberg 2020). Most previous studies assessed cumulative deaths until mid or end of April and thus the generalisability of their results is limited to the early stages of the epidemic (Liang et al., 2020, Travaglio et al., 2020, Wu et al., 2020). One study had data available up to June 5, 2020 (Cole et al. 2020) and another up to June 12, 2020 (Statistics 2020), capturing a proportion COVID-19 deaths attributable to the first wave.
In this nationwide study in England, we investigated the effect of long-term exposure to air pollution on COVID-19 mortality during the entire first wave of the epidemic, after accounting for confounding and spatial autocorrelation. We focused on exposure to NO2 and PM2.5 (atmospheric particulate matter that has a diameter of less than 2.5 µm). We downscaled the LTLA geographical information to the Lower Layer Super Output Area (LSOA) to alleviate the effect of ecological bias and exploit the variability of the exposure at high geographical resolution.
We included all COVID-19 deaths as reported to Public Health England (PHE) by June 30, 2020. These include deaths that had a laboratory confirmed report of COVID-19 (including at post-mortem) (EpiCell 2020), as well as suspected COVID-19 deaths, defined as deaths without a positive test but with mention of COVID-19 in the death certificate. These definitions were consistent during the study period and over the study region. The main outcome of this study was laboratory confirmed deaths. We selected COVID-19 deaths up to June the 30th to ensure we captured COVID-19 deaths attributable to the first wave of epidemic that in England and Wales was over by the end of May, when all-cause mortality was no longer elevated (Kontis et al. 2020). Individual data on age, sex, ethnicity, lower tier local authority (LTLA) of the residential address and type of residence type (i.e. nursing homes, prisons, medical facilities etc.) were available. Population at risk in England was available through Office for National Statistics (ONS). Information at the LSOA level about age and sex was available for 2018, whereas about ethnicity for 2011 (the most recent years available at time of analysis).
There were 317 LTLAs in England in 2019 (Supplemental Material Fig. S1). Such a coarse geographical unit is not expected to capture the strong localised spatial patterns of air-pollution. We thus downscaled the LTLA geographical information to the LSOA level. LSOAs are high resolution geographical units in England (32,844 units in 2011, see Supplemental Material Fig. S2). The median population per LSOA in 2018 was 1617, varying from 591 to 14,696 (min to max) (Supplemental Material Fig. S3), and the median area per LSOA was 0.4km2, varying from 0.0002km2 to 68.4km2(min to max). The LTLA boundaries are revised every year, whereas the LSOA ones at census. Let l~m denote that the l-th LSOA belongs to the m-th LTLA, nijkm the number of deaths in the m-th LTLA and Pijkl the population in the i-th age group (1<, 1–4, 5–9, …, 85–90, >90), j-the sex (male or female), k-th ethnic group (White, Mixed, Asian, Black, Other) and l-th LSOA. We sampled nijkm individual deaths at the l-th LSOA level from a Multinomial distribution with probabilities:πijkl=Pijkl/∑l~mPijkl,and repeated the procedure 100 times.
We considered exposure to NO2 and PM2.5 as indicators of air pollution. We selected these pollutants because: 1) they reflect different sources of air-pollution (NO2 reflects traffic related air-pollution, whereas PM2.5 is a combination of traffic and non-traffic sources), 2) they were considered in previous studies (Cole et al., 2020, Liang et al., 2020, Travaglio et al., 2020, Wu et al., 2020), and 3) they are responsible for the highest number of years of life lost compared to other pollutants in Europe (Ortiz 2019). We retrieved NO2 and PM2.5 concentration in England from the Pollution Climate Mapping (PCM; https://uk-air.defra.gov.uk/). The PCM produces annual estimates during 2001–2018 for NO2 and 2002–2018 for PM2.5 at 1x1km resolution for the UK. The PCM model is calibrated using monitoring stations across the nation and has high predictive accuracy, R2 = 0.88 for NO2 and R2 = 0.63 for PM2.5 (Brookes 2017). We defined long-term exposure to these compounds as the mean of the past 5 years for which data was available at the time of analysis, i.e. 2014–2018. An alternative is calculating the median, however the distribution of the air-pollutants using any of these metrics is almost identical, (Supplemental Material Fig. S4). We weighted the exposure using a combination of population estimates available from the fourth version of Gridded Population of the World collection at 1x1km grid as of 2020 (Center for International Earth Science Information Network - CIESIN - Columbia University 2018) and from ONS at LSOA level as of 2018. Let Xgl be the pollutant and Pgl the population in the intersection of the g-th grid cell and l-th LSOA. Assuming the Xg is constant (i.e. Xgl=Xg for all intersections) in the g-th grid cell, we define the population weighted version X¯lof Xgl as:X¯l=∑glP¯glXg∑glP¯gl.
To calculate P¯gl, we first compute w¯gl=wgl/∑glwgl, where wgl is the area weight per intersection. Then calculate the population per intersection: Pgl'=Pgw¯gl. We then use the Pl (LSOA populations) and obtain P¯gl=vglPl, where vgl is the normalised Pgl', ie vgl=
Pgl'/∑glPgl'.
We considered confounders related with meteorology, socio-demographics, disease spread, healthcare provision and health related variables (Table 1). As meteorological confounders, we considered temperature and relative humidity and calculated the mean for March-June 2018 as this is the latest year with data available at 1x1km grid retrieved from the MetOffice. We weighted temperature and relative humidity using the population weights calculated for the air-pollution exposure. As socio-demographical confounders we considered age, sex, ethnicity, deprivation, urbanicity, population density and occupation. Information on age (2018), sex (2018), ethnicity (2011), urbanicity (2011) and population density (2018) was available at the LSOA level from ONS (the most recent years available at time of analysis). To adjust for deprivation, we used quintiles of the index of multiple deprivation at LSOA level in 2019 (Ministry of Housing, Communities and Local Government), excluding the dimension related to air quality. We used estimates of occupational exposures to COVID-19, as calculated by ONS, to adjust for high risk exposure to COVID-19, defined as those with a score higher than 80/100 (corresponding to at least >1 per week exposed to someone infected, Supplemental Material Text S1.1 and Table S1). To account for disease progression, we used the number of days since the 1st reported case and the number of positive cases in each LTLA (as of 30th of June 2020, as retrieved from PHE). Adjustment for the latter factors is expected to attenuate geographical differences generated due to regional differences about the timing on the pandemic curve. For healthcare provision, we used the number of intensive care unit beds per population, in February 2020 per NHS trust, as retrieved from NHS. Last, as health-related variables, we considered smoking and obesity prevalence at the GP practice level during 2018–2019, as retrieved from PHE (Supplemental Material Text S1.1).
We specified Bayesian hierarchical Poisson log-linear models to investigate the association of COVID-19 deaths and NO2 and PM2.5 independently. The LSOA specific standardised mortality ratio is known to be an unstable estimator with high variance when the number of expected deaths is small. To overcome this problem, we used a well-established hierarchical framework, specifying spatially structured and unstructured random effects, so that the model borrows strength from the other areas across the entire study region, as well as from the neighbouring ones (Best et al., 2005, Wakefield et al., 2000, Wakefield, 2006). We model these random effects using a re-parametrisation of the Besag-York-Molliè conditional autoregressive prior distribution (Besag et al., 1991, Simpson et al., 2017). We fitted four models including: 1) each pollutant (model 1), 2) each pollutant and the spatial autocorrelation term (model 2), 3) each pollutant and all confounders (model 3) and 4) each pollutant, the spatial autocorrelation term and all confounders (model 4). All models were adjusted for age, sex and ethnicity using indirect standardisation; we used the English population as the standard population to calculate the rates. We do not report results from the joint analysis including both pollutants since they are highly correlated (Supplemental Material Figure S5).
In order to propagate the uncertainty resulted from the sampling we used for the downscaling, we fitted the models over 100 downscaled samples and then performed Bayesian model averaging to combine the estimates (Gómez-Rubio et al. 2020). We performed a complete case analysis since for only 1.1% of the cases information about age, sex and ethnicity is missing. We report results as posterior median of % increase in mortality risk for every 1 μg/m3 increase in the air-pollutants, 95% credible intervals (CrI) and posterior probability that the estimated effect is positive. We also report posterior median of spatial mortality relative risks (exponential of the spatial autocorrelation term) and posterior probabilities that the spatial relative risks are larger than 1.
The mathematical formulation of the models and prior specifications are given in the Supplemental Material Text S1.2.
All models were fitted in INLA (Rue et al. 2009). Covariate data and code for running the analysis are available at https://github.com/gkonstantinoudis/COVID19AirpollutionEn.
We performed a series of sensitivity analyses. First, we repeated the main analyses using data at the LTLA level with all exposures and confounding weighted by population. Second, we examined if there is a differential effect of long-term exposure to air-pollution at the early stages of the epidemic, considering the lockdown (23rd of March 2020) as a landmark. Third, we assessed the correlation between the latent field of the full model (model 4) with that of the model excluding or including only covariates indicating disease spread (i.e. number of tested positive cases and days since first reported cases). Fourth, we categorised pollutants into quintiles to allow more flexible fits. Fifth, we repeated the analysis including the suspected cases to the outcome. Sixth, we repeated the analysis changing the definition of long-term exposure to the mean of the past 3 and 10 years for which data was available at the time of analysis, i.e. 2016–2018 and 2009–2018. Seventh, we fitted a zero-inflated Poisson model to account for the proportion of zeros in the data (36% in the 100 samples – see Supplemental Material Fig. S6).
We identified 38,573 COVID-19 deaths with a laboratory confirmed test in England between 2nd March and 30th June (Fig. 1). The age, sex and ethnicity distribution of the deaths follows patterns reported previously (Supplemental Material Tables S2-3).
Fig. 2 shows the population weighted air-pollutants at LSOA level in England. We observe that the localised variation of NO2, for instance due to the highways, is adequately captured at the spatial resolution of the LSOAs. The mean of NO2 is 16.17 μg/m3 and it varies from 2.99 μg/m3 in highly rural areas to 50.69 μg/m3 in the big urban centres (Fig. 2). The mean of PM2.5 is 9.84 μg/m3 with a smaller variation, 5.14–14.22 μg/m3 (Fig. 2).
Plots and maps of the confounders can be found in Supplemental Material, Fig. S7-17.
We observe a 2.6% (95%CrI: 2.4%, 2.7%) increase in the COVID-19 mortality risk for every 1 μg/m3 increase in the long-term exposure to NO2, based on model 1 (Fig. 3 & Supplemental Material Table S4). There is still evidence of an effect, albeit smaller, once we adjust for spatial autocorrelation or confounders, with increases in the long-term exposure to NO2 of, respectively, 1.3% (95% CrI: 0.8%, 1.8%), 1.8% (95% CrI: 1.5%, 2.1%) for every 1 μg/m3. When we adjust for both autocorrelation and confounders the evidence is less strong, with estimates of 0.5% (95% CrI: −0.2%, 1.2%) for every 1 μg/m3 (Fig. 3 & Supplemental Material Table S4) and posterior probability of a positive effect reaching 0.93. The spatial relative risk in England varies from 0.24 (95% CrI: 0.08, 0.69) to 2.09 (95% CrI: 1.30, 3.11) in model 2 and from 0.30 (95% CrI: 0.10, 0.84) to 1.87 (95% CrI: 1.18, 2.93) in model 4, implying that the confounders explain very little of the observed variation (Fig. 3). The variation is more pronounced in the cities and suburban areas (with posterior probability higher than 1; Fig. 3).
We observe a 4.4% (95% CrI: 3.7%, 5.1%) increase in the mortality risk for every 1 μg/m3 increase in the long-term exposure to PM2.5, based on model 1 (Fig. 3 & Supplemental Material Table S5). When we adjust for spatial autocorrelation the effect increases slightly but the credible intervals are wider, 5.4% (95% CrI: 2.5%, 8.4%), whereas it is similar when we adjust for confounding 4.9% (95% CrI: 3.7%, 6.2%) (Fig. 3 & Supplemental Material Table S5). The effect is weak when we account for confounders and spatial autocorrelation 1.4% (95% CrI: −2.1%, 5.1%) (Fig. 3 & Supplemental Material Table S5). The posterior probability of a positive effect is lower than observed for NO2, and equal to 0.78. The spatial relative risk follows similar patterns as the one reported in the models for NO2, with the posterior median relative risk varying from 0.24 (95% CrI: 0.12, 0.46) to 2.26 (95% CrI: 1.32, 3.85) in model 2 and from 0.30 (95% CrI: 0.15, 0.57) to 1.90 (95% CrI: 1.14, 3.17) in model 4 (Supplemental Material, Fig. S18).
When LTLAs are the main geographical unit for analysis, the results are consistent, but higher in magnitude, potentially due to inadequate covariate and spatial autocorrelation adjustment due to the coarse geographical resolution (Supplemental Material Tables S6-7, Fig. S19-20). Restricting the study period to March 23, 2020 (N = 698) also results in similar estimates for both pollutants, however the uncertainty is higher (Supplemental Material Tables S8-9, Fig. S21-22). The latent field of model 4, with NO2 as the pollutant, is similar to the latent fields of the models with and without the disease progression variables, with a correlation coefficient of 0.94 and 0.93 respectively (Supplemental Material Fig. S23). The use of quintiles of the pollutants justifies the linearity assumption (Supplemental Material Fig. S24). The results are consistent, but the evidence weaker, when suspected COVID-19 deaths are included (Supplemental Material Tables S10-11, Fig. S25-26). The results are also similar when we used a 3 or a 10-year mean of the air-pollutants concentration (Supplemental Material Fig. S27). The results are consistent when we fitted a zero-inflated Poisson (Supplemental Material Tables S12-13 and Fig. S28-29).
In a post-hoc analysis we investigated if the evidence of an effect of NO2 on COVID-19 mortality can be attributed to pre-existing conditions. We selected hypertension, chronic obstructive pulmonary disease (COPD) and diabetes, because of 1) indications of previous literature that they increase the COVID-19 mortality risk (Williamson et al., 2020, Yang et al., 2020), 2) previous literature that suggest an effect with long-term exposure NO2 (Balti et al., 2014, Cai et al., 2016, Zhang et al., 2018) and 3) data availability. We retrieved prevalence data for these pre-existing conditions from PHE available at the GP practice level during 2018–2019 (https://fingertips.phe.org.uk/), Supplemental Material Fig. S30-32. The effect of NO2 remains similar, 0.6% (95% CrI: −0.1%, 1.3%) with the posterior probability being 0.94 whereas the spatial relative risk highlights the same geographical locations, Supplemental Material Fig. S33.
This is the first nationwide study in England investigating the effect of long-term exposure to NO2 and PM2.5 during 2014–2018 on COVID-19 mortality at LSOA level. The unadjusted models indicate that for every 1 μg/m3 increase in the long-term exposure to NO2 and PM2.5 the COVID-19 mortality risk increases. After considering the effect of confounding and spatial autocorrelation there is still some evidence of an effect, albeit is less strong, for NO2, while for PM2.5 there is larger uncertainty. The spatial relative risk has strong spatial patterns, identical for the different pollutants, potentially highlighting the effect of disease spread.
Our study is comparable with previous studies in the US, England and the Netherlands assessing the long-term effect of NO2 in COVID-19 mortality. The study in the US focused on deaths reported by April 29, 2020, using 3122 counties. For the exposure, they calculated the mean of daily concentrations during 2010–2016 as modelled by a previously described ensemble machine learning model (R2 = 0.79) (Di et al., 2019a). They reported a 7.1% (95% Confidence Interval: 1.2%, 13.4%) increase in mortality per 4.5 ppb (1 ppb = 1.25 μg/m3) increase in NO2 after adjusting for confounders and spatial autocorrelation(Liang et al. 2020)(that is approximately 1.3% increase per 1 μg/m3). A study in England, with partly overlapping data as in our analysis, also reported a significant association between NO2 and COVID-19 mortality (p < 0.05). For the analysis they focused on COVID-19 deaths reported in England up to April 10, 2020, used 317 LTLAs, and did not account for spatial autocorrelation (Travaglio et al. 2020). The study in the Netherlands using 335 municipalities, mean exposure during 2015–2019 and COVID-19 deaths up to June 5, 2020 reported 0.35 (95% CI: 0.04, 0.66) additional COVID-19 deaths for every 1 μg/m3 increase in NO2 after adjusting for confounders and certain spatial controls, such as transmission beyond the Dutch national borders (Cole et al. 2020). Since the mean number of deaths in their sample is 16.86, the above estimate translates to a 2.0% increase in the COVID-19 mortality for every 1 μg/m3 increase in NO2. An ONS report in England using 175 sampling units, 10-year averaged NO2 exposure (PCM) and COVID-19 deaths up to June 12, 2020 found a 0.6% (95% CI: −0.1%, 2.2%) increase in the COVID-19 mortality for every 1 μg/m3 increase in averaged NO2 exposure (Statistics 2020).
Our study is comparable with previous studies assessing the long-term effect of PM2.5 on COVID-19 mortality. The aforementioned study in the US also assessed the effect of PM2.5 on COVID-19 mortality(Liang et al. 2020). Their exposure model was previously validated having an R2 = 0.89 for the annual estimates (Di et al. 2019b). The evidence for PM2.5 was weak, namely 10.8% (95% CI:-1.1%, 24.1%) per 3.4 μg/m3 increase in PM2.5 concentration (that is approximately 3.2% increase per 1 μg/m3) after adjusting for confounding and spatial autocorrelation. The ONS report in England found a 1% (95% CI: −3%, 6%) increase in the COVID-19 mortality for every 1 μg/m3 increase in the 10-year averaged PM2.5 exposure (Statistics 2020). Our study comes in contrast with another study in the US that used deaths reported until April 22nd, 2020 and counties as the geographical unit (Wu et al. 2020). For the exposure, they used previously validated monthly PM2.5 concentrations (R2 = 0.70) (Van Donkelaar et al. 2019) and averaged them during 2000 and 2016. After adjusting for confounding but not for spatial autocorrelation, they found an 11% (95% CI: 6%, 17%) increase in the COVID-19 death rate for an increase of 1 μg/m3 in PM2.5 concentration (Wu et al. 2020). Our study comes also in contrast with the study in the Netherlands that reported 2.3 (95% CI: 1.3, 3.0) additional COVID-19 deaths for an increase of 1 μg/m3 in the averaged long-term PM2.5 concentration (Cole et al. 2020). Having a mean number of deaths equal to 16.86, the above estimate translates to a 13.6% increase in the COVID-19 mortality rate for an increase of 1 μg/m3 in PM2.5 concentration.
Our study is the first study to examine the association between long-term exposure to NO2 and PM2.5 and COVID-19 mortality at very high geographical precision. The spatial unit of our analysis is LSOAs, for which there are 32,844 in England (~130 000 km2), whereas previous studies have used 317 LTLAs or 175 sampling units in England, counties in the US (3 122 in an area ~9.8 million km2) and municipalities in the Netherlands (334 in an area ~41 500 km2). Such high-resolution allows capturing the localised geographical patterns of the pollutants but also ensures adequate confounding and spatial autocorrelation adjustment. Our study also covers, so far, the largest temporal window of the epidemic (capturing COVID-19 deaths attributable to the first wave, Supplemental Material Fig. S34), while most previous studies focused on the early to mid-stages of the first wave. This ensures better generalisability of the results. In addition, physical distancing and other public health interventions were introduced nationwide in England during the first epidemic, mitigating any distortion between air-pollution and COVID-19 mortality due to potential regional level differences. Our results are also consistent in a sensitivity analysis focusing on the pre-lockdown period, in the absence of public health interventions. Based on the scientific literature, we adjusted for several variables which would act as the confounders of the relationship between air pollution and COVID-19 mortality. Nevertheless, since the aetiology and the factors contributing to COVID-19 mortality are not fully understood yet, we included a spatial random effect to capture unknown spatial confounding. The spatial random effect was found to be a crucial component in the model. Not accounting for spatial autocorrelation, when spatial autocorrelation is present, is expected to give rise to narrower credible intervals and false positive effects (Lee and Sarran 2015).
Our study has also some limitations. The downscaling procedure will likely inflate the reported credible intervals. However, this naturally reflects the uncertainty of the place of residence resulted from the downscaling approach. Although we consider small areas, the study is still an ecological one and thus the reported effects do not reflect individual associations (Wakefield 2008). Case fatality might have been a more appropriate metric for the analysis, since disease spread is accounted for in the denominator. Nevertheless, given the asymptomatic infections and the fact that number of reported infections is not a random sample of the general population, the number of COVID-19 cases per LTLA is not reliable at this stage. For the same reason, using the number of reported cases to adjust for disease progression and clustering of cases and deaths might not adequately capture disease progression and clustering of cases and deaths. However, part of this clustering was captured in the spatial autocorrelation term. We did not account for population mobility during 2014–2018 and assumed constant residence and thus levels of exposure to air-pollution. While this is a limitation, we believe that it would have a minimal impact on the results given that 1) the exposure period is relatively short and 2) almost 93% of the deaths in our dataset occurred in people 60 years or older (Supplemental Material Table S2). This comprises a population less likely to have moved during the past 5 years (Burgess and Quinio 2020). We also could not account for non-residential air-pollution exposure. Spatiotemporal variation in the strains of COVID-19 can introduce bias (Villeneuve and Goldberg 2020), however at the time of publication there was no evidence supporting that strain types can confound the relationship between COVID-19 mortality and air-pollution.
Compared to the previous studies, our results are the smallest in magnitude, likely because of the high geographical precision that allows more accurate confounding and spatial autocorrelation adjustment. In addition, we report weak evidence of an effect, which could also be due to lack of power and individual exposure data. Nevertheless, as for NO2 we find a high posterior probability of an effect on mortality, we argue that a potential explanation might be the mediation effect of pre-existing conditions. While in our analysis the inclusion of area-level prevalence of hypertension, diabetes and COPD did not change the results, the ecological nature of the pre-existing conditions data does not allow us to account for the mediation effect at the individual level. Our study focuses on the mortality after contracting SARS-CoV-2, however we cannot rule out individual susceptibility to becoming infected as an explanation to the uncertainty in the effect estimates (Villeneuve and Goldberg 2020). Such susceptibility can reflect immunosuppression, leading to later increases in inflammation (Edoardo Conticini et al. 2020) and thus worse prognosis, or even disease spread, as recent studies have suggested that PM2.5 can proliferate COVID-19 transmission (Bianconi et al. 2020).
Our analysis captured strong spatial autocorrelation. The observed pattern could reflect residual variation from a potential inadequate covariate adjustment (including disease spread), spatial variation of pre-existing conditions, other unknown spatial confounders or a combination from all above. In a sensitivity analysis, we observed that the factors associated with disease transmission left the latent field unchanged (Supplemental Material Fig. S21), as did the inclusion of hypertension, diabetes and COPD (Supplemental Material Fig. S33). When we restricted the analysis to the pre-lockdown period, the latent field for both pollutants captured London and Birmingham, i.e. the cities with the first outbreaks. Considering the above, and the fact that COVID-19 is an infectious disease, we believe that large variation of Fig. 4 is likely due to disease spread, which is not adequately captured in the disease progression covariates.
Overall, this study provides some evidence of an association between averaged exposure during 2014–2018 to NO2 and COVID-19 mortality, while the role of PM2.5 remains more uncertain.
Garyfallos Konstantinoudis: Conceptualization, Methodology, Software, Formal analysis, Writing - original draft, Writing - review & editing, Funding acquisition. Tullia Padellini: Methodology, Software, Formal analysis, Writing - review & editing. James Bennett: Writing - review & editing, Methodology. Bethan Davies: Writing - review & editing. Majid Ezzati: Conceptualization, Project administration, Writing - review & editing, Funding acquisition. Marta Blangiardo: Conceptualization, Methodology, Writing - review & editing, Funding acquisition.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Environ Int
PMC7780967,Erratum: Association of Black Race with Outcomes in COVID-19 Disease: A Retrospective Cohort Study,"The authors would like to make a correction to their letter published in the October 2020 issue of AnnalsATS (1). The authors reported an adjusted odds ratio (OR) of 1.51 (95% confidence interval [CI], 1.03–1.05) for the association between Black race and hospitalization among SARS-CoV-2 patients. This value is incorrectly listed in a table and text, and the correct value for this adjusted OR for the association between Black race and hospitalization among SARS-CoV-2 patients in the study is 3.17 (95% CI, 1.86–5.43). For the convenience of our readers, AnnalsATS is replacing the online version of the article with a corrected version.",Ann Am Thorac Soc
PMC7774568,"Nonpolio Enterovirus Activity during the COVID-19 Pandemic, Taiwan, 2020","Nonpharmaceutical interventions have been shown to be effective in preventing the spread of infectious diseases. The strict compliance with nonpharmaceutical interventions implemented during the coronavirus disease (COVID-19) pandemic has been associated with a decline in influenza activity in many countries, including Taiwan (1–4). Handwashing, disinfecting frequently touched surfaces, and closure of schools might also be effective against nonpolio enteroviruses (NPEV), which commonly cause a spectrum of illnesses in young populations in Asia (5). We observed lower NPEV activity during the 2019–20 season in Taiwan compared with the average of the 5 previous seasons, which might be attributable to strict compliance with nonpharmaceutical interventions. We further estimated the protective effect that could have been achieved if the population strictly adhered to the same nonpharmaceutical interventions during those previous seasons.
We collected nationwide data on weekly outpatient and emergency department (ED) visits during November 2014–June 2020 from the Taiwan National Infectious Disease Statistics System (https://nidss.cdc.gov.tw) (6). Patients >15 years of age were excluded because of their milder symptoms and low number of cases. The original data were transferred from the National Health Insurance program of Taiwan, which covers >99% of Taiwan residents (Appendix). The Institutional Review Board of the National Health Research Institutes approved this study (approval no. EC1051207-R4).
NPEV activity was measured by using the number of visits that yielded diagnoses of hand, foot, and mouth disease (International Classification of Diseases [ICD], 9th Revision, Clinical Modification, code 074.3 or ICD, 10th Revision, Clinical Modification, code B08.4) or herpangina (ICD, 9th Revision, Clinical Modification, code 074.0 or ICD, 10th Revision, code B08.5). The period from week 47 of 1 year and week 23 of the following year was defined as 1 season. We estimated the change in NPEV activity after the first imported COVID-19 case in Taiwan, when nonpharmaceutical interventions were introduced and enforced, by using a difference-in-difference model used in a previous influenza study (Appendix) (4). The total number of outpatient and ED visits for NPEV at baseline was adjusted to eliminate the preintervention differences in NPEV activity between groups (2019–20 season vs. 2014–2019 seasons). The total number of outpatient and ED visits for all disease in different weeks and different years was used for normalization because their numbers decreased after the COVID-19 pandemic. We estimated the preventable fraction among the unexposed (PFu) to measure the reduction of NPEV that would have been possible in each week of the 2014–2019 seasons, had the same nonpharmaceutical interventions been strictly followed, and adjusted PFu to control for potential confounder (Appendix).
The number of NPEV visits during the 2019–20 season was 81,942, compared with the average of 205,979 during the 2014–2019 seasons (Appendix Table 1). NPEV activity increased after week 16 across the past 6 seasons except 2019–20, when the earlier low level of weekly activity continued (Figure; Appendix Figure 1). The difference-in-difference analysis revealed that after normalization by visits for NPEV at baseline and for all diseases, NPEV activity during weeks 16–23 in the 2019–20 season was significantly lower than during the same calendar weeks of the 2014–2019 seasons (Appendix Table 2). The lower activity during weeks 16–23 in 2019–20 remained significant across all age groups and hospital settings (Appendix Table 3, 4). The weekly PFu increased from 73% to 90% (from 17% to 71% for adjusted PFu) during weeks 16–23 (Table; Appendix Table 5). Similar benefits of the nonpharmaceutical interventions were observed across different age groups of patients and hospital settings (Table; Appendix Table 6).
We observed a significant and persistent decrease of NPEV during the 2019–20 season, which might be attributable to strict compliance with the nonpharmaceutical interventions. Up to 90% (71% adjusted) of NPEV activity might have been prevented during the 2014–2019 seasons by adopting the same nonpharmaceutical interventions enforced in 2020. Many factors, such as detection bias and healthcare avoidance, might confound our analyses. However, the detection of NPEV is based on symptoms and was less likely to be affected by the COVID-19 pandemic. In addition, COVID-19 had little impact on the surveillance system in Taiwan because <450 total COVID-19 cases had been reported as of June 17 and no local cases have been reported since April 12. 
Our study is limited by the healthcare avoidance caused by the COVID-19 pandemic (4). The normalization procedure using the number of visits for all diseases in our study and subgroup analyses on ED patients (Appendix Table 4, 6) are insufficient to eliminate the impact of healthcare avoidance; active surveillance is required. The effect of individual nonpharmaceutical intervention is difficult to assess. The prolonged winter break might have played a major role in reducing NPEV activity. However, considering the high contagiousness of NPEV, their activity was expected to peak after school reopening if no other interventions were implemented. The persistent low NPEV activity throughout the semester, which began in March 2020, indicated the effectiveness of other interventions.",Emerg Infect Dis
PMC7808169,Exploring the Predictive Power of News and Neural Machine Learning Models for Economic Forecasting,"Monitoring the current and forecasting the future state of the economy is of fundamental importance for governments, international organizations, and central banks. Policy makers require timely macroeconomic information in order to design effective policies that can foster economic growth and preserve societal well-being. However, they rely on economic indicators produced by statistical agencies that are released at low frequencies (e.g., monthly or quarterly), with considerable delays, and that are often subject to substantial revisions. With such an incomplete information set in real-time, the forecasts produced by economists are very uncertain and inaccurate even when forecasting the current economic situation as well as the future, thus making the task extremely challenging. Moreover, in a global interconnected world, shocks and changes originating in one economy could move quickly to other economies affecting productivity levels, job creation and welfare in different geographic areas. However, greater interdependence also means that the current and future conditions of a market are linked to instabilities and extreme events originated abroad. All these factors make the economic forecasting task extremely difficult, both in the short and in the medium-long run.
In this context, economists and researchers can leverage on the rapid advances in information and communications technology experienced in the last two decades, which have produced an explosive growth in the amount of information available leading to the era of Big Data [17]. Novel and alternative data sets can potentially contribute greatly to help us in monitoring and forecasting economic activity given its timeliness and its economic relevance. A major source of such information is represented by news text, since it discusses important events, economic and financial news releases, and experts opinions, among others, that can serve as a basis for economic and financial decisions [5]. In addition, news affect consumers’ perception of the economy through three channels. First, the news media convey the latest economic data and professionals’ opinion to consumers. Second, consumers receive a signal about the economy through the tone and volume of economic reporting. Last, the greater the volume of news about the economy, the greater the likelihood that consumers will update their expectations about the economy [7].
In a currently on-going research project, we aim to explore the predictive power of news for forecasting of economic and financial time series by leveraging on the recent advances in Data Science, specifically on Word Embedding [6, 18, 20] and Deep Learning [3, 15, 21, 22] models. Word Embedding models represent the contextual information of a given corpora and capture syntactic and semantic information with respect to the data set used for building the embeddings. Following a specific NLP information extraction pipeline, which we describe in Sect. 4, we extract sentences referring to a specific economic aspect from the news media. Then, from those sentences, we derive signals corresponding to the Word Embedding of the extracted sentences. For example, if we deal with daily economic time series data, the Word Embedding signals are calculated on the sentences extracted each day from the news text. In our on-going research activity we aim to compare the predicting capabilities of the most popular Word Embedding methods, from the widely used Word2Vec [18] and GloVe [20] models, to the most recent context-dependent models like BERT [6] or GPT-3 [4]. In this contribution we only consider Glove embeddings. The goal is to extract the hidden information embedded in economic news to provide useful predictive signals that can be used as additional features to improve the accuracy of economic forecasts [9].
In addition, we use a novel forecasting model based on Deep Learning [3, 14, 15] for addressing the economic forecasting task. In particular, in this work we rely on DeepAR [22], a powerful neural forecasting methodology that produces accurate probabilistic forecasts, based on training an auto-regressive Recurrent Neural Network (RNN) model on a large number of related time series, which in our case are the Word Embedding signals. We believe that by combining these two strong Data Science methodologies, that is Word Embedding and Deep Learning, effective solutions can be built to improve the accuracy of prediction tasks for economic and financial time series.
In this contribution we provide an overview of the methodology under development. We report on some preliminary findings on the use-case application of DeepAR along the Word Embedding extracted by a GloVe pre-trained model from United States (US) news ranging from January 1982 to September 2019, with the goal of predicting the future values of the US 10-Year Treasury Constant Maturity Minus 3-Month Treasury Constant Maturity (T10Y3M) time series given its past values.
Information encoded in text is a rich complement to the more structured kinds of data traditionally used in empirical research [10]. In recent years, we have seen an intense use of textual data in different areas of research. The idea consists of transforming strings of raw text into numeric variables, and then use them as predictors in different models. News articles, in particular, represent a relevant data source to model economic and financial variables, and several studies have already explored this additional source of information. For a recent overview on the application of text analysis in economics and finance the reader is also referred to [1, 10].
On the other end, there is a vast literature on the use of Deep Learning in the context of time series forecasting, e.g. see [14, 21]. For a survey the reader is referred to [3, 13, 15]. Neural Networks (NNs) in forecasting have been typically applied to individual time series, i.e. a different model is fitted to each time series independently [23]. Although it is fairly straightforward to use classic Multilayer Perceptrons NNs (aka MLPs) on large data sets, its use on medium-sized time series is more difficult due to the high risk of over-fitting. Classical MLPs can be adapted to address the sequential nature of the data by treating time as an explicit part of the input. However, such an approach has some inherent difficulties, namely the inability to process sequences of varying length and to detect time invariant patterns in the data. A more direct approach is to use recurrent connections that connect the neural networks hidden units back to themselves with a time delay. This is the principle at the base of Recurrent Neural Networks (RNNs) [15, 21], which are NNs specifically designed to handle sequential data that arise in applications such as time series, natural language processing and speech recognition. In finance, for example, the authors in [16] developed a multi-task RNN with high-order Markov random fields to predict stock price movement direction based upon a single stock’s historical records together with its correlated stocks.
Although RNNs have been widely used in practice, it turns out that training them is quite difficult given that they are typically applied to very long sequences of data. A common issue while training very deep neural networks by gradient-based methods using back-propagation is that of vanishing or exploding gradients which renders learning impossible. Long Short-Term Memory Networks (LSTMs) were proposed [12, 14] to address this problem. Instead of using a simple network at each time step, LSTMs use a more complicated architecture composed of a cell and gates which control the flow of input to the cell as well as decide what information should be kept inside the cell and what should be propagated to the next time step [14]. The cell has a memory state which is propagated across time along with the output of the LSTM unit, which is itself a function of the cell state. Unlike the output of the LSTM unit, the cell state undergoes minimal changes across time, thus the derivative with respect to the cell state does not decay or grow exponentially [11]. Consequently, there is at least one path where the gradient does not vanish or explode making LSTMs suitable for processing long sequences. For details on the working mechanisms behind RNNs and LSTMs we suggest the reader to go through the online tutorial in [19].
Recently, in [22] the authors have proposed DeepAR, an RNN-based forecasting model using LSTM or GRU cells, the latter being a simplification of LSTMs that do not use a separate memory cell and may result in good performance for certain applications. At each time step, DeepAR takes as input the previous time points and covariates, and estimates the distribution of the value of the next period. This is done via the estimation of the parameters of a pre-selected parametric distribution (e.g. negative binomial, student t, gaussian, etc.)1. Training and prediction follow the general approach for auto-regressive models [22]. One feature makes this forecasting setting appealing: in probabilistic forecasting one is interested in the full predictive distribution, not just a single best realization, making the analysis more robust and reducing uncertainty in the downstream decision-making flow. In addition to providing more accurate forecasts, DeepAR has also other advantages compared to classical approaches and other global methods [22]: (i) As the model learns seasonal behavior and dependencies on given covariates across time series, manual feature engineering is drastically minimized; (ii) DeepAR makes probabilistic forecasts in the form of Monte Carlo samples that can be used to compute consistent quantile estimates for all sub-ranges in the prediction horizon; (iii) By learning from similar items, DeepAR is able to provide forecasts for items with little history, a case where traditional single-point forecasting methods fail; (iv) DeepAR does not assume Gaussian noise, but can incorporate a wide range of likelihood functions, allowing the user to choose one that is appropriate for the statistical properties of the data.
The recent works in economics and finance on the application of text analysis from social media and news generally suffer from a limited scope of historical financial news available, and from the limitation of the analysis to short texts only (e.g. usually tweets or news headlines, see e.g. [1, 8]). In our study we consider a long time period and analyse the entire text contained in the news articles. The source of economic news was obtained from a commercial provider2. The data set consists of several million articles, full-text, from January 1982 until September 2019 (approximately 40 years) for the following US outlets: The New York Times, The Wall Street Journal, The Washington Post, The Dallas Morning News, The San Francisco Chronicle, and the Chicago Sun-Times. The economic variable of interest is the spread between the yield on 10-year T-bonds and 3-month T-bill, denoted by T10Y3M, which is obtained from the Saint Louis Fed FRED repository3.
In this section we describe the NLP information extraction pipeline used to extract sentences from the news text that refer to specific economic aspects, which we then use to derive the Word Embedding to be used in the forecasting exercise. The method works as follow. Suppose we want to extract from our news data the embeddings referred to a specific economic concept, for instance industrial production. First, its economic synonyms are derived from SPARQL queries of the World Bank Group Ontology4. For example, for industrial production, the economic synonyms that are obtained are: manufacturing; industrial output; secondary sector; industry productivity; manufacturing development; industrial growth; manufacturing productivity; etc. Given the goal of forecasting the T10Y3M time series, we used search keywords that are broadly related to the economy and to monetary and fiscal policy (the complete list can be found in the Appendix).
Afterwards, we employ a rule-based procedure that builds on the linguistic features of the spaCy Python library5. The NLP pipeline relies on the en_core_web_lg model of spaCy6, an English multi-task Convolutional Neural Network trained on OntoNotes and GloVe vectors trained on Common Crawl. The role of spaCy is to provide structured information about the text analyzed in the form of word vectors, context-specific token vectors, Part-of-speech (POS) tags, dependency parse and named entities. The following NLP steps are performed:Tokenization & lemmatization: News text is split into meaningful segments (tokens), considering noninflected form of the words (lemmas) in the text taken from WordNet7.Named Entity Recognition: Named-entity mentions in the news text are located and classified, including locations, organizations, time expressions, quantities, monetary values, etc.Most frequent location: Heuristic procedure which assigns the location to which a sentence is referring, as its most frequent named-entity location detected in the sentence text.POS tagging: News text is parsed and tagged using spaCy’s statistical model. We loop over the part-of-speech tags, stopping when our search concept, or one of its synonyms, is found.Dependency Parsing: After our search concept is found in a sentence, we loop over the available dependency parsing tree of the sentence. In particular we navigate over the neighbouring tokens of the discovered search concept by employing a rule-based approach leveraging on the syntactic dependency parsing tree. In this way chunks of terms related to our search concept are constructed.Tense detection: Heuristic procedure used to detect the tense of the constructed terms chunks extracted from the news and related to our search concept through our rule-based approach.

After the NLP pipeline has produced the chunks of terms related to our search concepts, we merge the GloVe Word Embeddings by averaging each embedding features, thus producing a unique vector of embeddings representing the extracted terms in that sentence. Similarly, all the extracted embeddings of the same frequency period of the time series considered (daily in our case) are merged together producing a unique vector of embeddings for each period. These represent the signals ordered in time that will be used as covariates for the forecasting exercise in our T10Y3M case study.

In this section we show our preliminary findings on the application of DeepAR to the forecasting of the T10Y3M time series, augmented by the extracted Word Embedding from the US economic news. Given that the T10Y3M daily time series (see Fig. 1, top) is a highly persistent and non-stationary process, we take its first log-difference and obtain a stationary series of daily changes (see Fig. 1, bottom). Forecasting the yield spread differences is an extremely challenging task, as the series behaves similarly to a random walk process. The time ranges from January 1\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{st}$$\end{document}st 1982 to August 30\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{th}$$\end{document}th 2019. Missing values for the target time series and covariates, mainly related to weekends and holidays, are dropped from the analysis, giving a final number of 9, 418 data points for the whole target time series.
All training, validation, and test data are historical values that have been smoothed using a logarithmic transformation and scaled on training data only. We have opted for a robust scaling of the variables by using statistics robust to the presence of outliers. That is, we remove the median to each time series, and the data are scaled according to the quantile range between the first quartile and the third quartile. Data standardization is a common requirement in the estimation of many machine learning models. Typically this is done by removing the mean and scaling to unit variance. However, outliers can often influence the sample mean/variance negatively. In such cases, as in ours, the median and the inter-quartile range provide better results. Centering and scaling happen independently on each feature by computing the relevant statistics on the training sets. These pre-processing approaches have been used throughout the analysis due to better experimental results relative to other smoothing and scale transformations. We employ a rolling window for training and validation, with a window length equal to half of the full sample, that is 4, 709 data points. For each window, we make one step-ahead forecasts.

The DeepAR model is implemented by adopting Gluon Time Series (GluonTS) [2]8, an open-source library for probabilistic time series modelling that focuses on deep learning-based approaches. The library is available in Python and relies on Gluon, which is the joint AWS/Microsoft open-source deep learning solution interfacing Apache MXNet9. The DeepAR parameters are set experimentally to 2 RNN layers, each having 40 LSTM cells, and using a learning rate equal to 0.001. As mentioned earlier, the employed training loss is the negative log-likelihood, and the probability distribution to draw the probabilistic forecasts is the student t-distribution. We set also a re-training step for the model equal to 7 d, meaning that every 7 consecutive data points the DeepAR model is completely retrained. As concerned the number of epochs for each training, we choose experimentally the value of 500 epochs, which delivers convergence of the training loss (e.g., see in Fig. 2 the training loss values for the first trained model).

The whole experiment is run in parallel on 40 cores at 2.10 GHz each into an Intel(R) Xeon(R) E7 64-bit server having overall 1 TB of shared RAM. The complete experiment required around 20 h of computation time.

Figure 3 shows the observations for the T10Y3M series (blue line) together with the median forecast (dark green line) and the confidence intervals in lighter green (i.e., dark green area = 50% confidence interval; light green area = 90% confidence interval""). To better visualize the differences between observed and predicted time series, we report the same plot on a smaller time range (50 d) in Fig. 4. A qualitative analysis of the figure suggests that the DeepAR forecasts do a reasonable job at capturing the variability and volatility of the time series. Forecasting an interval rather than a point is an important feature of the process since it provides an estimate of the uncertainty involved in the forecast which allows downstream decisions based to account for such uncertainty.
For a quantitative evaluation of the forecasts in the test set, we compute a number of commonly used metrics, such as the mean absolute scaled error (MASE), the symmetric mean absolute percentage error (sMAPE), the root mean square error (RMSE), and the (weighted) quantile losses (wQuantileLoss), that is the quantile negative log-likelihood loss weighted with the density. In particular, DeepAR obtains the following in-sample results:MASE = 0.42,sMAPE = 0.89,RMSE = 0.77,wQuantileLoss[0.1] = 0.24,wQuantileLoss[0.3] = 0.55,wQuantileLoss[0.5] = 0.65,wQuantileLoss[0.7] = 0.54,wQuantileLoss[0.9] = 0.24.


The out-of-sample results are instead:MASE = 0.75,sMAPE = 1.46,RMSE = 1.02,wQuantileLoss[0.1] = 0.82,wQuantileLoss[0.3] = 1.09,wQuantileLoss[0.5] = 1.16,wQuantileLoss[0.7] = 1.11,wQuantileLoss[0.9] = 0.84.

As expected the results worsen passing from the in-sample to the out-of-sample setting. However, the gap looks acceptable showing a good generalization of the trained model. Moreover, the model performs better at high (0.9) and low (0.1) quantiles, where it obtains lower weighted quantile losses. However, looking at Fig. 5, which shows the median absolute forecast error (MAFE, in orange) against the real T10Y3M observations (in blue), we see that the model is performing poorly during the crisis period (2007–2009), where the series presents clusters of high volatility. In future work, we aim to improve the performance of the algorithm by tweaking our NLP pipeline over the economic news by considering different economic searches and Word Embedding models, and by improving DeepAR’s forecasting results by changing architecture and/or hyperparameters.
To evaluate the forecasting performance of DeepAR we can compare the forecasting metrics against those produced by other models. For example, we can produce forecasts using a simple moving average (MA) and a naïve method (NM). With the moving average method, the forecasts of all future values are equal to the average (or “mean”) of the historical data. If we let the historical data be denoted by \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_1, ..., y_T$$\end{document}y1,...,yT, then we can write the forecasts as \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{y}_{T+h|T} = \bar{y} = (y_1 + ... + y_T)/T$$\end{document}y^T+h|T=y¯=(y1+...+yT)/T. The notation \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{y}_{T+h|T}$$\end{document}y^T+h|T is a short-hand for the estimate of \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_{T+h}$$\end{document}yT+h based on the data \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_1, ..., y_T$$\end{document}y1,...,yT. In our case we have chosen \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T=7$$\end{document}T=7, that is we do a one-week moving average on the T10Y3M time series. For the naïve forecasts, instead, we simply set all forecasts to be the value of the last observation for our target (i.e. the log-difference of T10Y3M). That is, \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{y}_{T+h|T}=\hat{y}_{T}$$\end{document}y^T+h|T=y^T. Because naïve forecasts are optimal when data observations follow a random walk, these are also called random walk forecasts. The naïve method works well for many economic and financial time series, as is the case with our T10Y3M data. Table 1 reports the out-of-sample results for the three methods listed above. There is a clear superiority of the DeepAR algorithm with respect to the two other approaches. An extensive computational analysis where the algorithm will be compared with other state-of-the-art forecasting approaches is the goal of future work.

In this contribution we provide some early results of a currently on-going project aimed at exploring the predictive power of news for economic and financial time series forecasting. The novelties of the approach is that we use Word Embeddings as features which we use in the DeepAR neural forecasting method. In this initial experiment, we forecast the yield spread between the US 10-Year Treasury Constant Maturity and the 3-Month Treasury Constant Maturity (T10Y3M). The Word Embeddings are calculated based on the GloVe model and extracted from US economic news. After providing an overview of the methodology under current development, we report some preliminary results on this use-case application, showing satisfactory performance of the devised approach for such a challenging task. Information extracted from news looks relevant for the forecasting exercise of this economic variable.
Certainly further extensive research still needs to be done. We notice that DeepAR attains a poor forecasting performance during the crisis period (2007–2009), where the T10Y3M suffered from high volatility. We aim to improve the performance of the algorithm by tweaking our NLP pipeline over the economic news by considering different economic searches. Furthermore, while in this contribution we only use Glove Word Embedding, in the future we will perform a comparison with other models, like the popular Word2Vec and the recent context-dependent BERT model. Moreover, we will try to improve the performance of the implemented DeepAR model by changing architecture and optimizing its hyperparameters. Interpretability of the model by using, e.g., computed Shapley values, will be object of future investigation.
To conclude, our approach that combines Word Embedding and Deep Learning seems a promising direction to follow in order to improve the forecast accuracy of economic and financial time series. We believe that by combining these two methodologies, effective solutions can be built to improve effectiveness for this type of prediction tasks.",Mining Data for Financial Applications
PMC7808168,Information Extraction From the GDELT Database to Analyse EU Sovereign Bond Markets,"Economic and fiscal policies conceived by international organizations, governments, and central banks heavily depend on economic forecasts, in particular during times of economic turmoil like the one we have recently experienced with the COVID-19 virus spreading world-wide [30]. The accuracy of economic forecasting and nowcasting models is however still problematic since modern economies are subject to numerous shocks that make the forecasting and nowcasting tasks extremely hard, both in the short and in the medium-long run. In this context, the use of recent Big Data technologies for improving forecasting and nowcasting for several types of economic and financial applications has high potentials. In a currently on-going project we are designing a methodology to extract alternative economic and financial indicators capturing investor’s emotions, topics popularity, and economic and political events, from the Global Database of Events, Language and Tone (GDELT)1 [17], a novel big database of news information. GDELT is a real-time, open-source, large-scale repository of global human society for open research which monitors worlds broadcast, print, and web news. The news-based economic and financial indicators extracted from GDELT can be used as alternative features to enrich forecasting and nowcasting models for the analysis of the sovereign bond markets of countries in the EU.
The very large dimensions of GDELT make unfeasible the use of any relational database and require ad-hoc big data management solutions to perform any kind of analysis in reasonable time. In our case, after GDELT data are crawled from the Web by means of custom REST APIs2, we use Elasticsearch [13, 24] to host and interact with the data. Elasticsearch is a popular and efficient NO-SQL big data management system whose search engine relies on the Lucene library3 to efficiently transform, store, and query the data.
After GDELT data are stored into our Elasticsearch infrastructure, a feature selection procedure selects the variables having higher forecasting potentials to analyse the sovereign bond market of the EU country under study. The selected variables capture, among others, investor’s emotions, economic and political events, and popularity of news thematics for that country. These additional variables are included into economic forecasting and nowcasting models with the goal of improving their performance. In current research we are experimenting different models, ranging from traditional economic models to novel machine learning approaches, like Gradient Boosting Machines and Recurrent Neural Networks (RNNs), which have been shown to be successful in various forecasting problems in Economics and Finance (see e.g. [4, 6–8, 16, 18, 29] among others).
The recent surge in the government yield spreads in countries within the Euro area has originated an intense debate about the determinants and sources of risk of sovereign spreads. Traditionally, factors such as the creditworthiness, the sovereign bond liquidity risk, and global risk aversion have been identified as the main factors having an impact on government yield spreads [3, 22]. However, a recent literature has pointed at the important role of financial investor’s sentiment in anticipating interest rates dynamics [19, 26]. An early paper that has used a sentiment variable calculated on news articles from the Wall Street Journal is [26]. In this work it is showed that high levels of pessimism are a relevant predictor of convergence of the stock prices towards their fundamental values. Other recent works in finance exist on the use of emotions extracted from social media, financial microblogs, and news to improve predictions of the stock market (e.g. [1, 9]). In the macroeconomics literature, [14] has looked at the informational content of the Federal Reserve statements and the guidance that these statements provide about the future evolution of monetary policy. Other papers ([27, 28] and [25] among others) have used Latent Dirichlet allocation (LDA) to classify articles in topics and to extract a signal with predictive power for measures of economic activity, such as GDP, unemployment and inflation [12]. These results, among others, have shown the high potentials of the information extracted from news variables on monitoring and improving the forecasts of the business cycle [9].
Machine learning approaches in the existing literature for controlling financial indexes measuring credit risk, liquidity risk and risk aversion include the works in [3, 5, 10, 11, 20], among others. Several efforts to make machine learning models accepted within the economic modeling space have increased exponentially in recent years (see e.g.. [4, 6–8, 16, 18, 29] among others).
GDELT analyses over 88 million articles a year and more than 150,000 news outlets. Its dimension is around 8 TB, growing 2TB each year [17]. For our study we rely on the “Global Knowledge Graph (GKG)” repository of GDELT, which captures people, organizations, quotes, locations, themes, and emotions associated with events happening in print and web news across the world in more than 65 languages and translated in English. Themes are mapped into commonly used practitioners’ topical taxonomies, such as the “World Bank (WB) Topical Ontology”4. GDELT also measures thousands of emotional dimensions expressed by means of, e.g., the “Harvard IV-4 Psychosocial Dictionary”5, the “WordNet-Affect dictionary”6, and the “Loughran and McDonald Sentiment Word Lists dictionary”7, among others. For our application we use the GDELT GKG fields from the World Bank Topical Ontology (i.e. WB themes), all emotional dimensions (GCAM), and the name of the journal outlets.
The huge number of unstructured documents coming from GDELT are re-engineered and stored on an ad-hoc Elasticsearch infrastructure [13, 24]. Elasticsearch is a popular and efficient document-store built on the Apache Lucene search library8 and providing real-time search and analytics for different types of complex data structures, like text, numerical data, or geospatial data, that have been serialized as JSON documents. Elasticsearch can efficiently store and index data in a way that supports fast searches, allowing data retrieval and aggregate information functionalities via simple REST APIs to discover trends and patterns in the stored data.
We use the available World Bank Topical Ontology to understand the primary focus (theme) of each article and select the relevant news whose main themes are related to events concerning bond market investors. Hence, we select only articles such that the topics extracted by GDELT fall into one of the following WB themes of interest: Macroeconomic Vulnerability and Debt, and Macroeconomic and Structural Policies. To make sure that the main focus of the article is one of the selected WB topics, we retain only news that contain in their text at least three keywords belonging to these themes. The aim is to select news that focus on topics relevant to the bond market, while excluding news that only briefly report macroeconomic, debt and structural policies issues. We consider only articles that are at least 100 words long. From the large amount of information selected, we construct features counting the total number of words belonging to all WB themes and GCAMs detected each day. We also create the variables “Number of mentions“ denoting the word count of each location mentioned in the selected news. We further filter the data by using domain knowledge to retain a subset of GCAM dictionaries that qualitatively may have potentials to our analysis. Then we retain only the variables having a standard deviation calculated over the full sample greater than 5 words and allowing a 10\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\%$$\end{document}% of missing values on the total number of days. Finally we perform a correlation analysis across the selected variables, normalized by number of daily articles. If the correlation between any two features is above 80\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\%$$\end{document}% we give preference to the variable with less missing values, while if the number of missing values is identical and the two variables belong to the same category (i.e. both are themes or GCAMs), we randomly pick one of them. Finally, if the number of missing values is identical but the two variables belong to the same category, we consider the following order of priority: GCAM, WB themes, GDELT themes, locations.
Here we show some preliminary results on the application of the described methodology for the use case of Italy. The main objective of this empirical exercise is to assess the predictive power of GDELT selected features for the forecasting of the Italian sovereign bond market.
We have extracted data from Bloomberg on the term-structure of government bond yields for Italy over the period 2 March 2015 to 31 August 2019. We have calculated the sovereign spread for Italy against Germany as the difference between the Italian 10 year maturity bond yield minus the German counterpart. We have also extracted the standard level, slope and curvature factors of the term-structure using the Nelson and Siegel [23] procedure and included these classical factors into the model. Being the government bond yields a highly persistent and non-stationary process, we have considered its log-differences and obtained a stationary series of daily changes representing our prediction target, illustrated in Fig. 1. This kind of forecasting exercise is an extremely challenging task, as the target series behaves similarly to a random walk process. Missing data, related to weekends and holidays, have been dropped from the target time series, giving a final number of 468 data points.

For our Italian case study, we have also extracted the news information from GKG in GDELT from a set of around 20 newspapers for Italy, published over the considered period of the analysis. After this selection procedure we obtained a total of 18,986 articles, with a total of 2,978 GCAM, 1,996 Themes and 155 locations. Applying the feature selection procedure described above, we have extracted 31 dimensions of the General Inquirer Harvard IV psychosocial Dictionary, 61 dimensions of Roget’s Thesaurus, 7 dimensions of the Martindale Regressive Imagery and 3 dimensions of the Affective Norms for English Words (ANEW) dictionary. After the features engineering procedure, we have been left with a total of 45 variables, of which 9 are themes, 34 are GCAM, 2 locations. The selected topics contained WB themes such as Inflation, Government, Central Banks, Taxation and Policy, which are indeed important thematics discussed in the news when considering interest rates issues. Moreover, selected GCAM features included optimism, pessimism or arousal, which explore the emotional state of the market. Figure 2 shows the top correlated covariates with respect to the target.

Several studies in the literature have shown that during stressed periods, complex non-linear relationships among explanatory variables affect the behaviour of the output target which simple linear models are not able to capture. For this reason, in this empirical exercise we have used a deep Long Short-Term Memory Network (LSTM) [15] to best accounting for non-linearities and assessing the predictive power of the selected GDELT variables. The LSTM was implemented relying on the DeepAR model available in Gluon Time Series (GluonTS) [2]9, an open-source library for probabilistic time series modelling that focuses on deep learning-based approaches and interfacing Apache MXNet10. DeepAR is an LSTM model working into a probabilistic setting, that is, predictions are not restricted to point forecasts only, but probabilistic forecastings are produced according to a user-defined predictive distribution (in our case a student t-distribution was experimentally selected). For our experiment we have set experimentally to use 2 RNN layers, each having 40 LSTM cells, and used a learning rate equal to 0.001. The number of training epochs was set to 500, with training loss being the negative log-likelihood function.
We have used a robust scaling for the training variables by adopting statistics robust to the presence of outliers. That is, we have removed the median to each time series, and the data were scaled according to the interquartile range. Furthermore we have adopted a rolling window estimation technique where the first estimation sample started at the beginning of March and ended in May 2017. For each window, one step-ahead forecasts have been calculated. The whole experiment required to run few hours in parallel on 40 cores at 2.10 GHz each into an Intel(R) Xeon(R) E7 64-bit server having overall 1 TB of shared RAM.

Figure 3 shows the observations for the target time series (blue line) together with the median forecast (dark green line) and the confidence interval in lighter green. To better visualize the differences between observed and predicted time series, we have reported the same plot on a smaller time range (50 days) in Figure 4. A qualitative analysis of the figure suggests that the forecasting model does a reasonable job at capturing the variability and volatility of the time series.




We have also computed a number of commonly used evaluation metrics [21], such as the mean absolute scaled error (MASE), the symmetric mean absolute percentage error (sMAPE), the root mean square error (RMSE), and the (weighted) quantile losses (wQuantileLoss), that is the quantile negative log-likelihood loss weighted with the density. The obtained in-sample and out-of-sample results are shown in Table 1. As expected the results worsen passing from the in-sample to the out-of-sample setting, but the gap is absolutely acceptable, confirming a good generalization capability of the trained LSTM model. The model showed higher performance at high (0.9) and low (0.1) quantiles with lower weighted quantile losses. Figure 5 illustrates the median absolute forecast error (MAFE, in orange) against the real time series observations (in blue). The performance of the model slightly worsen from the end of May to July 2018, corresponding to a period of political turmoil in Italy. Indeed, on the 29\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{th}$$\end{document}th of May, the Italian spread sharpely rose reaching 250 basis point. Investors where particularly worried about the possibility of anti-euro government and not confident on the formation of a stable government. From June until November 2018, a series of discussions about deficit spending engagements and possible conflicts with European fiscal rules continued to worry the markets. The spread strongly increased in October and November with values around 300 basis point. We can see this also from the performance of our model which worsen a bit in this stressed period, which however the model looks to handle quite well anyway. Since 2019, the Italian political situation started to improve and the spread smoothly declined, especially after the agreement with Brussels on budget deficit in December 2018. However, some events hit the Italian economy afterwards, such as the EU negative outlook and the European parliament elections which contributed to a temporary increase on interest rates. Our model performs quite well in this period in terms of absolute error ratios showing a good robustness.

Figure 6 shows a scatter plot amongst the median out-of-sample forecasted points and the real observations. To some degree the points in the scatter plot roughly follow the diagonal, showing a fine correlation among the forecasted points and the real observations, and suggesting good quality of the forecasting results. This is also confirmed by the acceptable value of 0.23 computed for the R-squared metrics on the out-of-sample median forecasts for such a challenging prediction exercise. This value of the R-squared measure indicates that the LSTM model explains a quite ample variability of the response data around its median, suggesting a certain degree of closeness among the forecasted data and the real observations.
In this contribution we have presented our work-in-progress related to the development of a methodology for building alternative economic and financial indicators capturing investor’s emotions and topics popularity from GDELT, the Global Data on Events, Location, and Tone database, a free open platform containing real-time worlds broadcast, print, and web news. The currently on-going project in which this work is developed is aimed at producing improved forecasting methods to analyse the sovereign bond markets of countries in the EU. We have reported some preliminary results on the application of this methodology for predicting the Italian sovereign bond market. This use case reveals initial good performance of the methodology, suggesting the validity of the approach. Using the information extracted from the Italian news media contained in GDELT combined with a deep Long Short-Term Memory Network opportunely trained and validated with a rolling window approach, we have been able to obtain quite good forecasting results.
This work represents one of the first to study the behaviour of government yield spreads and financial portfolio decisions in the presence of classical yield curve factors and information extracted from news. We believe that these new measures are able to capture and predict changes in interest rates dynamics especially in period of turmoil. Overall, the paper shows how to use a large scale database as GDELT to derive financial indicators in order to capture future intentions of agents in sovereign bond markets.
Certainly more research is still needed to be exploited in the directions of the presented work. First we will try to improve the performance of the implemented DeepAR model by tweaking architecture and optimizing the hyperparameters of the LSTM model. Furthermore, in current research we are experimenting other different prediction models, ranging from traditional economic methods to other novel machine learning approaches, including Gradient Boosting Machines and neural forecasting methods. In a future extended version of the paper we will compare and thoroughly analyze the performance of these methods to better exploit the non-linear effects of the dependent variables. Interpretability of the implemented machine learning models by using, e.g., computed Shapley values, will be an important object of future investigation in order to finely assess the contributions of the different covariates in the models predictions.",Mining Data for Financial Applications
PMC7808764,Application of physiologically based pharmacokinetic modeling to predict the pharmacokinetics of telavancin in obesity with renal impairment,"The glycopeptide antibiotic telavancin, a semi-synthetic lipoglycopeptide derived from vancomycin, is active against Gram-positive bacteria, including methicillin-susceptible and methicillin-resistant Staphylococcus aureus (MSSA/MRSA) [1]. It is approved by the U.S. Food and Drug Administration (FDA) for treating complicated skin and skin structure infections (cSSSI), hospital-acquired and ventilator-associated bacterial pneumonia (HABP/VABP) caused by S. aureus when alternative treatments are not suitable [2]. Telavancin dosing is based on total body weight (TBW) [2].
Telavancin is not absorbed orally, only intravenously. In healthy young adults, telavancin displays linear pharmacokinetics (PK) following single doses from 5 to 12.5 mg/kg and multiple doses from 7.5 to 15 mg/kg administered once daily for up to 7 days. Steady-state concentrations are achieved on the third day [2]. Telavancin has a high protein–binding rate (90%) and is not affected by renal impairment (RI) [2, 3]. It is mainly eliminated by renal excretion. In a single-dose radiolabeled telavancin study in healthy subjects, 76% of the dose was recovered in the urine and only 1% in feces. Forty-eight hours post-administration, most of the dose in the urine (83%) was excreted unchanged (63.08%) [1, 4]. Telavancin metabolism does not involve the hepatic cytochrome P450 (CYP) enzyme system, but its metabolic pathway has not been determined [2]. The mass balance calculation indicates that up to 30 to 37% of the dose is metabolized within 216 h post-administration [4].
Although telavancin is generally well tolerated, the risk of nephrotoxicity should be considered [3]. Several studies demonstrated that telavancin administration increases serum creatinine levels, indicating its potential nephrotoxicity [5–7]. Renal adverse events were more likely to occur in patients with baseline comorbidities known to predispose patients to kidney dysfunction (pre-existing renal disease, diabetes mellitus, congestive heart failure, or hypertension). Moreover, there was an increase in mortality in patients with HABP/VABP and pre-existing moderate-to-severe RI (CrCl ≤ 50 mL/min) [2]. Expose-response relationships for safety suggested that a total AUC from time zero to 24 h (AUC0–24) of ≥ 763 mg · h/L was associated with a higher acute kidney injury rate than a total AUC0–24 of < 763 mg · h/L [8].
Obesity is recognized as a global pandemic by the World Health Organization (WHO), and approximately 60% of the world’s population will be classified as overweight or obese by 2030, according to the body mass index (BMI) scale [9]. Physiological changes in obesity commonly affect the PK and pharmacodynamics (PD) of telavancin and may lead to suboptimal dosing in this expanding but under-researched population. Renal events occurred 2.8 times more often in patients with BMI ≥ 35 kg/m2 than in patients with BMI < 35 kg/m2 [10]. PK modeling and Monte Carlo simulations (MCS) suggested a fixed dose of 750 mg every 24 h should be equally effective and less toxic for the treatment of obese patients with normal renal function and S. aureus infections compared with 10 mg/kg every 24 h based on TBW. If higher systemic exposure in plasma concentrations is desired in obese subjects, a maximum dose of 1000 mg should be considered [8].
Obesity is associated with an increased risk of chronic kidney disease (CKD), which is also a public health problem [11, 12]. The aggravation of renal damage in CKD increases the antibiotic’s area under the plasma concentration-time curve (AUC) and half-time (t1/2) associated with a decrease in clearance (CL) [13]. Similar to obese patients with normal renal function, the FDA-recommended dosing levels based on TBW may also be too high, leading to toxicity in obese patients with different degrees of RI. Thus, it is necessary to design optimized dosing regimens for obese patients with different renal function.
To date, there is no PK study focused on the obese population with RI, although optimal telavancin dosing is challenging in these patients. In recent years, physiologically based pharmacokinetic (PBPK) modeling has emerged as a valuable tool for evaluating drug exposure in virtual populations and obtaining mechanistic insights into drug characteristics by integrating key drug and system parameters into a dynamically interconnected model that can improve guidance on dosing in a special population [14]. Specifically, we conducted this study to build and verify a PBPK model that could predict the PK of telavancin in obese hospital-acquired pneumonia (HAP) patients with different degrees of RI, maximizing the antibiotic’s efficacy and safety.
The PBPK modeling and simulations of telavancin were conducted using GastroPlus™ v.9.7 (Simulations Plus Inc., Lancaster, CA). The observed concentration–time profiles were captured directly by digitization (GetData Graph Digitizer 2.26) from the figures. MCS were performed using the Oracle Crystal Ball software (Oracle Co., Redwood Shores, CA).
The setting for modeling parameters and structure are presented in Supplementary Methods. The overall strategy for the development, verification, and application of the PBPK model for telavancin is presented as a workflow diagram in Fig. 1.
The telavancin PBPK model was verified using clinical PK data from the literature [4, 8, 13, 15–18], as shown in Supplemental Table S2. The detailed simulation steps for verification are described in Supplementary Methods. The prediction accuracy was graphically evaluated by superimposing the concentration-time profile observed in vivo on the simulated data. The accuracy of predicted PK parameters (AUC, Cmax, Tmax) was assessed by calculating the fold error as the predicted-to-observed PK parameter ratio, with an acceptable prediction being within a 2-fold error.
Population PK analyses from the literature demonstrate the similarity of the PK of telavancin among healthy subjects, patients with cSSSI, and patients with HAP [19]. Therefore, the telavancin PBPK model in healthy populations was used to predict the PK in HAP patients. The changes of AUC from time zero extrapolated to infinity (AUC0–inf) in obese (classes I, II, III) HAP patients with varying degrees of RI after a fixed dose of 1000 mg intravenous infusion over 1 h were predicted. The detailed methods for prediction are described in Supplementary Methods. Using the same drug administration regimen, the AUC ratio (AUCR) values of different obesity classes were calculated using Eq. 1.1\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathrm{AUCR}=\frac{{\mathrm{AUC}}_{\mathrm{RI}}}{{\mathrm{AUC}}_{\mathrm{Control}}}\kern2.75em $$\end{document}AUCR=AUCRIAUCControlwhere AUCRI and AUCControl are the AUC in RI subjects and AUC in patients without RI, respectively.
The mean AUCR of three obesity classes was used to provide dose regimen recommendations in 30-year-old obese American male patients with HAP and different RI.
The population simulation was carried out. Similar to the obesity, the population was set as 18–50 years old, 50% male, BMI 30–50, TBW 90–154 kg, and sample sizes of 200 [8]. AUC0–24 mean and standard error (SD) values were analyzed for obese HAP patients with different renal functions after various dosing regimens: fixed doses and the FDA-recommended regimen (e.g., for normal renal function: 750 mg fixed dose; 1000 mg fixed dose; 10 mg/kg based on TBW).
MCS were performed with 50,000 patients to evaluate the probability of target attainment (PTA) and the cumulative fraction of response (CFR). The 24-h unbound (free) area under the concentration-time curve (fAUC0–24)-to-minimum inhibitory concentration (MIC) ratio (fAUC0–24/MIC) values of 76.4 and 215 were the predictive PD targets, which were associated with a 1-log reduction in the number of colony-forming units (CFUs) from the baseline CFUs for four isolates of S. aureus in neutropenic murine models of lung and thigh infections, respectively [20]. The plasma protein binding of telavancin was assumed to be 90% [3]. The MIC data of S. aureus (MSSA/MRSA) were extracted from the European Committee on Antimicrobial Susceptibility Testing (EUCAST) [1]. The FDA-approved telavancin breakpoint is ≤ 0.12 mg/L for S. aureus [8], and the MIC value required to inhibit the growth of 90% of S. aureus isolates (MIC90) is 0.06 mg/L [1]. To evaluate the potential for exposure-related toxicity in this cohort, the probability of achieving a total AUC0–24 value of ≥ 763 mg · h/L was calculated. Finally, the telavancin-dosing regimen for obese HAP patients with varying degrees of RI was determined to maximize the PTA while minimizing the risk of reaching a threshold of exposure associated with nephrotoxicity.
The observed and the PBPK model–simulated mean plasma concentration–time profiles of telavancin were derived from healthy populations after administering a 10 mg/kg single-dose intravenous infusion, and 7.5 mg/kg and 10 mg/kg multiple-dose intravenous infusions (Supplemental Fig. S1). Importantly, the predicted and observed plasma concentration–time profiles had matching profiles. The predicted PK parameters (AUC, Cmax, Tmax) were generally consistent (< 1.3-fold error) with the observed values, except that the predicted AUC values on day 3 of 7.5 mg/kg and 10 mg/kg of intravenous infusion over 1 h every 24 h were smaller than the observed values (< 1.5-fold error), as shown in Supplemental Table S3.
The simulated and measured plasma concentrations shared matching profile shapes in healthy populations with varying degrees of renal function after administering single intravenous telavancin infusions of 7.5 mg/kg and 10 mg/kg (Supplemental Fig. S2). The predicted PK parameters (AUC, Cmax) were reasonably consistent (< 1.3-fold error) with the observed values, except that the predicted AUC values for 7.5 mg/kg telavancin in subjects with severe RI were smaller than the observed values (1.32-fold error), as shown in Supplemental Table S4. The Tmax predictions of 1 h were consistent with the observed values.
Relative changes in telavancin PK were compared between healthy populations and different renal function states (Supplemental Table S4), which shows that our model could accurately capture the increasing trend of telavancin AUC with the increasing severity of RI. The predicted CLR, CLR/CL(%), and CLh/CL(%) were similar to the observed values, as shown in Supplemental Table S5, indicating that RI might not affect CLh greatly and the PBPK model was reliable. GFR decreased with an increase in the degree of RI severity, leading to the decline of CLR and CLR/CL. However, in the hepatic metabolism, the contribution of the non-CYP-mediated metabolism to CL (CLh/CL) increased.
The PK parameters (AUC, Cmax) of telavancin in obese healthy populations with normal renal function after various fixed dosing regimens by PBPK modeling corresponded well (< 1.3-fold error) with the observed values (Supplemental Table S6). The Tmax predictions of 1 h were consistent with the observed values.
A comparison of the relative changes in PK, which was based on the 1000-mg dosage (Supplemental Table S6), reproduced the similarity of exposure in different classes of obesity. The model-simulated Vss, CL, and CLR are shown in Supplemental Table S7, indicating that Vss increased with obesity, whereas simulated CL and CLR values did not differ among the four weight classes.
The population simulation results of healthy subjects with different renal functions are presented in Fig. 2 and Fig. 3. Specifically, we found that all observed data were within the minimal and maximal individual subject simulations from the population simulations (i.e., 100% probability), except the predicted plasma concentration–time curves in subjects with severe RI, which were slightly lower than the observed concentration points. Furthermore, the fold error of AUC in subjects with severe RI was less than 1.5 (Supplemental Table S8), indicating acceptable recovery of clinical data by the model.
The AUC0-inf and AUCR of different obesity classes were simulated under the same drug administration regimen (1000 mg intravenous infusion over 1 h) (Supplemental Table S9). The calculated mean AUCR of the three obesity classes are presented in Supplemental Table S9. A comparison of the exposure simulations among the different RI levels indicated that exposure to telavancin increased with an increase in the degree of RI severity. The AUC0-inf for telavancin was predicted to increase 1.07-fold in mild RI, 1.23-fold in moderate RI, 1.41-fold in severe RI, and 1.57-fold in ESRD, compared with that in obese HAP patients with the normal renal function (Supplemental Table S9).
Obese HAP patients with mild RI are unlikely to require dose adjustments. However, there might be a need for dose adjustment across moderate and severe RI or ESRD populations after receiving the same dose. The administration regimen in obese HAP patients with normal renal function was 750 mg or 1000 mg, but the different degrees of RI required corresponding dose adjustments (Supplemental Table S10). The mean and SD of AUC0–24 in obese HAP patients with different renal functions after various dosing regimens (fixed doses and FDA-recommended regimen) are shown in Supplemental Table S10.
The results of the 50,000-patient MCS are shown in Table 1. The target attainment rate for the 24-h fAUC/MIC ratio breakpoint of 76.4 was 100% for all telavancin dosage regimens (fixed and weight-based) when the MIC values were ≤ 0.25 mg/L. When the breakpoint of 215 was evaluated, the 1000-mg-fixed dose regimen and FDA-recommended regimen (based on TBW) achieved a target attainment rate of 100% when the MIC values were ≤ 0.125 mg/L. Furthermore, the 750-mg-fixed dose regimen also achieved a target attainment rate of 99.9% for MIC values of ≤ 0.125 mg/L. When the MIC value was 0.25 mg/L in severe RI, only 10 mg/kg every 48 h resulted in target attainment rates of > 90% for the 24-h fAUC/MIC ratio of 215. Under the three dosing regimens, the CFR of telavancin against MSSA and MRSA in obese HAP patients with varying degrees of RI were all > 99.9% (Table 2).
The probabilities of attaining a toxicodynamic target (total AUC0–24 value of ≥763 mg · h/L) in obese HAP patients with varying degrees of RI are shown in Table 3. The lowest probability of almost 0% was associated with the 750-mg-fixed dose regimen, compared with those associated with the 1000-mg-fixed dose and FDA-recommended regimens. According to FDA labeling and the PBPK model, telavancin dosage regimens for normal-body-weight and obese HAP patients with varying degrees of RI are listed in Table 4.
This is the first study to develop a PBPK model for telavancin in healthy populations with different renal functions (normal renal function, mild, moderate, severe RI, and ESRD) and obese adults with varying degrees of renal function.
During the model development, CLR was calculated as GFR × fup. The predicted CLR values were reasonably consistent with the observed values, indicating that the contribution of other factors combined, including transporter-mediated renal tubular secretion and tubular reabsorption, might not be important for renal excretion of telavancin.
For subjects without RI or with RI, CLh was always defined as the half of CLR in individuals with normal renal function. Telavancin distribution to tissues is expected to occur in a permeability-limited manner due to the drug’s moderate lipophilicity and large size. When all tissues were set as permeability-limited tissues, GastroPlus™ assigned an upper limit for CLh that was much less than one half of the CLR value. Under this condition, the amount of telavancin entering the liver would be very small, and the prediction for AUCinf would generate a much larger value. This suggested that the liver might have a potential uptake transporter for telavancin besides passive diffusion. Since there is no published report on the hepatic transporter-mediated uptake of telavancin to date, we could not improve the simulation. However, when the liver was set as a blood perfusion-limited tissue, which means more drugs can enter the liver for metabolism, the prediction accuracy of the model was much higher. The involvement of a potential uptake transporter for telavancin in the liver needs to be further explored in the future.
RI can cause PK changes, which in turn affect the efficacy and even increase the risk of adverse reactions. Based on the PBPK model for healthy populations, the physiological parameters subject to alteration in response to RI were changed. Telavancin systemic exposure (AUCinf) increased with the severity of RI. GFR decreased in subjects with RI, leading to the decline of CLR and CLR/CL. CLh might not change greatly with the degree of severity of RI. However, due to the decrease of CL in subjects with RI, especially in the case of severe RI, the CLh/CL ratio increased greatly, and therefore, the contribution of non-CYP-mediated metabolism to CL was greatly increased in subjects with severe RI. There are no specific dosage adjustment recommendations for patients with ESRD (CrCl < 10 mL/min), including patients undergoing hemodialysis (HD) [2]. Thus, our PBPK model can be used to predict the PK of telavancin in subjects with ESRD.
The FDA has no specific dosing regimen for obese subjects with different renal functions. Clinical experience using telavancin in these populations is limited. We established and validated the telavancin PBPK model for obese healthy populations with normal renal function. The successful validation of the PBPK model in obesity supports that Vss of telavancin was the only PK parameter that tended to increase with body weight, and there is no physiological mechanism for enhanced elimination [8].
To evaluate the effect of inter-individual variability of population physiology parameters on the simulation results, we combined telavancin PK study with population simulations. The advantage of the MCS-based PBPK approach is that it facilitates the projection of the population mean of the PK characteristics as well as the variability, which will enable us to better anticipate the clinical reality. Population simulations were not carried out on obese healthy populations with normal renal function, due to the lack of observed plasma concentration–time profiles.
This model was applied for the first time to predict the PK of telavancin in obesity HAP with varying degrees of RI. Obese HAP patients with mild RI are unlikely to require dose adjustments. There may be a need for dose adjustment across the moderate-to-severe RI or ESRD populations after the initial administration of the recommended dose.
The PBPK model, combined with MCS, was used to predict the optimal PTA against S. aureus at or below the MIC breakpoint with a low probability of nephrotoxicity. We found that both fixed doses (dose adjustment based on 1000 mg fixed dose and on 750 mg fixed dose) attained the same PK-PD targets of efficacy as the FDA-recommended regimen based on TBW. Furthermore, the simulation indicated that the TBW-based regimen uses higher doses that lead to more toxicity. Dose adjustment based on the 750 mg fixed dose has a lower potential (almost 0%) to lead to exposures exceeding 763 mg · h/L than other dosing regimens in obesity with RI.
Our PBPK model also has some limitations in relation to validation data, the mechanism of telavancin distribution and clearance, ranges of age and weight among obesity subjects, and the evaluation of predictive performance. The detailed limitations are described in Supplementary Discussion.
In this study, a PBPK model of telavancin was developed to simulate the telavancin PK in healthy populations with varying degrees of renal function and obese subjects with normal renal function. The PBPK model was further extrapolated to generate predictions for obese HAP patients with RI. Our simulation suggests that dose adjustment based on the 750-mg-fixed dose can achieve effectiveness with a lower risk of toxicity than the current TBW-based dosing recommendation.",Eur J Clin Pharmacol
PMC7568495,"Zero-, one-, two- and three-dimensional supramolecular architectures sustained by Se(…)O chalcogen bonding: A crystallographic survey","Being present in the three domains of life, i.e. Archaea, Bacteria and Eukarya, selenocysteine has long being recognised as the 21st proteinogenic amino acid [1], [2], [3]. Natural biological functions of selenocysteine relate to redox moderation and anti-oxidant effects such as in the mammalian oxidoreductase system, thioredoxin reductase (TrxR), where it is present in the active site [4]. In connection with thyroid disease, selenocysteine is also present in the active sites of deiodinase enzymes which can activate or inactivate thyroid hormones [5]. The crucial role of selenium in natural biological functions implies a selenium-deficient diet causes disease and requires intervention [6]. Complimenting dietary supplements, synthetic selenium compounds also play a role/have potential as therapeutics [7], [8], [9], [10]. The most prominent selenium drug is Ebselen™, i.e. N-phenyl-1,2-benzisoselenazol-3(2H)-one, which is known to exhibit a variety of biological activities, partially owing to its ability to mimic the glutathione peroxidase enzyme, which regulates redox homeostasis and which protects cells from oxidative stress [7], [8], [9], [10]. Other medicinal benefits of Ebselen™ include cytoprotective and neuroprotective properties, and potential therapeutic applications relate to anti-cancer, anti-bacterial and anti-inflammatory activities [7], [8], [9], [10]. With this background, it is not surprising the biological mechanism(s) of Ebselen™ and related species have been investigated thoroughly [11], [12]. These experimental and theoretical investigations often point to the importance of both inter- and intra-molecular Se…O interactions in crucial biological processes [11], [12]. Stabilising Se…O interactions are now classified among chalcogen bonding interactions, a term possibly first employed in 1998 [15], whereby the Group XVI element functions as an electrophile [13], [14]. It is stressed that the focus of the present review is upon the role of intermolecular Se…O contacts and upon the supramolecular aggregation patterns they sustain. In general terms, chalcogen interactions find very practical applications in a range of contexts beyond biology and medicine [16], [17], [18], such as in molecular/anion recognition [19], [20], [21], [22], catalysts [23], [24] and materials science [25], [26]. With this level of activity, it is not surprising there are several authoritative reviews of chalcogen bonding [27], [28], [29], [30], including reviews of different physiochemical procedures for their detection in phases other than in crystals [31], [32], [33], the primary importance of X-ray crystallographic investigations notwithstanding.
The most convenient method for identifying chalcogen bonding in the solid-state relies upon crystal structure analysis with the earliest investigations of chalcogen bonding depending on the evaluation of crystal structures for contacts occurring at separations intermediate between the respective sums of the covalent and van der Waals radii for the participating atoms. In these present times where all manner of intermolecular contacts/supramolecular synthons are being “revealed”, it might be tempting to suggest chalcogen bonding, and related tetrel and pnictogen interactions involving, respectively, Group XIV and XV elements acting as the electrophile, are a recent phenomenon. While obviously these interactions already exist in the crystals of the relevant compounds capable of forming such interactions and may not necessarily have been recognised or appreciated as being significant previously, it turns out the discussion of secondary bonding interactions actually goes back well over 50 years. Among the first bibliographic reviews of the topic are those by H.A. Bent [34], Noble Laureate O. Hassel [35] and N.W. Alcock [36], with these being followed up by a number of general overviews of the topic [37], [38], [39], [40]. It is likely the first time the term secondary bonding was used in the context of these donor–acceptor interactions appeared in the title of a research paper was in a Conference Abstract published in 1975 [41] and then in a follow-up Journal article in 1977 [42]. The use of secondary bonding as a design element in crystal engineering endeavours was suggested as early as 1999 [43].
An initially disconcerting feature of many secondary bonding interactions, including halogen bonding [44], which also comes under the appellation secondary bonding [36], was that the interaction often occurred between two electron-rich species, i.e. a low oxidation state main group element, implying a lone-pair or even lone-pairs of electrons, and donors also having at least one lone-pair of electrons. Through the concept of a σ-hole, theory now aids the understanding of this apparent violation of basic electrostatic arguments. Conventionally the bonding in chalcogen bonds was described in terms of charge transfer from a lone-pair of electrons of the donor atom (D) to an anti-bonding orbital of the bond involving the chalcogen atom (A–X), i.e. (D)n2 → σ*(A–X), but the problem remains in that two electron-rich species are brought into close contact. The σ-hole concept, widely employed to explain the bonding in such circumstances [45], [46], relates to the anisotropic distribution of charge about the bonded chalcogen atom. With reference to the bonding axis of a A–X bond, there is an equatorial band of electron density about the A atom, i.e. perpendicular to the A–X bond, and a significant electron-deficient region at the extension of the bonding axis, the σ-hole (or polar cap). It is the latter that can form stabilising interactions with nucleophilic species. The success and general applicability of this approach in rationalising the formation of chalcogen bonds as well as tetrel, pnictogen and halogen bonds [47] notwithstanding, recent studies point to the importance of orbital delocalisation as being relevant [48]. Having a model for bonding, the question then arises as to what are the energies of stabilisation are provided by chalcogen and related interactions. Naturally, the calculated energies will be highly dependent on the nature of the bonds about the interacting atoms, steric profiles of the interacting residues and whether a chalcogen or other intermolecular interaction is operating independently of supporting or competing intermolecular interactions not to mention the level of theory/basis sets employed in the performing of the calculations. Nevertheless, there appears a consensus from calculations [49], [50], [51], [52], [53] that the energies of stabilisation afforded by secondary bonding interactions are comparable and often exceed those provided by conventional hydrogen bonding interactions [54] and which, in turn, are comparable to the energies associated with other supramolecular synthons involving heavy elements such as π(chelate ring)…π(chelate) interactions [55].
It was in the context of a long-held interest in secondary bonding interactions and the supramolecular architectures they sustain [56], [57], [58], [59], [60], [61], [62], [63], [64] and in the aforementioned biological relevance of Se…O chalcogen bonding interactions that the present survey of Se…O interactions operating in crystals was undertaken. This review of the crystallographic literature serves to highlight the diverse nature of selenium atom environments, geometries, oxidation states and numbers and types of Se…O secondary bonding interactions formed by selenium and the wide variety of supramolecular architectures these chalcogen bonding interactions sustain.
The Cambridge Structural Database (CSD; version 5.41) [65] was searched employing ConQuest (version 2.0.4) [66] for Se…O contacts present in crystals based on the distance criterion that the separation between the selenium and oxygen atoms had to be equal to or less than the sum of the van der Waals radii, i.e. assumed in the CSD as 3.42 Å [65]. Other general criteria were applied in order to keep the number of retrieved structures to a reasonable number and to ensure reliability in the data, namely structures with errors, were salts, polymeric and contained transition metal elements were omitted along with those with R > 0.075. In all 274 structures were retrieved. These were then evaluated manually to ensure that the Se…O interaction was operating in isolation of other obvious supramolecular synthons employing PLATON [67], Mercury [68] and DIAMOND [69].
Three classes of compounds were rejected from further analysis. Firstly, several structures that registered as a hit was in fact a false positive as the putative Se…O(hydroxyl) interaction was embedded within a hydroxyl-O–H…Se hydrogen bond. This is illustrated in Fig. 1
a for (-)-t-butylphenylphosphinoselenoic acid [70], where hydroxyl-O–H…Se hydrogen bonding (Se…O = 3.30 Å) occurs between the two independent molecules comprising the asymmetric unit in the crystal. The second scenario leading to the omission of structures also involved hydrogen bonding. Thus, in bi-nuclear 2,2′-(diselane-1,2-diyl)bis(pyridin-3-ol) [71], two centrosymmetrically related molecules are connected into a dimeric aggregate via hydroxyl-O–H…N(pyridyl) hydrogen bonds as shown in Fig. 1b. Contributing to the stability of this aggregate are Se…O(hydroxyl) contacts (3.36 Å) which, obviously, are not operating independently and so examples such as this were omitted from the survey. The third class of omitted compounds featured complementary secondary bonding interactions. An example of this is shown in Fig. 1c where some of the supramolecular association operating in the 1:1 co-crystal formed between co-formers 2,2-dimethyl-N-(7-oxo-6,7-dihydro[1,2,5]selenadiazolo[3,4-d]pyrimidin-5-yl)propanamide and 2,2-dimethylpropanoic acid [72] are highlighted. While Se…O interactions (3.27 Å) are noted, these occur within a tetra-molecule assembly sustained by Se…N secondary bonding interactions (2.83 Å) and eight-membered {…HOCO…NCNH} synthons.
After manual screening, there remained 224 examples of supramolecular aggregation featuring Se…O secondary bonding interactions. All of these are illustrated in Appendix A along with detail of the full composition of the crystal, citation details, selected distances and angles, and comments on supramolecular aggregation along with image(s). The structures are generally arranged in terms of the supramolecular aggregation patterns sustained by the Se…O secondary bonding interactions operating in the crystals, i.e. zero-, one-, two- and three-dimensional. For completeness, Se…O interactions occurring in solvates and co-crystals are also included. Within each of these categories, discussion of selenium(II) atoms participating in Se…O interactions precedes those involving selenium(IV) centres and, when known, selenium(VI) examples. Within in each oxidation state, mono-nuclear species are covered before bi-nuclear species, etc. and within each of these categories, aggregates sustained by one interaction are illustrated before those sustained by two interactions, etc. Generally, the examples are included in order of increasing Se…O distances. The exception to the last guideline occurs when there are significant numbers of closely related compounds. Comments on hydrogen bonding, when present in the crystal, are also included in Appendix A rather than in the main text unless pertinent to the discussion of the identified Se…O contacts. Finally, while the focus herein is upon intermolecular Se…O contacts, hypervalent intramolecular Se…O, and more rarely Se…F and Se…S contacts, are noted in a number of the structures included in this survey. In cases where these occur, details are also included in Appendix A.
The common feature of mono-selenium(II) molecules 1–5
[11], [73], [74], [75], [76] is that dimeric aggregates are sustained by a single Se…O chalcogen bonding interaction; in each of 2–5, the selenium atom is incorporated within a ring. For 2
[74], 4
[76] and 5
[11], Fig. 3
a, the contact forms between the two independent molecules comprising the crystallographic asymmetric unit. In 1
[73], there are four independent molecules and two pairs are connected by a single Se…O(carbonyl) interaction. In 3
[75], there are eight independent selenium(II)-containing molecules and four DMSO molecules in the asymmetric unit. In this instance, only one pair of selenium(II)-containing molecules is connected by a single Se…O(hydroxyl) contact. This is a relatively rare case as, usually, in cases where multiple molecules comprise the crystallographic asymmetric unit, all participate in the formation of Se…O contacts (vide infra). In diselenide 6
[77], a Se…O(ether) interaction is featured between the two independent molecules of the asymmetric unit, Fig. 3b. Compound 7
[78] features both selenium(II) and selenium(IV) centres connected within a ring with the selenium(II) atom of one of these connecting to an oxygen atom of the second independent molecule via a Se…O(N-oxo) contact as shown in Fig. 3c. In 8
[79], with four independent molecules in the asymmetric unit, two pairs of molecules are connected by a single Se…O(methoxy) contact. A similar situation pertains in tri-nuclear 9
[80], where a single Se…O(methoxy) contact links the two independent molecules, Fig. 3d. The molecule of 9 is notable in that in addition to two ring selenium atoms, a phosphorus-bound selenide selenium(II) atom is present but, it is one of the ring selenium atoms that engages in the Se…O(methoxy) interaction. Despite the presence of multiple selenium atoms in 6–9, only one of the possible selenium atoms in each is engaged in a Se…O contact.
The overwhelming majority of mono-nuclear selenium(II) molecules in this category adopt a two-molecule motif sustained by two Se…O contacts. This motif is found in the crystals of 10–27
[81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96]. Molecules 10–12 feature acyclic, two-coordinated selenium, 13 is a selenide and those of 14–27 are also two-coordinated but with the selenium atom incorporated within a ring. In 10
[81] and 20
[91] the Se…O interactions occur between the two independent molecules comprising the asymmetric unit whereas in the remaining examples, they occur between centrosymmetrically related molecules. The selenium atoms in 10
[81] and 12
[83], Fig. 3e, associate with nitro-oxygen atoms, in 11
[82] with carbonyl-oxygen, Fig. 3f, and in 13
[84], Fig. 3g, with hydroxyl-oxygen, the selenium donor being a phosphorous-bound selenide atom. While attention is directed towards intermolecular Se…O interactions in the present survey, it is worth highlighting here that several of these species discussed herein also feature close intramolecular Se…O contacts. This feature first occurs in this survey in 12 where, owing to the close proximity of a pendant nitro substituent, an intramolecular Se…O(nitro) contact of 2.58 Å occurs which is significantly shorter than the intermolecular Se…O(nitro) separation of 3.34 Å. While details of these intramolecular Se…O contacts, and rare examples of intramolecular Se…F and Se…O contacts, are not discussed herein, comments on these are included in Appendix A.
The ring-selenium atoms are generally incorporated within five-membered rings but form part of a six membered ring in 27
[96] and part of an eight-membered ring in 18
[89]. The molecules in 14
[85], 16
[87] and 27
[96], the latter having potential sulphoxide-oxygen atoms capable of forming Se…O contacts, Fig. 3h, associate via Se…O(carbonyl) contacts. In the crystals of 15
[86], Se…O(hydroxyl) contacts are formed despite the presence of bromide atoms, Fig. 3i, and in each of 17
[88] and 18
[89], Fig. 3j, Se…O(ether) contacts are formed despite the presence of potential carbonyl-oxygen donors. Phosphorus-bound oxide atoms provide the oxygen atoms to form the dimeric aggregate in 19
[90], Fig. 3k, amide-O in 20
[91], Fig. 3l, and N-oxide in 21
[92], Fig. 3m. The dimeric aggregates formed in 22
[93], Fig. 3n, 23
[94] and 24
[93] are sustained by Se…O(nitro) interactions despite the presence of potential competitive interactions with bromide (22) and carbonyl-O (23). The two remaining molecules in this section feature adjacent selenium and oxygen atoms in the five-membered ring and each of these, i.e. 25
[95] and 26
[95], assemble about a centre of inversion to form a supramolecular four-membered {…Se–O}2 synthon. In 25, Fig. 3o, there are nitro- and hydroxyl-oxygen atoms also capable of forming Se…O interactions but, do not. A related {…Se–N}2 synthon was observed in Fig. 1c and has been discussed in terms of being a reliable synthon in the supramolecular chemistry of selenium-nitrogen materials [97]. The foregoing highlights the fact that a myriad of oxygen atoms can participate in Se…O interactions and no definitive preference for one type oxygen atom over another is obvious.
There are four examples of bi-nuclear selenium(II) species forming centrosymmetric aggregates. In diselenide 28
[98], Se…O(N-oxide) interactions sustain the dimer while Se…O(carbonyl) contacts are found in each of 29
[99] and 30
[100]. In 31
[93], one of the ring-selenium atoms of the bi-nuclear molecule associates with a nitro-oxygen atom, similar to that seen in Fig. 3n. An extraordinary mode of association via Se…O(carbonyl) contacts is found in 32
[101]. Here, a four-molecule aggregate is formed about a four-fold rotatory inversion axis (4−) as shown in the images of Fig. 3p.
The majority of the selenium(IV) compounds form centrosymmetric dimers, indeed 14 of the 18 crystals feature this motif, and each of these is constructed about a four-membered {…Se–O}2 synthon. Compounds 33
[102], 34
[103], 35–37
[104] conform to the general formula R(R′)Se
000000000000
000000000000
000000000000
111111111111
000000000000
111111111111
000000000000
000000000000
000000000000
O. The dimeric aggregate for 34, being representative for this series, is shown in Fig. 5
a, and is sustained by Se…O(oxide) interactions and is notable for the presence of potentially competitive but, non-interacting sulphur, fluoride and bromide donors. Two structures conform to the formula R(R′O)SeO. In 38
[100], with R′ = H, the interaction sustaining the dimer is Se…O(carbonyl), Fig. 5b, while the Se…O(oxide) interactions persist in 39
[105], R′ = Me. Similar Se…O(oxide) interactions sustain dimers in instances when the selenium is incorporated in a five-membered ring as in the crystals of 40
[106] and 41
[107]. The first non-selenium oxide molecule is this section is 42
[108], Fig. 5c, where the selenium atom is C,O-chelated by two distinct ligands leading to four- and five-membered rings; the dimer is stabilised by Se…O(alkoxide) contacts. A similar contact occurs in the triorganoselenium species 43
[109], Fig. 5d, where the selenium atom is incorporated within a six-membered ring. The molecules in 44
[110], Fig. 5e, are connected by Se…O(N-oxo) interactions and those in 45
[111], Fig. 5f, and bi-nuclear 46
[112], Fig. 5g, by Se…O(alkoxide) and Se…O(oxide) interactions, respectively. The structure of 44 is the earliest reported crystal structure included in the present survey, being described in 1972. It is also noted here that the authors of this paper discussed the supramolecular association mediated by Se…O secondary bonding in their description of the molecular packing in this crystal. Higher nuclearity aggregates are noted in the remaining selenium(IV) structures to be described in this section.
Each of 47 and 48
[113] assemble into tetrameric aggregates in the solid-state. In the crystal of 47, there are two independent molecules in the asymmetric unit. One of these assembles about a centre of inversion by the familiar four-membered {…Se–O}2 synthon. Attached to either side of this aggregate are two of the second independent molecules whereby each selenium of each of the terminal molecules effectively bridges the oxo atom, already engaged in a Se…O contact implying this atom is bifurcated, and an alkoxide-oxygen atom of the O,O-chelating ligand, Fig. 5h. The tetrameric aggregate in 48, Fig. 5i, has the same centrosymmetric {Se…O}2 core but, the terminal connections are also of the type {Se…O}2, also formed by the second independent molecules. This compound is of particular interest as the asymmetric unit comprises four independent molecules. Two engage as shown in Fig. 5i, while the other two engage to form a supramolecular chain as discussed below, see 175
[113]. The last two selenium(IV) aggregates to be described are hexameric.
In the crystal of 49
[114], three independent molecules comprise the asymmetric unit. A hexagon of selenium atoms, with a pronounced chair conformation, is formed about a centre of inversion, with the connections between them being of the type Se…O(oxide), Fig. 5j. In this scheme, two of the independent molecules associate via the four-membered {…Se–O}2 synthon with two of these bridged by two of the third independent molecules. Thus, two of the selenium atom forms two Se…O(oxide) contacts and four make a single Se…O(oxide) contact. In terms of the oxide donors, two form two Se…O(oxide) contacts and the remaining four oxide-oxygen atoms participate in a single contact, indicating the hexamer is sustained by eight Se…O(oxide) interactions in all. A related situation pertains for the hexamer formed in the crystal of 50
[115], Fig. 5k. The core and asymmetry in the hexamer comprising 50 is as descried for 49. However, in the case of 50, there are two independent and linked {…Se–O}2 synthons which are bridged over the centre of inversion via a pair of Se…O(oxide) interactions. So, four of the selenium atoms form two Se…O(oxide) contacts and two make a single Se…O(oxide) contact, leading to a total of 10 Se…O(oxide) contacts sustaining the hexamer.
There are five selenium(VI) species featuring Se…O interactions, each leading to a centrosymmetric, dimeric aggregate. Compounds 51
[116], 52
[117], 53
[117] and 54
[118] feature Se(=O)2 entities, while that of 55
[119] is an adduct of Se(O)3. A {…Se–O}2 core is found in each of the five dimers. In diorgano 51, the selenium atom is incorporated within a six-membered ring, Fig. 5l. Two species feature CNO2 coordination geometries, i.e. 52 and 53, Fig. 5m. An O,O-chelating ligand, leading to a five-membered ring, is seen in 54, Fig. 5n. In the only example of a molecule based on Se(O)3 core is the ether adduct, 55, Fig. 5o.
The chemical diagrams of the 19 mono-nuclear selenium(II) molecules aggregating to form linear supramolecular chains in their crystals based on Se…O chalcogen bonding contacts, i.e. 56–74
[12], [120], [121], [122], [123], [124], [125], [126], [127], [128], [129], [130], [131], [132], [133], [134], [135], [136], [137], are shown in Fig. 6
.
A variety of selenium(II) and oxygen atom environments participate in Se…O contacts leading to linear, one-dimensional chains. The first six molecules have the common feature that they are diorganoselenium(II) species with the selenium atom not enclosed within a ring. Fig. 7
a shows the formation of Se…O(ether) contacts giving rise to the chain in the crystal of 56
[120]. Molecules 57
[121], 58
[122], 59
[123] and 60
[124] employ carbonyl-oxygen atoms in the chalcogen bonding interaction. As seen in Fig. 7b for 57, Se…O(carbonyl) interactions form in preference to putative Se…O(N-oxo, nitro) contacts. A similar situation pertains in 58 where bromide, cyano-nitrogen and two kinds of ether-oxygen atoms are available for secondary bonding interactions. The presence of Se…O(nitro) interactions are responsible for chain formation in the crystal of 61
[11], Fig. 7c. In 62
[125], Fig. 7d, Se…O(nitro) interactions are also formed. The interacting selenium atom in 62 is a rare example of a selenide forming Se…O interactions, as is the case for 63
[126], which forms Se…O(methoxy) contacts.
The selenium atom is incorporated within a five-membered ring and is flanked by two carbon atoms in five molecules: 64
[127], 65
[128], 66
[129], 67
[130] and 68
[131]. The Se…O(carbonyl) contacts in the chain formed by 64 are highlighted in Fig. 7e. The structure of 64 is notable as two independent molecules comprise the asymmetric unit and each self-assembles into a linear supramolecular chain. A similar mode association is found in the crystal of 68, where each of the two independent molecules self-associate into a linear chain. By contrast, in 65–67 the Se…O association involves ether-, methoxy- and nitro-oxygen atoms. In 69
[132], the selenium atom is incorporated within a six-membered ring and molecules assemble via Se…O(carbonyl) contacts, Fig. 7f. In each of the four remaining five-membered ring-containing molecules, the selenium atom is flanked by carbon and nitrogen atoms. In 70
[133], 71
[134] and 72
[135], Fig. 7g, the molecules are linked by Se…O(carbonyl) interactions whereas in 73
[136], Fig. 7h, Se…O(nitro) contacts are evident. The last structure is this category to be described is that of 74
[137] where the selenium atom formally carries a positive charge and one of three carboxylic acid substituents is deprotonated. As seen from Fig. 7i, the linear chain is sustained by Se…O(carbonyl) interactions; the carboxylate residue is engaged in charge-assisted hydrogen bonding, precluding it from participating in Se…O contacts.
The chemical diagrams of the 32 mono-nuclear selenium(II) molecules, i.e. 75–106 [11, 74,101,133, 138–162], forming zig-zag supramolecular chains in their crystals based on Se…O chalcogen bonding contacts are shown in Fig. 8
. With two exceptions, as detailed below, the zig-zag chains are propagated by crystallographic glide symmetry.
Seven compounds have the selenium atom not constrained within a ring while the remaining 25 feature cyclised selenium, usually within a five-membered ring. A representative example of a zig-zag chain is shown in Fig. 9
a, for 75
[138]. Here, Se…O(carbonyl) interactions are in play, as in crystals of 76
[139] and 77
[140]. In 78
[141], Fig. 7b, an example rich in heteroatoms, Se…O(sulphoxide) interactions are evident, as they are in 79
[142], Fig. 9c, with a rare C,S-donor set for selenium. The structures of 80
[143] and 81
[144] are examples of selenides are engaged in Se…O interactions. In 80, there are two independent molecules in the asymmetric unit and each of these self-associates into a supramolecular chain via CSe…O(nitro) interactions, one of these is shown in Fig. 9d. In 81, where the selenide is phosphorus-bound, the zig-zag chain, Fig. 9e, arises as a result of PS…O(ether) contacts. The remaining molecules to be covered have the selenium atom incorporated with a ring.
In the next six molecules, each selenium(II) atom has a C,C-donor set. The selenium atom in 82
[74] forms part of a four-membered ring and the molecules assemble into a zig-zag chain via Se…O(sulphoxide) contacts, Fig. 9f. The chains in 83
[145] are sustained by Se…O(methoxy) interactions, and in 84
[146], 85
[101], 86
[147] and 87
[148] by Se…O(carbonyl) interactions. Compound 85, Fig. 9g, is one of two molecules in this section assembling into a zig-zag chain not propagated by glide symmetry. In this case, there are two independent molecules which associate to form the supramolecular chain.
Next, is a series of molecules constructed about a 5-selanylidene-1H-pyrrol-2-one core, i.e. 88–99
[11], [149], [150], [151], [152], [153], [154], [155], [156], [157], featuring a variety of substituents, R, at the nitrogen atom: R = CH2Ph (88) [149], Ph, polymorphs 89
[11] and 90
[150], Ph-C(=O)OH-4 (91) [151], Ph-Br-4 (92) [152], Me (93) [153], H, acid 94
[152], Ph-Br-2 (95) [154], Ph-Me-3 (96) [155], Ph-Me-2 (97) [156], Ph-OH-3 (98) [11] and, lastly, R = a fused 1-ethylpiperidine-2,6-dione/naphthalene derivative (99) [157]. The common mode of the supramolecular association is the formation of Se…O(carbonyl) interactions, as illustrated for 95
[154] in Fig. 9h. Generally, these contacts are short, ranging from 2.53 Å in 88
[149] to 2.86 Å for 99
[157], suggesting considerable covalent character in these secondary bonding interactions. As indicated above, 89 and 90 are polymorphs. These exhibit the same supramolecular aggregation via Se…O(carbonyl) interactions with very similar Se…O separations of 2.53 and 2.57 Å, respectively. Of interest is the R = H derivative, 94, i.e. the acid form, where three independent molecules comprise the asymmetric unit. One molecule self-assembles into a zig-zag chain (glide symmetry). The two other molecules associate via a Se…O(carbonyl) interaction and the resultant dimeric aggregates assemble into a zig-zag chain, again propagated by glide symmetry. Variations of the above are seen in 100
[133], where the fused C6 ring carries a nitro substituent, and 101
[158], where the fused C6 ring is fused to a second C6 ring, and in 102 and 103
[159], where the fused C6 ring is substituted by a thienyl ring; each of the resultant zig-zag chains are sustained by Se…O(carbonyl) interactions. The Se…O(carbonyl) interactions persist in 104
[160], where the fused C6 ring of the above examples is now a pyridyl ring and 105
[161], where the selenium atom is incorporated into a six-membered ring. The final molecule in this section, 106
[162], Fig. 9i, is notable in that the selenium atom, embedded within a four-membered ring, forms two Se…O(sulphoxide) interactions to sustain the zig-zag chain.
The chemical diagrams of the mono-nuclear selenium(II) molecules, i.e. 107–123
[152], [163], [164], [165], [166], [167], [168], [169], [170], [171], [172], [173], [174], [175], [176], [177] and 124–126
[159], [178], [179], forming, respectively, helical and twisted supramolecular chains in their crystals based on Se…O chalcogen bonding contacts are shown in Fig. 10
.
The supramolecular chains with helical symmetry are typically propagated by crystallographic 21 screw symmetry, with two exceptions only, and, while less numerous than zig-zag supramolecular chains sustained by Se…O interactions, comprise 17 examples. Six of the molecules do not have selenium incorporated within a ring, and four of these have selenium within a C2-donor set: 107
[163], 108
[164], 109
[165], Fig. 10a, and 110
[166], and two of the examples are selenides 111
[167] and 112
[168], Fig. 11
b. Highlighting the diversity of oxygen-donors in these chains, in 107 and 109 they feature Se…O(carbonyl) contacts, 108 Se…(methoxy), 110 Se…O(sulphoxide), 111 Se…O(hydroxyl) and the chains in 112 are sustained by Se…O(ether) interactions. The remaining helical structures feature cyclised selenium atoms. The five-membered rings in 113
[169], 114
[170] and 115
[171] also feature C2 donor sets as does the selenium atom in 116
[172], Fig. 11c, which is now incorporated within a six-membered ring. The donor atoms forming the Se…O interactions are hydroxyl in 113 but, carbonyl in 114–116; in 114, both ether and hydroxyl donors are available but not employed in Se…O contacts. The remaining ring structures contain hetero-atoms, all having at least one nitrogen atom, with two exceptions. In 117
[173], the helical chain is sustained by a charge-assisted Se…O(N-oxo) interaction with the separation being a short 2.41 Å. Molecules 118
[152], 119
[174], 120
[152] and 121
[175] all feature the 5-selanylidene-1H-pyrrol-2-one core, as seen above in the sequence of molecules 88–99. The chains in 118 and 120 are sustained by Se…O(hydroxyl) interaction despite having potential carbonyl donors, whereas the chains in 119 and 121 feature Se…O(carbonyl) interactions. It is noted that 118 has two polymorphs: in 5, Fig. 3a, the two independent molecules of the asymmetric unit assemble by a single Se…O(carbonyl) interaction and in second polymorph, 98, molecules assemble into a zig-zag chain, but via Se…O(hydroxyl) interactions as in 118. The helical chain formed in 119 is especially noteworthy in that rather than the usually observed 21 symmetry, the chain is propagated by crystallographic 61 screw symmetry, Fig. 11d. In 122
[176], where there are two nitrogen atoms in the ring, flanking the selenium atom, the helical chain is sustained by Se…O(carbonyl) interactions, Fig. 11e. The supramolecular aggregation in 123
[177] is quite unusual, featuring three distinct Se…O contacts for the selenium atoms derived from the two independent molecules comprising the asymmetric unit. As viewed from Fig. 11f, one selenium atom forms a single contact with a nitro-oxygen atom while the other selenium atom spans the two oxygen atoms of a symmetry related five-membered ring. The shortest Se…O contact of 2.90 Å in the chain is associated with the Se…O(carbonyl) interaction. The other unusual feature of the resulting supramolecular chain is that it is propagated by crystallographic 41 screw symmetry.
There are three molecules, 124
[159], 125
[178] and 126
[179], assembling in their crystals to form twisted chains. In 124, Fig. 10g, and 125, two independent molecules comprise the asymmetric unit with the twisted arrangement arising due to the relative orientations of the independent molecules in the chains propagated by translational symmetry; chains are sustained by Se…O(carbonyl) contacts. The molecule in 126, Fig. 10h, has crystallographic two-fold symmetry with the selenium atom lying on the axis. Each selenium atom forms two Se…O(nitro) contacts with centrosymmetrically related molecules.
A linear chain is observed in crystals of 127
[180], Fig. 13
a, an example whereby the selenium atom is not embedded within a ring and where only one of the selenium atoms is engaged in a Se…O contact; in this case the donor is a carbonyl-oxygen atom. When embedded within a five-membered ring, the selenium atoms can be next to each other as in 128
[181] and 129
[182], Fig. 13b, or in a six-membered ring, i.e. 130
[183]. Again, only one of the selenium atoms in 128–130 forms a Se…O contact, with the donors being ether-, sulphoxide- and carbonyl-oxygen, respectively. The structure of 129 is especially noteworthy in that two molecules comprise the asymmetric unit, and these possess amide donors capable of forming hydrogen bonding interactions. One of the independent molecules forms a supramolecular chain, as just mentioned, and these are connected into a double-chain by conventional amide-N–H…O(sulphoxide) hydrogen bonds involving the same sulphoxide-oxygen atom forming the Se…O contacts. The second independent molecule also forms a supramolecular chain but, mediated solely by amide-N–H…O(sulphoxide) hydrogen bonds, there being no Se…O interactions of note. The adoption of Se…O and/or amide-N–H…O(sulphoxide) hydrogen bonds suggests, at least to a first approximation, some equivalence in the energies of stabilisation afforded by these modes of association. In 131
[184], the association leading to a linear chain involves both selenium atoms connecting to the carbonyl-oxygen atom of a translationally related molecule, Fig. 13c. A double-chain is noted for 132
[185], Fig. 13d. Here, two selenium atoms occur diagonally opposite positions in a centrosymmetric C2Se2 square, and each forms a Se…O(carbonyl) interaction to form a linear chain. Two independent molecules also comprise the asymmetric unit of 133
[186]. One of these self-associates into a linear chain via Se…O(sulphoxide) contacts whereby one selenium atom forms two contacts with translationally related molecules leading to seven-membered {…Se…OSSeSeSO} synthons. Centrosymmetrically related chains assemble into a double-chain, also via Se…O(sulphoxide) contacts, but involving the second selenium atom (forming the shortest Se…O contact) and six-membered {…OSSe}2 synthons, as shown in the views of Fig. 13e.
Four molecules of the general formula RSeSeR form supramolecular zig-zag chains in their crystals; these along with the other chains described in this section are propagated by glide symmetry. These are sustained by an average of one Se…O(sulphoxide) contact per molecule in 134
[186], Fig. 13f, Se…O(nitro) in 135
[187] and Se…O(carbonyl) in each of 136
[188] and 137
[189]. A variation is noted for 138
[95], Fig. 13g, where the selenium atoms are connected by an oxo-bridge and one of these forms Se…O(nitro) contacts. The selenium atoms are adjacent to each other in the five-membered ring of 139
[190] and one of these participates in Se…O(sulphoxide) interactions to form the zig-zag chain. In the five-membered rings of each of 140
[191] and 141
[192], Fig. 13h, the selenium atoms are separated by a carbon atom, and the chain is mediated by Se…O(carbonyl) interactions. In 142
[80], Se…O(hydroxyl) interactions involving the ring-bound selenium atom mediate the formation of the zig-zag chain rather than putative interactions involving the phosphorus-bound selenide atom. A variation in the general theme of one Se…O link per molecule to sustain the zig-zag chain is noted for 143 and 144
[190], Fig. 13i, where each selenium atom, occupying adjacent positions in a five-membered ring, participates in Se…O(sulphoxide) interactions with the same sulphoxide-oxygen atom.
The common feature of the seven helical chains formed by bi-nuclear selenium(II) molecules is that each is propagated by 21 screw symmetry. The first six molecules employ a single selenium atom in forming the Se…O chalcogen bond: 145, 146
[193], Fig. 14
a, 147
[194], 148
[195], 149
[196] and 150
[197]. The oxygen donors span a range of types, i.e. sulphoxide (145 and 146), ether (147) and carbonyl (148 and 150) and phenoxide (149). In 151
[198], Fig. 14b, the adjacent selenium atoms are embedded within a five-membered ring and form contacts to the same carbonyl-oxygen atom to form the helical chain, i.e. bearing a close resemblance to the aggregation pattern seen in 143 and 144, Fig. 13i. The bi-nuclear molecule in 152
[199], has two-fold symmetry with the axis bisecting the Se–Se bond, and each selenium atom forms a Se…O(nitro) contact to a centrosymmetrically related molecule with the result a twisted chain ensues, Fig. 14c.
There are two tri-nuclear selenium(II) species forming supramolecular chains in their crystals. As a result of Se…O(carbonyl) interactions whereby two of the three selenium atoms, each within a five-membered ring, form a contact to the same carbonyl-oxygen atom, a linear chain is formed in the crystal of 153
[152], Fig. 14d. In 154
[200], where there is an “open” selenium atom and two selenium atoms within five-membered rings, it is the former that forms a Se…O(ether) contact to generate a zig-zag chain via glide symmetry, Fig. 14e.
The remaining five selenium(II)-containing species in this section are tetra-nuclear. In 155
[201], two five-membered rings, each with a 1,3-disposition of selenium atoms, are connected to form the tetra-nuclear molecule. In the crystal, only one of the selenium atoms forms a Se…O(carbonyl) interaction with translationally related molecules so that a linear chain is formed, Fig. 14f. The macrocyclic compound, 156
[202], employs two of its selenium atoms to sustain a linear assembly via Se…(methoxy) interactions and eight-membered {…SeC2O}2 synthons, Fig. 14g. The molecule 157
[203] is clearly related to 155 but, in this case, this assembles into a zig-zag chain (glide symmetry), Fig. 14h. The remaining molecules, 158
[204], and 159
[205], assemble into helical chains, for 158, Fig. 14i, propagated by 21 screw symmetry. An interesting variation is noted for 159 in that the four selenium atoms line up in a chain within an eight-membered ring; two independent molecules comprise the asymmetric unit. The independent molecules assemble via a Se…O(carbonyl) contact and the resultant dimeric aggregate then assembles, via additional Se…O(carbonyl) contacts, into a supramolecular helical chain propagated by 31 screw symmetry, Fig. 14j.
While far less represented than their selenium(II) counterparts, there are 21 examples of selenium(IV) compounds, usually selenoxide derivatives, self-associating in their crystals to form one-dimensional chains via Se…O chalcogen bonding. The chemical diagrams for these species, i.e. 160–180
[93], [104], [105], [113], [188], [206], [207], [208], [209], [210], [211], [212], [213], [214], [215], [216], [217], are shown in Fig. 15
.
The three selenoxides, 160
[104], 161
[104] and 162
[206], Fig. 16
a, feature C2O-donor sets and associate in their crystals to form linear, supramolecular chains via Se…O(nitro) interactions in 160, and Se…O(methoxy) interactions in 161 and 162. Double-chains are often observed in the crystals of the selenium(IV) compounds in this category owing to the formation of multiple Se…O interactions. This is exemplified by 163
[207], Fig. 16b. Here, centrosymmetrically related molecules are connected by a pair of Se…O(oxide) interactions, leading to a {…Se–O}2 core, and the resultant dimeric aggregates assemble into a linear, double-chain so each selenium atom forms two Se…O contacts. Similar patterns are noted in 164
[208], Fig. 16c, and 165
[209] but, with the bridges leading to the chains being interactions of the type Se…O(nitro); in 164, the Se…O(carbonyl) separations are shorter than the Se…O(nitro) contacts whereas the opposite trend pertains in 165, underscoring the difficulty of correlating distances associated with weak interactions as discussed in section 8. In 166
[210], Fig. 16d, with a chelating O,O-ligand leading to a five-membered ring, the double-chain arises as the successive, centrosymmetrically related aggregates are connected by Se…O(alkoxide) interactions. In the dioxide species, 167
[211], Fig. 16e, the centrosymmetric aggregates are connected to translationally related dimers via a pair of Se…O(oxide) contacts so each selenium atom participates in three Se…O interactions. A more complicated mode of association between molecules occurs in 168
[113], Fig. 16f, for which two independent molecules comprise the asymmetric unit. One of the independent molecules assembles to form a dimer and translationally related dimers are bridged by a pair of the second independent molecule. There are six independent Se…O contacts involving oxide- (4) and alkoxide-oxygen (2) donors, and each selenium atom participates in three Se…O interactions.
Molecules 169
[93], 170
[113], Fig. 16g, and 171
[113], each with C2O donor sets, assemble into zig-zag chains mediated by a single Se…O(oxide) contact in each case. In 171, two independent molecules comprise the asymmetric unit and these are connected by a single Se…O(oxide) interaction and these dimers then assemble into a zig-zag chain via additional Se…O(oxide) interactions. Compounds 172
[188] and 173
[212], in which the selenium centres are O,O-chelated by two chelating ligands, are polymorphic. In 172, a single Se…O(carbonyl) interaction, on average, sustains a zig-zag assembly (glide symmetry). By contrast, in 173, Fig. 16h, the selenium atom lies on a two-fold axis of symmetry and there are, on average two Se…O(carbonyl) interactions per molecule with the Se…O(carbonyl) distance of 3.22 Å being longer than 3.02 Å observed in 172, as would be expected. The molecule in 174
[213], also has the selenium atom lying on a two-fold axis of symmetry and a similar mode of association as for 173 is noted in its crystal. The supramolecular association 175
[113] is of particular interest. Here, there are four independent molecules in the asymmetric unit and each participates in Se…O contacts. Two of the independent molecules assemble into a tetrameric aggregate via Se…O(oxide) and Se…O(alkoxide) interactions as shown for aggregate 48
[113] in Fig. 5h. In the second assembly found in the crystal of 175, involving the two remaining independent molecules, only Se…O(alkoxide) interactions are formed leading to a zig-zag chain with each selenium atom forming two Se…O interactions, Fig. 16i.
Helical chains (21 screw symmetry) are found in crystals of 176
[105], 177
[214] and 178
[215], Fig. 16j, sustained by either Se…O(carbonyl), 176 and 177, or Se…O(methoxy), 178, interactions. A helical chain, also with 21 screw symmetry, occurs in the crystal of 179
[216], Fig. 16k, as the selenium atom accepts bond Se…O(oxide) and Se…O(hydroxyl) interactions, rather than the single Se…O interactions of the previous three examples. Finally, in 180
[217] two independent molecules comprise the asymmetric unit and each selenium atom participates in two Se…O(carbonyl) interactions with the chain, propagated by translational symmetry, having a twisted topology owing to the relative orientation of the independent molecules comprising the repeat unit.
Several different motifs are noted in the two-dimensional arrays formed by the compounds in this section. In the crystal of mono-nuclear 181
[218], Fig. 18
a, molecules assemble about a centre of inversion, being connected by Se…O(nitro) interactions and eight-membered {…Se…ONO}2 synthons. The connections extend laterally as each selenium forms two contacts as does each nitro group, via both oxygen atoms, with the resultant layer being corrugated. The selenium atom also forms two contacts in 182
[219] but, with the same, bifurcated carbonyl-oxygen atom to sustain a flat, hexagonal-like grid, Fig. 18b. In the following structures, disparate Se…O interactions sustain the resulting two-dimensional array. In 183
[220], the selenium atom forms two interactions with carbonyl- and hydroxyl-oxygen atoms, derived from symmetry related molecules, which are linked by a hydroxyl-O–H…O(carbonyl) hydrogen bond. In 184
[133], the connections are of the type Se…O(carbonyl) and Se…O(nitro), and analogous contacts are formed in 185
[221], Fig. 18c. The layers in each of 183–185 have a jagged topology. There are two bi-nuclear selenium(II) compounds adopting two-dimensional aggregation patterns. In the first of these, 186
[222], each selenium atom forms a contact to a carbonyl-oxygen atom of two different molecules, Fig. 18d, leading to a flat, hexagonal pattern akin to that for 182, Fig. 18b. In a variation, in 187
[223], each selenium atom again forms a single contact but, two different carbonyl-oxygen atoms, Fig. 18e, leading to a corrugated topology. A polymorph of 187 exists, i.e. 132, which adopts a linear, one-dimensional chain in its crystal, Fig. 13d, forming the same number of Se…O(carbonyl) interactions. The difference in aggregation patterns arise as in 132, centrosymmetric, eight-membered {…SeC2O}2 synthons are formed whereas in 187, the molecules assemble through more open, 16-membered {…SeC2O}4 synthons, Fig. 18e.
Somewhat squarer arrangements are seen in the crystals of bi-nuclear 188
[224], Fig. 19
a, where each molecule participates in four Se…O(carbonyl) interactions, with one of the selenium atoms forming two interactions and one of the carbonyl-oxygen atoms forming two interactions; the layer is corrugated. An even more square appearance is seen for 189
[186], Fig. 19b, where the central atom of the tri-nuclear molecule participates in two Se…O(sulphoxide) interactions with two different molecules while at the same time donating two sulphoxide-oxygen atoms to another two symmetry related molecules; the resultant layer is flat. In tri-nuclear 190
[225], which has two-fold symmetry with the central selenium atom lying on the axis, it is the external selenium atoms of the Se3 chain that each form a single Se…O(carbonyl) interaction and each of the carbonyl-oxygen atoms also participates in a Se…O contact, Fig. 19c, leading to a corrugated layer. In tri-nuclear 191
[226], which has mirror symmetry with the central selenium lying on the plane, the selenide atoms lie to the periphery of the SeP–Se–PSe hetero-chain. In this instance, the selenide atoms form Se…O(phenoxide) contacts that generate a grid with a flat topology, Fig. 19d.
The final selenium(II) compound adopting a two-dimensional array in its crystal is also the only example of a tetra-nuclear compound in this category, 192
[205]. Here, the four selenium atoms are in a Se4 chain and, as seen from Fig. 20
, it is the 1,3-selenium atoms forming the Se…O(carbonyl) interactions with two different carbonyl-atoms that are responsible for the formation of the layer, which has a distinctive saw-tooth topology.
A smaller number of selenium(IV) compounds assemble into two-dimensional arrays. The structure of 193
[227] is the only example in this series where the selenium atom is not incorporated within a ring. This open arrangement coupled with the selenium atom is within an O3-donor set enables the formation of three interactions with each of the coordinated triflate anions, two of which are Se–O covalent bonds; each of the non-coordinating oxygen atoms participates in a Se…O(sulphonate) interaction, as seen from the detail of the selenium-atom environment of Fig. 21
a. The packing comprises inter-digitated rows of molecules connected by the aforementioned Se…O(sulphonate) interactions to form a flat layer. In 194
[228], molecules are connected into centrosymmetric dimers via Se…O(alkoxide) interactions and these in turn are connected into a grid by Se…O(oxide) interactions which form the shorter of the separations, Fig. 21b. Disparate Se…O interactions are evident in 195
[95] and 196
[113]. In the former, approximately orthogonal chains sustained by Se…O(nitro) and Se…O(oxide) interactions assemble molecules into a two-dimensional array, Fig. 21c. In 196, Se…O(alkoxide) and Se…O(oxide) interactions cooperate in a similar fashion. The resultant layer in each of 195 and 196 is jagged.
The selenium atom in 197
[113] is incorporated within a six-membered ring and forms a total of three Se…O interactions in the crystal, Fig. 22
a. Centrosymmetrically related molecules are connected by via Se…O(alkoxide) interactions, forming the shorter distances, and these are connected into a flat, two-dimensional array by Se…O(oxide) interactions. Two independent molecules comprise the asymmetric unit of 198
[229] and these are connected by Se…O(carbonyl) interactions to form the array shown in Fig. 22b; the topology of the layer is flat. The selenium atom in the first independent molecule forms two Se…O contacts and the carbonyl-O atom one, with the second independent molecule follows the opposite trend. This flexibility in association via Se…O contacts is reflected in the following observation. Compound 198 is of particular interest as three polymorphs have been reported. Earlier in this survey, aggregation patterns were reported for the first two of these, i.e. 172 and 173, Fig. 16h, each of which adopts a zig-zag chain in their crystal sustained, on average, by one and two Se…O(carbonyl) interactions, respectively. The selenium atom in 199
[230] is bis-chelated by C,O-donors and lies on a two-fold axis of symmetry. The selenium atom forms two Se…O(contacts) to form a flat, two-dimensional array, Fig. 22c. The only bi-nuclear compound in this section is found in 200
[231] where diagonally opposite selenium atoms are incorporated within a four-membered ring; the molecule has mirror symmetry with the nitrogen atoms of N2Se2 core lying on the plane. Each of the selenium and carbonyl-oxygen atoms forms a single Se…O(carbonyl) contact extending laterally to form a corrugated layer, Fig. 22d.
There are only three examples of selenium compounds comprising one chemical entity in the crystal assembling into a three-dimensional architecture based on Se…O chalcogen bonding. The chemical structures for these oxide-rich molecules, i.e. 201–203
[118], [232], are shown in Fig. 23
.
Only one selenium(II) molecule assembles to form a three-dimensional architecture in its crystal, namely 201
[232]. The bi-nuclear molecule has mirror symmetry containing both selenium atoms and relating the two cyclobutadiene residues. Here, each selenium atom forms four Se…O(carbonyl) interactions and each of the carbonyl-oxygen atoms forms two interactions to selenium as highlighted in Fig. 24
a. The resulting architecture resembles a skewed honeycomb array. The two remaining molecules feature selenium(VI) centres, i.e. tri-nuclear 202
[118] and tetra-nuclear 203
[118]. In the former, which lacks symmetry, only the oxide-oxygen atoms participate in Se…O interactions with each forming a single contact and each selenium atom forming two Se…O(oxide) contacts, Fig. 24b. Layers with a zig-zag topology are discernible in the packing, Fig. 24b, being connected by three distinct Se…O(oxide) contacts. The molecule in 204 is disposed about a four-fold centre of inversion (4−) with each Se(=O)2 unit involved in two donor and two acceptor Se…O(oxide) contacts, Fig. 24c. The resulting architecture comprises tetra-nuclear molecules assembled into columns, with a square appearance, connected orthogonally by the Se…O(oxide) contacts which define columns with a rectangular appearance, Fig. 24c.
Each of the mono-, bi- and tri-nuclear selenium(II) compounds, i.e. 204
[233], 205
[234] and 206
[235], illustrated in Fig. 26
a-c, respectively, feature a single Se…O contact between the molecule and solvent, i.e. dimethylformamide in 204 and 206, and methanol in 205. In tetra-nuclear 207
[235], which is disposed about a centre of inversion, there are two co-crystallised dimethylformamide molecules and the oxygen atom from each of these symmetrically spans two selenium atoms to form a three-molecule aggregate shown in Fig. 26d.
A one-dimensional chain with a zig-zag topology (glide symmetry) is formed in the crystal of 208
[236] whereby the dimethylsulphoxide-oxygen atom symmetrically bridges two selenium atoms to form the arrangement shown in Fig. 26e.
The focus now turns towards selenium(IV) species. A three-molecule aggregate is formed in 209
[237] where the dioxane molecule, situated about a centre of inversion, bridges two molecules as shown in Fig. 26f. A hydrated, linear supramolecular chain is formed in the crystal of 210
[238]. The water molecule is connected to the selenium atom, being separated by 2.92 Å, and the resultant two molecule aggregates assemble into a chain via Se…O(hydroxyl) chalcogen bonds (3.03 Å) as shown in Fig. 26g.
In the mono-selenium(IV) compound 211
[239], linear chains are sustained by Se…O(oxide) contacts and these are connected into a three-dimensional array by links provided by bridging dioxane molecules, Fig. 27
a. Thus, each selenium forms three Se…O interaction with the shorter of the separations involving Se…O(ether) contacts.
There are two mixed selenium(IV)/(VI) compounds in this category, i.e. 212
[118] and 213
[118], and a pivotal role for the co-crystallised dioxane molecules is evident in each. The tetra-nuclear molecule in 212 is disposed about a centre of inversion. There are two molecules of solvent for each tetra-nuclear molecule and it is the selenium(IV) centres that associate with two symmetry dioxane molecules to form a two-dimensional grid, Fig. 27b. In the second mixed valence compound, 213
[118], two tri-nuclear molecules and four dioxane molecules comprise the asymmetric unit. As shown in the left-hand image of Fig. 27c, molecules are assembled into a two-dimensional array with an undulating topology via Se…O(ether) interactions as each dioxane molecule is bridging and each selenium(IV) centre forms two contacts of this type. The links between layers to form a three-dimensional architecture are of the type Se…O(oxide), where the oxide-donors are bound to the selenium(VI) centres. The Se…O(oxide) interactions form separations systematically longer than the Se…O(ether) contacts, Fig. 27c.
A three-dimensional architecture is also found in the crystals of the selenium(VI) compound, 214
[118], a 1:1 dioxane solvate, with the bi-nuclear molecule bisected by two-fold axis of symmetry and with the dioxane molecule disposed about a centre of inversion. As seen in Fig. 27d, molecules are assembled into rows via Se…O(oxide) interactions and rows are connected by Se…O(ether) interactions derived from the bridging dioxane molecules. A systematic trend is noted in Se…O distances as for 213 in that the separations involving the Se…O(ether) contacts are shorter than the Se…O(oxide) contacts.
In this final section, a number of selenium(II) and selenium(IV) aggregates are described, with all but one example being zero-dimensional in consideration of Se…O interactions alone. The selenium(II) atom in mono-nuclear 215
[240] forms four Se…O(ether) contacts to sustain a two-molecule aggregate, Fig. 28
a. The asymmetric unit of 216
[241] comprises two selenium(II) molecules and the organic co-former, i.e. is a 2:1 co-crystal, one of the selenium(II) molecules makes a single Se…O(hydroxyl) interaction to form the two-molecule aggregate shown in Fig. 28b. In the 1:2 co-crystal 217
[242], each of the selenium atoms in the bi-nuclear molecule forms a Se…O(carbonyl) interaction to form a three-molecule aggregate, Fig. 28c. Another bi-nuclear molecule where the selenium atoms are connected to each other within a five-membered ring, 218
[243], forms a 2:1 co-crystal with a nitrogen-oxo-containing molecule; both species are radicals. The oxo atoms atom accepts four Se…O(oxo) interactions, one each from each of the selenium atoms of the two co-formers, Fig. 28d. The tri-nuclear molecules in each of 219 and 220
[244] featured earlier in 206, i.e. forming a two-molecule aggregate with a solvent molecule, Fig. 26c. In 219 and 220, Fig. 28e, this molecule is also a co-former in 2:1 co-crystals with potentially bridging molecules, at least via Se…O interactions; the organic co-former is disposed about a centre of inversion in both co-crystals. Indeed, one selenium(II) atom in each molecule is connected by Se…O(carbonyl) and Se…O(nitro) interactions in 219 and 220, respectively, to form a three-molecule aggregate in each case.
The only one-dimensional chain in this section is formed in the 2:1 co-crystal 221
[241]; the selenium(II) molecule also formed a solvate via a Se…O(hydroxyl) interaction in 216
[241], Fig. 28b. In 221, the benzene-1,4-diol molecule is situated about a centre of inversion and the association between molecules is also through Se…O(hydroxyl) interactions. Centrosymmetric {…Se–O}2 synthons are formed in the crystal leading to a linear, supramolecular chain, Fig. 28f.
There are three selenium(IV) molecules forming co-crystals based on Se…O chalcogen bonding, i.e. 222, 223 and 224
[240]. In 222, Fig. 28g, the selenium(IV) atom forms three Se…O(ether) contacts to form a zero-dimensional adduct. Similar, two molecule aggregates are formed in 223 and 224 where each selenium atom forms four Se…O(ether) contacts, resembling the situation illustrated for 215
[240] in Fig. 28a.
Allowing for multiple molecules in the asymmetric unit and the occurrence of several polymorphs, 224 distinct supramolecular aggregation patterns based on Se…O chalcogen bonding interaction are noted in the crystals of nearly 220 selenium compounds. The overwhelming majority of the compounds were homogeneous but examples of solvates and co-crystals are evident. By far the most predominant oxidation state is + II, with 163 examples (72%), followed by + IV (51) with a small number of compounds with selenium in the + VI (8) oxidation state; two mixed valent selenium(IV)/(VI) compounds are also included in the survey. Over two-thirds of molecules are mono-nuclear (161), with decreasing numbers of bi-, tri- and tetra-molecules, i.e. 43, 11 and nine, respectively. A full range of zero-, one-, two- and three-dimensional patterns are noted with the majority, i.e. over 55% (128 examples), being one-dimensional with the next most significant being, zero-dimensional, with 69 examples. There are 22 examples of molecules assembled into two-dimensional arrays and five forming three-dimensional architectures. The average number of Se…O interactions per participating species varies from 0.5, i.e. for zero-dimensional aggregates sustained by a single interaction to four in several architectures. Of the nearly 300 different Se…O contacts in the supramolecular aggregates described herein, over three-quarters (78%) involve a single Se…O interaction and 18% involve two Se…O interactions. There are six examples each of molecules where the selenium forms three or four contacts, always in higher-dimensional aggregates. Of the zero-dimensional aggregates, the majority comprise two like-molecules sustained by one (9) or two (41) Se…O interactions but, examples of four- and six-molecule aggregates are also observed. A variety of topologies are noted among the 125 zero-dimensional chains, including linear (38), zig-zag (52), helical (30) and twisted (5).
The large range of supramolecular aggregation patterns is complimented by the diversity in the oxygen donors participating in Se…O interactions. When aggregates featuring one type of Se…O interaction only, 41% involve carbonyl donors. The next most prevalent are ether (including methoxy) and SeO donors, each at 12%, followed by nitro-, sulphoxide- and hydroxyl-donors at 9, 8 and 6%, respectively.
Attention is now directed on the propensity of molecules to form Se…O chalcogen bonding in their crystals. Herein, 224 examples of aggregates sustained by Se…O chalcogen bonding interactions were identified. Put into perspective, after a search of the CSD [65] following the protocols outlined in section 2, there are 1722 “hits” for crystals containing both selenium and oxygen. This implies the percentage adoption of Se…O chalcogen bonding approximates 13% of all possible structures where these interactions can occur. This percentage is an underestimate as in the present survey as crystals where Se…O interactions were acting in concert with other identifiable intermolecular forces, the notable example being hydrogen bonding, were omitted. This percentage compares favourably to the 6% of selenium(lone-pair)…π(arene) interactions in crystals where these interactions can potentially form [248], [249]. Over and above different chemical composition, as alluded to above, secondary bonding interactions, including chalcogen bonding interactions, are notoriously subject to steric effects in that these interactions are mitigated when bulky metal-bound and/or ligand-bound substituents are present [54], [56], [57], [58], [59], [60], [61], [62], [63]. To probe further the likely adoption of Se…O interactions in crystals, the likelihood of specific classes of compounds to form Se…O chalcogen bonds was ascertained.
As noted above, Se…O(carbonyl) interactions featured in 41% of the crystals in the present survey. Hence, the CSD was searched for “selenium” and “carbonyl-oxygen” using the established protocols. This indicated that almost 50% of all crystals having these two components actually formed Se…O(carbonyl) interactions. An analogous search for residues containing SeO, often observed in the selenium(IV) compounds included herein, was conducted. This analysis indicated a smaller percentage adoption of about 25%. Throughout this survey, the 5-selanylidene-1H-pyrrol-2-one core, as found in Ebselen™, has been mentioned a good number of times. This core has a three-bond separation between the selenium and carbonyl-oxygen atoms, and with these acceptor and donor atoms largely constrained to a fixed disposition owing to their relationship through the five-membered ring. A search of the CSD revealed this core features in 52 crystals. With Se…O(carbonyl) interactions forming in 25 examples, the percentage adoption is over 48%. Interestingly, five others of these structures formed Se…O interactions in their crystals but, with selenide- (1), nitro- (1) and hydroxyl-oxygen (3) donors. With this relatively high adoption rate, the propensity of selenium molecules with selenium incorporated within a five-membered ring comprising four unspecified atoms and unspecified bonds between them was then evaluated. The CSD has about 945 “hits” for this fragment and with 102 examples having unassisted Se…O chalcogen bonding interactions, the percentage adoption is at least 10%, indicating this fragment alone does not promote Se…O interactions.
Consideration is now directed towards the geometric parameters characterising the observed Se…O secondary bonding interactions. The Se…O separations span a wide range, i.e. from a short 2.40 Å, indicative of some covalent character, right out to the van der Waals limit of 3.42 Å; the average distance of a Se…O interaction computes to 3.11 Å and the median value is 3.17 Å. It is noted that while many of the shorter interactions were in the dioxane adducts, such as 212 which exhibited the short contact cited above, short contacts were often noted in one-dimensional chains involving molecules incorporating the 5-selanylidene-1H-pyrrol-2-one core, e.g. the next shortest separation of 2.41 Å is observed in 118. However, these are only generalisations, with each class of molecule, respectively, also having longer contacts, e.g. 3.35 Å in 8 and 3.38 Å in 23. This observation is entirely consistent with the well-known axiom in supramolecular chemistry that geometric correlations of weak intermolecular interactions are not generally possible unless the molecules/interactions are very closely related/isostructural [245], [246], [247]. In the present case, the lack of systematic trends is not surprising considering the different chemical composition of the interacting species, different oxidation states and geometries, and range of oxygen donors engaged in the Se…O interactions.
Up to this point, no specific mention of the angles associated with the supramolecular Se…O interactions has been made; key angles subtended at oxygen donor atoms and selenium acceptor atoms are collated in Appendix A. Just as distance correlations are not reliable for intermolecular interactions [245], [246], [247], correlations involving angles are also problematic, as commented upon recently for secondary bonding interactions formed between selenium and the heavier main group elements [250]. This is because, as for distances, angles are going to be moderated by the chemical/electronic environment of the participating atoms. Based on the assumption that for the specified Se…O contacts, the oxygen atom is the Lewis base, providing the charge to the σ-hole located on the selenium atom of the Lewis acid, there are several variables impacting upon the magnitude of the Se…O interaction and the angles subtended at the interacting oxygen atom. In the case of the oxygen donor, these factors include but, are not limited to the steric and electronic profiles of the residues bound to oxygen, the hybridisation of the oxygen atom and, when the interacting oxygen atom is part of a nitro group, for example, the partial charge on the oxygen atom. For the selenium acceptor, again the steric and electronic profiles of bound atoms/groups come into play, as does the ligand donor set about the selenium atom along with the oxidation state of the selenium atom which, in turn, impacts on the number of sterically active lone-pairs of electrons about the selenium atom and therefore, stereochemistry.
These points are highlighted in the following observations on the sub-set of structures where the donor oxygen and acceptor selenium atoms participate in one contact only. Considering the angles subtended at the oxygen donors first, in the surveyed structures featuring a single contact between the participating atoms, the minimum angle of 82.4° (the Se…O separation is 3.38 Å) was found in 105 where the donor atom is a carbonyl-O to a selenium(II) centre, and the maximum angle of 160.2° (Se…O = 2.83 Å) is seen in 217 where a carbonyl-O atom is the donor and the acceptor is a selenium(II) atom flanked by nitrogen and sulphur atoms within a five-membered ring. The large range observed overall is also reflected in more specific contacts, for example S–O…Se contacts with a range of over 70°, i.e. from 87.7° in 2 to 159.7° in 78 with a spread of values within this range for the 10 structures having the oxygen and selenium atoms forming a single contact only. The above notwithstanding, the following represents an analysis of specific types of Se…O interactions.
For the sp3-hybridised hydroxyl-O atom, there are 11 examples and the range of values is somewhat reduced compared to the general survey, i.e. 94.1° in 13 to 126.2° in 15 if an outlier, i.e. 3 (144.7°), is ignored. While, to a first approximation, these values are in the generally expected range for a sp3-hybridised-O(lone-pair)…σ-hole(Se) interaction, the influence of hydrogen bonding interactions, for example, might also be expected to cause distortions, as in outlier 3. Conversely, if selenium-bound lone-pair of electrons is anticipated in a position diagonally opposite to a covalent bond involving selenium and carbon (or nitrogen or phosphorus), a close to linear angle at selenium would be anticipated. In the present series of structures involving hydroxyl-donors, these angles range from 148.6° for C–Se…O in 15, where the selenium(II) atom is part of five-membered ring to 175.0° for N–Se…O in 118, where the selenium(II) atoms is flanked by carbon and nitrogen donors within a five-membered ring.
A number of structures are constructed about a {…SeO}2 core and these present a robust set of SeO…Se and A–Se…O angles, where A = C, N or S. Only two examples of selenium(II) feature this core, i.e. 25 and 26, each resulting in a zero-dimensional aggregation, with pairs of SeO…Se and A–Se…O angles of 108.3 and 156.5°, and 111.2 and 156.1°, respectively. For the 15 selenium(IV) species, the SeO…Se angles range from 88.0°, for 43, to 121.4° for 44. In fact, these are outliers (see below) with the remaining angles lying between 93.2°, for 37, to 108.4° for 42. In terms of A–Se…O angles, these are consistently wider than for the selenium(II) species, lying between 163.6°, for 37 (A = C), to 177.5° for 39 (A = O). The two exceptional selenium(II) structures in this regard are 42, with C–Se…O = 144.9°, and 44 with C–Se…O = 138.9°. These, along with 43 mentioned above, feature concatenated, strained rings which readily account for the observed deviations. For the five zero-dimensional selenium(VI) structures featuring a {…SeO}2 core, the SeO…Se angles range from 105.3°, for 55, to 111.5° for 53, and the A–Se…O angles range from 167.5°, for 55 (A = O), to 174.1°, for 51 (A = C). The {…SeO}2 core also features in eight one-dimensional aggregation patterns and present narrow ranges for both SeO…Se, i.e. 94.6° (168) to 108.6° (165), and A–Se…O angles, i.e. 156.2° (165, A = O) to 176.8° (164, A = C). Finally, taking the sub-set of 29 zero-dimensional selenium(II) examples where the selenium atom forms one Se…O interaction only, there are two exceptional structures where A–Se…O lies between 127 and 128°, i.e. 8 and 22. Indeed, 21 examples have A–Se…O > 160°.
From the A–Se…O data included in Appendix A, it is a generalisation that the angle about the selenium atom, regardless of oxidation state, generally lies between 140 and 180°. This observation is consistent with expectation in terms of the σ-hole model to explain the nature of these interactions [45], [46], [47], [251]. It might be concluded that while to a first approximation, there is a general understanding of the mode of bonding leading to Se…O and related secondary bonding interactions, further investigations, such high-level crystallographic, including charge density studies and analysis [11], [252], [253], along with reliable computational chemistry studies [254], [255], [256] are required in order to gain a more complete picture of Se…O interactions. Also of interest would be the determination, experimental and theoretical, of the energies of stabilisation provided by specific Se…O contacts. Thus far, these are comparatively rare, e.g. 10–40 kJ/mol for molecules based on the EbselenTM (89 & 90) structure [11], i.e. as noted previously [54], an energy in the range observed for conventional hydrogen bonding interactions.
Finally, while the focus of the present review has been upon the identification of intermolecular Se…O interactions in crystals of molecular selenium compounds, the relevance of Se…O secondary bonding interactions in the biological context was alluded to in the Introduction. With the present covid-19 pandemic confronting the World, it is not surprising that EbselenTM and analogues have already been evaluated as potential inhibitors of the active site of the main protease (Mpro) of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) [257] in a classic case of drug repurposing [258]. On-going crystallographic, spectroscopic, e.g. 77Se NMR [259], and computational studies [260], [261] should also be alert for the potential influence of Se…O interactions in providing stability to poses adopted by selenium compounds in relevant active sites of target macromolecules.
Chalcogen bonding of the type Se…O contribute to the stability of crystals where they can form and are shown to sustain a full range of supramolecular aggregates: any complete analysis of the molecular packing of relevant compounds should include an analysis of these and other secondary bonding interactions. In the same way, any evaluations of the biological mechanisms of action, catalytic processes, rationalisation of chemical reactivity, etc. should be on the alert to the possible role of Se…O secondary bonding. Most notably by the prevalence of linear A–Se…O angles, for A = C, N, S and Se, the concept of the σ-hole provides a key impetus for the rationalisation of these interactions for selenium(II)- and selenium(IV)-containing compounds in the above contexts. However, further studies are required, both experimental and computational, for a more complete understanding of the formation of Se…O interactions and the energies of their association.
The author declares that there are no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Coord Chem Rev
PMC7808880,Prioritizing sexual and reproductive health in the face of competing health needs: where are we going?,"Reproductive and sexual health were first defined at the 1994 International Conference for Population and Development (ICPD) as “a state of complete physical, mental and social well-being and not merely the absence of disease or infirmity, in all matters relating to the reproductive system and to its functions and processes” [3]. Significant progress has been made since the concept of reproductive and sexual health was defined and promoted at the ICPD in Cairo [4]. The emphasis on “all matters relating to the reproductive system and to its functions and processes” was further reaffirmed at the landmark 1995 United Nations (UN) Fourth World Conference on Women in Beijing. The conference in Beijing marked a significant turning point for the global agenda for reproductive health with the upscaling of actions aimed at promoting sexual health, reproductive rights, gender equality and women’s empowerment [5]. The World Summit of the UN General Assembly in 2005 reflected these ideals in three of the eight 2001 UN Millennium Development Goals with a focus on reducing child and maternal mortality and rolling back HIV/AIDS [6]. In 2015, the Sustainable Development Goals (SDGs) laid out a 15-year roadmap that included goals and targets relating to access to SRH services and comprehensive sexuality education (CSE) [7]. This was on the backdrop of a growing realization that SRH intersects with the three central dimensions of sustainable development namely social, economic and environmental. CSE refers to a curriculum-based process of teaching young people about the cognitive, emotional, physical and social aspects of sexuality [8].
The SDG target 3.1 aims at reducing global maternal mortality rate (MMR) to less than 70 per 100,000 live births by 2030. Despite the tremendous gains of the commitment from the international community to adressing SRH issues, there are still significant challenges. For example, the global MMR was reduced by 38% between 2000 and 2017 with an average global decline of 2.9% per annum. However, the maternal deaths in 2017 was 295,000 [uncertainty interval 80%: 279 000–340 000] with approximately 86% of the global mortality occurring in sub-Saharan Africa and South Asia [9]. This reflects wide disparities as women from low-income countries are estimated to have a 130 times higher risk of maternal mortality when compared with women living in a high-income country [10].
Referring to SDG target 3.7 “by 2030, ensure universal access to sexual and reproductive health-care services, including for family planning, information and education, and the integration of reproductive health into national strategies and programmes”, some progress has been made. For example, the proportion of women who have been provided with modern family planning methods has risen from 74 to 76 percent (SDG indicator 3.7.1) between 2000 and 2019 [11]. However, a significant gap persists as the proportion of women with unmet need for family planning has remained at 10 per cent since 2000 till present [11]. The number of women of reproductive age who desire to avoid pregnancy but do not use any contraceptive method has risen to 190 million from 156 million in 2000 [11]. This unmet need is particularly high among the adolescents, migrants, refugees, women in the postpartum period and urban slum dwellers [12]. Many countries have made efforts to integrate SRH services into national strategies and programmes, but a lot of work is still required to translate these policy measures into tangible gains.
The control of sexually transmitted infections (STIs) contributes towards the attainment of several SDGs namely SDG 3.2 (By 2030, end preventable deaths of newborns and children under 5 years); SDG 3.3 (By 2030, end the epidemics of AIDS, combat other communicable diseases); SDG 3.7 (By 2030, ensure universal access to sexual and reproductive health care); SDG 3.8 (By 2030, achieve universal health coverage) [12]. Although some inroads have been made into controlling STIs, the global burden of STIs remains unacceptably high as more than one million STIs are estimated to be acquired everyday worldwide. The WHO estimated that four curable STIs accounted for 376 million new infections in 2016—gonorrhea (87 million); chlamydia (127 million); syphilis (6.3 million); and trichomoniasis (156 million) [12]. Genital infection with herpes simplex virus (HSV) is estimated to affect over 500 million people and over 290 million women are estimated to have human papillomavirus (HPV) infection, the primary cause of cervical cancer [13]. Chronic hepatitis B is estimated to affect 240 million people globally and both HPV and hepatitis B are vaccine preventable infections. Some of these STIs like HPV and syphilis increase the risk of HIV transmission and many ultimately result in untoward consequences such as foetal losses, congenital infections and infertility.
About 1.8 billion, a sixth of the world’s population, is comprised of 10 to 24 year olds who have vast SRH needs at one of life's most complex stages [14]. Every day, an estimated 39 000 child marriages occur [15]. Annually, a projected 21 million girls aged 15–19 years in low-income countries become pregnant (most of which are unintended) [16]. Approximately 777,000 births occur to girls under 15 years of age in low-income countries [17]. Complications during pregnancy and childbirth account for the most deaths among 15–19-year-old girls globally; this is linked to the higher risks of eclampsia and puerperal infections among adolescent mothers. Among this age group, an estimated 5.6 million abortions occur annually with over 70% occurring in unsafe conditions [18]. The unmet need for family planning is greatest among adolescents who are also at high risk for contracting HIV and are more prone to sexual violence [19].
The WHO considers women’s cancer a major issue. Both breast and cervical cancer are responsible for more deaths in women than any other cancer in low-income countries. Early cancer detection and screening tests are still unavailable in most low-income settings. In 2018, an estimated 2.09 million deaths occurred from breast cancer and there were an estimated 570,000 new cases of cervical cancer in the same year with a resultant 311,000 deaths worldwide (90% of these occurred in low-middle income countries) [20]. Primary prevention of cervical cancer can be achieved with the aid of vaccination against HPV 16 and 18. The HPV vaccines have been introduced in 106 countries, but the global coverage is just 15% with a large population lacking access to this vaccine [21].
Unmet SRH needs pose a unique and monumental burden on society at large. Access to SRH services is vital to achieving SDGs goals. Across many countries, SRH services, which encompass a range of preventive, promotive and curative services across the life-course, are critical components of Primary Health Care (PHC). SRH services address broad and cross-cutting health needs which touch all aspects of health, at all ages, for all genders. SRH services also serve as entry points to the health system. For example, women's visits for SRH needs provide opportunities for screening for malaria, HIV or cervical cancer, and seeking care for gender-based violence (GBV) and sexual assault [22]. Despite the strong evidence for SRH services being a “best buy”, these services remain largely neglected and excluded from the priorities of many countries. SRH services have not always been on the agenda when global, and national-level discussions and decisions related to UHC are made, on financing health care, allocating resources and setting priorities [23]. A lack of structured approaches and rational allocation of resources coupled with a lack political commitment has militated against the achievement of many SRH goals. Discrimination on the basis of sex has led to many health disadvantages for women [24]. Taboos around sex and sexuality and the stigma attached to these issues have contributed to making SRH services a low priority in Health Benefits Packages (HBPs).
The challenges of SRH services have been exacerbated by the recent COVID-19 pandemic that has triggered the reallocation of resources and attention away from SRH with untoward consequences. The disproportionate impact on the health, wellbeing, and economic stability of women, girls, and vulnerable populations has become more obvious with the COVID-19 pandemic. SRH services are being deemed non-essential and providers reassigned to frontline roles to control COVID-19 [25]. For example, a recent survey conducted in Tunisia revealed that up to 50% of the SRH clinics in the country had been either reduced or suspended since COVID-19 emerged [26]. Global shortages of contraception are anticipated [27]. Social isolation measures aimed at slowing the spread of COVID-19 and reducing the risk to medical staff is also limiting the engagement of clients with SRH services.
The systemic racism, discrimination, and stigma that has characterized the COVID-19 pandemic is likely to further impact access to SRH care for women and vulnerable groups [28]. In the USA, elective surgeries are being deferred to limit the infectious exposure and conserve medical equipment [29, 30]. Funding and technical assistance by international organizations to the public sector for SRH is also taking a hit due to COVID-19. An upsurge of sexual GBV and unintended pregnancies have been recorded in Africa [31]. Lockdown measures and reduced access to contraceptives have contributed to the upsurge in unintended pregnancies in Africa. Limited access to HIV medications for women and pre-exposure prophylaxis (PrEP) for female sex workers has been reported [32]. In addition, interrupted access to education and skills acquisition for adolescent girls and young women (AGYW) remain a major challenge [33].
Inadequate integration of comprehensive SRH services in HBPs results in the burden of payment falling on service users that are already poor. Funding for SRH is mostly through OOP payments, with only a small proportion funded by domestic public funding. There is an urgent need to reprioritize SRH and make the services more resilient to shocks that emanate from disease outbreaks and competing health conditions. This cannot be achieved without securing political commitment from national stakeholders [34]. Promoting universal access to SRH services and incorporating SRH into existing national strategies and programmes will create integrated and comprehensive care packages. A substantial increase in SRH financing and development of a competent SRH workforce is required. Key actions are recommended:Ensuring global actors meet current funding commitments for SRH services;Increasing domestic public funding for SRH services;Improving efficiency and equity of existing resources;Strengthening integration of SRH in HBPs; andEnsuring an effective delivery of SRH services through accountability measures and community participation in the provision of these services.",Reprod Health
PMC7529596,"Fluorescent probes based on nucleophilic aromatic substitution reactions for reactive sulfur and selenium species: Recent progress, applications, and design strategies","Reactive sulfur species (RSS) and reactive selenium species (RSeS) are important substances in the redox systems of organisms [1], [2]. The former include glutathione (GSH), cysteine (Cys), homocysteine (Hcy), hydrogen sulfide (H2S), thiophenol (PhSH), polysulfide (H2Sn), sulfite (SO3
2−), and bisulfite (HSO3
−) [3], [4], [5], [6]. The latter include selenocysteine (Sec), hydrogen selenide (H2Se), selenite (SeO3
2−), and selenate (SeO4
2−) [7], [8]. Proteins containing cysteine or selenocysteine bear thiol or selenol groups, which affect their folding and function [1], [9]. The functional sites of some proteins are composed of selenol or thiol groups, such as thioredoxin oxidoreductase (TrxR), selenoprotein P (Seleno P), and glutathione S transferase (GST) [9], [10]. These proteins are not only the important part of the redox system of the body, but also facilitate the transport of some important elements, such as sulfur, selenium, and mercury [11], [12], [13]. Both sulfur in RSS and selenium in RSeS can adopt a variety of oxidation states ranging from −2 to +4, endowing both classes of species with variable reactivity [10], [14], [15]. Therefore, RSS and RSeS mediate many redox reactions and physiological processes, offering disease diagnosis and treatment options [16], [17]. In recent years, the biology of RSS and RSeS has become a major focus of research.
RSS and RSeS are widespread in cells and organisms, and are the first line of defense of the body’s antioxidant barrier [15], [17]. Small-molecule thiols and selenols with redox activity are key factors for regulating cell function and body balance by maintaining a steady redox state of the microenvironment and buffering significant redox state changes [2]. Cells have a perfect regulatory system to maintain their redox balance. Abnormal levels of RSS and RSeS result in poor health, reduced immunity, and other factors that may cause various diseases, such as neurodegenerative diseases, cardiovascular diseases, diabetes, muscle diseases, and AIDS in HIV patients [18], [19]. PhSH belongs to a class of highly toxic and highly polluting compounds. According to reports, exposure to PhSH in liquid or vapor form can cause a series of serious health problems, including central nervous system damage, impaired breathing, muscle weakness, hind limb paralysis, coma, and even death. It appears that timely suppression and detection of PhSH are very important [3], [4].
Aromatic electrophiles are a class of thiol/selenol inhibitors, mainly bearing strongly electron-withdrawing groups (such as nitro, trifluoromethyl, methoxy, etc.) on the benzene ring other than halogens (F, Cl, Br), making it easier for halogens to attack thiol/selenol, forming the corresponding HX (X = F, Cl, Br). At the same time, the Se/S is arylated through a covalent bond to block the thiol/selenol, affecting the function and structure of the protein. 2,4-Dinitrochlorobenzene (CDNB), p-nitrochlorobenzene (CNB), p-nitrobromobenzene, p-methoxychlorobenzene, and o-trifluoromethylfluorobenzene are small molecules of this type. Since phenyl itself also has an electron-withdrawing effect, fluorobenzene, chlorobenzene, and so on, can also be used as electrophiles [20], [21], [22].
Aromatic small-molecule electrophiles can form a covalent bond with Cys or Sec at the active site of an enzyme to irreversibly inhibit enzyme activity [23]. CDNB and CNB are often used to determine substrate levels of GST [24], [25]. This effect of CDNB has also been used in cell culture experiments and animal model experiments. For example, as a depleting agent of GSH, CDNB can be used to monitor the formation of glutathione S-conjugate in the liver and determine its activity. The high proliferation and metabolism of cancer cells makes them produce more reactive oxygen species (ROS) than normal cells. This leads to an imbalance of the redox system in the cell, which in turn leads to oxidative stress [26], [27], [28]. In order to combat the harmful effects of ROS and oxidative stress, the content of Trx in the redox system becomes raised [29]. CDNB has the potential to act as an immunostimulant in the treatment of various diseases [30].
With reduced nicotinamide adenine dinucleotide phosphate (NADPH), CDNB can be used as a specific irreversible inhibitor of thioredoxin reductase (TrxR) and improve the activity of NADPH oxidase in the modified enzyme [31]. Without NADPH, CDNB has no effect on TrxR activity, which indicates that CDNB only inhibits the enzyme after blocking the active sites (thiol/selenol) of the reduced TrxR [32], [33], [34]. The active site of reduced TrxR is covalently modified by CDNB to produce the corresponding S-aryl derivative, which irreversibly inhibits the activity of the enzyme [35]. TrxR is an important part of the cell redox system [36]. CDNB can induce apoptosis through irreversible inhibition of TrxR activity. Therefore, TrxR is also an attractive target in the design of anticancer drugs [37], [38], [39], [40], [41].
The mechanism whereby the aromatic electrophilic compound inactivates the enzyme involves reaction of the active site (thiol/selenol) with the electrophilic inhibitor to form S-C and Se-C bonds [42], [43]. Blocking of TrxR by p-nitrochlorobenzene and o-nitrochlorobenzene may have a positive effect on the removal of ROS. TrxR-SeH blocked by p-nitrobenzenesulfonyl chloride or o-nitrobenzenesulfonyl chloride will be oxidized by ROS and release the corresponding selenic acid, thus participating in the removal of ROS from the body with the help of GSH [35], [36]. Based on the above-mentioned characteristics of aromatic electrophilic compounds, they may also be used as detection groups of fluorescent probes based on SNAr reaction, applicable for the detection of RSS and RSeS in vitro, in cells, and in animals.
Fluorimetry is a simple, inexpensive, and fast method for detecting analytes. The rise of the rapid detection field in recent years has provided broad scope for the development of fluorimetry [44], [45], [46], [47], [48]. In 2014, China formulated the “Proposal for Management of On-Site Rapid Testing (POCT) in Medical Institutions (In Hospitals)”, and in 2015 the rapid testing method was written into the Food Safety Law of the People’s Republic of China and rapid testing was further recognized [49], [50]. In early 2020, large-scale outbreaks of a new coronavirus (2019-nCoV) led to an urgent need for rapid detection methods. Indeed, this became one of the most widely reported and urgent needs for rapid detection [51].
Fluorescent probes have been widely studied and applied in many fields. In particular, their capacity to be used in temporal and spatial sampling and in vivo imaging applications makes them suitable for monitoring physiological and pathological processes, and they have continued to attract ever more attention in biomedical research [52], [53], [54], [55], [56]. By modifying the fluorescent matrix, a fluorescent probe can provide dynamic information about the location and quantity of an analyte in different matrices, so that the analyte can be easily studied [57], [58], [59]. Fluorescent probes can be used to remotely measure analytes and can be used in environments and samples that are difficult to access directly to avoid possible damage when the analyte is taken out of its natural medium. Fluorescent probes have become important tools in chemical and biochemical research due to their non-invasiveness, high sensitivity, high selectivity, operability, low cost, rapid response, high time resolution, and appropriate beneficial characteristics for easy signal detection [60], [61], [62], [63], [64], [65].
RSS- and RSeS-specific fluorescent probes have long been used for protein labeling [37], [66], [67], [68]. For the purpose of drug simulation and structural screening, researchers have synthesized various RSS-specific fluorescent probes [69]. At the beginning of the 21st century, researchers synthesized various types of highly selective RSeS-specific fluorescent probes capable of operating under physiological conditions by simulating the structure of RSS probes and optimizing the detection environment. Fluorescent probes based on SNAr reaction for RSS and RSeS have been hot spots in this field [7], [8], [66].
Because RSS and RSeS are prone to deprotonation, and their amounts in vivo are very small, the development of RSS- and RSeS-specific fluorescent probes for intracellular or in vivo targeting is very challenging [7], [8]. Observing the endogenous or exogenous RSS and RSeS in cells or animals is an important application of fluorescent probes [67], [70], [71], [72]. RSS- and RSeS-specific fluorescent probes should be able to provide insight into changes in specific RSS and RSeS in healthy and diseased cells and biological systems [73], [74], [75]. For the differentiation of different types of proteins containing Cys or Sec, as well as the detection of RSS and RSeS in blood, tissue, agricultural products, and food, the effect of thiols on food flavor is worth exploring [76], [77], [78], [79]. In this review, we first briefly summarize the latest developments in the field of fluorescent probes for RSS and RSeS based on SNAr reactions. Thereafter, based on the integration of different reports, we propose methods for the design and synthesis of RSS- and RSeS-selective probes based on SNAr reactions, current challenges, and future research directions, considering the selection of active sites, the effect of substituents on the benzene ring, and the introduction of other functional groups.
Benzenesulfonamide and benzenesulfonate are the main reactive groups of benzenesulfonic acid [20], [112], [113], [114], [115], [116], [117], [118], [119], [120]. RSS and RSeS can break the benzenesulfonamide or benzenesulfonate bond and become bound to the aromatic part of the detection group with the concomitant release of SO2. Due to the extinction of the quenching group, the fluorescence is enhanced, thus providing the test signal [121], [122], [123], [124], [125], [126], [127], [128]. Compared with the benzenesulfonate bond, the p-π conjugation effect of the benzenesulfonamide bond makes it stronger and more difficult to break, so it is more suitable to detect RSS with lower pK
a values in a physiological environment, such as H2S, PhSH, and even Sec [129], [130], [131], [132], [133], [134].
Hatsuo et al. have long been engaged in research on fluorescent probes for thiols. They appended 2,4-dinitrobenzenesulfonyl to rhodamine, and thereby synthesized two fluorescent probes (Fig. 1
, panels 1a and 1b) that could be used for thiol detection at physiological pH [135], [136]. The reaction rates of probes 1a and 1b with GSH were 1.7 × 102 and 1.4 × 102 M−1 s−1, respectively, and the detection limits for GSH and Cys were both lower than 2.0 pM, making these probes suitable as substitutes for the Ellman reagent in the quantitative determination of thiols. In further studies, Hatsuo et al. found that probe 1b, which was originally designed to detect thiols, reacted more quickly with selenols in phosphate buffer at pH 5.8, with an emission intensity ratio (ISeH/ISH) exceeding 200 [136]. The rate of reaction of this probe with Sec was 7.4 × 102 M−1 s−1 and the detection limit was 0.8 pM. However, this measurement method is incompatible with biological environments.
Although many fluorescent probes have been used to detect Cys, most of them have been used to image living cells, and detection methods based on fluorescent probes for Cys in foods need further development. Yang et al. appended a 2,4-dinitrobenzenesulfonyl moiety to fluorescein and applied the synthetic probe (Fig. 1, panel 2) to the detection of Cys in milk and water samples [137]. The probe proved to be highly selective and could be used to detect Cys concentrations in the range 0–400 μM. Its excitation and emission wavelengths of λex = 337 nm and λem = 520 nm were not affected in the range pH 6–9, the detection limit was 6.5 μM, the color of the solution changed from light-yellow to yellow-green, and the detection of Cys using this probe could be recognized by the naked eye.
(4′-Hydroxy-2,2′:6′,2″-terpyridine-6,6″-diyl)-bis(methylenenitrilo)tetrakis(acetic acid) (HTTA) is a functional ligand that can form highly stable complexes with both Eu3+ and Tb3+ ions. Yuan et al. found that the terbium(III) complex of this ligand (HTTA-Tb3+) has a higher fluorescence quantum yield under physiological conditions. However, its europium(III) complex (HTTA-Eu3+) has only weak fluorescence due to the negative charge on oxygen (terpyridine-O−) after deprotonation of the hydroxyl group on terpyridine. By introducing a 2,4-dinitrobenzenesulfonyl (DNBS) group on the HTTA structure, a ratio-based fluorescent probe (Fig. 1, panel 3) for biothiols was synthesized [138]. Due to the occurrence of photoinduced electron transfer (PET), NSTTA-Eu3+ and NSTTA-Tb3+ showed weak fluorescence. However, when reacted with a thiol, due to departure of the DNBS group, the PET function was lost, making the fluorescence of the terbium(III) complex significantly enhanced, whereas the fluorescence intensity of the europium(III) complex did not change significantly. Therefore, the fluorescence intensity ratio of the terbium(III) complex to the europium(III) complex (I540/I610) could be used as a fluorescence marker to perform quantitative detection of thiols. Indeed, it has been used for ratiometric imaging of thiols in several cell samples. NSTTA-Tb3+/Eu3+ was used to detect thiols in 5 min with a detection limit of 7 μM.
Xu et al. have been studying polymer micelles for a long time, using ring-opening polymerization (ROP) of cyclic carbonates to synthesize amphiphilic polymers. Through modification with 2,4-dinitrobenzenesulfonyl moieties, they synthesized a fluorescent derivative of the drug doxorubicin (DOX) and polycarbonate micelles (PMPC-DNS) capable of responding to Sec (Fig. 2
, panel 4) [139]. The amphiphilic copolymer could self-assemble to give a hydrophobic core with a hydrophilic shell at the periphery. It is worth noting that the hydrophobic termini of the micelle are the recognition sites for Sec. In the presence of Sec, the 2,4-dinitrobenzenesulfonyl recognition site is activated, rendering it hydrophilic and destabilizing the micelle, thereby releasing DOX. In this way, Sec can be detected in cells and tissue. PMPC-DNS formed spherical micelles with an average diameter of 118 nm in aqueous solution. The critical micelle concentration (CMC) was determined as 0.01245 mg mL−1. The drug loading efficiency (DLE) and drug loading content (DLC) of the micelle for DOX were 6.5% and 7.63%, respectively. The PMPC-DNS probe was successfully applied for the imaging of endogenous Sec in HeLa cells and live cervical tumors.
Aggregation-induced emission dots (AIED) have various advantages, such as high fluorescence, large Stokes shift, excellent light stability, and good biocompatibility. Gao et al. developed a new type of nanoprobe based on AIED for selective monitoring of endogenous H2S levels in lysosomes (Fig. 3
, panel 5) [140]. The prepared AIED showed good water dispersibility, optical parameters of λex = 435 nm and λem = 585 nm, a detection limit of 43.8 nM, selectivity for H2S superior to that of other thiols, and excellent long-term stability (>16 weeks). In addition, confocal fluorescence imaging experiments confirmed that AIED mainly resided in lysosomes, permitting specific imaging of the levels of exogenous and endogenous H2S in living cells.
Based on the simple synthesis of tetrastyrene (TPE), easy modification, and the special properties of aggregation-induced emission (AIE), Li et al. designed and synthesized a tetrastyrene-based fluorescent probe TPENNO2 for the specific detection of Cys (Fig. 1, panel 6) [141]. The kinetic rates of reactions of this probe with Cys, Hcy, and GSH, respectively, were determined. It was found that the changes in their fluorescence responses with time were different. Thus, Cys, Hcy, and GSH could be detected sequentially according to different time sequences. The response time of this probe to cysteine was 30 min, the detection range was 0–500 μM, with λex = 319 nm and λem = 490 nm, and the limit of detection was 0.18 μM. In addition, TPENNO2 could also be used for the detection of thiols in live cells.
Fang et al. constructed a small library of selenol probes based on the mechanism of SNAr. By adjusting the reactivity of the probes, a fluorescent probe (Sel-green) with high selectivity for selenol under physiological conditions was identified, and the relationship between the probe structure and activity was established (Fig. 1, panel 7) [129]. 2,4-Dinitrophenyl is a strongly electron-withdrawing group used for the recognition of thiol or selenol. Moreover, 2,4-dinitrophenyl ether and 2,4-dinitrobenzenesulfonamide have superior abilities to distinguish between selenol and thiol than the 2,4-dinitrobenzenesulfonate group. Sel-green has been used to quantify the content of Sec in TxR and to detect Sec in HepG2 cells. When Sel-green was used to stain cells to study the cytotoxicity of selenium compounds, it was found that highly toxic compounds also showed a positive signal, indicating that their toxicity depends on their ability to metabolize into selenol in cells. The response time of the probe to Sec was 3 min, the detection range of selenium compounds under physiological conditions was 0–100 μM, and the detection limit was 62 nM. Sel-green was the first probe capable of selectively recognizing Sec under physiological conditions.
Wang et al. combined an NBD fluorophore with a 2,4-dinitrobenzenesulfonyl group via a secondary amine group to synthesize a probe (Fig. 1, panel 8) for specifically detecting PhSH [142]. Since the pK
a of PhSH is about 6.5, whereas that of an aliphatic thiol is about 8.5, in a physiological environment, the dissociation of high levels of PhSH will generate the corresponding thiolate, which can effectively react with benzenesulfonamide. Aliphatic thiols are maintained in a neutral form with lower reactivity, such that sulfonamide cleavage is very slow. The probe showed λex = 465 nm and λem = 555 nm, and the detection limit for PhSH was 0.2 × 10−5
 M.
Yang et al. have long studied the pK
a transformation mechanism of the Schiff-base structure of hemicyanine, and developed a long-wavelength fluorescent probe (MC-Sec) for the detection of selenol by introducing a strongly electron-withdrawing 2,4-dinitrobenzenesulfonyl group (Fig. 1, panel 9) [143]. The pK
a value of MC-Sec is 6.40. At physiological pH, it mainly exists in the form of its Schiff base and shows no fluorescence. When Sec is added to its solution, Sec and the probe MC-Sec undergo a nucleophilic substitution reaction, releasing the fluorophore with a higher pK
a value (pK
a = 9.0). Therefore, under physiological conditions, the fluorophore mainly exists in the form of a protonated Schiff base, which causes the absorption wavelength of the detection system to be red-shifted and the fluorescence intensity to increase significantly. The probe showed high selectivity and sensitivity for the detection of selenol, λex = 550 nm, λem = 593 nm, the detection range was 0–70 μM, and the limit of detection was 68 nM. The probe could be applied in serum and live cells.
Chen et al. synthesized a fluorescent probe, Mito-di NO2 (Fig. 1, panel 10), for detecting selenol, by connecting a 2,4-dinitrobenzenesulfonamide responsive group with a lipophilic triphenylphosphine cationic mitochondrial targeting group to a near-infrared (NIR) heptamethine cyanine fluorophore [144]. The probe showed a rapid response to selenol within 4 min. Since the introduction of a methyl group makes the amide bond form a tertiary amine, a certain degree of steric hindrance can be generated, but it is not affected by some macromolecular RSeS during detection. At the same time, it is more difficult to cleave than the above sulfonamide bond, so it should be free from the interference of RSS, ROS, RNS, metal cations, and anions. This probe could be used to target mitochondria and quantify the selenol concentrations in BRL 3A, RH-35, HL-7702, HepG2, and SMMC-7721 cell lines. It has been successfully used to detect changes in the concentration of selenium in a model of mitochondrial-related acute cell inflammation induced by CS2, and to evaluate the protective effect of selenium on acute/chronic hepatitis induced by CS2.
Carbon dots (CDs) have received much attention due to their unique optical properties, high photostability, biocompatibility, and low toxicity [145]. Li et al. used m-aminophenol as a carbon source to synthesize and screen CDs with yellow-green fluorescence, and covalently coupled 2,4-dinitrobenzenesulfonyl to the surface of carbon quantum dots through a sulfonamide bond. A CD-based fluorescent probe for specifically detecting Sec was thereby obtained (Fig. 4
, panel 11) [146]. The probe showed excellent sensitivity and specificity for Sec. Preliminary studies showed CD-DNS to be of low toxicity, to have optical parameters of λex = 450 nm and λem = 514 nm at pH 4.94–9.18, and to show excellent sensitivity and specificity for Sec with a limit of detection of 23 nM. This makes them suitable for fluorescence imaging of exogenous and endogenous selenol in living cells.
With phenyl-O ether as the reaction site of the probe, selenol or thiol will break the phenyl-O ether bond, and thereby become bound to the aromatic moiety of the detection group. The probe is displaced by the quenching group, and the enhanced fluorescence provides the detection signal [156], [157], [158], [159], [160]. Response times of phenyl-O ether groups to the detection group of RSS and RSeS are longer, the selectivity is not high, but the fluorescence is strong [161]. However, introducing electron-withdrawing groups at other positions on the benzene ring of the detection group can shorten response times and quench the fluorescence of the fluorophore [162], [163], [164], [165], [166]. Therefore, for RSS and RSeS with low pK
a values, nitrophenyl-O ethers are good choices [167], [168], [169], [170].
Feng et al. have studied the benzopyranonitrile moiety. A fluorescent probe (Fig. 5
, panel 12) for detecting Sec was synthesized by introducing 2,4-dinitrophenyl ether into a benzopyranonitrile fluorophore [171]. This probe was used to detect Sec in bovine serum samples and exogenous and endogenous Sec in live cells. The probe (λex = 560 nm, λem = 706 nm) showed good linearity in the Sec concentration range 0.2–80 mM, with a detection limit of 62 nM. Although the detection limit of this probe is slightly higher, the larger Stokes displacement is more conducive to naked eye observation.
Graphene quantum dots (GQDs) are endowed with excellent solubility, biocompatibility, highly adjustable photoluminescence (PL), excellent light stability, good cell permeability, easy functionalization, and low cost. They are widely used in the field of fluorescent probes. The photoluminescence properties of GQDs are highly sensitive to light-induced electron-transfer phenomena due to their extremely small size and related quantum confinement effects. Chen et al., based on the formation of phenyl-O ethers with 2,4-dinitrophenyl and tyrosine to functionalize GQDs, developed H2S-specific fluorescent probes (Fig. 5, panel 13) and used them to respond to the real-time dynamic changes of intracellular H2S levels in response to stimulation imaging [172]. At physiological pH, the detection limit was as low as 0.05 nM, and the maximum linear response was as high as 30 nM, with optical parameters of λex = 480 nm and λem = 534 nm.
Wu et al. have long studied thiol probes, introduced 2,4-dinitrophenyl-O ether groups into external cyanine NIR dyes, and synthesized H2S-specific dual-mode fluorescent probes (Fig. 5, panel 14). These could be used to image endogenous H2S in tumor-bearing HCT-116 mice [173]. More importantly, they could also be used to monitor metformin-induced liver injury in mice by detecting liver H2S. With the help of multispectral optoacoustic tomography (MSOT), the probe could be successfully used to distinguish, accurately locate, and assess the volume of liver damage. In addition, the probe NR-NO2 showed quite good response specificity, sensitivity to H2S, and good biosecurity; with optical parameters of λex = 680 nm and λem = 725 nm, its limit of detection was 40 nM.
Based on an assembly of tetrastyrene, 3-hydroxyflavone, and 2,4-dinitrophenyl-O ether, Wu et al. also designed and synthesized an H2S-specific fluorescent probe with aggregation-induced emission (AIE) and excited-state intramolecular proton transfer (ESIPT). A cationic liposome was used to encapsulate the probe TPE-1, endowing it with enhanced biocompatibility, water solubility, and cell uptake capacity (Fig. 6
, panel 15) [174]. The probe had a diameter of 72.31 nm, a polydispersity index (PDI) of 0.218, a zeta potential of 56.9 mV, optical parameters of λex = 452 nm and λem = 550 nm, and a low detection limit of 55 nM. At physiological pH, the cationic liposome nanoprobe showed good stability and detection capability, reaching equilibrium within about 5 min. The detection mechanism shows that cleavage of the phenyl ether bond occurs due to the nucleophilic nature of H2S, the hydroxyl group is deprotected, intramolecular proton transfer is restored, and an intramolecular hydrogen bond is formed. As a result, internal rotation of the tetrastyrene structure is restricted, and the aggregate is fluorescent. The probe permitted fluorescence imaging of endogenous H2S in cells and of exogenous H2S in zebrafish.
For probes that use phenyl-S ether as the reaction site, since sulfur already occupies the binding site on the detection group, when the analyte breaks the phenyl-S ether bond, both the analyte and the fluorophore are covalently bonded with sulfur; due to the concomitant loss of the quenching group, the fluorescence of the probe is changed, providing the detection signal [175], [176], [177]. The appending of electron-withdrawing groups on the benzene ring of the detection group can shorten response times. Compared with the phenyl-O ether group, the phenyl-S ether group responds to RSS more quickly [100], [154]. At the same time, because the analyte forms a covalent bond with the fluorophore rather than the detection group, the steric effect and covalent bond can be combined to distinguish glutathione from Cys/Hcy [100], [101]. However, when the phenyl-S bond is strong, it is not only not less likely to react with RSS, but also less likely to be oxidized by ROS. Fortunately, because the valence state of S increases after oxidation, it is easily reduced by S with a lower valence state, so it readily reacts with RSS with lower pK
a values [178], [179].
Zhang et al. have studied BODIPY fluorescent probes for a long time. By introducing a phenyl-S ether group at the 8-position of BODIPY, they developed a selective fluorescent probe for detecting GSH (Fig. 7
, panel 16) [180]. The detection of two emission channels allowed the distinction of GSH from Cys and Hcy, with only the latter two inducing intramolecular ammonolysis of thioether. The probe could be used to detect GSH within 30 min, with λex = 480 nm and λem = 535 nm, and the detection limit was 10 nM. Concomitantly, the detection of Cys and Hcy could also be achieved within 6 min, with λex = 390 nm and λem = 462 nm. Colorimetric or fluorescence observation can be conveniently applied to measure the content of GSH in human plasma.
Chen et al. designed a fluorescent probe for detecting GSH based on a cyanine dye as the fluorophore and 3,5-bis(trifluoromethyl)thiophenol as the detection group (Fig. 7, panel 17) [181]. The detection limit of the probe for GSH was 3.3 × 10−7
 M, with λex = 780 nm and λem = 805 nm. After reacting with Cys or Hcy, the emission wavelength of the probe was blue-shifted, and the fluorescence intensity was weakened (λem = 740 nm, λex = 650 nm). The probe was also used for imaging GSH in living cells and for fluorescence detection of GSH in SCC7 tumor-bearing mice.
Yang et al. introduced a triethylene glycol group at the 3-position of the BODIPY framework through a click reaction to improve its water solubility. At the 5-position, p-nitrothiophenol or p-nitrophenol was introduced to synthesize fluorescent probes for Cys (Fig. 7, panels 18a and 18b) [151]. The amino group of Cys can undergo rapid intramolecular substitution through a five-membered-ring transition state to generate amino BODIPY, causing blue shifts in the absorption and emission spectra. The six-membered-ring transition state of Hcy is similar, but the reaction rate is slower, and it exists in the form of thiol-BODIPY, reacting with GSH in a certain time. The significant difference in the photophysical forms of BODIPY substituted by amino and mercapto can be used to distinguish Cys from Hcy/GSH. Because the phenyl-S ether bond is less stable than the 2,4-dinitrophenyl ether bond, p-nitrothiophenol is more easily cleaved than p-nitrophenol. Consequently, probe 18a shows faster reaction rates than probe 18b, and the former is more suitable for detecting thiols. The detection range of 18a is 0–100 μM, with λex = 528 nm and λem = 588 nm, and the detection limit is as low as 2.12 × 10−7 M.
Zhao et al. used 1,3,5,7-tetraaryl-substituted BODIPY compounds with large steric hindrance and long absorption wavelength as fluorophores and 4-methoxyphenyl-S ether as a detection group to assemble two fluorescent probes (Fig. 7, panels 19a and 19b) for the detection of Cys and Hcy [182]. The detection of Cys and Hcy by probe 19a was complete within 30 min, with λex = 470 nm and λem = 581 nm. The detection range was 0–15 μM, and the limits of detection were 44 nM for Cys and 63 nM for Hcy. The detection of Cys by probe 19b was complete within 90 min, with λex = 525 nm and λem = 608 nm. The detection range for Cys was 0–25 μM, and the limit of detection was 286 nM. The slower rate for 19b was attributed to the increased steric congestion of the 1,7-diphenyl moieties in the conformationally restricted BODIPY dye. Both of these fluorescent probes were successfully applied for the selective imaging of Cys and Hcy in living cells.
Yin et al. combined the heptocyanine fluorophore with p-aminothiophenol through a thioether bond to synthesize a fluorescent probe (Fig. 7, panel 20) for detecting GSH [183]. The probe (λex = 710 nm, λem = 818 nm) showed a detection range of 0–30 μ,M its reaction reached equilibrium within 40 min, and the limit of detection was 20 nM. The probe showed good water solubility, biocompatibility, and cell permeability, coupled with low cytotoxicity, making it an effective biomarker for monitoring GSH levels in living cells.
In 2008, Burgess et al. reported a series of amine- and thiol-regulated pyrrole dyes [184]. Interestingly, their aminopyridine red dye had λex = 460 nm and λem = 540 nm, whereas their mercaptopyridine red dye had significantly red-shifted absorption and emission wavelengths (λex = 598 nm, λem = 619 nm). Inspired by this report, Guo et al. connected 4-methoxythiophenol with pyrochrome to design a probe (Fig. 7, panel 21) for detecting thiols [185]. This probe could be deployed in phosphate-buffered saline (PBS), and the simultaneous monitoring of two near-infrared (NIR) channels allowed the selective detection of Cys/Hcy and GSH. This was accompanied by fast reaction kinetics and an obvious fluorescence turn-on response. The reaction time of this probe with Cys (Hcy) was 15 min, with λex = 455 nm and λem = 546 nm, and the detection range was 0–60 μM. The reaction time with GSH was 2 min, with λex = 580 nm and λem = 622 nm, and the detection range was 0–1.0 mM. Because intracellular concentrations of Cys and GSH are in the ranges 30–200 μM and 1–10 mM, respectively, the probe is sufficiently sensitive to image biothiols in cells [186], [187].
In a follow-up study, Guo et al. introduced Si into the rhodamine fluorophore and designed a cysteine-specific fluorescent probe with 4-methoxythiophenol as the detection group (Fig. 7, panel 22) [188]. The detection range of this probe for Cys was 0–2 μM, with λex = 488 nm and λem = 620 nm, and the limit of detection was 2.6 nM. The probe initially reacted non-selectively with Cys and GSH to form a fluorescent Cys adduct and a non-fluorescent GSH adduct. However, the GSH in the latter could be further replaced by Cys to produce more of the former, overcoming the problem of probe consumption by GSH. Therefore, the presence of GSH is not problematic for the specific detection of Cys. Importantly, the deployment of this probe not only proved that inhibiting cysteine/glutamate antiporter (system xc−) is more effective in sensitizing cancer cells to chemotherapy than inhibiting glutamate-cysteine ligase (GCL), but also revealed a possible self-protection mechanism of cancer cells. When extracellular Cys is blocked, cancer cells can still survive by exporting intracellular GSH/GSSG as a source of Cys to provide intracellular Cys to resist harmful oxidative stress. The probe also confirmed that disrupting self-protection is a more effective strategy for sensitizing cancer cells to chemotherapy.
A near-infrared zone two (NIR-II) fluorescent probe can realize high-resolution biological imaging with deep tissue penetration. However, due to a lack of target specificity, existing NIR-II materials usually have a poor signal-to-noise ratio. Zhao et al. encapsulated an H2S-responsive fluorescent probe in a hydrophobic core–shell silica nanocomposite so as to assemble an activatable NIR-II nanoprobe to visualize colorectal cancer cells (Fig. 8
, panel 23) [189]. The detection range of this nanoprobe for H2S was 0–10 μM, and the limit of detection was 37 nM, with λex = 520 nm and λem = 780 nm. Although the maximum emission wavelength was 900 nm, the emission spectrum was quite broad and extended to the NIR region II (1000–1300 nm). The probe reaction reached equilibrium within 5 min, and could be used to monitor H2S and related biological processes in real time. This nanoprobe showed a specific and proportional fluorescence response to H2S, and could be used to selectively identify H2S-rich colon cancer cells and to distinguish live cell types based on their differences in H2S contents in a two-color imaging mode. More importantly, H2S specifically activates fluorescence in the NIR-II region, and the probe can detect and distinguish cancer in vivo by taking full advantage of the depth and spatial resolution of NIR-II imaging.
For probes that use phenyl-Se ether as the reaction site, when the analyte breaks the phenyl-Se ether bond, since selenium already occupies the binding site on the detection group, the analyte is forced to form a covalent bond with the fluorophore [103], [104]. At the same time, the fluorescence of the probe is enhanced due to the loss of the quenching group, and this provides the detection signal. The response of the phenyl-Se ether group to RSS is faster than those of phenyl-O ether and phenyl-S ether. Because the analyte forms a covalent bond with the fluorophore instead of the detection group, steric hindrance and different combination modes may be exploited to distinguish GSH, Cys/Hcy, H2S, and so on. Phenyl-Se ether can also be oxidized by ROS, and the latter may be detected on the basis of the resulting fluorescence changes. Conversely, RSS will reduce selenium and restore fluorescence [190], [191].
Churchill et al. inserted a phenyl-Se ether moiety at the 4-position of coumarin to synthesize a fluorescent probe capable of specifically detecting GSH (Fig. 7, panel 24) [103]. This functional group can quench the fluorescence of coumarin by PET and can also act as a leaving group. The aldehyde group at the 3-position also plays a dual role: it enhances the electrophilicity of the Michael acceptor at the 4-position, while also inducing the cyclization reaction of the thiol and primary amine groups of Cys/Hcy. When the probe reacts with GSH, the latter is inserted at the 4-position of coumarin in the form of a thioether. Due to steric hindrance, the amino group of GSH can only attack the 3-position with respect to the aldehyde group, causing GSH and the fluorophore to form a ring structure, increasing the conjugation of the system. Concomitantly, the amino group forms an internal hydrogen bond with the adjacent carbonyl group, and the fluorescence is enhanced. The limit of detection of the probe for GSH was 2.7 × 10−7 M, with λex = 471 nm and λem = 518 nm, the detection range was 0–40 μM, and equilibrium was attained within 100 ms (as determined by UV/Vis monitoring). Cys/Hcy will form a secondary amine group at the 4-position of coumarin. Cys/Hcy also undergo a cyclization reaction with the aldehyde group in the 3-position, decreasing the fluorescence. The probe has also been successfully used for imaging GSH in Hep3B cells.
Qin et al. introduced phenyl-Se ether groups at the 3- and 5-positions of the BODIPY framework to synthesize fluorescent probes (Fig. 7, panel 25) for detecting H2S [104]. In the presence of excess H2S, the second phenyl-Se ether group of the probe was substituted, and the fluorescence emission intensity was further reduced. The detection range of this probe for H2S was 0–15 μM, the limit of detection was as low as 2.5 nM, and the detection reached equilibrium within 20 min, with λex = 582 nm and λem = 610 nm. The fluorescence of the probe is shut down by H2S, providing excellent sensitivity and selectivity for its detection. It has been widely used in intracellular H2S detection and fluorescence microscopy imaging.
With NBD-O ether as the detection group of a probe, after the RSS breaks the NBD-O ether bond, the fluorescence of the fluorophore recovers, and the analyte concomitantly forms a covalent bond with the NBD to achieve the purpose of detection [205], [206], [207]. Since an NBD-S bond will quench the fluorescence of NBD, H2S, PhSH, GSH, and thiol-containing proteins cannot restore it. Therefore, NBD-O ether can be used for distinguishing Cys or Hcy from other RSSs based on the fluorescence recovery of fluorophores and the change of NBD fluorescence [208], [209], [210], [211].
Ma et al. combined NBD with the hydroxyl group of resorufin to synthesize a specific fluorescent probe for distinguishing GSH from Cys/Hcy, which showed unique emission modes of Cys and GSH at only one excitation wavelength (Fig. 9
, panel 26) [212]. Upon reaction with Cys/Hcy, this probe releases the amino NBD and resorufin (λex = 470 nm, λem1 = 540 nm, λem2 = 585 nm), but only one emission is seen after reaction with GSH (λem = 585 nm). Evidently, the sulfur atom of GSH quenches the fluorescence of NBD, but due to steric hindrance the amino NBD cannot be formed. The limits of detection of Cys and GSH at λem = 585 nm were determined as 0.13 μM and 0.07 μM, and the detection ranges were 1–40 μM and 1–18 μM, respectively. The probe was also applied for the detection of Cys and GSH in human plasma samples, with recovery rates of 95–109% and 102–104%, respectively.
Feng et al. introduced NBD-O ether, methyl, and aldehyde groups at the 2-, 3-, and 5-positions, respectively, of a 2-(2-hydroxyphenyl)benzothiazole (BHT) fluorophore, and thereby synthesized a highly selective fluorescent probe for the detection of H2S (Fig. 9, panel 27) [213]. The detection range of this probe for H2S was 0–50 μM, the limit of detection was 150 nM, with λex = 382 nm and λem = 455 nm, and the detection reaction reached equilibrium within 500 s. Since a methyl group is present at the ortho position of the NBD-O ether, there is a certain degree of steric hindrance, which greatly slows the rates of the thiolysis reactions of Cys, Hcy, and GSH. Therefore, probe 27 can also recognize H2S with high selectivity and high sensitivity. Indeed, this probe has been used for intracellular H2S detection and fluorescence microscopy imaging.
Lin et al. synthesized a fluorescent probe for the specific detection of thiols through combining the hydroxyphenyl benzothiazole merocyanine (HBTMC) fluorophore and the NBD fluorophore (Fig. 9, panel 28) [214]. Cys/Hcy cleave the NBD-O ether, release the HBTMC unit (λex = 550 nm, λem = 609 nm), and form amino NBD (NBD-Cys/Hcy, λex = 470 nm, λem = 546 nm) through a sequence of nucleophilic substitution and intramolecular rearrangement, lighting up in green and red. GSH can generate free HBTMC1 and dark-colored thio-NBD (NBD-GSH) through a one-step nucleophilic substitution reaction, eliciting only red emission. H2S is a stronger nucleophile, and the ether bond will also be cleaved, resulting in dark thiol-NBD (NBD-SH) and free HBTMC (HBTMC1). HS− will further undergo an addition reaction with the double bond of HBTMC1 to form an HBTMC derivative (HBTMC-SH, λex = 410 nm, λem = 485 nm), resulting in a new blue emission. On further adding H2S to a mixture of probe 28 and Cys/Hcy or probe 28 and GSH, the intermediate products NBD-Cys/Hcy or NBD-GSH will be further substituted, and HBTMC1 will be attacked by HS– anions to produce dark NBD-SH and blue fluorescent HBTMC-SH, accompanied by quenching of the green and red emission. In summary, probe 28 can distinguish Cys/Hcy, GSH, and H2S by the change order of three clearly defined emission bands (blue, green, and red). The limits of detection of this probe for Cys, Hcy, GSH, and H2S were 4.25, 5.11, 4.30, and 6.74 μM, respectively. The unique design of probe 28 may open the way to the design of other fluorescent probes for distinguishing and sequentially detecting biothiols, providing hope for revealing the interrelated effects of biothiols under various physiological and pathological conditions.
In contrast to the previous case, for probes with NBD-S ether as the reaction site, after the NBD-S ether is cleaved by RSS, the fluorescence of the NBD group is quenched by sulfur, and the analyte and fluorophore are forced to form a covalent bond. The quenching effect of sulfur depends on its distance from the fluorophore; if the distance is larger than 0.6 nm, the quenching effect will be weak or non-existent. The quenching ability of sulfur is only moderate, much weaker than that of a nitro group. Only Cys/Hcy can form a covalent bond with the fluorophore through the amino group to restore the fluorescence [107], [110], [111].
Shao et al. appended NBD fluorophores on the surface of gold nanoclusters to assemble a ratiometric fluorescent probe for the detection of Cys and Hcy (Fig. 10
, panel 29) [215]. The probe reacted with Cys and Hcy to form amino NBD and gold nanoclusters, with λex = 410 nm, λem1 = 485 nm, and λem2 = 540 nm. The detection ranges for Cys and Hcy were 8.33–100 μM and 16.67–100 μM, with limits of detection of 1.45 μM and 1.8 μM, respectively. The probe was also successfully used for fluorescence imaging of Cys and Hcy in HeLa cells, giving good results.
For probes with NBD-N as the reaction site, after an RSS breaks the NBD-N bond, the fluorescence of the NBD group is quenched by S, and the fluorescence of the fluorophore is enhanced due to exposure of the amino group, which provides the detection signal [216], [217], [218].
Yi et al. have long studied NBD fluorophores and thiol probes. They connected an NBD fluorophore to a cyanine dye through a piperazine moiety to synthesize an NIR fluorescent probe capable of selectively detecting H2S in vivo (Fig. 9, panel 30) [219]. The detection range of this probe for H2S was 0–100 μM, and the limit of detection was 39.6 nM, with λex = 730 nm and λem = 796 nm (87-fold fluorescence enhancement). Biological imaging results showed that: (1) d-Cys can induce the production of endogenous H2S in living cells and stimulate angiogenesis; (2) intravenous injection of the probe into the tail of a mouse produces strong fluorescence in its liver, and intraperitoneal injection of d-Cys can further enhance the fluorescence from the liver; (3) intratumoral injection of the probes allows the rapid and selective detection of endogenous H2S in colorectal cancer cells (HCT116, HT29) in vitro and in mouse tumor models. These results indicate that the probe can be used as an effective tool for detecting H2S and even cancer in living animal cells.
Yi et al. used trimethyl-lock containing quinone propionic acid (Q3PA) as the detection group for human NADPH: quinine oxidoreductase 1 (hNQO1), NBD-N as a detection group for H2S, and naphthalimide as a fluorophore. These were assembled to form a fluorescent probe showing dual responses to H2S and hNQO1 (Fig. 9, panel 31) [220]. The probe only showed enhanced fluorescence in the simultaneous presence of H2S and hNQO1; the single components alone did not elicit a response. It showed high sensitivity, excellent selectivity, and good biocompatibility, with λex = 465 nm and λem = 535 nm. This allowed us to distinguish the activation levels in HT29 and HepG2 cells from those in FHC, HCT116, and HeLa cells, due to the significantly different endogenous levels of H2S and hNQO1 in these cell lines.
Chen et al. used heptamethine cyanine dye as the fluorophore and 4-nitrobenzoate as the detection group (Cy-NB) to synthesize an NIR ratiometric fluorescent probe (Fig. 11
, panel 32) for detecting Cys [229]. Its optical parameters were λex = 720 nm and λem = 785 nm. Cys forms a thiobenzoate with the 4-nitrobenzoic acid group. The π-electron system of the fluorophore is modified upon conversion from the enol form to the ketone form, and a spectral shift occurs; λex = 560 nm, λem = 640 nm. Using this principle, Cy-NB could be used to detect the NIR ratio of Cys through the fluorescence ratio (F640 nm/F785 nm). This probe could be used to detect Cys within 5 min with a detection limit of 0.2 µM, and could sensitively detect changes in Cys levels in mitochondria under different oxidative stress states in HepG2 cells. The probe was also used to detect changes in Cys levels in mice. The results indicated that mitochondrial Cys could be viewed as a biomarker for oxidative stress, offering potential for simple clinical application.
By using the characteristics of the two -SH groups in H2S2, Xian et al. designed and synthesized a fluorescent probe (Fig. 11, panel 33) containing two 2-fluoro-5-nitrobenzoate groups to detect H2Sn (n > 1) [230]. H2S2 first underwent electrophilic reaction with fluorine, and then further underwent a bimolecular aromatic nucleophilic substitution reaction (SN2Ar) with a benzoate group to form a thioether, thereby turning on fluorescence. The fluorescence intensity of this probe was linearly related to the concentration of Na2S2 in the range 0.5–15 μM, and the limit of detection was approximately 71 nM, with λex = 490 nm and λem = 515 nm. The probe was successfully used to sensitively and selectively detect H2Sn/H2S2 in aqueous buffer and cells, and also served to prove that the formation of H2Sn may be related to the reaction of H2S and ROS (such as ClO−).
The active site of thiobenzoate is also called a natural chemical linkage (NCL), and this reaction has been widely used in peptide synthesis [231], [232], [233]. The NCL of peptides involves reaction between a peptide α-thioester and an N-terminal cysteine peptide. The main characteristics of the NCL response include: (1) a high degree of chemical selectivity for thiols that is not disturbed by other biologically relevant species, and (2) the reaction proceeds in vivo and can be carried out in living cells. Thiobenzoate groups are a type of natural chemical linking group used to detect thiols [234].
Yang et al. combined rhodamine with p-nitrothiophenol to assemble a fluorescent probe that responded to GSH and Cys/Hcy (Fig. 11, panel 34) [232]. The probe (λex = 305 nm) reacted with Cys/Hcy to form the corresponding deconjugated spirolactam based on NCL. After adding Cys/Hcy, the fluorescence emission of the thioester intermediate (λem = 587 nm) formed by the transthioyl esterification reaction intensified, thus eliminating the 4-nitrobenzene-induced PET quenching process. Over time, the intramolecular S,N-acyl group shifted to form the corresponding amide (λem = 454 nm). This amide was further spirocyclized to obtain a colorless lactam under neutral conditions. The process was completed within minutes. In the presence of GSH, only the thiobenzoate group transfer reaction proceeded, thereby eliminating the PET process caused by the electron-deficient 4-nitrobenzene moiety and thus the emission band of rhodamine (λem = 587 nm). A large fluorescence enhancement was observed, and the fluorescence intensity reached a stable level within 10 min. The detection ranges of this probe were 1–10 mM for GSH and 30–200 μM for Cys, and the limits of detection for Cys, Hcy, and GSH were determined as 44, 52, and 96 nM, respectively. The probe was also successfully applied to the detection of GSH and Cys in serum and cells.
Lin et al. designed a ratiometric fluorescent probe for the detection of thiols based on NCL (Fig. 11, panel 35) [235]. The probe consisted of a rhodamine dye, a thiobenzoic acid ester group, and a BODIPY dye. According to the NCL reaction, Cys attacks the electrophilic carbon of the thioester group to form a new thiobenzoate, which leads to cleavage of the dimer showing fluorescence resonance energy transfer (FRET). Upon reaction of the probe (λex = 470 nm) with Cys, the BODIPY group (λem = 510 nm) is released, the emission intensity of the rhodamine group (λem = 590 nm) decreases, and FRET is turned off. The detection range of the probe for Cys was 0.1–100 μM, the detection limit was 82 nM, and reaction equilibrium was reached in 30 min. The probe was also used for FRET-based ratiometric imaging of thiols in living cells.
Ebselen (2-phenyl-1,2-benzisoselenazol-3(2H)-one) is well known as a glutathione peroxidase (GPx) mimic [236], [237], [238]. The catalysis of GPx activity by this drug may be related to the cleavage of Se-N bonds by thiols. A thiol can form selenium sulfide with the detection group; therefore, phenylselenamide can be used as the active site of a probe for RSS [239], [240]. Since GPx is a selenium enzyme, such a group can be expected to be useful for RSeS detection.
Tang et al. inserted m-trifluoromethylbenzylphenol into the amine group of rhodamine to synthesize a fluorescent probe for detecting thiols (Fig. 12
, panel 36) [241]. When the probe reacts with a thiol, it forms a selenium-sulfur bond with the detection group, resulting in exposure of the amino group fluorophore, and the fluorescence is turned on to realize detection of the thiol. This probe (λex = 525 nm, λem = 550 nm) showed a good linear relationship with the concentration of GSH, the detection range was 3.0–120 nM, and the limit of detection was 1.4 nM. This probe was successfully applied to thiol imaging in HL-7702 and HepG2 cells with high sensitivity and selectivity.
Chen et al. inserted 2-nitrophenylselanyl and 3-(trifluoromethyl)phenylselanyl groups into the secondary amine group of the NIR fluorophore of heptamethrin, thereby synthesizing two fluorescent probes (Fig. 12, panels 37a and 37b) for the detection of thiols [242]. Probe 37a showed a linear response to GSH concentration at 750 nm, F750 nm = 16236.17 [GSH/μM] – 17657.72 (r = 0.9814), as did probe 37b, F750 nm = 6599.80 [GSH/μM] – 3179.94 (r = 0.9867). Both probes (λex = 635 nm, λem = 750 nm) could be used to detect different levels of thiols in living cells and tissue samples.
There have been many types of RSS- and RSeS-specific probes reliant on small aromatic molecules as detection groups. Those surveyed above are just some of the more mainstream detection groups. There are many small aromatic molecules that can bind to fluorophores and are attacked by RSS or RSeS. Below, we describe some unusual cases [243], [244], [245], [246].
Yang et al. synthesized a fluorescent probe for the detection of thiols by connecting BODIPY and coumarin through an ether bond (Fig. 13
, panel 38) [247]. The BODIPY fluorophore was designed to react with GSH and Cys to generate distinct products with different photophysical properties, while the coumarin fluorophore served as an internal standard. This probe showed green emission in aqueous solution. After adding Cys, the N-BODIPY fluorescence produced was weak (S-BODIPY: λem = 540 nm; N-BODIPY: λem = 560 nm), and the free coumarin showed blue emission light (λem = 452 nm). In the presence of GSH, monosulfide- and disulfide-substituted BODIPY (λem = 558 nm, λem = 588 nm) and coumarin (λem = 452 nm) were generated, such that different concentrations of GSH produced various emission colors. Interestingly, the solution showed white fluorescence at a GSH concentration of 0.4 mM. The fluorescence intensity at 452 nm showed a good linear relationship with Cys concentration in the range 0–100 μM. The limit of detection was calculated as 3.66 × 10−7 M. The fluorescence intensity at 588 nm showed a good linear relationship with GSH concentration in the range 0–1 mM, with a limit of detection of 1.07 × 10−6 M. This probe was successfully used to detect Cys and GSH in living cells.
Song et al. combined 7-diethylaminocoumarin and resorufin through ether bonds to synthesize fluorescent probes for distinguishing and detecting different thiols (Fig. 13, panel 39) [248]. These probes reacted with H2S to release the red fluorescent resorufin (λem = 582 nm) along with non-fluorescent mercaptocoumarin, giving a strong red fluorescence signal. The probes reacted with GSH, Cys, and Hcy to not only release the red-light-emitting resorufin, but also the corresponding thiocoumarin (C-S-GSH, C-S-Cys, or C-S-Hcy; λem = 432 nm), emitting green fluorescence. Through different degrees of intramolecular rearrangement, C-S-Cys can be completely converted into a blue-fluorescent C-N-Cys (five-membered ring, λem = 374 nm), and C-S-Hcy can be partially converted into a blue-fluorescent balanced state C-N-Hcy (six-membered ring, λem = 374 nm). Because the energy of a ten-membered ring is kinetically high, C-S-GSH (λem = 432 nm) is very stable and can only maintain green fluorescence. Therefore, the probe was able to show different signal patterns for different biothiols in solution and live cells, namely red for H2S, blue-red for Cys, blue-green-red for Hcy, and green-red for GSH.
Kim et al. used heptocyanine as the fluorophore and nitroazobenzene as the detection group to synthesize NIR fluorescent probes (Fig. 13, panel 40) for distinguishing GSH from Cys/Hcy [249]. After adding GSH, the fluorescence spectrum of the probe showed a significant red shift of its maximum (λex = 600 nm, λem = 810 nm), whereas the addition of Cys or Hcy elicited a weak, blue-shifted fluorescence response at λem = 747 nm. The limit of detection for GSH was 26 nM. The probe was successfully applied for cell imaging of GSH in mitochondria, showing a good response to different amounts of mitochondrial GSH in cells, and may thus be used as a mitochondrial GSH tracer.
Yoon et al. combined the heptamethine cyanine fluorophore and the dansyl detection group through a piperazine linkage to synthesize a fluorescent probe for detecting GSH (Fig. 13, panel 41) [250]. Their probe (λex = 730 nm, λem = 736 nm) showed high selectivity for GSH, which could be detected within 15 min. The amide group of GSH may form a hydrogen bond with the piperazine ring unit of probe 41. There may also be electrostatic interaction between the indole cation of the probe and the carbonate anion of GSH. The interaction between these moieties may cause the thiol and sulfonamide groups to be closer together, which may be the reason for the higher reactivity of GSH. Probe 41 can be used to detect changes in the GSH concentrations in living cells due to the oxidation promoted by increased H2O2 concentration. In whole-body images of mice, strong fluorescence was observed in various tissues, including liver, kidney, lung, and spleen.
Chen et al. synthesized a fluorescent probe for the detection of GSH by linking two NIR fluorophores with p-benzenedithiol (Fig. 13, panel 42) [181]. The limit of detection of this probe (λex = 780 nm, λem = 805 nm) for GSH was 630 nM. When this probe was reacted with Cys and Hcy, the emission wavelength was blue-shifted (λex = 650 nm, λem = 740 nm) and the fluorescence intensity decreased. The probe was also used to assess different concentrations of GSH in living cells and for fluorescence detection of GSH in SCC7 tumor-bearing mice.
Zhao et al. have studied thiol probes for a long time, and recently functionalized the BODIPY fluorophore with sulfoxide (Fig. 14
, panel 43) [179]. Their probe was encapsulated in core–shell silica nanoparticles to improve chemical selectivity. The inherent molecular size sieving properties of the porous silica shell prevented competing biothiols from entering the core molecular probe, while allowing specific reactions with the small target H2S. Therefore, this strategy avoids interference from coexisting RSS and achieves highly chemically selective detection. Upon reaction with H2S, the sulfoxide group of the probe is converted into a disulfide bond, and further reacts with H2S to displace the detection group, forming a thiol BODIPY. The absorption and emission spectra showed a clear red shift (λex = 620 nm, λem = 713 nm). The limit of detection of the probe was 53 nM, and the detection range was 0–15 μM. The reaction rate proved to be proportional to the content of Si in the porous shell. When the particle size was 113 ± 10 nm, H2S was equilibrated within 3 min. This probe was successfully used to detect estrogen-induced endogenous production of H2S in cardiomyocytes and live mice.
When constructing SNAr-based RSS- and RSeS-specific fluorescent probes, an ether linkage is a popular choice as the reaction site [251], [252], [253], [254], [255], [256], [257], [258], [259]. Phenyl-O ether, phenyl-S ether, and phenyl-Se ether have mainly been used, among which the C-O, C-S, and C-Se bonds become increasingly long [161]. Although energies of these three bonds increase in sequence, SNAr reaction becomes more likely to occur [151]. Stronger bonds are more selectively cleaved by RSS or RSeS with lower pK
a. Probe 18b (with p-nitrothiophenol) is more rapidly cleaved by thiols than probe 18a (with p-nitrophenol). Chen et al. constructed a probe containing a phenyl-S ether group, and its reaction with Cys reached equilibrium within 15 min [152]. Probe 25, containing a phenyl-Se ether group, reached its initial equilibrium with H2S within 10 min [104]. It cannot be ignored that there are large numbers of free electrons around S and Se in ether groups. These groups are thus negatively charged, making them susceptible to oxidation, especially the phenyl-Se ether group. There are already some probes for detecting ROS based on the oxidation of such linkages [178], [260], [261]. It is interesting that the oxidation is reversible, with reduction typically being achieved with RSS or RSeS. This also makes many RSS and RSeS probes with ether as the reaction site to be somewhat susceptible to interference from ROS in the monitoring environment. For RSS and RSeS probes with phenyl-O ether groups as the reaction site, interference from ROS in the environment is much less likely. Another benefit of using an ether as the reaction site is its quenching effect on fluorescence, which is especially notable for phenyl-S and phenyl-Se groups [104], [180]. At the same time, because S or Se will leave the fluorophore as the ether group is cleaved, the test substance will be connected to the fluorophore through a covalent bond. The fluorophore will be changed through the amino group of Cys or Hcy, which constitutes a good design strategy [99], [100], [101], [180].
A probe containing an amine group reaction site will release this group after reacting with the analyte. Subsequent SNAr reaction of RSS or RSeS with the detached group will cause the emission of the fluorophore to be red-shifted. Benzenesulfonamide, NBD-N, and phenylselenamide are the most commonly applied groups [142], [219], [241]. However, amine groups of many forms may connect the detection group to the fluorophore, such as secondary and tertiary amine groups (including piperazinyl) [131], [143], [144]. Compared with the benzenesulfonate group, the bond energies of the benzenesulfonamide and phenyl-O ether groups are higher, and their selectivities to RSS or RSeS are also higher [129]. Tertiary amine bonds have higher energies than oxyether bonds or secondary amine bonds, and have a certain steric hindrance, and their selectivity is also improved. Although a secondary amine group has a certain steric hindrance when reacting with a detection group, its pK
a is much higher than that of a tertiary amine, so SNAr reaction is more likely to occur [144], [258]. Since a conjugated system of a fluorophore decreases the pK
a of the amine group, it is also a good choice to introduce a secondary amine group (instead of a primary amine group), as this can greatly improve the yield and stability of the product. Zhang et al. appended 2,4-dinitrobenzenesulfonyl to the hydroxyl group in the 9-position of 4-amino-naphthalimide through p-hydroxyaniline instead of the primary amino group in the 4-position, which could be accomplished even in an extremely strongly alkaline reaction environment, and the yield of the reaction exceeded 50% [258]. Chen et al. appended 2,4-dinitrobenzenesulfonamide to the secondary amine group of the NIR heptamethine cyanine fluorophore [144], but we are not aware of any reports of appending 2,4-dinitrobenzenesulfonyl to the primary amine group of this fluorophore. Upon SNAr reaction of RSS or RSeS probes containing a piperazine group with the analyte, two products of the detection group with piperazine and the fluorophore with piperazine may be formed at the same time [250]. The piperazine moiety can adopt a boat or chair conformation, and studies have shown that a preference for the latter conformation improves the selectivity of the probe for RSS [262], [263], [264], [265], [266]. Since both nitrogen atoms of piperazine can be reaction sites, the sensitivity to the analyte is increased, and the time for the reaction to reach equilibrium is greatly shortened [143], [144], [254].
The introduction of electron-withdrawing groups on the benzene ring lowers the electron density at the detection group, reduces the bond strength at the reaction site, and increases the bond length and the degree of dissociation at the reaction site [154], [161]. The introduction of electron-donating groups on the benzene ring increases the electron density at the detection group, increases the bond strength at the reaction site, and decreases the bond length and the degree of dissociation at the reaction site [183]. Nitro is a typical electron-withdrawing group. The detection group of probe 18a is p-nitrophenyl-S, with which detection of Cys can reach equilibrium within 200 s [151]. Without any substituents, the detection group of probe 16 is phenyl-S, with which the detection of Cys/Hcy reaches equilibrium within 6 min and the detection of GSH reaches equilibrium within 30 min [180]. Methoxy is a strongly electron-donating group. The detection group of probe 19a is 4-methoxyphenyl-S, with which the detection of Cys/Hcy reaches equilibrium within 30 min [182]. Amino is also a strongly electron-donating group. The detection group of probe 20 is p-aminophenyl-S, with which the detection of GSH reaches equilibrium within 42 min [183]. Ito et al. synthesized fluorescent probes (Fig. 15
) for detecting GST by connecting different detection groups to rhodamine. The four detection groups 2,4-dinitrobenzenesulfonamide, 2-nitro-4-cyanobenzenesulfonamide, 2-nitro-4-acetylbenzenesulfonamide, and 2-nitro-4-butoxy were compared [153]. The fluorescent probe with 2,4-dinitrobenzenesulfonamide as the detection group reached equilibrium of GST detection within 10 min, and the yield exceeded 80% (Fig. 15, panel 44a). The reactions with the other three probes did not reach equilibrium in 30 min, and the yields were all below 60%. The reaction rates of the four probes were consistent with the order of the respective groups on the classic Hammett electron-withdrawing scale.
The position of the introduced group on the benzene ring will affect the reactivity of the active site [155], [161], [267]. For example, introducing a nitro group on the benzene ring will increase the degree of dissociation of the active site. From the perspective of induction effect, a nitro group attracts the electron cloud of the active site, and the closer its substitution position to the reaction site, the greater the degree of dissociation of the active site. At the same time, the conjugation effect increases the electron cloud density at the active site, which will have a decreasing effect on the degree of dissociation at the active site. Overall, the effectiveness of nitro in activating the active site decreases in the positional order ortho > para > meta
[161], [267]. Chen et al. introduced m-nitrophenyl-O ether into heptacarmine cyanine to synthesize fluorescent probes for detecting H2S and H2Sn. Although their probes contained nitrophenyl-O ether groups, the active sites for the reactions with H2S and H2Sn were the nitro groups, not the ether bond, and the reaction required 1 h to reach equilibrium [268], [269]. Zhang et al. compared the response rates to thiols of three NIR fluorescent probes (Fig. 16
, panels 45–2-b, 45–2-c, and 45–2-d) with different detection groups (2,4-dinitrobenzenesulfonate, o-nitrobenzenesulfonate, and p-nitrobenzenesulfonate), respectively, and found that the mono-nitro-substituted groups responded more slowly [267].
The number of groups appended on the benzene ring will affect the reactivity of the active site [155], [161], [267]. At present, it is common to introduce doubly-substituted groups, such as 2,4-dinitrophenyl ether, 2,4-dinitrobenzenesulfonamide, 3,5-dinitrophenyl-O ether, 2-fluoro-4-nitrobenzoate, and so on. Taking the 2,4-dinitrophenyl ether group as an example, to maximize the conjugation and induction effects of the electron-withdrawing groups, they are introduced at both the ortho and para positions of the benzene ring. This arrangement will lower the density of the electron cloud on the benzene ring, which will decrease the bond strength of the reaction site and increase the bond length, so that the reaction site will react more easily [267]. However, the simultaneous introduction of two nitro groups at the meta positions of the benzene ring cannot affect the active site through the conjugation effect, and the degree of dissociation is insufficient. Wang et al. appended a 3,5-dinitrophenyl-O ether group on the dicyanoisophorone fluorophore and introduced a formaldehyde group at an ortho position of the phenyl-O ether to synthesize a fluorescent probe for detecting H2S. With phenyl-O ether lacking the ortho formaldehyde group, the response of the probe to H2S was very slow. Introducing the ortho formaldehyde group (Michael acceptor) as an auxiliary detection group caused HS– to induce an initial nucleophilic addition reaction on the aldehyde group, and then reaction of the phenyl-O ether bond eventually formed 3,5-dinitrothiophenol [270]. 2-Fluoro-5-nitrobenzoate is a notable specific group. Theoretically, the response of m-nitrobenzoate groups to thiols would be extremely slow; however, the introduction of a fluoro substituent as an auxiliary detection group with an electron-withdrawing effect adjacent to the active site modifies the reactivity of the active site. It facilitates electrophilic reaction with H2Sn of lower pK
a in preference to the active site, and then another part of unreacted -SH attacks the active site, thereby achieving the purpose of detecting H2Sn
[222], [230], [271]. Because there are few cases of two different substituents, these are still difficult to discuss.
There are many RSS- and RSeS-specific fluorescent probes based on SNAr reactions, many of which have different detection groups attached to the same fluorophore. Here, we summarize some similar cases and analyze some cases of optimized detection groups.
Dicyanoisophorone is a very popular fluorophore. Because of its simple synthesis, good solubility in water, large Stokes shift, and maximum emission wavelength in the NIR region, it has attracted much attention. Between 2017 and 2019, there were 11 reports concerning the use of dicyanoisophorone as a fluorophore, bearing different electrophilic small aromatic molecules to detect RSS and RSeS (Table1 and Fig. 17
). Three of these reports concerned probe 46 (Fig. 17, panel 46) [272], [273], [274], and two concerned probe 47 (Fig. 17, panel 47) [275], [276]. Evidently, 2,4-dinitrobenzenesulfonamide is one of the most commonly used RSS and RSeS detection groups. It can be seen that the response times of the 2,4-dinitrophenyl-O ether (Fig. 17, panel 50) [277] and 2,4-dinitrobenzenesulfonamide groups are similar, both shorter than that with 2,4-dinitrobenzenesulfonate (Fig. 17, panel 48) [278]. With the incorporation of piperazine, both nitrogen atoms are reaction sites, thus, the response time is significantly shorter than that with 2,4-dinitrobenzenesulfonimide, and the limit of detection is also lower. However, due to steric hindrance, the rate of reaction of PhSH is significantly slower than that with H2S. Unfortunately, PhSH has not been included in reported selective experiments on fluorescent probes for H2S. The 3,5-dinitrophenyl-O ether group (Fig. 17, panel 49) [270] showed a very slow response to H2S. Since the NBD group produces different fluorescence emissions when it is incorporated into different structures, NBD-O ether (Fig. 17, panel 52) [279] can be used for distinguishing between Cys/Hcy and GSH, and the reaction rates with PhSH and H2S are very slow. The NBD-N group (Fig. 17, panel 53) [280] incorporating piperazine is more selective for H2S. The 2-fluoro-5-nitrobenzoate group is very selective for H2Sn (Fig. 17, panel 51) [271], but unfortunately there have been no reports on selective experiments on PhSH in the salient literature.
Zhang et al. combined two NIR fluorophores with 2,4-dinitrobenzenesulfonate, o-nitrobenzenesulfonate, p-nitrobenzenesulfonate, and 2,4-dinitrophenyl-O ether groups, and synthesized seven kinds of fluorescent probes for detecting RSS (Fig. 16) [267]. The selectivity of 2,4-dinitrophenyl-O ether for PhSH, H2S, and GSH was significantly higher than that of nitrobenzenesulfonate. 2,4-Dinitrobenzenesulfonate showed higher sensitivity than o-nitrobenzenesulfonate or p-nitrobenzenesulfonate.
Zhao et al. attached different detection groups (p-methoxyphenyl, p-methylphenyl, phenyl, p-trifluoromethylphenyl, p-nitrophenyl, or 2,4-dinitrophenyl) to BODIPY fluorophores through secondary amine group, thioether, or oxyether linkages (Fig. 18
) [154]. Due to the poor dissociation ability of aromatic amines, all fluorescent probes with aromatic amines as detection groups show almost no reaction with biothiols. All fluorescent probes with phenyl-S ether as the detection group can react with thiols. Appending an electron-withdrawing substituent on the benzene ring enhances the susceptibility of the detection group to cleavage, lowering the selectivity. All fluorescent probes with a phenyl-O ether detection group can respond to thiols. Appending a weakly electron-withdrawing substituent on the benzene ring lowers the susceptibility of the detection group to cleavage, retarding the response to biothiols. After structural optimization, probes containing p-methoxyphenyl-S (Fig. 18, panel 54-S-1) and 2,4-dinitrophenyl-O ether (Fig. 18, panel 54-O-6) were identified as the most suitable for distinguishing Cys/Hcy and GSH.
Han et al. used naphthalimide as the fluorophore and differently substituted benzenesulfonates as detection groups to screen and synthesize fluorescent probes for detecting GST activity (Fig. 19
) [155]. Probes similar to probe 55–1 proved to be ultra-sensitive. By screening different substituents, the non-enzymatic noise of the probe could be greatly reduced, while keeping the sensitivity almost unchanged. For probes 55–11 and 55–12, the most electrophilic centers were identified as the alternative β-carbon instead of the α-carbon, indicating that they are not suitable as GST detection probes. Probe 55–6 responded slowly to GST with low sensitivity and no background noise at all. It is worth noting that the order of the reaction rates of different probes (55–2 < 55–4 < 55–3 < 55–5 < 55–1) is very consistent with the order of the increase rates of fluorescence in non-enzymatic tests. By moderately reducing the sensitivity, probe 55–3 (λex/em = 445/560 nm) was found to be a more suitable probe. It was also used in more practical and rigorous applications. The limit of detection of this probe for GST was 3.7 nM.
The introduction of specific functional groups can increase the selectivity of the probe to certain specific RSS or RSeS and accelerate the response rate. Theoretically, the response of m-nitrobenzoic acid groups to RSS would be extremely slow. Introducing a fluorine atom in the ortho position of the m-nitrobenzenesulfonate group (the para position with respect to the nitro group) improves the selectivity of the probe for H2Sn, and the greater the number of sulfur atoms, the faster the response [222], [230], [271]. The 3,5-dinitrophenyl-O ether group responds very slowly to RSS. It is a good choice to introduce a formaldehyde group (Michael acceptor) in the ortho position of the fluorophore. The formaldehyde group first reacts with RSS to form activated S−, and then undergoes SNAr reaction with the phenyl-O ether bond [270]. When the detection group is phenyl-Se ether and a formaldehyde group is introduced adjacent to the detection site of the fluorophore, one GSH molecule can react with two detection groups at the same time, resulting in a more conjugated system, whereas Cys or Hcy can only react with one of the detection groups [103]. The response of 2,4-dinitrophenyl-S to RSS is very slow. The introduction of an o-phenyl-S benzoate group between this group and the hydroxyl group in the fluorophore can greatly shorten the RSS response time. When H2S reacts with the benzoate, O– is first released to attack the phenyl-S, and then the benzoate and phenyl-S bonds are successively broken; the hydroxyl group on the fluorophore is exposed to achieve H2S detection [281], [282], [283]. Of course, introducing a piperazine group between the detection group and the fluorophore increases the number of reaction sites, and hence the sensitivity to the analyte, and the reaction equilibrium time is greatly shortened [250], [275], [276]. In addition, the introduction of selenophenol at the ortho position of the benzoate can make the selenophenol form a selenium-sulfur bond with highly active thiols, thereby causing internal cyclization to break the benzoate, which has achieved the purpose of detecting sulfane sulfur [225], [228].
To date, most RSeS probes based on SNAr reactions have been designed by simulating RSS probes. 2,4-Dinitrophenyl-O ether and 2,4-dinitrobenzenesulfonamide have mainly been used as detection groups, but 2,4-dinitrobenzenesulfonate is not strong in distinguishing RSeS and RSS [129], [267]. However, in order to avoid the interference of thiols as far as possible, rational selection of the detection group is only one aspect. The pH of the detection environment is another aspect. Cys-SH has a pK
a of 8.5 and Sec-SeH has a pK
a of 5.2. In physiological systems, Se in selenol decomposes into R-Se−, which is more reactive than a thiol, whereas S in thiol exists in the form of undecomposed R-SH. Therefore, R-SeH can be selectively probed over R-SH in an acidic environment [146]. Hatsuo et al. proved that 3′-(2,4-dinitrobenzenesulfonyl)-2′,7′-dimethylfluorescein (BESThio, Fig. 1, panel 1b) has a dual ability to detect selenol in an acidic environment and thiol under neutral or alkaline conditions [135], [136]. This is not only due to the different pK
a values of R-SeH and R-SH, but also because selenol has stronger nucleophilicity than thiol.
In this review, we have described a series of fluorescent probes based on SNAr reaction for the specific detection of RSS and RSeS, and have classified them according to their reaction mechanisms. The mechanism of detecting RSS and RSeS is reliant on the strong nucleophilicity of thiol and selenol, as a result of which an aromatic detection group is displaced, thereby modifying the fluorescence of the probe [129], [136]. Benzenesulfonate, phenyl-O ether, phenyl-S ether, phenyl-Se ether, 7-nitro-2,1,3-benzoxadiazole, benzoate, and a selenium-nitrogen bond are all good detection groups [44], [45], [46], [47], [48]. All of the probes discussed herein exhibit excellent optical performance upon reaction with the target analytes and represent powerful tools for the direct detection of RSS and RSeS.
When designing a fluorescent probe based on an SNAr reaction, the main factors affecting the selectivity to RSS and RSeS are the reactivity of the site at which the substitution occurs, and the nature, number, and positions of substituents on the detection group. An ether linkage is a popular reaction site. The ease of dissociation of an ether increases with the increasing atomic radii of O, S, and Se. Due to the inherently low degree of dissociation of a phenyl-O ether group, although a phenyl-O linkage moiety bearing a single substituent can respond to RSS and RSeS, the response times are too long and the selectivity is poor [161]. More popular phenyl-O ether groups are those bearing two substituents, which show shorter response times to RSS and RSeS and improved selectivity, most notably the 2,4-dinitrophenyl-O ether group [162], [163], [164], [165], [166]. The phenyl-O ether group itself can respond to RSS and RSeS, but it does not have a quenching effect, so it is not very suitable for detection [161]. The quenching effect of phenyl-O ether groups is mainly dependent on the substituents on the benzene ring, so the selectivity for RSS and RSeS depends more on the detection environment and the pK
a of the analyte. The degree of dissociation of the phenyl-S ether group is moderate. Generally, the introduction of appropriate substituents at the ortho and/or para positions of the benzene ring can impart a response to RSS. At the same time, because the covalent bond with sulfur produces a quenching effect, detection does not depend on the substituent. After displacement of the detection group, the analyte combines with the fluorophore, so it is more suitable for distinguishing RSS with different structures, but similar pK
a values [100], [101]. Of course, RSS with higher pK
a can also be detected. However, the sulfur atom is intrinsically susceptible to interference from ROS, modifying the fluorescence of the probe [178]. There have been few studies on RSS probes employing phenyl-Se ether as the detection group, but we have gratifyingly found that phenyl-Se ether can detect RSS without any substituent on the benzene ring [103], [104]. However, selenium atoms are more susceptible to interference from ROS than sulfur atoms, eliciting fluorescence changes [190], [260], [261]. Benzenesulfonamide has a lower degree of dissociation and higher selectivity than benzenesulfonate, so it is suitable for detecting RSS and RSeS with lower pK
a values [129]. The influence of substituents on the benzene ring also follows the above rules. 2,4-Dinitrobenzenesulfonamide and 2,4-dinitrobenzenesulfonate are the two most commonly used detection groups. Since the NBD group is modified upon analyte-induced dissociation, it produces different fluorescence emissions [208], [209]. Therefore, NBD-O ether can be used to distinguish RSS with different structures but similar pK
a values [210], [211]. Thiolysis of the NBD-N group is H2S-specific, and may be exploited for the development of highly selective fluorescent probes and scavengers for H2S. The active sites of benzoates mainly simulate NCL reaction [221], [222]. In fact, regardless of whether the detection site is thiobenzoate or benzoate, the test substance always forms a new thiolipid with the carboxyl group. For benzoate esters, the exposure of hydroxyl groups of the fluorophore occurs concomitantly with the combination of RSS and benzoic acid [221], [229]. For the active sites of thiobenzoates, due to the powerful quenching effect of sulfur atoms, the thiophenol-containing groups are always displaced, and the fluorophores combine with the analyte to produce fluorescence at different emission wavelengths. Therefore, RSS probes with thiobenzoate as the active site are suitable for distinguishing RSS with different structures based on the ratio of their fluorescences [231], [232], [235]. Interestingly, the same type of detection group responds more rapidly to RSeS than to RSS. Larger conjugated systems or more stable detection groups or active sites can be used to detect RSS with lower pK
a or even RSeS [129]. Some selenium-containing fluorescent probes based on SNAr reaction have not been considered as fluorescent probes for detecting RSeS, but may be potentially useful for this purpose [76], [77], [284]. The introduction of RSS reactive groups (such as Michael acceptors, disulfide bond compounds, etc.) following other mechanisms in the vicinity of the active site (whether fluorophore or detection group) is beneficial for improving the reactivity at this site and the selectivity for the test substance [103], [230], [270], [285]. Bridging the fluorophore and detection group with piperidine has been shown to be helpful for improving the sensitivity of the tested substance and greatly shortens the detection time [250]. In fact, there are many aromatic groups that can be combined with fluorophores and attacked by RSS or RSeS in an SNAr fashion [243], [244], [286]. Some probes containing aromatic groups for detecting ROS or RNS are also potential tools for detecting RSS or RSeS.
The international enthusiasm for developing RSS and RSeS fluorescent probes based on SNAr reactions is very high. Despite significant progress in this area, there are still some challenges that require further research in the design and application of probes. Thus, (1) inexpensive, highly emissive, and highly stable fluorophores are still urgently needed. (2) The development of new sensing mechanisms is crucial, not limited to SNAr. Indeed, SNAr is just a common reaction mechanism inspired by classical organic synthesis literature and various natural products with thiol or selenol inhibitors. (3) Due to the different concentrations of RSS and RSeS in biological environments, the sensing mechanism should be carefully considered when detecting different analytes at the same time. Meanwhile, the influence of the cell microenvironment on the response characteristics of the probe cannot be ignored. (4) In testing certain specific biological samples, it is necessary to fully evaluate the key point of application, such as biological significance, test results visible to the naked eye, test speed, and so on. (5) RSeS is more active than RSS in anti-oxidation, maintaining physiological balance. The demand for RSeS probes operating under physiological conditions is urgent. We hope that high-level research in this area will continue, and eventually provide tools that can image and measure RSS and RSeS concentrations with high accuracy and reproducibility. Multidisciplinary intersection and wide application is the trend in this field. We should cooperate with biologist, environmental protection scholars, food industry employees, and clinical experts to design and develop tools in a way that is useful and applicable to these users. Only then can we generate new biological knowledge through the detection of RSS and RSeS to better understand, diagnose, monitor, and treat diseases.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Coord Chem Rev
PMC7808460,Effect of bilevel continuous positive airway pressure for patients with type II respiratory failure due to acute exacerbation of COPD: A protocol for systematic review and meta-analysis,"The COVID-19 epidemic has again brought respiratory diseases to the forefront. As a representative of respiratory pathology, the incidence of chronic obstructive pulmonary disease (COPD) has been high. Data shows that there are currently more than 600 million people living with COPD in the world, COPD has become the fifth largest burden in the world,[1] and global deaths due to COPD are increasing year-by-year. In 2012, more than 3 million people died of COPD worldwide. It has been predicted that COPD will become the 3rd leading cause of death worldwide by the year 2020.[2–4] COPD is divided into the stable phase and acute exacerbation of COPD (AECOPD),[2] and AECOPD is the critical period in the course of COPD. One study found that the in-hospital mortality rate for AECOPD patients was 11%, and the mortality rate 2 years after discharge was 49%.[5] Due to the impairment of expiratory capacity in AECOPD, CO2 retention can easily lead to type II respiratory failure, which causes not only respiratory acidosis but also rapid loss of lung function. Type II respiratory failure due to AECOPD can greatly increase mortality[6] and puts the patient at severe risk.
Patients with type II respiratory failure due to AECOPD experience deterioration of lung function and retention of CO2; therefore, medication and respiratory support therapy are required. Respiratory support includes oxygen therapy, high-flow oxygen therapy, non-invasive ventilation (NIV), and invasive mechanical ventilation. NIV is the first choice for AECOPD patients without related contraindications because of benefits such as improving gas exchange and reducing the loss of respiratory function.[2] NIV mainly includes 2 modes: continuous positive airway pressure (CPAP) and noninvasive pressure support ventilation (NIPSV). Bi-level continuous positive airway pressure (BIPAP) is based on noninvasive pressure support ventilation in NIV. The BIPAP gas volume varies dynamically in each respiratory cycle.[7] The advantages of BIPAP in patients with type II respiratory failure due to AECOPD are avoidance of repeated inhalation of exhaled gas, reduction of CO2 retention, and correction of acid-base imbalance. BIPAP can fully rest the respiratory muscles to prevent further deterioration of lung function.
In the studies of Carrera,[8] Castillo,[9] and Khilnani,[10] it was found that BIPAP could significantly improve respiratory acidosis and pulmonary function compared with conventional oxygen therapy; however, Barb et al[11] found no significant difference between the 2 methods. At present, there is no corresponding recommendation for BIPAP in type II respiratory failure due to AECOPD in the relevant guidelines.[2,12]
The purpose of this study is to explore the effect of BIPAP on pulmonary function and CO2 retention in patients with respiratory failure due to AECOPD, and to provide reliable evidence for related clinical practice.
We will only choose randomized controlled trials (RCTs); other study designs, including non-randomized controlled trials, will be excluded.
All participants were adults (aged >18 years) meeting the following criteria:
All participants will receive standard treatment, including bronchodilators, glucocorticoids, antibiotics, low flow oxygen therapy, and if necessary respiratory stimulants will be used to treat. The experimental group will receive BIPAP + routine treatment, generally selecting S/T mode. The inspiratory pressure (IPAP) will be greater than the expiratory pressure (EPAP), the oxygen flow rate will be adjusted to ensure an arterial oxygen saturation (SaO2) greater than 90%, and the daily duration of treatment will be more than 5 hours.
These include results of blood gas analysis, including partial pressure of arterial oxygen (PaO2), PaCO2, and pH; intubation rate; and pulmonary function, including forced expiratory volume in 1 second and forced expiratory volume in 1 second/forced vital capacity.[13]
These include heart rate, respiratory rate, hospitalization time, incidence of complications, blood pressure, and mortality.
The search strategy for this study will be applied to 4 Chinese databases: China National Knowledge Infrastructure (CNKI), Wanfang Database, Chinese Science and Technology Journal Database (VIP), and Chinese Biomedical Literature database (SinoMed); and 5 foreign literature databases: PubMed, Cochrane Library, Springer, EBSCO, and Web of Science. All the English and Chinese literature published from inception to October 2020 will be included. The search strategy for PubMed is shown in Table 1, and searches in other databases also follow this search strategy.
The literature will be searched independently by 2 researchers who have participated in a series of evidence-based courses, selecting titles and abstracts according to the inclusion criteria and excluding irrelevant studies. If it is necessary to read the full text to decide whether a study is included, reviews, conference summaries, and studies with incomplete data must be excluded in the process, and if there is a dispute, the decision will be made by a third researcher who has achieved the training qualifications of the Australian JBI Evidence-based Health Care Centre. For questionable data, we will contact the author through e-mail for consultation. The details of research selection are shown in the PRISMA flow diagram (Fig. 1).[14]
Data will be extracted and duplicated by 2 independent researchers. Detailed data and information will be extracted in the following forms: basic information (first author, year of publication, country), type of study, main characteristics of participants (age, course of disease, physiological indicators, sample size), intervention measures (intervention mode, duration of intervention), and main outcome.
If the data are incomplete or missing, we will contact the author by email to gain the information. In the case of unavailable data, we will exclude the study.
Two researchers who attended and graduated from a series of evidence-based courses will independently use the Australian Joanna Briggs Institute Center critical appraisal tool for RCTs[15] to evaluate each of the 13 quality areas included in the literature. These include random grouping, allocation concealment, baseline comparability, subject blind method, intervention blind method, evaluator blind method, full follow-up, comparison of other intervention measures, reliability of evaluation methods, comprehensive result analysis, same evaluation methods, credibility of data analysis methods, and reasonableness of research and design. The quality level of each study will be assigned a grade of A, B, C, or D from high quality to low. Any divergence will be resolved through discussion and negotiation with the third researcher.
Funnel charts will be used to assess the potential for study bias, and the results of the assessment will be explained using Review Manager 5.4 charting.
The Q test will be used to qualitatively determine inter-study heterogeneity; if P ≥ .1, there is no inter-study heterogeneity. For the included study, I2 statistics will be used to quantify the statistical heterogeneity and to evaluate the heterogeneity of the study.
We will use Review Manager 5.4 software for data analysis. For continuous variables, we will calculate the mean difference (MD) when the parameters of ventilator and blood gas analysis equipment are different in the study; we may calculate the standard mean difference with 95% confidence interval (CI). For dichotomous variables, such as intubation rate, the risk ratio with 95% confidence interval will be calculated. When the Q-test result shows P < .1, it indicates inter-study heterogeneity. For the included study, I2 statistics will be used to quantify the statistical heterogeneity. When I2 < 50%, the heterogeneity is considered acceptable, and the fixed effect model will be adopted. When I2 > 50%, the heterogeneity is considered significant, and sensitivity analysis and subgroup analysis to explore the source of heterogeneity is needed. If there is no significant clinical heterogeneity, a random effect model will be used for analysis; otherwise, descriptive analysis will be conducted.
If there is significant heterogeneity between the results, we will conduct a subgroup analysis of BIPAP inspiratory pressure (IPAP), time point of the measured results after intervention (<1 day vs >1 day), duration of intervention (<15 hour/day vs >15 hour/day), and age of the participants (<60 vs >60 years).[2]
We will rule out the combined study one-by-one for sensitivity analysis to observe whether there is a significant change in the comprehensive results. If so, the removed study may affect the overall synthesis results, and we will re-evaluate the results carefully for merging.
Meta-analysis is an accumulation of multiple trial results, but it can increase random errors and exaggerate the efficacy of intervention. Trial sequential analysis is used for related verification.[16] This study will use TSA v0.9, developed by the CTU of the Copenhagen Clinical Trial Center, to complete the analysis. Comparing the sample size with the amount of information is required to determine whether the sample size is illustrative. The influence of random error is explained by judging the boundary value of trial sequential analysis formed by correction and the significant horizontal line and the cumulative Z-value curve of the meta-analysis.
We will use GRADE (Grading of Recommendations, Assessment, Development, and Evaluation) to evaluate the quality of this study.[17] According to GRADE, we will divide the results into 4 levels: high, medium, low, and very low, so as to evaluate the evidence quality of the study and reflect whether the study can provide reliable recommendations.
Systematic reviews do not require ethical approval because individual data are not used. The results of this study will provide a reliable basis for the application of BIPAP in patients with type 2 respiratory failure due to AECOPD, and are also of great significance to clinical practice and research.
The literature on the intervention effect of BIPAP in patients with type II respiratory failure due to AECOPD is controversial. Studies have provided evidence that early use of BIPAP can effectively alleviate deterioration and speed recovery of patients with type II respiratory failure due to AECOPD.[8–10] However, some studies have shown that BIPAP is less effective than conventional therapy in these patients.[11] This meta-analysis combines available evidence based on the widespread use of BIPAP in these patients to measure the degree of remission attributable to intervention with BIPAP. It will determine whether the existing BIPAP non-invasive ventilation techniques are more effective and reliable in patients with type II respiratory failure due to AECOPD.
This meta-analysis attempts to compare the differences in physiological indexes among participants at different time points after BIPAP intervention. For example, the studies of the Collaborative Research Group[18] and Carrera[8] measured outcome indexes such as blood gas values <24 hours and ≥24 hours after BIPAP intervention. In addition, the meta-analysis included some RCTs with innovative techniques, such as the newly designed sham BIPAP ventilator in the Carrera study,[8] which was provided to the control group for intervention. The physical appearance of the sham BIPAP ventilator is the same as that of BIPAP, but it can only provide oxygen therapy (which has been verified by experiments). This design is different from the conventional intervention in the control group. It can make double blinding more achievable in most studies.
Studies have shown that not all modes of NIV are suitable for respiratory failure due to AECOPD.[19–21] BIPAP is based on the NIPSV mode in NIV. The gas volume of BIPAP is dynamic,[7] and its inspiratory positive airway pressure (IPAP) can overcome airway resistance and increase alveolar ventilation. Expiratory positive airway pressure (EPAP) promotes CO2 exhalation for patients with respiratory failure due to AECOPD.[22] However, there are no official recommendations in this regard; therefore, this study will attempt to explore the effect of BIPAP on pulmonary function and CO2 retention in patients with type II respiratory failure due to AECOPD, so as to provide a reliable basis for clinical application.
Conceptualization: Wenzhe Teng, Hu Chen, Kangyao Cheng.
Data curation: Wenzhe Teng, Hu Chen, Siyao Shi.
Formal analysis: Wenzhe Teng.
Funding acquisition: Kangyao Cheng.
Investigation: Hu Chen, Siyao Shi.
Literature retrieval: Wenzhe Teng, Hu Chen and Siyao Shi.
Methodology: Kangyao Cheng.
Resources: Wenzhe Teng.
Supervision: Yin Wang, Kangyao Cheng.
Validation: Wenzhe Teng.
Visualization: Wenzhe Teng.
Writing – original draft: Wenzhe Teng.
Writing – review & editing: Wenzhe Teng.",Medicine (Baltimore)
PMC7808498,The effects of health-preserving sports on the treatment of COVID-19: A protocol for systematic review,"In December 2019, some medical institutions have appeared unknown causes of pneumonia patients in Wuhan. Influenza and related diseases were monitored continuously in Wuhan, and 27 cases of viral pneumonia were found, all of which were diagnosed as viral pneumonia/pulmonary infection. December 31, 2019, the expert group of National Health Commission of the People's Republic of China arrived in Wuhan to carry out virus typing detection, isolation treatment, final disinfection, and so on. January 30, 2020, WHO recommends “2019-nCoV” as a temporary name for the virus (“n” = new disease, “CoV” = coronavirus), and declared the novel coronavirus outbreak a Public Health Emergency of International Concern (PHEIC), WHO's highest level of alarm. February 11, 2020, WHO announced that the disease caused by the novel coronavirus would be named COVID-19 (Corona Virus Disease 2019).[1] March 11, 2020, COVID-19 identified by the WHO have pandemic characteristics. By November 19, 2020, globally have been 55,928,327 confirmed cases of COVID-19, including 1,344,003 deaths, reported to WHO.[2]
COVID-19 is an infection caused by the SARS-CoV-2 virus, SARS-CoV-2 is one of the coronaviruses, this virus was transmissible from person to person,[3] people susceptible to SARS-COV-2 include of all ages.[4] The mean incubation period is about 3 to 9 days, with a range between 0 and 24 days.[5] infection can be spread by asymptomatic, presymptomatic, and symptomatic carriers,[6] some studies have pointed out identified five potential transmission modes of COVID-19 including airborne, droplet, contact with contaminated surfaces, oral and fecal secretions,[7] and attention to address the significance of aerosols with important implications for public health protection.[8] The main clinical symptoms of COVID-19 patients include symptoms include fever, cough, fatigue, pneumonia, headache, diarrhea, hemoptysis, and dyspnea,[9] some patients also report gastrointestinal symptoms such as diarrhea, vomiting, and abdominal pain.[10] SARS-CoV-2 are widely acknowledged as severe traumatic events that impose threats not only because of physical concerns but also because of the psychological distress of infected patients.[11]
Exercise is known to mitigate many of the identified side effects from the pharmaceutical agents being trialled but has not yet been considered as part of management for COVID-19.[12] In China, there are many Health-Preserving Sports as a common way for people to exercise, such as Six-Character Tactic, Tai Chi, Five-Animal Exercise, Eight-Section Brocade, and Muscle-Bone Strengthening. Tai Chi, which combines psychological treatment and physical exercise and requires no special equipment, is widely practiced in China and is becoming increasingly popular in the rest of the world.[13] Five-Animal Exercise as the branch of traditional Chinese medicine, is a popular mind-body exercise in China and shown to improve emotional well being.[14] A study present a modified version of rehabilitation exercises based on the underlying mechanism of the disease to mild cases of COVID-19, the modified rehabilitation exercises were retrieved from the Eight-Section Brocade, and are specifically designed for rehabilitation of COVID-19 patients at home or health facilities.[15] However, there is no a systematic study to show the efficacy Health-Preserving Sports on COVID-19 patients. Therefore, this study aims to provide a method to assess the efficacy and safety of Health-Preserving Sports for the prognosis of COVID-19.
This systematic review protocol has been registered in International Prospective Register of Systematic Reviews (PROSPERO), registration number is CRD420202195260.
We will include researches related to Health-Preserving Sports of patients suffering from COVID-19. Studies will be selected according to the criteria outlined below:
CBA studies will be included only if there are at least two intervention sites and two control sites. We will exclude cross-sectional studies, case series, and case reports.
Patients diagnosed with COVID-19 of all ages and racial groups will be included, regardless of their sex, education level, or economic status. Postoperative infections, psychopaths, patients with severe pneumonia or other reasons who cannot exercise will not be included.
The studies at least one of the groups received Health-Preserving Sports intervention will be included, which can be carried out alone, or combined with other kinds of therapies. Health-Preserving Sports methods referred to in this article include Six-Character Tactic, Tai Chi, Five-Animal Exercise, Eight-Section Brocade and Muscle-Bone Strengthening Exercise. Excluding Boxing, Sanda, Mixed Martial Arts (MMA), and other Martial Arts Routines.
Comparisons will include retreats, drug therapy alone, and so on. In addition, the study will include studies that compare the use of Health-Preserving Sports in combination with another treatment vs Health-Preserving Sports alone, or that compare the use of Health-Preserving Sports in combination with another treatment versus the use of other treatments alone.
Primary outcomes: The disappearance of the main symptoms (including fever, cough, Nucleic acid test, temperature recovery time) and indicators of body function (blood pressure, heart rate, body composition, muscle strength, range of motion of the joints, Activity of Daily Living), the return of white blood cell count to normal.
Secondary outcomes: The disappearance of the accompanying symptoms (such as myalgia, stuffiness, runny nose, headache, chest distress, nausea, vomiting, and diarrhea); the results of COVID-19 nucleic acid test are negative on 2 consecutive occasions (not on the same day), CT image improvement, and so on.
The following electronic databases will be searched: PubMed, the Cochrane Central Register of Controlled Trials (CENTRAL), Excerpta Medica Database (EMBASE), MEDLINE, Web of Science, China National Knowledge Infrastructure Database (CNKI), Chinese Biomedical Literature Database, China Science and Technology Journal Database and Wan-Fang Database. Search dates: from inception dates to December 2020.
The search terms on PubMed are as follows: “Health-Preserving Sports” (and such as “Six-Character Tactic” OR “Tai Chi” OR “Five-Animal Exercise” OR “Eight-Section Brocade” OR “Muscle-Bone Strengthening Exercise”); “COVID-19” OR “Corona Virus Disease 2019” OR “Novel Corona Virus” OR “2019-nCoV”; “convalescence” OR “rehabilitation” OR “recovery”; “randomized controlled trial” OR “randomized” OR “randomly” OR “clinical trial.” According to the characteristics of the database, the comprehensive retrieval of the combined of Medical Subject Headings (MeSH) and text words was carried out. The full search strategy for PubMed is provided in Table 1, the same strategies are used in other electronic databases.
Before searching the literature, all reviewers will discuss and determine the screening criteria. After the screening requirements are clearly defined, the 2 reviewers will independently review and screen the titles and abstracts yielded by the search against the inclusion criteria, and then excluded some duplicate studies or studies with incomplete information. After literature retrieval, the literature records will be imported into EndNoteX9 software for management. Any inconsistency is resolved by discussing with the third reviewer. If the full text is not available, we will try to contact the appropriate author. We chose the PRISMA flow chart to show the process of selecting literature for the entire study (Fig. 1).
In this protocol, we will use 95% confidence interval (CI) risk ratio (RR) to rigorously analyze the dichotomous data. And for the continuous data, mean difference (MD) or standard MD (SMD) is used to measure the efficacy of 95% CI.
The data will be extracted and recorded onto an Excel file, will include at least the following items: The title of the first author, publication journal name, year of publication, study sample size, intervention methods, intervention results, bias risk assessment, and findings. The result will be cross-checked by two reviewers, any disagreement will be resolved by consensus, and any persistent disagreement will be arbitrated by a third reviewer. We will contact the corresponding authors by telephone or email for additional information if necessary. All data will be analyzed by the Review Manager software (RevMan V.5.3).
Two reviewers will use the Cochrane Handbook for Systematic Reviews of Interventions to assess the methodological quality of each trial. The risk of bias was evaluated for each study by random sequence generation, allocation concealment, blinding of participants and personnel, blinding of outcome assessment, incomplete outcome data, selective reporting, and other sources of bias. A judgment as to the possible risk of bias on each of the domains will be made from the extracted information; the risk of bias is evaluated at 3 levels: low risk, high risk, and unclear risk.
We will try our best to ensure the integrity of the data. When there are missing data, we will attempt to obtain missing data by contacting the corresponding author. If the corresponding author cannot be contacted, we will remove the experiment with incomplete data.
Each outcome will be calculated and combined using the RevMan 5.3. Specific implementation was based on the current version of the Cochrane Handbook for Systematic Reviews of Interventions. If tests of heterogeneity are not significant, the Mantel-Haenszel method will be chosen for fixed effect model, and if statistical heterogeneity is observed (I2 ≥ 50% or P < .1), the random effects model will be used. If heterogeneity is substantial, we will perform a narrative, qualitative summary.
If data are available, we will conduct a subgroup analysis according to different Patients characteristics, intervention method (Six-Character Tactic, Tai Chi, Five-Animal Exercise, Eight-Section Brocade, Muscle-Bone Strengthening Exercise), duration of treatment, and outcome measures.
Sensitivity analysis is used to analyze research quality, intervention method, publishing type, and so on. The trials with quality defects will be excluded to ensure the stability of the analysis results.
We will use the evidence quality rating method to evaluate the results obtained from this analysis. Five factors: bias, inconsistent, inaccurate, indirect, and publication bias; 4 evaluation levels: high, medium, low, and very low.
The content of this article does not involve moral approval or ethical review because it is based on published literature. The results will be submitted to journal or conferences for publication and information sharing.
This article mainly describes how to systematically review the therapeutic effect of Health-Preserving Sports on COVID-19, which mainly includes: Inclusion criteria, Data sources, Data collection, analysis, and so on. This study can provide some methods guidance for other scholars to study the prevention and treatment effect of Health-Preserving Sports on COVID-19 in the future. However, due to some limitations, also have shortcomings of this study.
Conceptualization: Yu Ji.
Data curation: Dandan Song, Hezhi Liu, Li Chen.
Formal analysis: Yu Ji, Guorong Qiu, Dandan Song.
Funding acquisition: Yu Ji.
Methodology: Dandan Song.
Software: Guorong Qiu, Hezhi Liu, Li Chen.
Writing – original draft: Yu Ji.
Writing – review & editing: Guorong Qiu, Dandan Song.",Medicine (Baltimore)
PMC7808500,"Medical treatment of 55 patients with COVID-19 from seven cities in northeast China who fully recovered: A single-center, retrospective, observational study","Coronavirus disease 2019 (COVID-19) is highly contagious and spreads rapidly through human-to-human transmission.[1] The pathogenesis of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection remains unclear, and effective drugs and regimens for the treatment of COVID-19 have not been identified.[2,3] In China, nationally recommended trial-based antiviral and other symptom-managing drugs are administered. As such, a retrospective review of the types and doses of clinical drugs, courses of treatment, and intervention times in patients cured of COVID-19 would be highly informative for treating patients with this disease worldwide.
Data on medications that were administered to patients who ultimately recovered from COVID-19 are scarce but crucial for clinicians. To that end, we aimed to investigate the administered medications and intervention times for 55 patients confirmed to have COVID-19 who completely recovered after being transferred to Shenyang Sixth People's Hospital, a designated treatment facility in Liaoning Province.
We performed a single-center, retrospective, and observational study at Shenyang Sixth People's Hospital (Shenyang, Liaoning, China), a government-designated centralized medical facility for the treatment of patients with COVID-19 in Liaoning Province. All patients were from hospitals that received patients for initial COVID-19 treatment in 7 cities in Liaoning Province, including Shenyang Chest Hospital. According to the Interim Guidelines issued by the World Health Organization (WHO) on January 12, 2020,[4] patient throat swabs and sputum samples were collected. Real-time reverse transcription polymerase chain reaction (RT-PCR) was used to detect the nucleic acid of SARS-CoV-2. We included all 55 consecutive patients with COVID-19 who were treated between January 20 and March 15, 2020; none were excluded. Patients were categorized into 2 groups: the “mild” group (with mild/moderate symptoms) and the “severe” group (those with severe/critical symptoms). These classifications were according to the criteria stated in the COVID-19 Diagnosis and Treatment Plan issued by the National Health Commission of the People's Republic of China.[3]
The study was reviewed and approved by the Ethics Committee of Shenyang Chest Hospital (approval number: KYXM-2020-001-01) and was also documented by the Ethics Committee of the Shenyang Sixth People's Hospital. The requirement for written informed consent was waived owing to the rapid development of the infectious COVID-19 disease.
We reviewed clinical manifestations as well as laboratory and radiological findings of all enrolled patients and collected data that included age, sex, epidemiological history, past history, symptoms, complications, laboratory indicators, therapeutic drugs, and intervention time.
The endpoint was the total patient recovery rate; individuals who met the discharge criteria were included in the “recovered” statistics. These discharge criteria were consistent with the China's COVID-19 Diagnosis and Treatment Plan[3] as follows:
Given that the purpose of this study was to examine the clinical characteristics and drug administration data for patients with COVID-19, no formal hypothesis was established with which to calculate the optimal sample size. Continuous variables are expressed as means (standard deviations) or medians (interquartile ranges [IQRs]), while categorical variables are denoted as percentages.
The mean age of the 55 patients in our study was 46.8 years. Among them, 30 (54.55%) were male, 28 (50.91%) had been in Wuhan/Hubei, and 19 (34.55%) were complicated with other chronic diseases. Lung computed tomography scans showed local or diffuse infiltration shadows in 54 patients (98.18%), whereas the remaining patients (1.82%) had no inflammatory changes. There were 47 patients (85.45%) in the mild group and 8 (14.55%) in the severe group (Table 1). The most common symptoms of COVID-19 were fever (32 patients, 58.18%) and cough (27 patients, 49.09%). Seventeen patients (30.91%) were complicated with liver function impairment, 15 (27.27%) with hypoxemia, and 2 (3.64%) with acute respiratory distress syndrome (ARDS) (Table 2). The white blood cell counts, lymphocyte counts, and percentage of lymphocyte counts of patients in the mild group were in the normal range, although C-reactive protein levels (15.73 mg/L) were elevated. In the severe group, however, lymphocyte counts (0.78 × 109 /L) and the percentage of lymphocytes (12.30%) were suppressed, while C-reactive protein levels (47.21 mg/L) were elevated (Table 2). In the mild and severe groups, the median durations for the lymphocyte counts to return to normal were 11 and 9 days, respectively; for those with lung shadows, marked improvements took on average 4 and 6 days, respectively. The time it took to achieve a negative COVID-19 RNA conversion was 12 and 19 days, respectively (Fig. 1).
Fifty-three patients (96.36%) received antiviral therapy for a median time of 14 days (IQR 12–18 days), while 2 patients (3.64%) were not administered antiviral drugs (1 was a pregnant woman and the other had asymptomatic infection). Among those who received antiviral drugs, 45 were in the mild group (95.74% of this group); their median treatment time was 14 days (IQR 12–17 days) and 17 of them (37.78%) were treated with umifenovir, 17 (37.78%) with umifenovir + lopinavir/ritonavir, and 5 (11.11%) with lopinavir/ritonavir. Moreover, all 8 patients in the severe group received antiviral drugs, with a median treatment time of 17.5 days (IQR 11–19.25 days). Four patients in the severe groups (50%) were treated with lopinavir/ritonavir, 3 (37.50%) with umifenovir + lopinavir/ritonavir, and 1 (12.50%) with umifenovir. Twenty-nine patients (52.72%) were treated with antibiotics for a median time of 10 days (IQR 8.5–15); 19 of these 29 patients (65.52%) were treated with moxifloxacin while 3 (10.34%) received linezolid. Among the patients treated with antibiotics, 21 were in the mild group (44.68% of this group); their median treatment time was 13.5 days (IQR 5.75–9.25 days) and 15 (71.42%) were treated with moxifloxacin while 2 (9.52%) received carrimycin. The remaining antibiotic recipients included all the 8 patients in the severe group (100%), with a median treatment time of 9 days (IQR 9.75–15.25); 4 patients (50%) were treated with moxifloxacin and 2 (25%) with linezolid. Seven patients (12.72%) were treated with glucocorticoids. Among the 7, 3 (6.38%) were in the mild group and 4 (50%) were in the severe group. Twenty of 55 patients (36.36%) received recombinant human interferon alpha-1b, including 17 patients (36.17%) in the mild group and 3 patients (37.50%) in the severe group; 9 (16.36%) were treated with thymalfasin, including 6 (12.76%) in the mild group and 3 (37.50%) in the severe group (Figs. 1–3).
Patients with COVID-19 in the present study achieved a 100% recovery rate. Thus far, effective antiviral drugs to treat COVID-19 have not been identified, and opinions on whether antiviral drugs should even be used to treat COVID-19 differ.[2] The National Health Commission of the People's Republic of China has repeatedly issued and revised the COVID-19 Diagnosis and Treatment Plan, which recommends antiviral drugs such as lopinavir/ritonavir, ribavirin, umifenovir, and alpha-interferon.[3] In the present study, 53 patients (96.36%) received antiviral therapy early in the course of their disease for a median time of 14 days (IQR 12–18 days). In the mild group, 17 (37.78%) of the patients were treated with umifenovir (0.2 g orally once every 8 hours) and another 17 (37.78%) received a combination of umifenovir (0.2 g orally once every 8 hours) + lopinavir/ritonavir (400 mg/100 mg orally once every 12 hours) for a median time of 14 days (IQR 12–17 days). Liu et al[5] described the effectiveness of umifenovir in the treatment of emerging respiratory infectious diseases such as influenza A (H1N1). Ji et al[6] also confirmed the efficacy of umifenovir for the treatment of coronavirus infections in an in vitro study. Our present findings indicated that umifenovir might benefit patients with mild symptoms. In the severe group, 8 patients (100%) were administered antiviral drugs for a median time of 17.50 days (IQR 11–19.25 days); 4 (50%) were treated with lopinavir/ritonavir and 3 (37.50%) received a combination of lopinavir/ritonavir regimen. Lopinavir alone has poor bioavailability. Ritonavir can increase the plasma concentration of lopinavir by inhibiting CYP3A-mediated degradation of lopinavir in the liver.[7] Nukoolkarn et al[8] observed through molecular dynamics simulation studies that lopinavir/ritonavir can combine with the main protease 3CLpro of the severe acute respiratory syndrome (SARS) virus to achieve anti-coronavirus effects, but their affinity is not obvious. Chu et al[9] found that lopinavir/ritonavir could inhibit coronavirus replication to some extent, thereby reducing the risk of ARDS or death in patients with SARS. Chan et al[10] confirmed the efficacy of the combination of lopinavir/ritonavir and interferon-β for the treatment of Middle East Respiratory Syndrome Coronavirus (MERS-CoV) infection in animal models. In the present study, the use of lopinavir/ritonavir in the severe group was apparently effective in mitigating fever symptoms, promoting lung shadow absorption, and rapidly restoring the number of lymphocytes. The efficacy and safety of lopinavir/ritonavir are expected to be verified in future clinical randomized controlled trials. Ribavirin and interferon are also mentioned in the COVID-19 Diagnosis and Treatment Plan[3]; in the present study, 4 patients in the mild group (7.27%) were administered ribavirin combined with antiviral therapy. Nucleoside analogs theoretically ought to possess anti-coronavirus activity to a certain extent[11]; however, ribavirin was found to have a minimal antiviral effect against coronavirus in vitro.[12] In the present study, 20 patients received aerosol inhalation of alpha-interferon soon after diagnosis (50 μg, twice per day). A retrospective study of patients with Middle East Respiratory Syndrome (MERS) in 2019 showed that interferon did not accelerate virus clearance,[13] while a study of patients with SARS showed that alpha-interferon did not improve the patients’ prognosis.[14] In the present study, a small number of patients were treated with ribavirin, and alpha-interferon was simply used to assist aerosol inhalation. Therefore, the usefulness of these 2 drugs for patients with COVID-19 is difficult to evaluate.
In terms of antimicrobial use, the WHO recommends empirical antimicrobial therapy based on the clinical diagnosis.[4] China's COVID-19 Diagnosis and Treatment Plan[3] also emphasizes the avoidance of blind or inappropriate use of antibiotics. Kim et al[15] found that 38% of their patients with H1N1 infection developed secondary bacterial pneumonia 48 hours after admission to the intensive care unit, and that early empirical treatment helped improve their prognosis. Experience with SARS[16] and MERS[17] also suggests that prophylactic antibiotics may be appropriate after assessing the risk of co-infection in patients with severe symptoms.
Bacterial infection rates after SARS-CoV-2 infection remain unclear. In the present study, among 21 patients received antibiotics in the mild group, 12 (57.14%) patients were administered prophylactic drugs and 9 (42.86%) underwent empirical treatment (mainly with single-antibiotic moxifloxacin 400 mg ivgtt, qd); the possibility of atypical pathogenic bacteria (such as Mycoplasma pneumoniae) related infections was also considered. Epidemiological survey results in China show that M pneumoniae and Streptococcus pneumoniae are the main pathogens of adult community-acquired pneumonia in China. Because of their high resistance to macrolides, our guidelines recommend respiratory quinolone antibiotics usage.[18] In the severe group, 8 patients received antibiotics, 5 (62.50%) patients were administered prophylactic medication, and 3 (37.50%) received empirical treatment. Prophylactic medication was administered to comorbid patients with diabetes, chronic lung diseases, and ARDS who were at the early stage of receiving glucocorticoids. In the severe group, patients with a relatively high risk of infection by drug-resistant bacteria (1 case each of prehospital antibacterial treatment ineffectiveness with ARDS, ventilator-associated pneumonia, and chronic structural lung disease with ARDS) were treated with broad-spectrum antibiotics. In consideration of influenza virus infection, Staphylococcus aureus and S pneumoniae are the main infections.[19,20] The treatment plan is based on linezolid combined with cefoperazone and sulbactam or imipenem and cilastatin. One patient with ventilator-associated pneumonia had multi-drug-resistant Klebsiella pneumoniae in sputum culture and was administered meropenem. Gradually treatment was downgraded after symptoms improved. No evidence of secondary bacterial infection was observed in patients who received prophylactic medication. The present study suggested that early and prudent use of prophylactic antibiotics in patients with COVID-19 may help reduce the risk of co-bacterial infections. Empirical anti-infective treatment for severely ill patients under the pressure of high risk of drug resistance may benefit the prognosis of the disease.
The WHO does not recommend the systematic use of glucocorticoids for viral pneumonia or concurrent ARDS.[4] China's COVID-19 Diagnosis and Treatment Plan recommends hormones as adjuvant therapy.[3] In the present study, 48 (87.28%) patients did not receive glucocorticoids, while 7 patients (12.72%) received such agents during the rapid progression of their disease (i.e., respiratory failure and large area exudation in both lungs). Glucocorticoids were administered to inhibit inflammation and improve oxygenation at a dose of Methylprednisolone 1 to 2 mg/kg/day. Treatment was gradually reduced over 5 to 7 days until discontinuation; and they showed no adverse reactions. As such, glucocorticoids appear to be unnecessary for patients with mild manifestations of COVID-19, while their use in treating patients with severe disease is controversial.
Thymosin α1 is a thymosin hormone responsible for restoring the homeostasis of the immune system. It plays a key role in the development of thymocytes, as well as increases the resistance of thymocytes to glucocorticoid-induced death. There is evidence that thymosin α1 is used as an immune enhancer for SARS patients and can effectively control the spread of infection. According to the COVID19 treatment guidelines of the National Health Commission of China, the use of thymosin α1 may be an alternative treatment option for COVID-19 patients with low lymphocyte count or immunodeficiency.[21] There are currently research reports that Thymosin α1 (Tα1) can restore reduced lymphocytes and improve the function of failed T cells, thereby reducing the mortality of severe COVID-19,[22] In the present study, 9 (16.36%) patients were administered thymalfasin. Thymus Faxin is a chemically synthesized drug, similar to the human body's natural thymosin α1 in chemical structure and spatial structure with potential clinical application. This notion requires further clinical observation and study. While high-flow oxygen therapy, invasive mechanical ventilation, and extracorporeal membrane oxygenation were provided to patients in the present study, their use was not investigated.
Our findings suggest that, while specific antiviral drugs are yet to be developed, currently available antiviral agents should be considered when treating patients with COVID-19. The prophylactic administration of single antiviral drugs to patients with severe symptoms, as well as to a proportion of those with mild manifestations, may help reduce the risk of co-infection. However, the use of glucocorticoids and immunomodulators needs further study.
Our study had some limitations given its single-center, retrospective, and observational nature. Owing to its small sample size, only descriptive data were available, and no statistical analyses were performed. Hence, randomized, double-blind, and controlled trials remain necessary for more accurate conclusions. Nevertheless, our data ought to provide helpful preliminary information at this stage of the COVID-19 pandemic.
We thank all patients involved in the study. We would like to thank Editage (www.editage.cn) for English language editing.
Yu Chen and Yongyu Liu designed the study. Chang Liu and Na Li were responsible for the literature search. Lichao Fan and Ye Gu collected the epidemiological and clinical data. Huan Liu and Lichao Fan processed statistical data, Huan Liu and Yu Chen drafted the manuscript. Yongyu Liu revised the final manuscript.
Conceptualization: Yu Chen, Huan Liu, Yongyu Liu.
Data curation: Na Li, Chang Liu.
Formal analysis: Lichao Fan.
Funding acquisition: Yu Chen.
Investigation: Huan Liu.
Methodology: Lichao Fan, Chang Liu.
Project administration: Ye Gu, Yongyu Liu.
Resources: Ye Gu.
Software: Lichao Fan, Na Li.
Supervision: Na Li, Yongyu Liu.
Validation: Huan Liu.
Writing – original draft: Yu Chen, Huan Liu, Yongyu Liu.
Writing – review & editing: Yu Chen, Chang Liu, Yongyu Liu.",Medicine (Baltimore)
PMC7444934,Applications of an electronic nose in the prediction of oxidative stability of stored biodiesel derived from soybean and waste cooking oil,"The steady increase in demand for energy has been driven by the rapid growth in manufacturing industry, migration to cities and transportation services, but >80% of global energy consumption still depends on fossil fuels [1]. According to the International Energy Outlook report of 2016 [2], the increase in consumption of liquid fuels by services relating to the movement of people and goods is expected to average around 1.1% per year for the period 2012–2040 and to account for some 62% of the total increase in usage of these fuels. This rate of growth in the consumption of liquid fossil fuels is considered unacceptable since depletion of fossil energy reserves on such a scale would incur an enormous environmental cost. In addition, the combustion of liquid fossil fuel emits harmful pollutants, such as nitrogen oxides and ultra-fine particles, together with greenhouse gases including methane, carbon dioxide, and carbon monoxide. It is of note that the transportation sector is already responsible for approximately 22% of total greenhouse gases emissions worldwide [3], [4]. Although the use of liquid fuel fell dramatically during the Covid-19 pandemic of 2020, the expectation is that consumption will return to pre-lockdown levels within 2 to 3 years. It is worth noting, however, that the equally dramatic decrease in air pollution in most large cities recorded during the quarantine measures [5] is certain to increase the demand for renewable energy sources to replace petrol and diesel.
Nevertheless, the production of any substitute fuel must be technically practical, environmentally sustainable and economically viable [3]. In this context, biodiesel has an important role to play in the provision of an alternative fuel for the future. The production of biodiesel from oil crops and animal fats represents a significant technological advance, and the use of the fuel either alone or blended with petrodiesel has been encouraged and adopted by many countries, most especially by members of the Organization for Economic Cooperation and Development [6]. In Brazil, the production, transportation, storage and marketing of biodiesel must comply with the specifications issued by the Brazilian Petroleum Authority (Agência Nacional do Petróleo, Gas Natural e Biocombustíveis; ANP) [7]. Currently, petrodiesel must contain at least 12% biodiesel (blend B12), but this percentage is expected to increase year-on-year [8].
Waste cooking oil (WCO) is a promising feedstock for biodiesel production because the material is cheap and readily available, and its use not only avoids an oil extraction process but also represents an appropriate destination for a waste product that is often discarded inadequately with unfortunate environmental consequences [9]. The physicochemical characteristics of WCOs depend on a number of factors, including the origin of the oil, the length of time and the temperature of the frying process, the type of food cooked, the time and conditions of storage of the oil and the extent of exposure to air. Many of these factors also impact upon the properties of the final biodiesel product. For example, the amount of water released by frying foods at high temperatures influences the concentration of free fatty acids (FFAs) present and, subsequently, the occurrence of parallel reactions during transesterification. Moreover, the removal of any excess FFAs requires additional purification steps that reflect in the final cost of the biodiesel [1], [10], [11].
Despite many advantages, biodiesel and its blends with petrodiesel exhibit poor oxidative stability during handling and storage. Fuel stability, defined as resistance to degradation, is a key parameter in establishing the quality of biodiesel upon which engine performance depends [12]. Several techniques are available for evaluating, or even predicting, the quality and oxidative stability of biofuels, including thermogravimetric analysis and the PetroOXY and Rancimat approaches. However, some of the methods are not conclusive when used alone, while those that provide more accurate results tend to be expensive and time-consuming [13]. It is, therefore, important to develop and validate accurate, affordable and rapid methods of analysis of biodiesel, particularly in a country such as Brazil that depends on an efficient logistic network to guarantee the supply of quality fuel throughout its extensive territory. In addition, the large variation in climate and the diversity of raw materials across the country render the evaluation of quality and stability of biofuel even more complex [14].
An electronic nose (or e-nose) is a multisensory system that can analyze the volatile components in the headspace of a sample. E-noses have found wide application in the food and beverage industries, in agriculture and forestry, in medicine and health-care, and in military and civilian security systems [15], [16]. However, application of this technology to the characterization of biodiesel is in its infancy, even though progress in the field would be very especially important for biodiesel producers, distributors and retail outlets. In light of the above, the objectives of this study were: (i) to assess the physicochemical characteristics of fresh and stored biodiesel derived from WCOs using standard methods, (ii) to investigate the oxidative stability of WCO-biodiesel samples using an e-nose with a 32-sensor array, (iii) to establish the reliability of an e-nose based model in predicting oxidative stability at storage sites.
In order to show that is possible to work with blends, samples of WCO (n = 6) were supplied by local restaurants (Lorena, SP, Brazil), while commercial refined soybean oil Liza™ (SBO; Grupo Cargill, São Paulo, Brazil) was used as control. Solid impurities were removed from WCO samples by vacuum filtration prior to analysis. Each of the WCO samples was analyzed separately according to the methods described in Section 2.4. and the results expressed as mean ± standard deviation of the six samples.
Based on the acid value of the WCO and SBO feedstocks, biodiesel samples were synthesized by the usual transesterification reaction in the presence of homogeneous alkaline catalyst [17], [18]. Potassium hydroxide (1% of the mass of oil) was dissolved in that amount of ethanol required to give a final molar ratio of 9:1 (alcohol: oil) and the solution added to a jacketed batch reactor containing WCO or SBO preheated to the reaction temperature (60 °C). The reaction mixture was left for 2 h under constant stirring (500 rpm), following which the products were transferred to separating funnels and washed with portions of distilled water preheated at 60 °C to allow the separation of biodiesel (upper phase) from glycerol (lower phase). The pH of the residual water from each of the biodiesel washings was monitored in order to determine the stage at which all remaining catalyst had been removed. The biodiesel was submitted to rotary evaporation at 80 °C for 40 min and dried over anhydrous sodium sulfate [19].
Biodiesel products were homogenized and distributed in equal aliquots between 60 mL flasks made of either AISI 1020 carbon steel or high density polyethylene (HDPE), these being the materials normally used in the fabrication of storage tanks for commercial biodiesel [20], [21]. Flasks were closed with caps fitted with nylon protectors to allow gas exchange with the environment and stored for 30 or 60 days at room temperature or under conditions of accelerated degradation at 43 °C [22]. After the storage period the samples were hermetically closed until analysis.
Acid and peroxide values were determined in triplicate according to the methods described by the Association of Official Analytical Chemists [23]. Densities of 2 mL samples were recorded at 20 °C using a portable digital density meter model DMA 35 N EX (Anton Paar, Graz, Austria), while the absolute viscosities of 1 mL samples were established as a function of shear rate at 40 °C using a model LVDV-IIIU digital viscometer (Brookfield, Harlow, United Kingdom) with CP-42 cone. Water content was determined in duplicate according to ASTM D6304-00 [24] using a model AKF5000 Coulometric Karl Fischer Titrator (Koehler Instrument Company, Holtsville, NY, USA). Color was evaluated at 25 °C according to the CIELAB color space system using a HunterLab (Reston, VA, USA) ColorQuest XE bench top spectrophotometer and EasyMatch QC software.
Fatty acids in oil samples were assessed as their methyl esters according to the method described by Carvalho et al. [25] using a Varian CP-380 gas chromatograph (Agilent Technologies, Santa Clara, CA, USA) equipped with a CP 8410 autosampler, a flame ionization detector and a TRACE™ TR-FAME capillary column.
Iodine values of biodiesel samples were determined in triplicate using the Hübl’s method [26], while ester content was established as described by Paiva et al. [27] from nuclear magnetic resonance spectra acquired with a Varian (Agilent Technologies) MercuryPlus 300 MHz spectrometer.
Oxidative stabilities of oils and biodiesels were assessed in duplicate using a Metrohm Rancimat model 873 instrument (Herisau, Switzerland) in which the sample is exposed to a continuous air flow at a constant temperature of 110 °C. Fatty acids and their esters are oxidized to peroxides (primary oxidation products) and subsequently to low molecular weight volatile organic compounds (VOCs), typically comprising alcohols, aldehydes and carboxylic acids (secondary oxidation products), all of which are transported in the air flow to a measuring vessel where electrical conductivity is recorded automatically. The time that elapses until secondary oxidation products are detected is known as the induction time and is a measure of the oxidation stability of the sample [28], [29]. This procedure is in accordance with ANP regulations and European Standard EN 14112 [30], [31].
The olfactory profiles of fresh WCO-biodiesels (n = 6) and SBO-biodiesel (n = 1) and of samples that had been stored for 30 or 60 days in two types of container at room temperature or at 43 °C were determined using a Sensigent (Baldwin Park, CA, USA) Cyranose® 320 chemical vapor-sensing device. This instrument comprises an array of 32 thin-film nanocomposite sensors (NoseChip® array) and employs algorithms to detect VOCs based on variations in electrical resistance of the sensors. Prior to analysis, the samples of biodiesel were stabilized at 23 °C and ten replicates of each sample were analyzed [19] under the following conditions: baseline readings 10 s, sample readings 20 s and purge and sensor update 35 s.
Variables characterizing WCO, SBO, WCO-biodiesel and SBO-biodiesel were expressed as mean values (±standard deviations where appropriate). Two statistical approaches were used to determine the reliability and consistency of e-nose data in predicting the oxidative stability of biodiesel (response variable) as determined by the Rancimat method. In the first approach, the maximum variation in the electrical resistance of all 32 e-nose sensors was submitted to principal component analysis (PCA) followed by multiple linear regression (MLR) analysis. This method is valid when the signal has stabilized at the time of acquisition, but such stabilization does not always occur and the definition of maximum value becomes arbitrary. Furthermore, the signal noise inherent to the system can render it difficult to obtain an accurate maximum variation.
An alternative approach involved the use of a stochastic model based on the average behavior and variability of the e-nose signal during sorption and desorption of biodiesel as represented by the parameters a, b, c, k and p described previously by Siqueira et al. [19], [32]. According to this model, the maximum signal value can be estimated from the value of b while the function m (defined as a + bk) is proportional to the concentration of VOCs present in the sensor region. In the construction of a final model for the prediction of oxidative stability, the parameters from each of the 32 sensors were included or excluded by stepwise regression.
For each model, the assumption of normality of residuals was assessed using the Anderson-Darling test and the predictive performance was established from the coefficients of determination (R2) obtained using a training set comprising 45 samples [5 biodiesels × 9 conditions (8 stored samples and 1 fresh sample)] and a validation set containing 18 samples (2 biodiesels × 9 conditions as before). Statistical analyses were performed using R version 3.5 and Minitab 18 software with the level of significance set at 10%.
The physicochemical attributes of WCO in comparison with those of SBO are shown in Table 1
. For WCO, the acid value (n = 6) varied between 0.37 and 0.52 mg KOH/g oil with a mean value that was slightly higher than that of SBO but within the range reported in the literature [33]. According to Phan and Phan [34], an acid value > 1 mg KOH/g oil may result in inactivation of the alkaline catalyst and lead to the formation of soaps. The peroxide value of WCO varied between 37.3 and 51.0 mEq/kg oil with a mean value that was around 14-times higher than that of SBO. The mean water content of WCO was found to be 1.3-times higher than that of SBO, although this result was as expected. Nevertheless, the feedstock should always contain minimal amounts of water since its presence favors the formation of FFAs that undergo parallel reactions in the transesterification process [13].
While the mean densities of WCO and SBO were similar, the mean kinematic viscosity of the former was 15% higher than that of SBO. According to Cordero-Ravelo and Schallenberg-Rodriguez [35], the ideal viscosity for transesterification is < 38.46 mm2/s implying that the WCO samples employed in this study were appropriate for the synthesis of biodiesel. Not surprisingly, the cooking process had altered the color of WCO considerably in comparison with that of SBO. The CIELAB L* axis indicated that WCO was darker than SBO, while the enhanced positive values of the chromaticity components a* in SBO and b* in WCO showed that the color of these oils tended, respectively, towards the red and yellow ends of the color space.
The fatty acid composition of a WCO is related to its origin since it varies considerably depending on the plant oil or animal fat used [12]. As shown in Table 1, the mean percentage values of fatty acids in the WCO samples were comparable with those of SBO and similar to values reported earlier [36]. The main differences between WCO and SBO were associated with the amounts of polyunsaturated fatty acids present, these being lower in the waste oil owing to the breakage of double bonds during the cooking processes. Regarding oxidative stability, the induction time of WCO varied between 1.52 and 3.58 h with a mean value that was less than half that of SBO, indicating that the waste oil had suffered substantial oxidative degradation as a result of cooking and subsequent storage.
The characteristics of fresh WCO- and SBO-biodiesels were evaluated based on the quality specifications demanded by ANP standards (Table 1). The two types of biodiesel presented analogous acid value, all of which were below the maximum (0.5 mg KOH/g oil) allowed by ANP [37]. Values above this limit are indicative of high concentrations of FFAs that can give rise to internal engine corrosion among other problems [38].
The iodine value is a measure of unsaturation in the fatty acid ethyl esters (FAEEs) present and provides a rough estimate of the quality of the biodiesel, since larger iodine values are indicative of higher levels of unsaturation and greater susceptibility to oxidation. Iodine values for both biodiesels were below the EN 14,214 limit (120 g I2/g oil), although the mean value of WCO-biodiesel was around 5% lower than that of SBO-biodiesel, and this correlates with the reduced levels of polyunsaturated fatty acids detected in the WCO feedstock.
Since the combustible components of biodiesels obtained in this work are FAEEs, the percentage content of these esters is a measure of both the purity of the fuel and the efficiency of conversion of the feedstock. According to the ANP standard, the ester content of a biodiesel should be at least 96.5%, a value that was exceeded by the SBO-biodiesel and five of the six WCO-biodiesel samples. However, the ester content of one of the WCO-derived biodiesels was established as 95.4% and this reduced the mean value of the six sample set to a level somewhat below that of the SBO-biodiesel.
The water content of the WCO-biodiesels varied between 196 and 491 ppm, with the majority of samples containing less water than the SBO-diesel. Considering the regulations regarding water content, 33% of the WCO-biodiesel samples were below the 200 ppm limit set by ANP, whilst all WCO- and SBO-derived biodiesels complied with EN 14,214 maximum of 500 ppm. Densities of the WCO- and SBO-diesels were similar and within the ANP range of 0.85–0.90 g/cm3. Similarly, the viscosities of both types of biodiesels were within the ANP norm of 3.0–6.0 mm2/s, although the viscosity of the SBO-biodiesel was lower than that of WCO-biodiesel verifying the higher concentration of esters in the former [39].
The CIELAB L* axis indicated that WCO- and SBO-biodiesels tended to be darker in color than their respective feedstocks. Values of the a* and b* components of the biodiesels showed that the color of the SBO-derived product was relatively neutral compared with that of the feedstock while the color of the WCO-biodiesel tended more towards the red end of the color space in comparison with the unreacted oil. The oxidative stability of WCO-biodiesel samples varied between 3.52 and 7.74 h, with the majority of samples presenting induction times that were shorter than that of SBO-diesel reflecting the poorer quality of the WCO feedstock. According to ANP, the oxidative stability of biodiesel must be > 12 h, although this degree of resistance to oxidation is achieved by the addition of antioxidants which, although mandatory in Brazil, were not employed in the present study. All WCO- and SBO-biodiesel samples complied with the ASTM recommended induction time of ≥ 3 h.
The physicochemical characteristics of WCO- and SBO-biodiesels that had been stored at 43 °C over periods of 30 or 60 days in HDPE (Table 2
) or AISI 1020 carbon steel flasks (Table 3
) were determined in order to understand the effects of storage conditions on the rate of oxidative degradation [40]. Acid value increased in WCO- and SBO-biodiesel samples under all conditions of storage indicating that FAEEs present were hydrolyzed to the corresponding carboxylic acids. Nevertheless, the acid value of all samples were below the limit specified by ANP (0.5 mg KOH/g oil) after 30 or 60 days of storage at room temperature, while those of samples stored at 43 °C exceeded the limit irrespective of the time of storage or the storage container. In particular, after 30 days storage at 43 °C, mean acid value was higher in SBO-diesels in comparison with their WCO-derived counterparts irrespective of storage container, although this situation was reversed after 60 days storage at 43 °C. The highest mean acid value was recorded for WCO-biodiesel stored for 60 days at 43 °C in a carbon steel flask.
The iodine values of biodiesel samples decreased during storage, especially after 60 days at 43 °C irrespective of the type of flask, indicating a reduction in the concentration of polyunsaturated esters following reaction with molecular oxygen [13]. The mean water content rose markedly during storage under all conditions, with increases of 2.6-times in WCO-biodiesel stored for 30 days at 43 °C in HDPE and 5.5-times in SBO-biodiesel stored for 60 days at room temperature in carbon steel. The higher water-affinity and water-retaining capacity of biodiesel compared with petrodiesel has been investigated by Fregolente et al. [41], who reported that soluble water in biodiesel was 10- to 15-times higher than in petrodiesel. The hydrophilic nature of biodiesel is due mainly to the presence of hygroscopic FAEEs, and this constitutes an important aspect of biodiesel technology since it can cause problems such as water accumulation and microbial growth in fuel tanks and transportation equipment.
No variation in density was observed under the studied storage conditions, while the only notable increases in viscosity occurred in samples stored for 60 days at 43 °C in carbon steel flasks. Previous studies have shown that these properties are little influenced by degradation [42]. Moreover, the color of biodiesel samples changed only slightly during storage irrespective of conditions.
As shown in Table 2, Table 3, storage exerted a profound influence on the oxidative stability of WCO- and SBO-biodiesels, with induction times varying between 0.02 and 4.17 h depending on storage conditions. Storage for 30 days at room temperature in HDPE flasks gave rise to the smallest reductions in induction time, namely 42.8 and 59.0%, respectively for WCO-biodiesel and SBO-biodiesel, while the respective reductions after storage at 43 °C in carbon steel flasks were 91 and 98%. The lower oxidative stability, higher acidity and lower iodine values obtained for biodiesel stored in carbon steel flasks suggest that the contact of the fuel with the metal surface accelerates the oxidation rate. This may be explained by the formation of free radicals induced by the presence of metal ions throughout the storage [43], [44]. According to the induction times obtained, 93% of the WCO- and SBO-samples in storage would be unsuitable for use according to ASTM standards. Therefore, the addition of antioxidants is essential in maintaining the properties of B100 fuel (pure biodiesel) even for short-term storage [43]. The results presented herein showed that high temperature and long storage time increased the acidity and reduced the iodine value and oxidation stability of samples stored in similar types of container, thus reinforcing earlier findings that temperature and storage time contribute to the degradation and, consequently, alteration of the physicochemical properties of biodiesel [45].
The VOCs generated by the degradation of FAEEs during the storage of biodiesel can be detected in the headspace by e-nose sensors that change their electric resistance in the presence of specific types of volatile compounds. The output signal from the e-nose exhibits an initial rapid increase followed by a so-called 'plateau' region, the maximum value of which is related to the concentration of VOCs and should provide information about the oxidative stability of the fuel. Typical olfactory profiles of biofuels can be exemplified by the responses of sensor 10 towards fresh WCO-biodiesel (Fig. 1
a) and a biodiesel sample stored in a carbon steel flask at 43 °C for 60 days (Fig. 1b), in which it is possible to observe that the data points were narrowly dispersed in relation to the central curve of the stochastic model. In contrast, the responses of sensor 8 towards fresh WCO-biodiesel (Fig. 1c) and biodiesel stored in a carbon steel flask at 43 °C for 60 days (Fig. 1d) were more widely dispersed. These two opposing examples show that the proposed stochastic model fitted well the experimental data generated by the sensors. In order, to combine all the information obtained from the different biodiesel samples, the stochastic parameters were considered as input variables in the regression model.
MLR is the most common technique for expressing the dependence of a response variable (i.e. oxidative stability) on quantitative explanatory variables (predictors), while PCA is useful when the explanatory variables are correlated with each other (multicollinearity), particularly if it is not obvious which of the variables should form the predictor set. PCA creates new variables known as principal components (PCs) that are uncorrelated one with another and interpreted by association with original variables through the corresponding factor loadings. PCA has been widely employed in the analysis of olfactory profiles [16], [46], [47], [48].
In the present study, PCA was performed with the purpose of reducing the number of random variables under consideration (dimensionality reduction) contained in the signals generated by all the 32 e-nose sensors. The first three PCs explained 93% of the total variability in the data and the representation of each variable was>76.5%. MLR was subsequently employed with PC, PC2 and PC3 as the predictor variables and oxidative stability (according to the Rancimat method) of the biodiesel product as the response variable. According to the coefficients of determination for the initial model, the goodness of fit obtained with the 45 sample training set was represented by the values of R2
training (0.2449) and R2
adjusted (0.1897), while the quality of prediction obtained with the 18 sample validation set was inferred from the value (0.5494) of R2
validation. In the final MLR model PC2 was excluded because its effect on the response variable was not statistically significant (P = 0.2331). The results of ANOVA applied to the final MLR model are shown in Table 4
, while the corresponding values of R2
training and R2
adjusted were 0.2024 and 0.1644, respectively, and the quality of prediction was inferred from the value (0.4119) of R2
validation. According to the Anderson Darling test, the hypothesis of normality of the residuals in the final MLR model was rejected since the value of P (0.018) was lower than the alpha level, thereby compromising the application of this model for future samples. Moreover, the 3D scores plot of the first three PCs (Fig. 2
) shows that the biodiesel samples are dispersed with no recognizable clustering patterns by which to discriminate the samples on the basis of their VOCs, implying that the PCA/MLR approach is not suitable for predicting the oxidative stability of biodiesel.
In the stochastic model, information from the e-nose matrix was extracted according to the stochastic differential equation proposed by Siqueira et al. [32] in which the predictor variables were the parameters a, b, k, c, p and m (defined as a + bk) relating to the signals of each of 32 sensors and the response variable was oxidative stability according to the Rancimat method. Non-significant predictor variables were excluded from this model using stepwise regression in order to establish the final model (equation (1)), the results of ANOVA for which are presented in Table 5
.(1)Oxidativestability=0.1031k8+121314c15-193829c17-0.26451/k21+0.30881/k26-7644168m11.a2+309455853m19.a6-8710842758a6.a8+210266881m31.a3

The goodness of fit of the final model was represented by the values of R2
training (0.91), R2
adjusted (0.89) and R2
predicted (0.85) obtained with the 45 sample training set, while the quality of prediction was inferred from the value (0.84) of R2
validation obtained using the 18 sample validation set. It is of note that the value of R2
validation was very close to that of R2
predicted. According to the Anderson-Darling test, the assumption of normality of the residuals in the final model was not rejected since the value of P (0.23) was greater than the alpha level.
Rancimat values of oxidative stability were plotted against the values estimated by the final regression model applied to the training set (Fig. 3
a) and the validation set (Fig. 3b) in order to assess the existence of any outliers. The results show that the combination of parameters from the signals of 11 sensors (i.e. 2, 6, 8, 11, 15, 17, 19, 21, 26, 30 and 31) of the 32-sensor array was sufficient to obtain a good prediction of oxidative stability. Based on the values shown in Table 5 and considering equation (1), the key variables for measuring oxidative stability are, in decreasing order of importance: the interaction between the amount of VOCS reaching sensor 31 with the slope of sensor 30 threshold [m (sensor 31) * a (sensor 30)], the time for the e-nose signal to reach the threshold in sensor 26 [1/k (sensor 26)] followed by sensor 21 [1/k (sensor 21)], and the variability of the sensor 15 signal [c (sensor 15)].
According to the e-nose manufacturer, sensor 2 is sensitive to non-polar aliphatic/aromatic hydrocarbons, whereas sensors 6 and 31 are sensitive to polar substances and hydrogen bonds. The other sensors are sensitive to intermediary compounds including two sensors that are responsive to volatiles. It is worth noting that the final regression model represented by equation (1) can only provide reliable predictions of oxidative stability when values of the predictor variables are within the ranges shown in Fig. 4
in order avoid extrapolation of the multivariate model.
It is possible to synthesize biodiesels from WCOs with physicochemical characteristics that are within the specifications of ANP. The oxidative stabilities (induction times) of samples of fresh WCO-biodiesel ranged from 3.52 to 7.74 h, values that comply with the ASTM standard (>3h). Regardless of storage conditions, the oxidative stability of WCO-biodiesel varied from 0.02 to 4.17 h. Oxidative stability fell particularly rapidly during storage at 43 °C, especially when the biodiesel was kept in a steel carbon recipient. The stochastic model applied in this study for the prediction of oxidative stability based on the analysis of e-nose signals was efficient and reliable. Use of the proposed e-nose system by producers and distributors of biodiesel would facilitate fuel quality assessment and eliminate the need for complex and time-consuming laboratory tests.
I.G.V, M.L.C.P.S. and A.L.G.F. conceived and planned the experiments. I.G.V., D.S.G and E.H.S.C. contributed to sample preparation and carried out the experiments. A.F.S. and M.P.M. performed the statistical analysis of data. A.F.S, M.P.M., I.G.V., D.S.G. and A.L.G.F. contributed to the interpretation of the results. I.G.V., M.P.M. and A.L.G.F. drafted the manuscript. All authors analyzed the results, provided critical feedback, and revised the final version of the manuscript.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Fuel (Lond)
PMC7524510,The stochastic evolution of a rumor spreading model with two distinct spread inhibiting and attitude adjusting mechanisms in a homogeneous social network,"Rumors, the oldest form of mass media, are defined in [1] as being improvised news resulting from a process of collective discussion. Typically, rumors spread at first between close friends or by means of other similar informal encounters, before making their way, often reshaped or distorted, into public discourse.
Certain rumors spread faster since they are targeting deep insecurities, making people uncertain of outcomes, afraid of consequences and distrustful of real, truthful information. For instance, there are rumors in circulation which allege that high-speed 5G cellular technology is to blame for the rapid spread of COVID-19, that the spread of the Zika virus is caused by genetically modified mosquitoes and that microcephaly is caused by vaccines, which, via ever-shifting alleged mechanisms, also cause autism. Other rumors, especially popular in West Africa, allege that Ebola can be contracted from a motorcycle helmet. The “Obama is a Muslim” rumor, built upon questions caused in part by his middle name, was a recurrent theme of the 2008 US presidential elections and reverberated for a long time, as a 2014 poll showed that 54% of the (Republican) subjects believed that “deep down” Obama was a Muslim.
To understand the impact of rumor spreading, it is useful to investigate the dynamical behavior of appropriate mathematical models which are often not unlike disease propagation models. The research on rumor spreading models started in the 1960s. In their seminal papers [2], [3], Daley and Kendall compared the difference between the basic tenets of a model of virus transmission and those of a model of rumor spreading, proposing their classical compartmental model of rumor spreading. This model keeps track of three compartments: ignorants, spreaders and stiflers and assumes that an ignorant should absolutely become a spreader upon hearing a rumor, which is not always factual.
Since then, the DK model has been actively modified and expanded, leading to a more accurate account of rumor spreading. Maki and Thompson [4] developed a model which allowed for a more nuanced interaction between ignorants, spreaders and stiflers. Zanette [5], [6] proposed a rumor propagation model on a small-world network and performed simulations for the MT model. In 2004, Moreno et al. [7] studied the stochastic properties of the MT model on scale-free networks by means of Monte Carlo simulations. In 2008, Kawachi [8] established global behavior patterns for rumor propagation models that also extended the classical DK model. In 2014, Afassinou [9] considered the influence of education rate of the population, which led to the proposal of a susceptible, educated, infected, and recovered (SEIR) rumor spread model.
Recently, other mechanisms aiming at a fine-grained description of rumor spreading, such as forgetting mechanisms (Zhao et al. [10]), incubation mechanisms (Al-Tuwairqi et al. [11]), hesitation mechanisms (Xia et al. [12]), punishment and control by the government (Li and Ma [13], Zhao and Wang [14]), memory effects (Zhang and Xu [15]), different probabilities for spreaders to become stiflers (Zhao et al. [16]), have attracted the attention of various authors. In addition, a rumor spreading model accounting for two distinct rumors spreading simultaneously in a target population was proposed and investigated by Wang et al. [17]. In 2017, Zhu and Wang [18] used a modified susceptible–infected–removed (SIR) model to characterize the dynamics of rumor diffusion both on homogeneous networks and heterogeneous networks, taking also variation of connectivity into consideration. In 2018, Hu et al. [19] established a Susceptible–Hesitating–Affected–Resistant (SHAR) model incorporating different attitudes towards rumor spreading. Zhu and Wang [20] investigated a rumor diffusion model accounting for the uncertainty of human behavior, in a spatio-temporal diffusion framework. Zan [21] studied two types of double-rumors spreading models: the DSIR (“double” SIR) model and the C-DSIR (comprehensive DSIR) model. Recently, Horst [22] pointed out that rumor spreading agents change their activities at random points in time, at a rate that depends on the current state of a designated neighborhood and on the average choice throughout the entire population, making a case for the use of stochastic models to describe rumor spreading.
Rumors can destroy confidence, affect self-esteem and even ruin reputations. They may also lead to anxiety, depression, suicidal thoughts and to a host of other issues. Rumors can alienate friends and lead to ostracization and other forms of relational aggression. On a societal level, the rise and ubiquity of social media led to an increase in the exposure of users to unsubstantiated rumors, fake news, defined as fabricated information that mimics news media content in form but not in organizational process or intent (Lazer et al. [23]), extremely biased news, conspiracy theories and to other forms of misinformation, which became more and more pervasive. In online social media, social-cognitive biases such as selective exposure and confirmation bias helped the emergence of echo chamber-like communities consisting of opinionated, like-minded (or perhaps hive-minded) users sharing similar beliefs about polarizing topics and avoiding communication with those who have opposite views. These communities are prone to spreading information aligning with these beliefs in sharing cascades, without a substantive veracity check (Wang et al. [24], Bovet and Makse [25], Liu et al. [26]). By analyzing a dataset of tweets collected during the 5 months preceding the US 2016 presidential elections, Bovet and Makse [25] found that 25% of these tweets spread either fake or extremely biased news. Also, it has been determined in Del Vicario et al. [27] that, for two distinct types of online communities, homogeneity and polarization are the main determinants for predicting the sizes of sharing cascades.
One of important responsibilities of any governmental body is then to put in place effective measures to control the spread of rumors, thereby containing and minimizing any harm they may cause. However, inhibiting and clarifying all sorts of ubiquitous rumors on social networks is often a long-term process, requiring a stable, sustained budget input. In our model of rumor spreading, we attempt to introduce two spread inhibiting and attitude adjusting mechanisms, which depend only upon governmental input, acting towards reducing rumor spreading from spreaders to newcomers and changing the attitude of spreaders, respectively. We then discuss the effects of the qualitative properties of the inhibiting and adjusting functions, respectively, upon rumor spreading, with a view towards contributing to a better understanding of the mechanisms of rumor spreading and providing the governmental bodies and the public with significant insights for rumor control.
This paper is organized as follows. In Section 2, we introduce a deterministic model for rumor spreading which accounts for two inhibiting and adjusting mechanisms. In Section 3, the stability properties of the deterministic model are characterized in terms of a basic influence number, viewed as a threshold parameter. In Section 4, we propose the corresponding stochastic model and discuss its asymptotic behavior around the equilibria of the deterministic system. In Section 5, we illustrate, support and enhance our results via numerical simulations. Several concluding remarks are given in Section 6.


It is well known that an undirected graph G=(V,E), where V represents a set of nodes and E represents a set of sides, can be obtained from a social network consisting of N individuals if the individuals and the contacts between them are considered as nodes and sides, respectively. The size of the total population which is subject to mechanisms for rumor control is understood to be variable and is denoted at time t by N(t). This population is subdivided into three categories: newcomer (S), spreader (I) and stifler (R). Upon hearing a rumor, the newcomer, who has no previous information about that rumor, may subsequently display two different attitudes. Specifically, certain individuals will choose not to spread the rumor or not to believe it (stiflers), while other individuals will actively spread it (spreaders). After a newcomer hears the rumor through the contact with a spreader at a rate α¯, it then has two possible choices: to become a spreader with probability θ1, or to become a stifler with probability 1−θ1. Once a rumor spreads in a social network, the government then has the authority to use inhibiting and adjusting mechanisms, whose strength and resources are quantified through the use of the inhibitor variable U, to contain the various damages caused by the rumors.
The movement of individuals from one class to another, given in Fig. 1, is supposed to be unidirectional, which means the flowchart is irreversible. We assume that the flow into the newcomer class is constant and denoted by Λ and denote the constant leaving rate of each non-inhibitor compartment by μ. The constant Γ represents the allotted budgeting rate by the government for adjusting and inhibiting mechanisms and e is the decay rate of those mechanisms. At any time, certain spreaders adjust their attitude towards spreading rumors as a result of the constant governmental work to improve the mechanisms for clarifying and inhibiting rumors, thereby becoming stiflers at a rate g(U).
For the sake of simplicity, we consider only rumors spreading through human contacts, rather than rumors spreading through the media, which motivate our use of an augmented SIR-like model. We now introduce our mathematical model, which involves different attitudes towards rumors and two distinct mechanisms for rumor control, in the following form (1)dSdt=Λ−α¯k¯SIf(U)−μS,dIdt=θ1α¯k¯SIf(U)−g(U)I−μI,dUdt=Γ−eU−δIUK+U,dRdt=(1−θ1)α¯k¯SIf(U)+g(U)I−μR.Here, the functions f and g stand for the effects of rumor control mechanisms upon attenuating rumor spreading to newcomers and changing the attitudes of spreaders, respectively. Also, k¯(≥2) denotes the average degree of the network. The constants δ and K quantify the usage of the inhibitor, δ being the maximal uptake rate of I and K being a half-saturation parameter. The resulting uptake rate of the inhibitor δUK+U is increasing (the more the inhibitor is available, the higher the uptake rate is) and saturates for large U. Assume that the C1 function f:[0,∞)→R satisfies

(f.i)
f(U)≥0, f(0)=1;(f.ii)
f is non-increasing on [0,∞).

Assumption (f.i) represents the fact that the interaction between newcomers and spreaders leads to a decrease in the number of newcomers, some of them becoming either spreaders of stiflers, and that the function f is normalized (f(0)=1 means that the mechanisms for the inhibition of rumor spreading are not active), the strength of the interaction between newcomers and spreaders being also quantified through the use of the parameter α¯. In fact, f(0)=1 is a modeling assumption (a description of the control mechanism), which is not actually needed for any of our proofs. Assumption (f.ii) describes that the attempts to control rumor spreading do not backfire (more of the inhibitor U leads to less rumor spreading). Also, the C1 function g:[0,∞)→R satisfies

(g.i)
g(U)≥0;(g.ii)
g is non-decreasing on [0,∞);(g.iii)
lim¯U→∞g(U)≤g¯.

Assumption (g.i) represent the fact that the use of rumor control mechanisms does indeed change the attitude of spreaders, while assumption (g.ii) signifies that the attempts to adjust attitudes do not backfire either (more of the inhibitor U leads to more spreaders changing their attitudes). Assumption (g.iii) describes the fact that the attitude adjustment mechanisms eventually saturate. Let us also assume that

(fg.i)
fg+μf is non-decreasing on [0,∞).

While assumptions (f.i-ii) and (g.i-iii) stem from social considerations, the motivation for assumption (fg.i) is purely mathematical, as it is employed only to ensure the local stability of the rumor-prevailing equilibrium. If f≡1, then (fg.i) is trivially satisfied, since it reduces just to g being non-decreasing on [0,∞) (that is, to (g.ii)).

Remark 2.1An example of a function f modeling the inhibiting mechanisms, which satisfies assumptions (f.i) and (f.ii) is f(U)=A+Be−UA+B, A≥0,B>0, while an example of a function g modeling the adjusting mechanisms which satisfy assumptions (g.i-iii) is g(U)=AUB+U, A,B>0. However, there are many other possible examples, as the assumptions have been kept to a minimum. Further efforts should go into determining more specific forms or sets of assumptions for each function, which will allow us to further refine and analyze our stability results.


Remark 2.2We view U as a variable “proxying” (sort of) the rumor control. That is, U can model the resources of an organization mandated by the government to deal with rumor control (but we do not want to limit ourselves just to this interpretation). There is a (constant) growth of resources due to government budgeting, an uptake of resource in which each subject (spreader) is allotted (in average) an amount of resources which increases as more resources become available and a decay of resource (interpretable, for instance, as administrative costs).

Having in view the social significance of the variables, we are interested only in solutions that are nonnegative and bounded. It can be easily proved that the solutions of the system (1) which start with nonnegative initial data, that is, with S(0)≥0,I(0)≥0,U(0)≥0,R(0)≥0stay nonnegative for all t≥0. From (1), we see that dN(t)dt=dS(t)dt+dI(t)dt+dR(t)dt=Λ−μN(t),which implies that N(t)=N(0)−Λμe−μt+Λμfor all t≥0, which ensures the boundedness of S, I and R. Also, dU(t)dtU(t)=Γe≤0.Hence, U is bounded as well and a positively invariant set of (1) is Ω=(S,I,U,R)∈R4:0≤S+I+R≤Λμand0≤U≤Γe.

It is easy to see that the system (1) has a rumor-free equilibrium E0, given by E0=Λμ,0,Γe,0.To discuss the dynamics of the model via an approach which has been proven highly successful in Mathematical Epidemiology and to rearrange the system (1) to fit the framework of the next generation method laid out in [28], let us first notice that I and R are “infected-like” compartments, while S and U are “noninfected-like” compartments.
Let us denote X=(I,R)T, Y=(S,U)T and α=α¯k¯. Then the system (1) can be rearranged as dXdt=F(X,Y)−V(X,Y),dYdt=h(X,Y) in which F(X,Y)=θ1αSIf(U)0,V(X,Y)=(g(U)+μ)I−(1−θ1)αSIf(U)−g(U)I+μR.We thereby obtain that F=DF|E0=θ1αΛμf(Γe)000and V=DV|E0=g(Γe)+μ0−(1−θ1)αΛμf(Γe)−g(Γe)μ.Hence, a threshold parameter for the stability of the system (1), called ad hoc the basic influence number of the system (1), is the spectral radius of matrix FV−1, given by (2)R0=θ1αΛf(Γe)μ(g(Γe)+μ).


Remark 3.1Note that, in the above fraction, the numerator is an non-increasing function of Γ due to (f.ii), while the denominator is an increasing function of Γ, due to (g.ii). As a result, R0 is a non-increasing function of Γ, which leads to the conclusion that the higher the allotted budgeting rate for the rumor control mechanisms Γ is, the lower the average influence of a spreader in a totally susceptible population R0 becomes.

To investigate the possible existence of a positive (or rumor-prevailing) equilibrium E∗, E∗=(S∗,I∗,U∗,R∗),let us first observe that the equilibrium relations take the form (3)Λ−μS∗−αS∗I∗f(U∗)=0,θ1αS∗I∗f(U∗)−g(U∗)I∗−μI∗=0,Γ−eU∗−δI∗U∗K+U∗=0,(1−θ1)αS∗I∗f(U∗)+g(U∗)I∗−μR∗=0.By straightforward algebraic manipulations, one sees that (4)S∗=Λμ−(g(U∗)+μ)θ1μI∗,I∗=(Γ−eU∗)(K+U∗)δU∗,R∗=(1−θ1)αS∗I∗f(U∗)+g(U∗)I∗μSubstituting the explicit formulas in terms of U∗ given by (4) into the second equation of (3), one sees that (5)R0f(Γe)g(Γe)+μg(U∗)+μ−α(Γ−eU∗)(K+U∗)μδU∗f(U∗)=1.Let us define a continuous function τ by τ:(0,∞)→R,τ(U)=R0f(Γe)g(Γe)+μg(U)+μ−α(Γ−eU)(K+U)μδUf(U).Since limU→0+τ(U)=−∞ and τ(Γe)=R0, there is a solution U∗ of (5), not necessarily unique, provided that R0>1. This, in turn, leads to the existence of (at least) one rumor-prevailing equilibrium E∗.
The uniqueness of U∗ (or, equivalently, of the positive equilibrium E∗) depends on the concrete forms of f and g and may or may not hold for arbitrary functions. However, it is easy to note that τ′(U)>0 for U∈(0,Γe) ensures both the uniqueness of E∗ when R0>1 and its nonexistence when R0≤1.

Theorem 3.2
The rumor-free equilibrium
E0=Λμ,0,Γe,0
is locally asymptotically stable provided that
R0<1
.



ProofThe Jacobian matrix of the system (1) at E0 is (6)J(E0)=−μ−αΛμf(Γe)000θ1αΛμf(Γe)−g(Γe)−μ000−δΓΓ+eK−e00(1−θ1)αΛμf(Γe)+g(Γe)0−μWe observe that J(E0) has three negative eigenvalues λ1,2=−μ, λ3=−e, the remaining eigenvalue λ4 being given by λ4=θ1αΛμf(Γe)−g(Γe)−μ=g(Γe)+μ(R0−1).Since R0<1, one sees that λ4<0 and consequently E0 is locally asymptotically stable. Note also that E0 is unstable if R0>1. This completes the proof.  □

Via similar computations, it is seen that the Jacobian matrix of the system (1) at E∗ has a negative eigenvalue λ1=−μ, the other three eigenvalues being the roots of the equation (7)|λ+a11a12a13a21λa230a32λ+a33|=0,where a11=αI∗f(U∗)+μ,a12=g(U∗)+μθ1,a13=αS∗I∗f′(U∗),a21=−θ1αI∗f(U∗),a23=−θ1αS∗I∗f′(U∗)−I∗g′(U∗),a32=δU∗K+U∗,a33=e+δKI∗(K+U∗)2.Note that a23=−θ1αg(U∗)+μθ1αf(U∗)I∗f′(U∗)−I∗g′(U∗)=−I∗f(U∗)g(U∗)f′(U∗)+g′(U∗)f(U∗)+μf′(U∗)=−I∗f(U∗)(fg+μf)′U(t)=U∗ and consequently a23≤0, by assumption (fg.i). This implies that λ3+c1λ2+c2λ+c3=0,where c1=a11+a33>0,c2=a11a33−a12a21−a23a32>0,c3=a13a21a32−a11a23a32−a12a21a33>0.Applying the Routh–Hurwitz criterion, the remaining eigenvalues are negative or have negative real part if and only if c1c2>c3.However, it is obvious that c1c2−c3=a112a33+a11a332−a11a12a21−a23a32a33−a13a21a32>0.Hence, one obtains the following result.

Theorem 3.3
If
R0>1
, then the rumor-free equilibrium
E0
is unstable and there is at least one rumor-prevailing equilibrium
E∗=(S∗,I∗,U∗,R∗)
, which is necessarily locally asymptotically stable.



Remark 3.4Note that, in some sense, assumption (fg.i) is not necessarily optimal, since it ensures that each of the three terms (the sign in front of them being included) involved in the expressions of c2 and c3 are positive, condition which is strictly stronger than their sum being positive. Consequently, E∗ may be locally asymptotically stable even if (fg.i) is not satisfied.


Remark 3.5From Theorem 3.2, Theorem 3.3, it is seen that R0 is indeed a threshold parameter as far as the stability of the model (1) is concerned, separating the extinction of the rumor from its prevailment. Let us denote lim_x→∞f(x)=f_. If θ1αΛf_>μ(g¯+μ),(which happens, for instance, if the newcomers recruitment rate Λ or the percentage of newcomers who become spreaders θ1 are too high, or if the maximal attitude adjustment rate g¯ is too low, or the maximal transmission attenuation rate f_ is still too high), then (8)R0≥θ1αΛf_μ(g¯+μ)>1,which leads to the (perhaps unpleasant) conclusion that the rumor will persist regardless of the budget devoted to rumor control. However, it can also be seen that, in such a situation, efforts to improve any of the mechanisms (lowering f_ or increasing g¯) can bring back R0 below 1 and ensure the success of rumor control.Also, at the opposite end of the spectrum, if θ1αΛ<μ2(which happens, for instance, when the newcomers are generally not inclined to become spreaders or the recruitment rate of newcomers is low), then (9)R0≤θ1αΛμ2<1,and the rumor will disappear on its own, no budget for rumor control measures being necessary.


Remark 3.6Let us think for the moment of R0 as a function of Γ, R0=R0(Γ), and suppose that θ1αΛμ(g(0)+μ)>1,θ1αΛf_μ(g¯+μ)<1,that is, limΓ↓0R0(Γ)>1,limΓ→∞R0(Γ)<1.Let us also suppose that at least one of the functions f, g is strictly monotonic, which leads to R0(Γ) being strictly decreasing. In this situation, there is a unique Γc which solves the equation R0(Γ)=1. This Γc can be thought as a sharp lower bound for the least amount of funding necessary to extinguish the rumor. However, the equation R0(Γ)=1 might be transcendental (and it is, in our examples, where f contains an exponential and g is a rational function), and consequently Γc can sometimes be only approximated, not determined explicitly. Also, there is the caveat that Γ>Γc guarantees the elimination of the rumor only in the long term, which may or may not be acceptable in a social setting, for which time is also a concern.

Denote R+3={(x1,x2,x3)|xi>0,i=1,2,3}.We observe that the stochastically perturbed system (10) is mathematically (and socially) well-posed, as it has a unique global solution which is positivity-preserving.

Theorem 4.2
For any initial value
(S(0),I(0),U(0))∈R+3
, there exists a unique global solution
(S(t),I(t),U(t))
of the system
(10)
for
t≥0
that will remain in
R+3
with probability 1.


The proof of this Theorem can be found in Appendix. We can now further discuss the behavior of these solutions by investigating the dynamics of the stochastic model (10) around the equilibria of the corresponding deterministic, reduced model (1)
′.
As mentioned in the previous section, the deterministic system (1) has a rumor-free equilibrium E0=(Λμ,0,Γe,0), which is locally asymptotically stable provided that R0<1. However, for the stochastic system (10), E0 is no longer the rumor-free equilibrium, due to the stochastic perturbations, which implies that the solutions cannot converge to E0. In this section, we shall investigate the asymptotic behavior of the stochastic system (10) around E0′=(Λμ,0,Γe), the corresponding equilibrium of (1)
′.

Theorem 4.3
If
R0<2μ2(g¯+2μ)(g(Γe)+μ)f(Γe)
and the following conditions hold
σ12<μ,σ22<2μ,σ32<e,
then for any given initial value
(S(0),I(0),U(0))∈R+3
, the unique global solution
(S(t),I(t),U(t))
of the system
(10)
satisfies
lim supt→+∞1tE∫0t(S(s)−Λμ)2+I2(s)+(U(s)−Γe)2ds≤θ12σ12(Λμ)2+c2σ32(Γe)2κ,
in which
κ=min{θ12(μ−σ12),μ−12σ22,c2(e−σ32)}
and
c2=−(g¯+2μ)(g(Γe)+μ)αδf(Γe)ΓeR0−2μ2(g¯+2μ)(g(Γe)+μ)f(Γe).


The proof of this Theorem can be found in Appendix. As seen from Theorem 4.3, if the value of the basic reproduction number R0 is not too high and the intensities of the stochastic perturbations σ12, σ22, σ32 are low, then the solutions of the stochastic model (10) will oscillate around the rumor-free equilibrium of the deterministic model (1)
′. That is, if the spreaders are not very convincing and the strength of the stochastic perturbations is limited, then the solutions of the stochastic model (10) will still be close enough to the rumor-free equilibrium, most of the time. Note that, strictly speaking, Theorem 4.3 does not require that R0<1.
In this subsection, we assume that R0>1, which implies that the deterministic system (1) has a (not necessarily unique) rumor-prevailing equilibrium E∗=(S∗,I∗,U∗,R∗), which is locally asymptotically stable. However, E∗ is not a rumor-prevailing equilibrium for the stochastic system (10) anymore, due to the stochastic perturbations. We shall then investigate the asymptotic behavior of the system (10) around E∗.

Theorem 4.4
If
R0>1
and the following conditions hold

(C1)
σ12<μ−1θ1g(U∗)+c3(Λ+α(1−f(U∗)))
;
(C2)
σ22<μ−(1+θ1)g(U∗)−(θ1S∗+I∗)(g¯−g(U∗))−c3g(U∗)−c3θ1α[1−f(U∗)]−δU∗
;
(C3)
σ32<e(1+U∗)−Γ
,


then for any given initial value
(S(0),I(0),U(0))∈R+3
, the unique global solution
(S(t),I(t),U(t))
of the system
(10)
satisfies
lim supt→+∞1tE∫0t(S(s)−S∗)2+(I(s)−I∗)2(s)+(U(s)−U∗)2ds≤Θρ,
in which
Θ≐θ1g(U∗)(S∗2+I∗2)+2g(U∗)I∗2+[(θ1S∗+I∗)(g¯−g(U∗))](12+I∗2)+(θ12σ12S∗2+σ22I∗2)+c3g(U∗)12+I∗2+c3(g¯−g(U∗))I∗+12c3I∗σ22+c3θ1α(1−f(U∗))(S∗2+I∗2)+c3θ1ΛS∗2+12S∗2+σ32U∗2+δI∗U∗K+U∗U∗2+12+δU∗(I∗2+12).
ρ=min{−θ12μ+θ1g(U∗)+θ1σ12+c3θ1α(1−f(U∗))+c3θ1Λ,−μ+(1+θ1)g(U∗)+(θ1S∗+I∗)(g¯−g(U∗))+c3g(U∗)+σ22+c3θ1α[1−f(U∗)]+δU∗,Γ−e(1+U∗)+σ32}
and
c3=g(U∗)+2μαf(U∗).


The proof of this Theorem can be found in Appendix. In a similar vein to what was already observed above, Theorem 4.4 establishes that if the deterministic model (1)
′ has a rumor-prevailing equilibrium and the intensities of the stochastic perturbations σ12, σ22, σ32 are low, then the solutions of the stochastic model (10) will oscillate around the rumor-prevailing equilibrium of the deterministic model (1)
′. That is, if the strength of the stochastic perturbations is limited, then the solutions of the stochastic model (10) will still be close enough to the rumor-prevailing equilibrium, most of the time.

Remark 4.5Conditions (C1)–(C3) have a theoretical value only, as they cannot be verified a priori (i.e., they explicitly depend upon the coordinates of the rumor-prevailing equilibrium, for which explicit expressions are not available). However, they take a somewhat simpler form if f≡1 (the mechanisms for the inhibition of rumor spreading are not active).

For our numerical simulations, we employ a number of parameter values taken from the available literature and estimate several others, as shown in Table 1.

780624 780624
We first choose f(U)=0.5(1+e−U), g(U)=U5(1+U) and μ=0.25, so that fg+μf is an increasing function, as shown in Fig. 2. Fig. 3 illustrates the bilinear dependence of the basic influence number R0 upon the rate of flow into the newcomer class Λ and upon the average contact rate α=k¯α¯ , the other parameters being fixed (Γ=1 and e=0.5).

As seen from the expression of R0 given by (2), the parameters Λ, α, Γ and e play a vital role for rumor spreading analysis, and so do the explicit forms of f and g. In what follows, we establish the contributions of the variances of Λ, α, Γ and e to the variance of R0, as shown in Fig. 4. To this purpose, we use the Sobol method (Sobol [31], Dimitriu et al. [32]), which is a model-independent approach to performing global sensitivity analysis based on variance decomposition. By analyzing the first-order and the total-effect sensitivity indices, it is seen that the variance of α provides the main contribution to the variance of R0.

Fig. 5 depicts mean values of the basic influence number R0 for random values of parameters. Here, f(u)=K1(1+e−u) and g(u)=0.2uK2+u, while Γ∈(0.5,1.5), e∈(0,1), K1∈(0,1) and K2∈(0.5,1.5), respectively. Obviously, as shown in Fig. 5(c), as f_ (that is, K1, for our example of f) increases, so does the mean value of R0. For other randomly selected input parameters, the mean value of R0 oscillates up and down around 1, as shown in Fig. 5(a), (b) and (d), illustrating the influences of Γ, e and K2, respectively.

Fig. 6 illustrates the evolution of the total densities of newcomers, spreaders and of the inhibitor for the following parameter values: (Λ,α)=(3,0.1), or (3.5,0.15), or (4,0.2), the other parameter values being given in Table 1.
According to Theorem 3.2, a rumor outbreak does not occur when R0<1. As observed from Fig. 6, Fig. 7, the density of spreaders declines to zero, which implies that the rumor dies out. For a low initial density of spreaders, (Fig. 6), the densities of newcomers and of the inhibitor, respectively, steadily increase until they reach their respective equilibrium states. However, for a high initial density of spreaders, (Fig. 7), the densities of newcomers and of the inhibitor, respectively, sharply descend at first and then increase to their respective equilibrium states.

Fig. 8 shows different rumor propagation outcomes for different initial conditions, with S(0) ranging from 2 to 20, I(0) changing from 0.5 to 5, and I(0) varying from 1 to 10. The system no longer has a rumor-prevailing equilibrium and the rumor-free equilibrium is stable, which is in agreement with the results of our analysis.
To illustrate the existence, uniqueness and stability of the rumor-prevailing equilibrium, we choose Λ=5.8 and α=0.28, the other parameter values being given in Table 1. We then determine the unique rumor-prevailing equilibrium as having coordinates (9.123,2.012,0.996), and being stable, as shown in Fig. 9. This validates our theoretical result given in Theorem 3.3.
In Fig. 10, we use the pairs (Γ,α) employed above, that is, (Γ,α)=(5.8,0.28) and (Γ,α)=(4,0.2), along with f(U)=0.3(1+e−U), to illustrate that a different value of f(0) not satisfying the normalizing condition f(0)=1 in the assumption (f.i) does not influence the local asymptotic stability of E0 and E∗.
To illustrate the asymptotic behavior of the solutions of the stochastic system around the rumor-free equilibrium, we choose Λ=2, α=0.1, the values of the other parameters being given in Table 1. It is then seen that R0=0.2369<2μ2(g¯+2μ)(g(Γe)+μ)f(Γe)=0.2644.Also, let σ1=0.2, σ2=0.5, σ3=0.6 and note that σ12=0.04<μ=0.25, σ22=0.25<2μ=0.5, σ32=0.36<e=0.5, the hypotheses of Theorem 4.3 being satisfied.

Fig. 11, Fig. 12 illustrate the time evolution of the total densities of each group (newcomers, spreaders and inhibitors) in the stochastic rumor spreading model for different initial conditions. To illustrate the asymptotic behavior of the solutions of the stochastic system around the rumor-prevailing equilibrium of the deterministic model, we set f(U)≡1, Λ=2, α=10, μ=0.5, e=1.2, θ1=0.5, δ=0.5, Γ=1, K=1 and g(U)=0.1U1+U. For these values, it is seen that R0=36.67. We also choose σ1=0.1, σ2=0.2 and σ3=0.4, for which conditions (C1)−(C3) are satisfied. Fig. 13 illustrates the asymptotic dynamics of the total densities of three groups (newcomer, spreader and inhibitor) in the stochastic rumor spreading model for different initial conditions.


By extending the traditional DK rumor model to account for the effects of the attitude adjusting and spread inhibiting mechanisms depending upon governmental input, we propose deterministic and stochastic models, respectively, to discuss the control of rumor spreading on social networks. Although our starting deterministic model can be characterized as being an augmented SIR model, the use of a fourth variable, the inhibitor, which can be thought as being budget-related rather than having an epidemiological significance, transcends, in some sense, the epidemiological framework. Also, the use of the possibly nonlinear attitude changing function g makes the coupling between the equations of the model slightly more involved. For those reasons, we have been unable to obtain global stability results.
First of all, we find an explicit expression for our threshold parameter, the basic influence number R0, and then investigate the stability of rumor-free and rumor-prevailing equilibria, respectively, of the deterministic model, in terms of R0, being also observed that R0 is a non-increasing function of the budgeting rate Γ, that is, the higher the budgeting rate is, the lower the average influence of a spreader in a totally susceptible population becomes. Depending upon the interplay of the parameters of the model, it is observed that, in certain situations, the rumor will persist regardless of the budget allotted to rumor control, while in others the rumor will disappear by itself even without exterior intervention, no budget for rumor control measures being necessary. For all the other situations in-between, a sharp lower bound for the amount of funding Γc, necessary to make the rumor go away, is determined.
Second, to account for the effect of random external fluctuations, we augment our model by considering stochastic perturbation of white noise type. Here, the stability properties obtained in the deterministic case are replaced by estimations in terms of expected values. It is proved that if the spreaders are not very convincing (R0 is low enough) and the strength of the stochastic perturbations is limited, then the solutions of the stochastic model will still be close enough to the rumor-free equilibrium, most of the time.
It is also proved that if the deterministic model has at least one rumor-prevailing equilibrium (R0>1) and, similarly to the above, the strength of the stochastic perturbations is limited, then the solutions of the stochastic model will still be close enough to this rumor-prevailing equilibrium, most of the time. However, a shortcoming of the necessary conditions in this case is that they are expressed in terms of the coordinates of the rumor-prevailing equilibrium, for which explicit expressions are not available (i.e., they cannot be verified a priori). Still, this is also not unexpected, since there can be multiple rumor-prevailing equilibria in this case, as condition R0>1 does not ensure uniqueness, and it is then natural for a generic condition to depends somehow on the equilibrium it refers to.
In order to complement our analysis, numerical simulations are performed to illustrate and enhance our mathematical findings. To establish the contributions of the variances of the parameters to the variance of R0, a Sobol sensitivity analysis has been performed. By analyzing the first-order and the total-effect sensitivity indices, it is seen that the variance of α, the “normalized” contact rate between newcomers and spreaders, provides the main contribution to the variance of R0. Further, the evolution of the newcomer population, of the spreader population and of the inhibitor are depicted for both how and high initial densities of spreaders. This study does not consider the influence of the network structure on rumor spreading, which is left as a possible avenue of further research.

Ming Li: Conceptualization, Writing - original draft, Data curation, Editing. Hong Zhang: Methodology, Writing - original draft, Visualization, Editing, Supervision, Funding acquisition. Paul Georgescu: Methodology, Writing - original draft, Editing, Supervision, Writing - revision. Tan Li: Conceptualization, Project administration, Funding acquisition.
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Physica A
PMC7809685,Accurate detection of Covid-19 patients based on Feature Correlated Naïve Bayes (FCNB) classification strategy,"Coronavirus is highly threatening for both animal and human life. Many types of coronavirus can transfer from animals to the human population (Shaban et al. 2020; Barstugan et al. 2020). Humans have not previously identified COVID-19 because it is a new species that appeared in 2019. COVID-19 is a global epidemic problem that can spread rapidly among people (Shaban et al. 2020; Li et al. 2020a). On the 7th of January 2020, COVID-19 has been identified by the World Health Organization (WHO) and the Chinese government as a global pandemic (Kang et al. 2020). COVID-19 has typical symptoms that involve shortness of breath, fever, headache, cough, fatigue, sore throat, and muscle pain (Huang et al. 2020). Physical contact is the main reason of the spread of COVID-19 disease among people. The infections are transferred from the infected COVID-19 person to the healthy person through hand contact, mucous contact, or breathe contact. Because of the rapid spread of COVID-19 around the world, it causes a destructive impact on issues like public health, the global economy, and daily activities. Moreover, COVID-19 infection takes less than 4 weeks to quash the medical system once it begins to spread (Shaban et al. 2020).To this end, early detection of COVID-19 especially with the lacking of specific cures or vaccines, is an essential process for treating and controlling the disease from spreading.
A real-time Reverse Transcription-Polymerase Chain Reaction (RT-PCR) is the most preferable test that is currently used for detecting COVID-19 patients (Zu et al. 2020). Although RT-PCR tests are sensitive, fairly quick, and reliable, these tests suffer from the risk of eliciting false-negative and false-positive results. Consequently, the spread of COVID-19 infection has been increased because RT-PCR tests cannot immediately distinguish the infected people (Zu et al. 2020). Chest radiological imaging such as Computed Tomography (CT) images and X-rays play an important role in the early detection and treatment of COVID-19 patients. Despite the advantages of CT images for detecting COVID-19 patients, misclassification may occur between the imaging features of COVID-19 and other types of diseases (Shaban et al. 2020; Li et al. 2020a, b). With increasing demand toward providing accurate tests, the dependency on CT images or RT-PCR tests as accurate tools for the detecting of COVID-19 patients is decreased dramatically. To this end, fast and accurate detection of COVID-19 patients is very important to prevent the sources of infection. Recently, machine learning is an adjunct tool for clinicians. Machine learning can automatically support medical diagnosis as a helping tool for identifying and detecting the novel coronavirus.
Machine learning is an application of Artificial Intelligence (AI) that is used for the concept of software that automatically learns how to execute a task or solve a problem (Rabie et al. 2015; Rabie et al. 2019a). Machine learning techniques become more and more accurate over time, and they work on the same principle. Firstly, they receive some input training data. Then, build the mathematical model depending on this training input data. Finally, the mathematical model is used to solve the problem at hand. Many methods have been provided for COVID-19 detection based on machine learning techniques (Zhong et al. 2020; Rustam et al. 2020; Alazab et al. 2020). Despite the efficiency of these methods, they suffer from many limitations such as low diagnosis accuracy, high complexity, and long prediction time.
Naïve Bayes (NB) is a simple, popular classifier, and powerful machine learning technique. It has been verified as the highly professional probabilistic classifier that has solid mathematical fundamentals (Kumar et al. 2019; Rabie et al. 2015, 2019a). NB has worked very well in several complex real-world applications such as; medical diagnosis, real-time prediction, spam filtering, and weather forecasting despite its oversimplified assumptions and its Naïve design (Dada et al. 2019; Ali and Ali 2020; Hewage et al. 2020; Lei et al. 2020). Thus, NB can be considered as one of the best classifiers that can be applied for COVID-19 detection. This is due to many reasons, which can be summarized as follows; (1) NB can provide fast predictions rather than other classification algorithms because the training time has an order O(N) with the dataset, (2) it can be easily trained with small amount of input training dataset and it can be used also for large datasets as well, (3) the simplicity and easy implementation with the ability of real-time training for new items, (4) the implementation of this classifier has no required adjusting parameters or domain knowledge, (5) It handles both continuous and discrete data, (6) NB is less sensitive to missing data, (7) NB has high capability to handle the noise in the dataset, (8) NB is an Incremental learning approach because its functions work from an approximation of low-order probabilities which are extracted from the training data. Hence, these can be quickly updated as new training data are obtained, (9) If the Naive Bayes conditional independence assumption holds, then it will converge quicker than discriminative models like logistic regression, (10) NB can be used for both binary and multiclass classification problems and (11) NB is sufficient for real-time applications such as diseases diagnoses because it relies on a set of pre-computed probabilities that make the classification done in a very short time (Khotimah et al. 2020; Kaur and Oberoi 2020), Although NB has proven efficiency with real-time applications, its performance is sometimes thumping in many cases because of the unrealistic assumption that all features have the same degree of importance and are independent of the given class value. Hence, this unrealistic assumption should be mitigated to overcome such hurdles. Recently, there have been extensive researches to provide solutions for this issue such as feature selection and weighting. However, the desired performance of NB has not been introduced yet. More efforts should be performed to enhance the performance of NB to match real-world conditions.
The contributions of the proposed work are listed as follows.A novel Feature Correlated Naïve Bayes (FCNB) classification strategy for accurate detection of Covid-19 patients has been proposed.The FCNB consists of two stages, namely; (1) Pre-Processing Stage (P2S) and (2) Classification Stage (CS).The P2S contains the first three phases of the FCNB strategy called Feature Selection Phase (FSP), Feature Clustering Phase (FCP), and Master Feature Weighting Phase (MFWP). Moreover, the CS contains the Feature Correlated Naïve Bayes Phase (FCNBP) that represents the last phase of the FCNB strategy.In the P2S, the collected historical data on both COVID-19 patients and non- COVID-19 people are represented in suitable form after performing many essential processes to enable the diagnostic model in the next stage to accurately diagnose COVID-19 patients.During P2S, the most significant features will be selected by using the Genetic Algorithm (GA) in FSP, and then these selected features will be put into groups or clusters in the FCP by using a new clustering technique in which each group is called Master Feature (MF) that includes a set of dependent or related features. Then, the MFWP will assign a weight value to each MF by using a new weight calculation method based on the number of features in MF, the correlation between features, and the summation of weights for each feature in MF.During the second stage (CS), the FCNBP tries to provide a fast and accurate diagnosis for COVID-19 patients based on the data received from the P2S by using a new classification model.The main objective of the proposed classification model is to overcome the problems of traditional weighted NB for improving its performance by (1) taking into consideration the correlation between features, and (2) reduces the classification time because it considers the weights of the used MFs rather than the weights of many individual features.
The paper is organized as follows: In Sect. 2, the main problem of this study is formulated. In Sect. 3, the diagnosing methodologies of COVID-19 are presented. In Sect. 4, related work is reviewed. In Sect. 5, the weighted Naïve Bayes is explained. In Sect. 6, the proposed Feature Correlated Naïve Bayes (FCNB) classification strategy is elaborated. An illustrative example is introduced in Sect. 7. The experiments are presented and the results are analyzed in Sect. 8. In Sect. 9, the paper is concluded and the future work is presented.
Due to the unavailability of a specific vaccine against COVID-19 infections with no drug has proven a high clinical efficacy, the early detection of COVID-19 disease is essential for disease cure and control. Undoubtedly, the management of COVID-19 will place considerable pressure on health-care systems (Wang et al. 2020; Li et al. 2020a, c). Moreover, the low availability of appropriate personal protective equipment for front-line health-care staff causes these key staff to be disproportionately affected by COVID-19. Nowadays, fast detection and isolation of the infected people is an effective method for the healthcare system protection from becoming overwhelmed because it will flat the epidemic curve as depicted in Fig. 1. Otherwise, with no protective measures, the capacity of the health-care systems will be broken. Disruption or complete breakdown of health-care systems would result in high mortality since the care of all illnesses will be degraded. Due to the unavailability of the diagnosis system everywhere, the detection of COVID-19 is currently a tedious task, which will cause panic. Because of the limited availability of COVID-19 testing kits especially in developed countries, there is a critical need to rely on other diagnosis strategies (Li et al. 2020a, c).
Rapid and accurate detection of COVID-19 is an increasingly vital issue since the infected people may not be recognized and get suitable treatment on time. The infected people will spread the virus to healthy people due to the communicable nature of COVID-19. Although several COVID-19 diagnosis strategies based on data mining and artificial intelligence have been recently introduced, the desired diagnose accuracy to flatten the COVID-19 epidemic curve has not been reached yet (Li et al. 2020a, b; Jamshidi et al. 2020). The aim objective of this paper is to introduce an accurate, fast, and reliable COVID-19 diagnosis strategy, called FCNB, which inherits the advantages of NB with several modifications.
Generally, the diagnosing of COVID-19 can be achieved using three different methodologies as depicted in Fig. 2. These three methodologies are (1) Real-Time reverse transcriptase- Polymerase Chain Reaction (RT-PCR) (Tahamtan and Ardebili 2020; Waller et al. 2020; Li et al. 2020a, d), (2) chest CT imaging scan (Mishra et al. 2020; Li et al. 2020a, e; Kovács et al. 2020), and (3) numerical laboratory tests (Brinati et al. 2020; Kukar et al. 2020; Cabitza et al. 2020; Qiu et al. 2020). RT-PCR tests are fairly quick, sensitive, and reliable. The sample is collected from a person’s throat or nose; adding some chemicals for removing any proteins, fats, and other molecules, leaving behind only the existing Ribonucleic Acid (RNA) (Huang et al. 2020). The separated RNA is a mixture of a person’s RNA and the coronavirus’s RNA if exists. Despite its popularity, the RT-PCR test suffers from the risk of false-negative and false-positive results (Chen et al. 2020a, b; Kasteren et al. 2020).
Although several studies had observed that the sensitivity of Chest CT in the diagnosing of COVID-19 is higher than that of RT-PCR, the American College of Radiology (ACR) has issued guidance that CTs and X-rays are not accurate tools for diagnosing COVID-19 (Gietema et al. 2020). There are three significant reasons for ACR’s recommendation, which are; (1) both chest CT and X-ray cannot accurately distinguish between COVID-19 and other respiratory infections. They can only point to signs of an infection, which could be due to other reasons such as seasonal flu. (2) A huge number of patients infected with COVID-19 have normal chest CTs, which wrongly convince them that they are healthy. Those convince patients can easily spread the virus to others. (3) The usage of the imaging equipment on COVID-19 patients is a critical hazard for doctors and other patients. CT scanners are complex and large machinery pieces (Gietema et al. 2020). They need to be carefully cleaned after each potential COVID-19 patient.
However, even with precise cleaning, there is a high risk that the virus could remain on the surface of the CT scanner room. Moreover, the movement of COVID-19 patients to and from a CT scanner room increases the risk of spreading the virus inside of the healthcare system. On the other hand, the use of accurate Numerical Laboratory Tests (NLTs) can be considered as the most accurate method for diagnosing COVID-19. Recently, the use of NLTs is the only method that the Centers for Disease Control (CDC) currently endorse. Hence; it makes perfect sense that the use of NLTs will provide more accurate diagnosis with less waiting time. The work in this paper is concentrated on providing a new COVID-19 diagnosis system based on NLTs, which have proven to be the most effective methodology for COVID-19 diagnosis. A new diagnosis strategy called FCNB will be introduced, which is based on the weighted Naïve Bayes algorithm with several modifications.
Recently, there has been extensive research on COVID-19 patients detection.
A Textual Clinical Reports Classification (TCRC) model was provided by Khanday et al. (2020) for detecting COVID-19, Severe Acute Respiratory Syndrome (SARS), Acute Respiratory Distress Syndrome (ARDS), and both (COVID-19, ARDS) by using different classical and ensemble machine learning methods. The experimental results showed that the logistic regression and multinomial Naïve Bayes provided the best results compared to other machine learning algorithms.
Ozturk et al. (2020a) developed a Deep Learning (DL) model to detect COVID-19. The proposed model was implemented on the dataset that consists of three classes called; COVID-19, pneumonia, and normal X-ray imagery. This study passed through two main steps, which are; pre-processing step and the classification step. In the pre-processing step, the fuzzy coloring method was used to re-structure the data classes and the structured images were stacked. In the classification step, deep learning models (MobileNetV2, SqueezeNet) were trained and then the social mimic optimization technique was used to obtain a set of efficient features. These efficient features were combined to provide the classification by using Support Vector Machines (SVM) as a classifier. The experimental results proved that the proposed classification model could efficiently detect the COVID-19 disease.
Maghdid et al. (2020) introduced a Convolution Neural Network (CNN) model to detect COVID-19 cases based on chest X-ray and CT images dataset. The proposed CNN model contained two main algorithms called CNN architecture and AlexNet as a transfer-learning algorithm. Although the simplicity of this proposed model, its accuracy is not enough for the diagnosing of COVID-19 patients. The experimental results illustrated that the maximum accuracy of the utilized models was provided by using a pre-trained network, but the minimum accuracy was provided by using the modified CNN.
Chen et al. (2020a, b) introduced a COVID-19 Diagnostic Model (CDM) based on radiological semantic and clinical features without the need for the nucleic acid test. The experimental results demonstrated the effectiveness of the proposed CDM technique for the diagnosing of COVID-19 cases in which CDM provided better diagnostic performance and more considerable net benefits.
Waheed et al. (2020) proposed an Auxiliary Classifier Generative Adversarial Network (ACGAN) based GAN called CovidGAN to produce synthetic Chest X-Ray (CXR) images. The synthetic images generated from CovidGAN were utilized to enlarge the dataset and to enhance the performance of Convolutional Neural Network (CNN) for COVID-19 detection. The experimental results proved that the accuracy of the usage of CNN based on the synthetic images generated from CovidGAN was better than the accuracy of using CNN alone. Although the proposed detection model provided the best accuracy, it depended on a small dataset. Additionally, the quality of the synthetic samples needed to be improved by adding more labeled data, which increased the learning process of GAN.
An Automatic COVID-19 Detection Model (ACDM) based on using the DarkNet model as a classifier was provided by Ozturk et al. (2020b). The proposed ACDM method was used as a new detection method based on using chest X-ray images. This model represented the development of deep learning techniques to be able to perform both binary and multi-class classification. The experimental results demonstrated that the effectiveness of ACDM to perform binary tasks was better than its effectiveness in performing multi-class tasks as the accuracy of binary was higher than in multi-class.
Sun et al. (2020) presented an Adaptive Feature Selection guided Deep Forest (AFS-DF) based on using chest CT images was introduced to classify COVID-19 patients. For learning a high-level representation of features, the AFS-DF method used a deep forest model. Based on the trained forest, an adaptive feature selection operation was used to decrease the redundancy of the features for improving the performance of the classification process. The experimental results showed that the AFS-DF model outperformed several existing methods in which it could efficiently classify COVID-19 cases based on CT images. Table 1 illustrates a comparative study of the previous efforts on COVID-19 patients detection methods.
No doubt, Naïve Bayes (NB) is a popular classifier that had been applied in several domains such as; weather forecasting, bioinformatics, image and pattern recognition, and medical diagnosis. NB allows each feature to contribute towards the classification decision both equally and independently of other features. Although such simplicity increases computational efficiency, it sometimes makes NB insufficient with real- world conditions.
Consider F = {f1, f2, f3, …fn} to be a set of feature vectors of a new item IC to be classified and C = {c1, c2, c3, ….cm} be set of target classes. The probability of a new item being in class cj using NB is given by (1) (Berrar 2018; Taha et al. 2013)1\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Target\left( {IC} \right) = \mathop {\text{argmax}}\limits_{c_j \in C} \left[ {P\left( {c_j |F} \right)} \right] = \mathop {\text{argmax}}\limits_{c_j \in C} \left[ {\frac{{P\left( {F |c_j } \right) \times P\left( {c_j } \right)}}{P\left( F \right)}} \right] $$\end{document}TargetIC=argmaxcj∈CPcj|F=argmaxcj∈CPF|cj×PcjPFwhere, P(cj|F) is the conditional probability of class cj given the feature vector F (also called posterior probability), P(F|cj) is the conditional probability of class F given the class cj (also called likelihood), and P(cj) is the prior probability of class cj. Since features are independent, this yields;\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ P\left( F \right) = P\left( {f_1 ,f_2 ,f_3 , \ldots f_n } \right) = P\left( {f_1 } \right) \times P\left( {f_2 } \right) \times P\left( {f_3 } \right) \times \cdots \times P\left( {f_n } \right) = \mathop \prod \limits_{i = 1}^n P\left( {f_i } \right) $$\end{document}PF=Pf1,f2,f3,…fn=Pf1×Pf2×Pf3×⋯×Pfn=∏i=1nPfi\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ P\left( {F|c_j } \right) = P\left( {f_1 ,f_2 ,f_3 , \ldots f_n |c_j } \right) = P\left( {f_1 |c_j } \right) \times P\left( {f_2 |c_j } \right) \times P\left( { f_3 |c_j } \right) \times \cdots \times P\left( {f_n |c_j } \right) = \mathop \prod \limits_{i = 1}^n P\left( {f_i |c_j } \right) $$\end{document}PF|cj=Pf1,f2,f3,…fn|cj=Pf1|cj×Pf2|cj×Pf3|cj×⋯×Pfn|cj=∏i=1nPfi|cj
Substitute in (1), this yield (2) (Jabeen et al. 2019)2\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Target\left( {IC} \right) = \mathop {\text{argmax}}\limits_{c_j \in C} \left[ {\frac{{P\left( {c_j } \right) \times \prod_{j = 1}^n P\left( {f_i |c_j } \right)}}{{\prod_{i = 1}^n P\left( {f_i } \right)}}} \right] $$\end{document}TargetIC=argmaxcj∈CPcj×∏j=1nPfi|cj∏i=1nPfi
Since the denominator in (2) remains constant for a given input for all target classes, it can be removed as illustrated in (3) (Zhang et al. 2021; Subramanian and Prabha 2020; Abellán and Castellano 2017)3\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Target\left( {IC} \right) = \mathop {\text{argmax}}\limits_{c_j \in C} \left[ {P\left( {c_j } \right) \times \mathop \prod \limits_{i = 1}^n P\left( {f_i |c_j } \right)} \right] $$\end{document}TargetIC=argmaxcj∈CPcj×∏i=1nPfi|cj
However, the performance of NB is sometimes low due to the unrealistic assumption that all features are independent and equally important given the class value. The performance of NB can be increased by mitigating this assumption. Many improvements have been proposed to resolve this problem including feature selection and feature weighting. Generally, feature selection can be applied to enhance the performance of the traditional Naïve Bayes classifier. Hence, the target class can be identified by (4) (Lee et al. 2011).4\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Target\left( {IC} \right) = \mathop {\arg \hbox{max} }\limits_{c_j \in C} \mathop {\left[ {P\left( {c_j } \right) \times \mathop \prod \limits_{i = 1}^n P\left( {f_i |c_j } \right)^{S_i } } \right]}\limits_{where S_i \in \left\{ {0,1} \right\}} $$\end{document}TargetIC=argmaxcj∈CPcj×∏i=1nPfi|cjSiwhereSi∈0,1
However, assigning an equal value of weight to all considered features breaks the nature of real-world applications. Accordingly, different weights can be assigned to each feature as a generalization of feature selection as illustrated in (5) (Yu et al. 2019; Jiang et al. 2019)5\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Target\left( {IC} \right) = \mathop {\arg \hbox{max} }\limits_{c_j \in C} \mathop {\left[ {P\left( {c_j } \right) \times \mathop \prod \limits_{i = 1}^n P\left( {f_i |c_j } \right)^{W_i } } \right] }\limits_{where W_i \in {\mathbb{R}}^+ } $$\end{document}TargetIC=argmaxcj∈CPcj×∏i=1nPfi|cjWiwhereWi∈R+
As depicted in (5), unlike traditional NB, each feature fi has its weight wi, which can be a positive number representing the significance of the feature. However, both traditional and Weighted Naïve Bayes (WNB) classifiers are based mainly on probabilities, namely; the conditional probabilities of the input features given the considered target classes as well as the classes prior probabilities. From another point of view, promoting the performance of the WNB classifier can be achieved by compensating its performance with another heuristic besides conditional and prior probabilities.
Usually, records of patients contain many features used to support the medical diagnosis. However, for the early COVID-19 detection task, not all of these features have the same importance. The performance of the diagnostic operation may rely on the selected features in all phases of the FCNB. Hence, the main objective of FSP is to eliminate the irrelevant features and select the best features before using the diagnostic model. Selecting the best features will improve the performance of the machine learning algorithm, decrease the time of processing, increase the computational efficiency, minimize the storage requirement, and increase the convergence of learning (Wosiak and Zakrzewska 2018; Saleh et al. 2016). In this paper, the considered methodology to select the most effective subset of features on COVID-19 is Feature Selection based on Genetic Algorithm (FSGA) methodology. FSGA is a wrapper method used to select the most important features depending on specific evaluation metrics.
Unlike classical selection methods which search from a single point and can deal poorly with large search spaces, FSGA depends on GA that can discover the global optimal solution and prevent the trapping in local optimal solution (Sivanandam and Deepa 2008). To implement FSGA, consider that the Feature set (F) of ‘n’ features can be expressed by F = {f1, f2, f3, f4, …, fn}, where the input training data set of ‘k’ patients can be expressed by I = {I1, I2, I3I4, …, Ik}. Additionally, the testing dataset of ‘q’ patients can be expressed by G = {G1, G2, G3, G4, …, Gq}. Each patient of Yj ∈ I and Ri ∈ G is expressed as an ordered set of ‘n’ features; Yj(f1, f2, f3, f4, …, fn)= [f1j, f2j, f3j, f4j, …, fnj]and Ri(f1, f2, f3, f4, …, fn)= [f1i, f2i, f3i, f4i, …, fni]. Accordingly, each training patient Yj and testing patient Ri can be expressed in an ‘n’ dimensional space of features. For the considered COVID-19 detection problem, it is important to use FSGA as a suitable feature selection methodology to reduce or eliminate the irrelevant features to enhance the performance of the classifier.
After extracting the features from laboratory tests for both COVID-19 patients and non -COVID-19 people, the collected dataset should be passed to FSGA for selecting the most effective features on COVID-19 cases. The FSGA depends on applying GA as it is an optimization technique and adaptive search heuristic algorithm that followed the process of natural evolution. The GA starts with a population of potential solutions, and then it employs the concept of survival of the fittest to generate the closest optimal solutions according to a fitness function of an optimization problem (Saleh et al. 2016; Oluleye et al. 2014). Hence, FSGA begins with an initial population, which is a group of candidate solutions, or chromosomes in which every chromosome composes of series of genes. The value ‘1’ of a gene denotes that the feature is selected in the particular subset. Otherwise, the value ‘0’ of a gene denotes that the feature is eliminated from the particular subset (Saleh et al. 2016; Kaviani and Dhotre 2017). Consider that a single chromosome has ‘n’ genes (i.e., the same number of features in the dataset), hence; F = {f1, f2, f3, f4, …, fn}. Assume that “n = 15 features”, thus, a single chromosome can be represented as; {f1, f2, f3, f4, …, f15} as shown in Table 2. The biological functions (three operators of FSGA) such as selection, crossover, and mutation are applied to these chromosomes to produce a new generation of the population. These three operators are repeated until a termination condition has been satisfied.
The accuracy of NB is evaluated to be used as a fitness function in FSGA for choosing the best chromosome that includes the most effective features on COVID-19. The main objective of selecting the best subset of the features is to achieve the highest accuracy of the used COVID-19 detection model. Finally, there are many steps to implement FSGA as presented in Fig. 4. At first, the initial population (p) of FSGA is represented by many candidate solutions, which are called chromosomes. Each chromosome consists of genes; each gene represents a feature in COVID-19’s dataset. The existence or absence of a feature is determined by the value of the gene, where the value equals ‘1’ means the feature is existing, and ‘0’ means the feature is eliminated. Secondly, NB’s accuracy as a fitness function is calculated for each chromosome (candidate solution) in p to provide a fitness value that indicates the goodness of the solution. The optimal solution is the solution that maximizes the fitness function.
Based on the fitness values, the selection of parent members (chromosomes) for reproduction is done according to the probability of selection (psel). After that, the crossover between the parent members is done to produce the offspring according to the probability of crossover (pcross). According to the probability of mutation (pmut), the mutation is performed for each offspring. Loops over these steps are repeated from the selection until the size of the next population equals the size of the initial population. If the terminal condition is not satisfied, the previous steps will be repeated from the fitness function. In the end, when the terminal condition is satisfied, the chromosomes in the population will be evaluated as the final results by using only the fitness function. Then, the chromosome that provides the highest fitness value contains the best subset of features donated by ‘1’ value. The steps to implement FSGA are illustrated in Algorithm 1.
Generally, records of patients can be used to represent the data in supervised learning. Each record is described by a set of features. These features take one of two types, which are; “nominal” or “numeric” values. While nominal values represent members of an ordered set, and numeric values represent real numbers. In fact, the number of features which affected COVID-19 patients is “15” features (n = 15) as described in Table 3. As an illustrative example, a nominal dataset of 25 patients as well as the features, which affected them, are represented in Table 4. For simplicity, each patient in Table 4 has been described by a subset of features presented in Table 3. This subset of features contains ‘6’ features, which are; Platelet Count (PC), White Blood cell (WBC), Monocytes Count (MC), Aspartate aminotransferase (AST), Basophils Count (BC), and Lactate Dehydrogenase (LDH). Hence, the features in Table 4 are represented as; F = {f1, f2, f3, f4, f5, f6} = {PC, WBC, MC, AST, BC, LDH} in which nominal values of each feature is presented in Table 5. Each patient has a class label, which indicates one of the two target classes “True, False”. True indicates COVID-19 Patient and False indicates non-COVID-19 People. The first 15 records in Table 4 represent the training dataset (e.g., k = 15); I = {I1, I2, I3, I4, …, I15} and the last 10 records represent the testing dataset (e.g., q = 10); G = {G1, G2, G3, G4, …, G10}.
To implement the NB classifier, it is essential to create the frequency distribution tables (also called “contingency tables”) to construct the relationships between the features and the class categories (Huang et al. 2020; Saleh et al. 2016). Tables 6a–f are the frequency distribution tables that represent the relationships between the features and the class categories in the considered “COVID-19” dataset. Tables 6a–f, are used to calculate the probabilities which are used to apply the NB equation.
The FSGA is a feature selection method that is used on the “COVID-19” dataset in Table 4 to choose the most effective features on COVID-19 patients. The accuracy of the NB classifier is used as a fitness function to evaluate each chromosome in the population of FSGA in which NB’s accuracy can be calculated by using the confusion matrix (Saleh et al. 2016; Visa et al. 2011). There are many assumptions to implement FSGA on the considered“COVID-19” dataset as presented in Table 7. Based on the previous assumptions, after employing FSGA, the steps followed in the first and the second iterations are illustrated in Figs. 5 and 6 respectively. Finally, the best subset of features according to the best chromosome contains ‘3’ features; F = {WBC, AST, LDH}. After applying FSGA methodology on the original set of features (n = 15) in the considered “COVID-19” dataset, the number of the selected features becomes “10” features. Thus, a new set of features that contains “10” features instead of “15” features is represented as; F = {f1, f2, f3, f4, f5, f6, f7, f8, f9, f10} = {WBC, AST, LDH, LC, ALT, CRP, EC, ALT, NC, GGT}.
According to the first step called construct actual clusters, each feature in the Features set is considered as a centroid of the cluster as illustrated in Fig. 8. Then, the distance between each centroid and their neighbours should be calculated by using Euclidean distance to determine their nearest neighbours (e.g. no. of nearest neighbours = 2), hence, nth = 3. For simplicity, assume that the Euclidean distance d(c, f) will be implemented between the centroid c and one of its neighbour features f in 2-dimension; c(x1, y1) and f(x2, y2) by using (6) (Dokmanic et al. 2015; Liu et al. 2020).6\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ d\left( {c,f} \right) = \sqrt {(c_{x1} - f_{x2} )^2 + (c_{y1} - f_{y2} )^2  } $$\end{document}dc,f=(cx1-fx2)2+(cy1-fy2)2where d(c, f) is the distance between the centroid c and one of its neighbours f, x and y are the coordinates of both the centroid and the feature. Distance calculation should be performed between the centroid and all neighbors of features. According to the smallest distances, the centroid can determine their nearest neighbors (e.g. no. of nearest neighbors = 2). On the other hand, the ZHD can be determined for the cluster in which its value is the largest distance between the centroid and its neighbours as illustrated in the third step of Fig. 7. Then, actual clusters are constructed by placing the features in Fordered in an ascending order based on their ZHD. After that, the feature which has the smallest ZHD is selected to be a centroid of the first actual cluster.
The centroid neighbours should be determined and assigned to their corresponding cluster, and then these neighbours should be removed from Fordered as illustrated in the fourth step of Fig. 7. The same steps will be repeated according to the current Fordered until all actual clusters have been constructed. Although actual clusters that include similar features have been constructed, many isolated features do not belong to any actual cluster such as f1 and f2 as illustrated in the fifth step of Fig. 7. Thus, these isolated features need to be assigned to the nearest cluster or need to construct a new dummy cluster that includes them. The next subsection describes how to assign the isolated features.
After creating all actual clusters, there are many isolated features. An isolated feature is a feature that doesn’t belong to any actual cluster. This feature needs to be assigned to the nearest cluster or needs to construct a new dummy cluster that includes it (Arunadevi et al. 2019). There are many steps to solve this problem as shown in Fig. 9. Figure 9 illustrates the assignment of the isolated features to the nearest cluster or a new dummy cluster. At first, the largest radius of all actual clusters (ZHDmax) should be determined. Then, the distance between each isolated feature and the nearest centroid should be calculated by using Euclidean distance and then compared to ZHDmax. If the distance is more than ZHDmax, this means that the isolated feature will construct a new dummy cluster. Otherwise, the isolated feature will belong to the cluster of the nearest centroid (Ci). If there is more than one centroid has the same distance to the isolated feature, the isolated feature will belong to any one of these nearest centroids. Finally, the Master Features (MFs) are constructed to represent the final clusters after assigning the isolated features to their corresponding clusters.
After the construction of actual clusters has been performed and then the isolated features have been assigned to their corresponding cluster, the features should be weighted. Weighting features is a significant process in P2S because it can decrease the complexity, increase the performance of the machine-learning algorithm, and increase the resource efficiency of the used classifier. Usually, many classification algorithms suppose that all features have the same importance (same weights) or neglect the consistency of weights assigned to features. To solve this problem, it is important to calculate the feature weight value in which the largest weights should be assigned to the most effective features on COVID-19. Hence, different features can have different levels of importance in class prediction (Arunadevi et al. 2019). The last step in the FCP is to calculate the weight of each feature in the constructed Master Feature (MFi). The weight of each feature fh can be calculated by using (7).7\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ W\left( {f_h } \right) = \, Accuracy \, of \, classifier \, \left( { + f_h } \right) \, - \, Accuracy \, of \, classifier \, \left( { - f_h } \right) $$\end{document}Wfh=Accuracyofclassifier+fh-Accuracyofclassifier-fhwhere W(fh) is the weight value of feature fh, Accuracy of classifier (+ fh) is the accuracy of the used classifier when the feature fh is included in the feature set, and Accuracy of classifier (− fh) is the accuracy of the used classifier when fh is eliminated.
MFWP is the third and final phase in the P2S stage that is used to assign a weight to each MF. Indeed, the correlation between features is very important before assigning weights to them. Hence, it is an essential process to determine the correlation between features by using a suitable correlation method. Correlation analysis is one of the well-known widely used techniques that identifies; (1) the relationship between the features and the predicted class and (2) the relationship between the features with each other. Mathematically, the relationship between features can be determined by a decimal value called the correlation coefficient. The positive sign of the coefficient indicates that the two features are positively correlated, the negative sign means negative correlation, and the ‘0’ value means no correlation (Li et al. 2016). In this paper, the proposed feature correlation method based on the distance measurement has been introduced to calculate the relationship between the features of MFi. The steps of implementing the proposed feature correlation methodology are illustrated in Fig. 10.
Figure 10 shows three proposed feature correlation methods to measure the correlation between the features of the MFi. The first method measures the correlation by determining the multiplicative inverse of ZHD, but it does not take into consideration the correlation between features. For example, as shown in Fig. 10, if “ZHD of MFi = 10” and “ZHD of MFj = 5” then, the correlation of MFi and MFj are 0.1 and 0.2 respectively. This means that MFj is more correlated than MFi, but it is not correct. In the second method, the correlation is measured by determining the total distance between the centroid and all features of the master feature. The limitation of this method is that it does not take into consideration the correlation between the features with each other. In the third and final method, the correlation is measured by determining the total distance between the features of the master feature. This method considers the correlation between the features and the centroid, and also the correlation between the features with each other. Accordingly, the third method is the best correlation method used to measure the correlation between features. After implementing the third correlation method to calculate the relationship between the features of the MF, MFWP can be implemented to calculate the weights of MFs.
NB classifier is a common that is used in machine learning and data mining. It is crucial to use NB for solving different data classification problems because it is simple to be trained, easy to implement, and can provide fast and accurate predictions. However, it assumes that all features are conditionally independent which is often harming the performance of classification. This is not correct in real-world applications because the features don’t have the same importance (Taheri et al. 2014). To improve the performance of NB, many modified methods based on NB have been proposed. One of these modified methods is to assign a weights value to each feature. In this paper, the weight of each master feature (MFi) depends on three parameters, which are; the number of features in this master feature, the correlation value between features in MFi, and the summation of weights values for each feature in MFi. The weight of master feature MFi can be calculated by using (8).8\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ W\left( {MF_i } \right) = N_i \times corr\left( {MF_i } \right) \times \sum \limits_{\forall f_j \in MF_i } w_i $$\end{document}WMFi=Ni×corrMFi×∑∀fj∈MFiwiwhere W(MFi) is a weight of master feature MFi, Ni is the number of features in the master feature MFi, and corr(MFi) is the correlation value between features in the master feature MFi. wi is the weight value of each feature fj that belongs to the master feature (MFi). After calculating the weights of all MFs, the weighted MFs will be used in the next stage (CS) to implement the weighted NB in FCNBP. In the next section, FCNBP will be explained in detail to classify the COVID-19 patients by implementing the weighted NB classifier on the weighted MFs.
NB is known to be an effective, robust, and efficient classification algorithm. NB is a promising solution as it only requires a little amount of training data to estimate the parameters required for classification and able to accommodate new incoming data for training both efficiently and incrementally. Although NB had received extensive attention due to its excellent classification performance and simplicity, it sometimes has a degraded performance due to the naïve assumption that features are independent and equally weighted. To compensate the performance of the traditional NB, a new classifier is proposed in this phase, which is called Feature Correlated Naïve Bayes (FCNB). The proposed FCNB enhances the performance of the traditional NB by clustering the selected features into groups called master features (MFs) in which each MF includes a set of dependent or related features. Moreover, each MF is weighted based on the importance of the features it includes as well as the correlation among the included features. FCNB operates just like weighted NB; however, it replaces the employed features with a set of constructed MFs. Also, it considers the weights of the used MFs rather than the weights of the individual features. This has a positive effect in (1) promoting the performance of the traditional weighted NB as it considers the correlation among features and (2) minimizes the classification time as it considers a smaller number of MFs rather than many individual features.
To explain how FCNB operates, consider a diagnosis database that includes ‘Ca’ cases in which ‘A’ cases are infected with COVID-19 and ‘B’ cases are not, hence; Ca = A + B. Consider ‘s’ selected features labeled as; f1, f2, …, fs, which are clustered into mm master features labeled as MF1, MF2, MF3, … and MFmm, where s > mm. Like any supervised learning- based classifier, FCNB operates in two sequential phases; namely training and testing. The training of the proposed FCNB is accomplished by constructing a Conditional Probability Table (CPT) for each master feature MFi as illustrated in Table 8 based on the input diagnosis database. As depicted in Table 8, for simplicity, it is assumed that MFi includes three dependent features, namely; fx, fy, and fz in which each feature takes ‘L’ or ‘H’ value, which corresponds to “Low” or “High” respectively. Accordingly, MFi has 8 distinct values labeled as; Xij ∀ j∈{1, 2, 3, …, 8}. However, each MF can include more dependent features in which each feature can takes one of many values rather than ‘L’ and ‘H’ only. For illustration, a feature may take a value V∈{VL, L, M, H, VL}, which indicates “Very Low”, “Low”, “Medium”, “High”, or “Very High” respectively. Table 8 illustrates CPT of MFi in which the conditional probability for each value Xij ∀ j ∈ {1, 2, 3, …, 8} of MFi for each target class (e.g., T or F) is calculated given the input diagnose database. It is assumed that the weight of MFi is Wi while the prior probabilities of the considered target classes are; P(T)= A/Ca and P(F)= B/Ca.
On the other hand, the task during the testing phase of FCNB is to diagnose the input case to indicate whether the case is infected with COVID-19 or not. Assuming an input case IC who has the following feature vector 〈f1, f2, f3,…, fs-1, fs〉 with the corresponding values〈L, L, H,…, h, L〉. Initially, the input features are clustered into the corresponding master features (e.g., MF1, MF2,…, MFmm) with the corresponding values. Considering the CPT of each employed MF, it will be easy to find the conditional probability for each value of the employed master features. Hence, it will be easy to diagnose the new case by estimating the posterior probability that the case is belonging to each class (T or F) as shown in (9) (Yearwood et al. 2014).9\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ P\left( {c_i |IC} \right) \propto \left[ {P\left( {c_i } \right) \times \mathop \prod \limits_{j = 1}^n P\left( {MF_j |c_i } \right)^{W_j } } \right] $$\end{document}Pci|IC∝Pci×∏j=1nPMFj|ciWjwhere P(ci|IC) is the posterior probability that the case IC belongs to class ci, P(ci) is the prior probability of class ci, P(MFj| ci) is the conditional probability of the master feature MFj given the target class ci, and Wj is the weight of MFj. Considering two target classes (e.g., T and F), this yields (10) and (11) (Lee et al. 2011).10\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ P\left( {T |IC} \right) \propto \left[ {P\left( T \right)*\mathop \prod \limits_{j = 1}^n P\left( {MF_j |T} \right)^{W_j } } \right] $$\end{document}PT|IC∝PT∗∏j=1nPMFj|TWj11\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ P\left( {F |IC} \right) \propto \left[ {P\left( F \right)*\mathop \prod \limits_{j = 1}^n P\left( {MF_j |F} \right)^{W_j } } \right] $$\end{document}PF|IC∝PF∗∏j=1nPMFj|FWj
Finally, the target class for the input case IC can be calculated by using (12) (Ji et al. 2019).12\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Target\left( {IC} \right) = \mathop {\arg \hbox{max} }\limits_{c_i \in \left\{ {T,F} \right\}} \mathop {\left[ {P\left( {c_i } \right) \times \mathop \prod \limits_{j = 1}^n P\left( {MF_j |c_i } \right)^{W_j } } \right]}\limits_{where W_j \in {\mathbb{R}}^+ } $$\end{document}TargetIC=argmaxci∈T,FPci×∏j=1nPMFj|ciWjwhereWj∈R+
In this section, an illustrative example showing how the diagnosis decision can be taken in the Classification Stage (CS) of the proposed Feature Correlated Naïve Bayes (FCNB) classification strategy. As illustrated in Table 9, consider a COVID-19 diagnosis database for 100 persons in which 40 persons are infected by COVID-19 while the other 60 persons are not. For simplicity, Considering 8 selected features labeled f1, f2, …, f8, which are clustered into three master features labeled MF1, MF2, and MF3, as well as two target classes, namely; “True” and “False” diagnose. The symbols ‘L’, ‘M’, and ‘H’ represents “low”, “medium”, and “high” respectively, while ‘T’ and ‘F’ represents “true” or “false” diagnose of the COVID-19 virus. The weight of each master feature is also reported in the last row of Table 9. On the other hand, the conditional probability for each feature value given different classes as well as the prior probability for each class are illustrated in Tables (10, 11, 12).
Now, it is required to diagnose a new case IC who has the following feature vector 〈f1, f2, f3, f4, f5, f6, f7, f8〉 with the corresponding values 〈L, L, H, H, L, L, h, L〉. Initially, the input features are clustered into the corresponding master features (e.g., MF1, MF2, MF3) with the corresponding values. Considering the input values of the selected features, it is found that; MF1=
X1, 2, MF2=
X2, 5, MF3=
X3, 3. From Tables 10, 11, 12, it will be easy to find the conditional probability for each value of the employed master features, which are; P(X1, 2|T)= 0.145, P(X1, 2|F)= 0.098, P(X2, 5|T)= 0.077, P(X2, 5|F)= 0.143, P(X3, 3|T)= 0.212, and P(X3, 3|F)= 0.194. On the other hand, the weights of the employed master features are illustrated at the bottom of Table 9, numerically; 0.42, 0.38, and 0.59 for MF1, MF2, and MF3 respectively. Since the employed database has 40 infected persons with COVID-19, while the remaining persons are not, the prior probability for the target classes (e.g., T and F) are; 0.4 and 0.6 respectively. Hence, it will be easy to diagnose the new case by estimating the posterior probability that the case is belonging to each class (T or F) as shown below.\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ QT = \left[ {P\left( T \right) \times \mathop \prod \limits_{j = 1}^n P\left( {MF_j |T} \right)^{W_j } } \right] = 0.4 \times P\left( {X_{1,2} |T} \right)^{W_1 } \times P\left( {X_{2,5} |T} \right)^{W_2 } \times P\left( {X_{3,3} |T} \right)^{W_3 } $$\end{document}QT=PT×∏j=1nPMFj|TWj=0.4×PX1,2|TW1×PX2,5|TW2×PX3,3|TW3\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ QT = 0.4*(0.145) ^{0.42} \times \left( {0.077} \right)^{0.38} \times \left( {0.212} \right)^{0.59} = 0.02687 $$\end{document}QT=0.4∗(0.145)0.42×0.0770.38×0.2120.59=0.02687\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ QF = \left[ {P\left( F \right)*\mathop \prod \limits_{j = 1}^n P\left( {MF_j |F} \right)^{W_j } } \right] = 0.6 \times P\left( {X_{1,2} |F} \right)^{W_1 } \times P\left( {X_{2,5} |F} \right)^{W_2 } \times P\left( {X_{3,3} |F} \right)^{W_3 } $$\end{document}QF=PF∗∏j=1nPMFj|FWj=0.6×PX1,2|FW1×PX2,5|FW2×PX3,3|FW3\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ QF = 0.6 \times (0.0.98) ^{0.42} \times \left( {0.143} \right)^{0.38} \times \left( {0.194} \right)^{0.59} = 0.04104 $$\end{document}QF=0.6×(0.0.98)0.42×0.1430.38×0.1940.59=0.04104where QT indicates the degree of confidence that IC is infected with COVID-19 and QF indicates the degree of confidence that IC is not infected with COVID-19. Hence, since QT < QF, then the input case IC is not infected with COVID-19.
COVID-19 dataset is a real dataset that is used to detect COVID-19 patients. This real dataset contains results of routine blood tests collected from different cases who were admitted to San Raffaele Hospital (Milan, Italy) (Ferrari et al. 2020; Brinati et al. 2020). Additionally, this dataset contains personal information of cases like age and gender (Male or Female). The total number of cases in this real dataset is 207. The dataset is divided into training and testing sets where the number of cases in training data is 140 and the number of cases in testing data is 67. According to this real dataset, it is considered two class categories called; COVID patients and Un-COVID people as shown in Table 14. The distribution of the used cases in the collected dataset has been represented according to “Age”, “Gender” as shown in Figs. 11, 12, 13.
During the next experiments, the evaluation parameters such as accuracy, error, recall, and precision will be calculated. Then, F-measure, micro average and macro average related to precision and recall will be measured. The confusion matrix is used to calculate the values of these parameters. A confusion matrix is applied as presented in Table 15. Various formulas are used as a summarization of the confusion matrix as depicted in Table 16. Finally, the speed of COVID-19 detection algorithms should be measured by using the second unit.
The effectiveness of the proposed feature selection method called FSGA is evaluated and compared with other existing approaches, which are; FSJaya (Das et al. 2020), MGOA (Sehgal et al. 2020), SDS (Shanthi and Rajkumar 2020), and ACO (Sowmiya and Sumitra 2020) by using the considered COVID-19 dataset. These feature selection approaches are described in Table 17. To prove the effectiveness of the feature selection method, the NB classifier is applied as a standard classifier (Rabie et al. 2019a, b, 2020; Ayyad et al. 2019). The obtained results show that the FSGA outperforms other approaches which are presented in Table 17. The results are shown in Figs. 14, 15, 16, 17, 18, 19, 20, 21, 22, 23.
As illustrated in Figs. 14, 15, 16, 17, FSJaya, SDS, ACO, MGOA, and FSGA techniques introduced accuracy with 0.82, 0.84, 0.88, 0.87, and 0.98 respectively with 140 training patients. The best accuracy is achieved by FSGA because FSGA can accurately select the most effective features of COVID-19 diagnosis. Thus, FSJaya, SDS, ACO, MGOA, and FSGA techniques give error values of 0.21, 0.19, 0.17, 0.13, and 0.01 respectively. FSGA gives a precision value that equals 0.89 while FSJaya, SDS, ACO, and MGOA give 0.65, 0.66, 0.63, and 0.68 respectively. While the recall value of FSGA is 0.84, the recall values of FSJaya, SDS, ACO, and MGOA are 0.6, 0.62, 0.63, and 0.67 respectively. Consequently, Figs. 14, 15, 16, 17 show that FSGA is better than other recent methods, which are; FSJaya, MGOA, SDS, and ACO because FSGA provides the maximum accuracy and the minimum error.
The results in Figs. 18, 19, 20, 21, 22 show that the highest macro-average precision value is provided by FSGA with a value that reaches 0.8 at a training number of 140 patients. On the other hand, the lowest macro-average precision value is introduced by FSJaya with a value reaches to 0.63. Additionally, macro-average recall for FSGA is about 0.84 which represents the highest value concerning other techniques, while the lowest one is FSJaya with a value of 0.61 at a training number of 140 patients. At the maximum number of training data (e.g., 140 patients), FSGA gives the highest micro-average precision value equals 0.8 while SDS introduced 0.61 which is the lowest value of micro-average precision. At a training number of 140 patients, FSGA provides a micro average recall value that equals 0.79, while FSJaya, SDS, ACO, and MGOA provide 0.59, 0.6, 0.66, and 0.67 respectively. F-measure value for FSGA is about 0.78 while it is about 0.60, 0.64, 0.65, and 0.65 for FSJaya, SDS, ACO, and MGOA respectively. In Fig. 23, the run-time of FSGA is 10 (s) that represents the highest speed while SDS introduces the lowest speed with a run-time value equals to 20 (s). In the end, FSGA outperforms other recent methods, which are; FSJaya, MGOA, SDS, and ACO because it can accurately select the most informative features with high speed.
In this section, the proposed FCNB strategy that includes four phases, which are; feature selection, feature clustering, master feature weighting, and classification phases will be evaluated. To ensure the effectiveness of the FCNB strategy, it is compared to some of the recently used COVD-19 classification strategies as presented in Table 1. Those methods are TCRC (Khanday et al. 2020), DL (Ozturk et al. 2020a), CNN (Maghdid et al. 2020), CDM (Chen et al. 2020a, b), COVIDGAN (Waheed et al. 2020), ACDM (Ozturk et al. 2020b) and AFS-DF (Sun et al. 2020). In fact, the proposed FCNB classification strategy depends on many essential techniques which enable the classification model to provide fast and accurate classifications. These essential techniques are FSGA that is employed for selecting the best subset of features in FSP, the proposed clustering method in FCP that is applied on the selected features to put them in clusters, the proposed weighting method in MFWP that is used to weight the master feature, and the weighted NB classifier that is applied on the weighted master features in FCNBP to accurately detect COVID-19 patients. Results are shown in Figs. 24, 25, 26, 27, 28, 29, 30, 31, 32, 33. As shown Figs. 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, the proposed FCNB strategy demonstrates the best performance while its error and run-time are decreased. Really, the accuracy, precision, recall, macro-average, micro-average, and F-measure of FCNB are promoted. This proves the effectiveness of FCNB in which its phases are FSP, FCP, MFWP, and FCNBP, can efficiently work together.
As shown in Figs. 24, 25, 26, 27, TCRC, DL, CNN, CDM, COVIDGAN, ACDM, AFS-DF, and FCNB provide accuracy values reach to 0.8, 0.81, 0.87, 0.85, 0.90, 0.92, 0.96, and 0.99 respectively at the maximum number of training data (e.g., 140 patients). The best accuracy is achieved by FCNB depends on the usage of many main processes in the pre-processing stage before applying the classification model to accurately diagnose COVID-19 patients. Accordingly, TCRC, DL, CNN, CDM, COVIDGAN, ACDM, AFS-DF, and FCNB techniques introduce error values equal 0.2, 0.19, 0.13, 0.15, 0.10, 0.8, 0.4, and 0.02 respectively. FCNB gives precision value that equals 0.84 while TCRC, DL, CNN, CDM, COVIDGAN, ACDM, and AFS-DF give 0.63, 0.65, 0.63, 0.68, 0.67, 0.69, 0.73, 0.69, and 0.73 respectively. While the recall value of FCNB is 0.79, the recall values of TCRC, DL, CNN, CDM, COVIDGAN, ACDM, and AFS-DF are 0.6, 0.62, 0.63, 0.67, 0.66, 0.68, and 0.75 respectively. Hence, Figs. 24, 25, 26, 27 show that FCNB is better than other recent methods, which are; TCRC, DL, CNN, CDM, COVIDGAN, ACDM, and AFS-DF because FCNB introduces the maximum accuracy and the minimum error.
The results in Figs. 28, 29, 30, 31, 32 show that the highest macro-average precision value is provided by FCNB with value reaches to 0.78 at training number of 140 patients. On the other hand, the lowest macro-average precision value is introduced by TCRC with value reaches to 0.61 at the same training number of patients. Additionally, the macro-average recall for FCNB is about 0.77 which represents the highest value concerning techniques, while the lowest one is TCRC with a value of 0.60 at a training number of 140 patients. FCNB gives the highest micro-average precision value equals 0.78 at the same training number of patients, while DL introduced 0.59 which is the lowest value of micro-average precision. FCNB provides micro average recall value that equals 0.78 while TCRC, DL, CNN, CDM, COVIDGAN, ACDM, and AFS-DF provide 0.59, 0.61, 0.60, 0.64, 0.66, 0.67, and 0.71 respectively. The highest F-measure value is introduced by FCNB with a value that equals 0.76, while the lowest value is introduced by TCRC with a value that equals 0.59 at the training number of patients = 140. In Fig. 33, the run time of FCNB is 11 (s) that represents the highest speed while DL introduces the lowest speed with run-time value equals to 20 (s). Finally, FCNB is better than other recent techniques which are; TCRC, DL, CNN, CDM, COVIDGAN, ACDM, and AFS-DF.
It is very important to detect COVID-19 positive cases as early as possible to prevent the further spread of this pandemic and to quickly treat affected patients. In this paper, the FCNB classification strategy has been provided as a new COVID-19 diagnoses strategy to accurately diagnose COVID-19 patients with high speed. FCNB strategy is built upon two essential stages, which are; P2S and CS. P2S includes three essential phases, which are; FSP, FCP, and MFWP. In FSP, the most effective features on COVID-19 have been selected by using the FSGA method. In FCP, the selected features have been grouped into many clusters called Master Features (MFs) in which each MF includes a set of related features. In MFWP, each MF has been weighted based on the importance of the features it includes as well as the correlation among included features. On the other hand, in CS, the weighted NB has been implemented on the weights of MFs rather than the weights of individual features to introduce fast and accurate diagnosis. Experimental results have shown that the proposed FCNB strategy increases the performance of the traditional weighted NB as it considers the correlation among features. Additionally, FCNB minimizes classification time as it considers small number of MFs rather than many individual features. In the future, we plan to apply the proposed FCNB strategy in fog on the COVID-19 dataset collected in the fog’s cache server to provide fast diagnosis and to directly rehabilitate the infected people. In fact, this will greatly reduce the efforts of medical systems (e.g., hospitals) because fog depends on the Internet of Things (IoT) sensors that can automatically measure the body temperature and other symptoms to maintain social distance and to prevent spreading the infection.",J Ambient Intell Humaniz Comput
PMC7808881,Reconsidering Internet Gaming Disorder During the COVID-19 Pandemic,"The discourse surrounding the classification of gaming disorders has teemed with debate in recent years (American Psychiatric Association 2013b; Kuss et al. 2017; World Health Organization 2015). In 2013, a provisional diagnosis of Internet gaming disorder (IGD) was tentatively included in the 5th edition of the Diagnostic and Statistical Manual of Mental Disorders (DSM-5) contingent on further evidence to warrant IGD’s existence as an independent disorder altogether (APA 2013b; WHO 2015). In spite of calls to delay the inclusion of a similar diagnosis in the 11th edition of the International Classification of Diseases, the World Health Organization voted to formalize the diagnosis of gaming disorder in 2019 (van Rooij et al. 2018; WHO 2019). While debate over the validity of IGD and its diagnostic criteria continues, concurrent research on the demographic characteristics of gamers in the USA has found that 10% of gamers nationwide—over 18 years of age—identify as a sexual or gender minority (Nielsen Community 2020).
Online gaming has greatly evolved in recent years (Johnson 2019). Contextualized by the monetization of certain gaming platforms, research has acknowledged the importance of gaming for ethnic and racial minority gamers as well as gamers living with chronic conditions and physical disabilities (Gray 2017; Johnson 2019; Leonard 2019). Besides gaming as a potential source of income, sexual and gender minority populations’ engagement with gaming is not new. In fact, the inclusion of queer characters and storylines in popular games as of late may signal an already extant subpopulation of gamers living with marginalized identities rather than a shift in the population (Parker 2016). Limited research has also indicated that gaming occupies a unique role among LGBTQ+ populations in respect to sexual and gender identity formation and expression. Role play games, for example, may provide sexual and gender minority gamers the freedom of gender expression otherwise not afforded to them in-person (Griffiths et al. 2016). Further research has also indicated that such forms of gaming may provide an entry point for gamers to safely explore their sexual identity in relative anonymity (Nielsen 2015). As such, the recently released data on LGBTQ+ gamers may serve to further justify future research on the psychosocial benefits of gaming for sexual and gender minority populations in the USA (Nielsen Community 2020).
The Coronavirus Disease 2019 (COVID-19) pandemic—caused by the severe acute respiratory syndrome coronavirus 2 (SARS-Cov-2)—has seen a marked increase in the consumption of video game products across the USA possibly due to the enforcement of the Centers for Disease Control and Prevention’s social distancing and self-isolation guidelines (CDC 2020; The NPD Group 2020). Further, while sexual and gender minority populations in the USA regularly face unique stressors, such as a lack of social support or discrimination on the basis of sexual or gender identity, emerging research has also indicated that such populations are at unique risk of COVID-19 infection due to a confluence of factors (Meyer 2003; Phillips et al. 2020). These factors include a high likelihood to work in essential industries, inadequate health insurance coverage, job insecurity, and other variables, which increase this aforementioned risk of infection (Human Rights Campaign Foundation 2020). In fact, burgeoning research on sexual minority men in the USA found that over 19% of the study cohort reported job loss due to the pandemic alone, testifying to the socioeconomic vulnerability of such minority groups (Sanchez et al. 2020).
While research has been limited, gaming may present as a common form of emotion-focused coping for sexual and gender minorities broadly (Kuo et al. 2016; Lazarus 2006; Meyer 2003). Further, gaming among LGBTQ+ populations may become increasingly popular as the pandemic persists—as recent research has shown (Fish et al. 2020). Considering this limited, but emerging data on LGBTQ+ gamers in the USA, as well as the distinct social context of the COVID-19 pandemic for such populations, it is imperative to discuss the implications of both sexual and gender identity as well as the current public health crisis on the diagnostic criteria of future iterations of gaming disorder classifications.
Although gamers nationwide are by average 35–44 years of age, most diagnoses of IGD occur in adolescents (ESA 2020; Wu et al. 2018). This statistic may be evidence of the often-overlooked role of parents in the IGD diagnostic process, the so-called first line in perceiving problematic Internet and gaming use in their children (Bonnaire et al. 2019; Gentile et al. 2017; Schneider et al. 2017). Negative parental attitudes toward gaming and lower family functioning have been found to be reliable predictors of IGD among adolescents, though more research on the role parents play in the diagnosis of IGD is needed (Bonnaire and Phan 2017). The COVID-19 pandemic places parents in a unique position in respect to IGD. Despite the resumption of in-person learning in some states, others are expected to continue online learning until the approval of a COVID-19 vaccine (Sheikh et al. 2020). As such, adolescent populations in the USA may naturally increase their Internet consumption as a necessity while sexual and gender minority youth, in particular, may engage in gaming at typical or increased rates as a function of gender expression, identity formation, and emotion-focused coping (Fish et al. 2020; Griffiths et al. 2016; Guessoum et al. 2020).
Since parents have become de facto educators in lieu of formal in-person instruction, they may also become preoccupied with the perceived increase in gaming behaviors of their children and consequently seek mental healthcare services to assuage their concern (Bonnaire and Phan 2017). At the same time, research has shown that the risk factors for IGD, based on the DSM-5 criteria, have been unable to distinguish problem gamers from recreational gamers, shedding light on the complex and nuanced role that parents may play in the diagnostic process (Jory et al. 2017). Therefore, the USA may see a disproportionate increase in treatment seeking for symptoms consistent with IGD—not from those exhibiting the symptoms, but from parents who are distressed by their children’s gaming behavior.
This narrative of how mental healthcare practitioners may see a higher prevalence of IGD related symptoms is speculative—and some may also question the detrimental effect of an IGD diagnosis in such cases altogether. However, limited research has indicated that gaming, notwithstanding the diagnosis of IGD, is met with immense social stigma (Peter et al. 2019). While an IGD diagnosis would not be the only diagnosis to be met with such stigma, IGD is unique due to its provisional inclusion in the DSM-5 contingent on further research (Parcesepe and Cabassa 2013). As studies on the expression of IGD symptoms continue during the current pandemic, researchers would be remiss not to contextualize the detrimental impact such a diagnosis may produce for vulnerable sexual and gender minority populations in the USA. Moreover, while the diagnosis of other disorders (e.g., substance use disorders) may also be met with the aforementioned social stigma, a formal diagnosis of IGD fails to account for the benefits of gaming (which substance use does not impart) for LGBTQ+ populations notwithstanding (Kowert et al. 2014).
Furthermore, while the treatment of IGD symptoms has pulled from multiple theoretical approaches and types (including cognitive behavioral therapy and psychopharmacological treatments), the treatment of substance use disorders has also served as a template for IGD interventions (Zajac et al. 2017). In fact, as research has touted the prescription of bupropion for the treatment of IGD symptoms, this pharmacological regimen is also commonly prescribed for the treatment of nicotine addiction—which may be emblematic of IGD’s conception as similar to substance use disorders (Petry et al. 2018; Song et al. 2016). Additionally, research on policy-level interventions for IGD symptoms abroad has found that such structural efforts to mitigate problematic gaming use through prohibitive measures are similar to policies that aim to curb alcohol consumption (Király et al. 2018).
“Wilderness” therapies, commonly used in the treatment of substance use disorders, are also endorsed for the treatment of IGD symptoms (Bennett et al. 1998; Király et al. 2018). Such therapies consist of an abatement of the “substance” or a lengthy “detox” process via costly in-patient treatment programs and cognitive behavioral therapy (Király et al. 2018; Wang et al. 2019; Xiang et al. 2020). The goal of such treatment is for the gamer to disavow gaming and supplant gaming usage with supposed pro-social activities anchored in the non-virtual world (Peter et al. 2020). Yet, the logic behind such treatment for LGBTQ+ gamers is highly flawed as (1) gaming has been shown to be fundamentally interpersonal, and (2) IGD treatment fails to account for the potential benefits LGBTQ+ youth may reap from gaming in respect to gender and sexual expression during a particular formative developmental period (Institute of Medicine, Board on the Health of Select Populations,, and Committee on Lesbian, G. B. T. H. I. R. G. O. 2011; Kowert et al. 2014). Further, while in-person interactions remain limited due to the pandemic, treatment that would posit such a change in activity from online to in-person is simply impractical.
Consequently, questions regarding how to proceed in the assessment of IGD and future classifications of gaming disorders in the age of COVID-19 demand our attention. Firstly, research ought to examine bias against technology and gaming in the field of mental healthcare. In a study, 61.5% of clinicians surveyed were concerned about the addictiveness of Internet gaming (Ferguson 2015). The abovementioned study suggests that such concern may be a function of warning bias toward new technology (e.g., Internet gaming), with clinician’s age, gender, and negative attitude toward youth predicting negative attitudes toward gaming (Ferguson 2015). As this is the case, sexual and gender minority mental health consumers who engage in gaming as a means of sexual or gender identity expression may be treated by clinicians who could be averse to acknowledging the psychosocial benefits of gaming for these populations. Consequently, these attitudes toward technology may contribute to mental health inequities for LGBTQ+ populations in the USA.
Secondly, mental healthcare practitioners should also make efforts to understand sociocultural contexts (i.e., the COVID-19 pandemic and the role of gaming for LGBTQ+ gamers) as they may pertain to sexual and gender minority patients with symptoms of IGD. Such considerations may be achievable via the Cultural Formulation Interview included in the DSM-5 (APA 2013a). Although research has identified barriers to the use of this assessment tool (e.g., extra time needed for conducting the interview, patient discomfort with clinicians, and confusing syntax), it remains one of the few protocols that allows for the inclusion of culture-bound behavior in the diagnostic process (Aggarwal et al. 2013). An amendment to the interview protocol may also be warranted for LGBTQ+ adolescents in particular so as not to frame their gaming behavior as a problem before understanding how their use may, in fact, undergird their identity.
Such an amendment would take into account the age of the patient, especially if the patient is a minor, and the conditions under which they are speaking with a clinician. It would also be prudent for the Cultural Formulation Interview to remove reference to a “problem” in the introduction section of the protocol and use less charged language by asking about the reason for the patient’s visit instead. Further, adopting the description used by the patient throughout the remainder of the interview—as opposed to first adopting said language in the “Cultural Definition of the Problem” section, as is currently instructed—would be an important change to make as well (APA 2013a).
As public health experts advise that COVID-19 may be further evidence of an onslaught of similar such coronaviruses to come, it is imperative that mental healthcare services consider the changing role of gaming among those at greatest risk for poor psychological and somatic health outcomes (Morens and Fauci 2020). Neglecting the psychosocial benefits of gaming for such populations during a critical phase of development would not only further contribute to the marginalization of sexual and gender minority populations broadly but would also undercut our own understanding of the mental health implications of gaming at large.",J Technol Behav Sci
PMC7809537,"Implementierungsprozess einer Smartphone-basierten Ersthelferalarmierung: Herausforderungen bei der Einführung, Weiterentwicklung zum System 2.0","Im Jahr 2018 wurden in den Rettungsdienstbereichen, die am Deutschen Reanimationsregister teilnehmen, 13,2 % der Patienten nach außerklinischem Herz-Kreislauf-Stillstand lebend aus dem Krankenhaus entlassen [3]. Bei 42 % der Patienten wurden vor Eintreffen des Rettungsdiensts Thoraxkompressionen durchgeführt [3]. Den Daten des Deutschen Reanimationsregisters zufolge wurde 2019 in 23 % der Reanimationen telefonunterstützte Reanimation (T-CPR) durchgeführt. Bei den Maßnahmen zur Verbesserung der Überlebenswahrscheinlichkeit steht die Reduktion des reanimationsfreien Intervalls im besonderen Fokus. Die Zeit vom Kollaps bis zum Beginn der Thoraxkompressionen sollte weniger als vier Minuten betragen. Dies ist nur mit dem professionellen Rettungsdienst und den Leitstellen nicht zu erreichen [4].
In der deutschen Bevölkerung verwenden 70 % der Bürger ein Smartphone [8], darunter viele Personen mit medizinischer Qualifikation. Es ist naheliegend, bei einem Herz-Kreislauf-Stillstand Personen zu aktivieren, die sich in unmittelbarer Nähe befinden. Ringh zeigte, dass die Ortung von Ersthelfern über Mobilfunkmasten und Alarmierung über Kurznachricht (SMS) das therapiefreie Intervall um mehrere Minuten reduzieren können [11]. Seit 2012 ist in Dänemark das System FirstAED etabliert. Dieses ortet Ersthelfer über eine Smartphone-App, alarmiert gleich mehrere Helfer und teilt Aufgaben zu. Ein bis zwei Helfer werden zum Patienten geschickt, ein weiterer wird zum nächstgelegenen AED geschickt und bringt diesen zum Notfallort [6].
In Deutschland sind verschiedene App-basierte Ersthelferalarmierungssysteme etabliert. Eine Erhebung hierzu bei deutschen Rettungsleitstellen wurde 2018 von Gross veröffentlicht und dokumentierte dabei auch typische und wiederkehrende Hürden und Herausforderungen bei der Etablierung [5]. In Baden-Württemberg startete 2016 ein Pilotprojekt, in dem unter Koordination des Ministeriums für Inneres, Digitalisierung und Migration in drei verschiedenen Landkreisen die damals verfügbaren Ersthelferalarmierungssysteme (corhelp 3r, FirstAED, Mobile Retter) etabliert und evaluiert werden sollten [10]. Mittlerweile sind mindestens zwei weitere Ersthelferalarmierungssysteme in Deutschland kommerziell verfügbar.
Zusätzlich zur Alarmierung von Ersthelfern kann ein ganzheitliches Herangehen an das Problem des außerklinischen Herz-Kreislauf-Stillstands sinnvoll sein. Im Tessin wurde ein beeindruckendes Netzwerk öffentlich zugänglicher AED geschaffen, die alarmierten Ersthelfer sehen die verfügbaren AED in ihrer App [1]. In der Region Süddänemark ist die Alarmierungs-App FirstAED ebenso an eine AED-Datenbank angebunden. Von den drei alarmierten Helfern wird einer von der App zum nächsten AED geleitet [13].
Ziel des Projekts war die Etablierung und Evaluation eines Smartphone-basierten Ersthelferalarmierungssystems sowie die Weiterentwicklung und Anpassung an die regionalen Strukturen. Im Fokus der Evaluation stand die Evaluation der Ersthelferzahlen, der Ersthelferverfügbarkeit bei Alarmierungen, der Erfassung der Eintreffzeiten sowie der Verfügbarkeit von AED bei der Versorgung durch die Ersthelfer.
Das System wurde im Bereich der Integrierten Leitstelle (ILS) Freiburg etabliert. Dazu zählen die Stadt Freiburg (230.241 Einwohner, 153 km2) sowie der Landkreis Breisgau-Hochschwarzwald (262.795 Einwohner, 1378 km2).
FirstAED besteht aus einer Ersthelfer-App sowie einer Server-Software, die innerhalb der Leitstellen-Firewall installiert wird. Die Anbindung an das Einsatzleitsystem (Siveillance Command, Siemens, München) wurde über Rescuetrack (Convexis GmbH, Reutlingen) realisiert.
An den FirstAED-Server angebunden ist die App „Region der Lebensretter“ für Smartphones (Android, iOS). Nach Registrierung und Einweisung erhalten die Ersthelfer ein Login zum Freischalten der App.
Für den Betrieb und die Weiterentwicklung der Software, die Registrierung der Helfer und die Finanzierung des Projekts wurde der Verein Region der Lebensretter e. V. gegründet, der Verein ist korporatives Mitglied im DRK Kreisverband Freiburg e. V.
Bei einer Alarmierung mit den Einsatzstichworten „bewusstlos“ und „Reanimation“ werden die Ersthelfer automatisch über ihr Smartphone geortet und alarmiert, sofern sie sich in einem definierten Radius um den Einsatzort befinden (Abb. 1). Medizinische Einrichtungen (z. B. Pflegeheime) als Einsatzort sind von der Alarmierung ausgeschlossen. Von den Ersthelfern, die den Einsatz annehmen, erhalten zwei die Aufgabe, sich zum Notfallort zu begeben und die Basisreanimation einzuleiten, ein Helfer wird zum nächstgelegenen AED geleitet. Der vierte Ersthelfer weist den Rettungsdienst ein bzw. betreut die Angehörigen. Sobald der Einsatz vom Helfer angenommen wird, erscheint dieser als Rettungsmittel auf der Kartenübersicht der ILS.
Hilfe nach besonders belastenden Einsätzen wird den Helfern beim Ausfüllen des Helferberichts angeboten und über die Vermittlung zur psychosozialen Notfallversorgung (PSNV) organisiert.
Bereits vorhandene Helfer-vor-Ort(HvO)-Systeme bleiben unverändert in der Alarm- und Ausrückeordnung (AAO) berücksichtigt. Die HvO-Gruppen wurden eingeladen, sich im Projekt zu registrieren.
Mindestqualifikation ist eine Sanitätshelferausbildung. Pflegekräfte und Ärzte sind qualifiziert, sofern sie regelmäßig die Maßnahmen des Basic Life Support trainieren.
In den Hilfsorganisationen, Feuerwehren und Krankenhäusern in der Region gibt es verantwortliche Personen, die Helfer registrieren. Jeder Helfer wird mit Warnweste, Taschenbeatmungsmaske und Einmalhandschuhen ausgestattet.
Durch eine strukturierte Recherche wurden AED-Standorte eruiert und in die Datenbank des FirstAED-Servers eingetragen. Die AED-Standorte sind in der Kartenansicht der App sichtbar. Alle Ersthelfer wurden aufgefordert, AED-Standorte, die noch nicht im System verzeichnet sind, zur Ergänzung der Datenbank zu melden.
Das Forschungsvorhaben wurde von der Ethik-Kommission der Albert-Ludwigs-Universität Freiburg genehmigt (Nr: 482/18) und beim Deutschen Register Klinischer Studien registriert (Nr: DRKS00016625).
Die Einsatzdaten werden im Backend des FirstAED-Servers gespeichert. Für die Ermittlung der Eintreffzeiten der Ersthelfer wurden die Ersthelfer im Einsatz geortet. Der Zeitpunkt, zu dem der Ersthelfer weniger als 100 m von der GPS-Position des Einsatzorts entfernt war, wurde als Eintreffzeit dokumentiert. Der Anteil der Einsätze, in denen mindestens ein Ersthelfer den Alarm akzeptiert hat, an der Gesamtheit der Einsätze, in denen das System FirstAED aktiviert wurde, bestimmt die Kennzahl Einsatzübernahme. Die deskriptive statistische Auswertung erfolgte mit Microsoft Excel.
Nach jedem Einsatz wurden die Ersthelfer über die App gebeten, einen Fragebogen auszufüllen. Es wurden auch Freitextantworten zur Zufriedenheit mit der App-Alarmierung bzw. zu Verbesserungsvorschlägen abgefragt. Diese wurden thematisch zusammengefasst und qualitativ ausgewertet.
Das System wurde am 01.07.2018 gestartet, zeitgleich wurde mit der Helferrekrutierung begonnen. In der Zeit vom 01.07. bis 31.07.2018 erfolgte der Testbetrieb mit einer kleinen Anzahl von Helfern, die Software und Abläufe intensiv getestet haben. Alle Einsätze in der Zeit vom 01.08.2018 bis 30.06.2020 wurden in die Auswertung übernommen. In der Zeit vom 16.03.2020 bis 26.05.2020 wurde das System aufgrund der COVID-19-Pandemie-bedingten Vorgaben für die Alarmierung von HvO-Systemen pausiert. Eine gesonderte Auswertung der Eintreffzeiten wurde vom 01.07.2020 bis 31.07.2020 durchgeführt.
Die Autoren evaluierten die Daten aus dem Pilotbetrieb alle sechs Monate. Nach jeder Halbjahresevaluation wurden Optimierungsmöglichkeiten eruiert und priorisiert. Hierbei arbeiteten die Autoren auch mit den Entwicklern der Firma FirstAED zusammen, um bei der Diskussion um softwareseitige Optimierungen Realisierbarkeit und Entwicklungsaufwand abschätzen zu können. Bei allen Optimierungen wurde nach dem PDCA-Zyklus vorgegangen. Neue Features oder Optimierungen wurden geplant und spezifiziert („plan“). Nach Programmierung wurde zunächst unter Laborbedingungen und anschließend von einer kleinen Gruppe Ersthelfer unter Realbedingungen getestet. Nach Korrektur eventueller Fehler wurde die Änderung für alle Benutzer freigegeben („do“). Die Verbesserungen des Systems durch die Optimierung der Software wurden anhand der Einsatzdaten im Echtbetrieb in den folgenden Monaten evaluiert („check“) und im Rahmen der Halbjahresevaluation erneut diskutiert. Daraufhin erfolgten bei Bedarf weitere Optimierungen („act“).
Die Entwicklung der Anzahl registrierter Ersthelfer im System ist in Tab. 1 aufgeführt. Im ersten Halbjahr 2020 wurden die Alarmierungen im Zeitraum vom 15.03. bis 26.05. aufgrund der Coronapandemie ausgesetzt. Die Registrierung neuer Ersthelfer wurde in dieser Zeit fortgeführt.
In Tab. 1 sind für die vier Halbjahre des Pilotprojekts die Gesamtzahl der Alarmierungen sowie die Anzahl der Einsätze, in denen mindestens ein Ersthelfer den Einsatz übernommen hat, aufgeführt. Die Steigerung der Ersthelferzahlen im 1. Halbjahr 2020 führte zum größten Anstieg der Einsatzübernahme (von 34 auf 49 %). In Abb. 2 ist für die Postleitzahlenbereiche in der Projektregion die Helferdichte (Wohnadresse) farblich gekennzeichnet. Jeder Einsatz im Erhebungszeitraum ist mit einem Punkt markiert. In den Regionen mit geringerer Helferdichte werden nur selten Einsätze übernommen.
Die Eintreffzeiten der jeweils ersteintreffenden Ersthelfer sind in Tab. 1 aufgeführt. Ebenso aufgeführt sind die mittleren Eintreffzeiten des ersteintreffenden Rettungsmittels. Der Anteil der Einsätze, in denen ein Ersthelfer den Einsatzort vor dem Rettungsdienst erreichte, war im Pilotzeitraum nahezu unverändert (Tab. 1).
Die Abfrage bereits vorhandener AED im zweiten Halbjahr 2018 ergab eine Anzahl von 190 Geräten. 50 davon waren ohne Zutrittsbeschränkung verfügbar und konnten im System hinterlegt werden.
Das Smartphone war auf lautlos oder Vibration gestellt, bei der Alarmierung wurde kein Ton abgespielt. Manche Helfer berichteten, dass sie die Alarmierung verzögert wahrgenommen haben. Andere berichteten, dass sie auch schon Alarme verpasst haben und erst zu spät den verpassten Alarm entdeckt haben (Meldung im Sperrbildschirm des Smartphones) (28 Meldungen).
Aufgrund zu großer Entfernung zum Einsatzort bzw. kurzer Eintreffzeit des Rettungsdiensts hat der Ersthelfer den Patienten nicht vor dem Rettungsdienst erreicht. Auch wurde bemängelt, dass das Verkehrsmittel des Ersthelfers nicht berücksichtigt wird (27 Meldungen).
Der Ersthelfer hatte die Aufgabe, einen AED zur Einsatzstelle zu bringen. Ein anderer, mit AED ausgerüsteter Ersthelfer war im selben Einsatz, das Abholen des AED war somit unnötig (9 Meldungen).
Rückmeldungen von Ersthelfern, die bei sehr kurzer Eintreffzeit des Rettungsdiensts erst nach den Rettungsmitteln eingetroffen sind (5 Reports). Zusätzlich wurde beobachtet, dass im ländlichen Bereich nur selten Ersthelfer den Einsatz übernehmen. Wunsch nach größerem Alarmierungsradius bei langen Eintreffzeiten des Rettungsdiensts.
Zusätzlich kamen Rückmeldungen per E‑Mail bezüglich der fehlenden Möglichkeit, sich als Ersthelfer am Notfallort auszuweisen. In Einzelfällen wurde Ersthelfern der Zutritt zur Wohnung des Patienten verweigert.
Ursprünglich wurden Ersthelfer im Umkreis von 1500 m um die Einsatzstelle alarmiert. Seit Juli 2019 übermittelt Rescuetrack bei jedem Einsatz die voraussichtliche Fahrtzeit („estimated time enroute“ [ETE]) von Rettungswagen und Notarzt auf der Basis von Verkehrslage und antizipierter Geschwindigkeit und schickt die kürzere ETE an den FirstAED-Server. In den Einstellungen des Systems wird festgelegt, für welche ETE welcher Alarmradius angewendet wird (Abb. 3).
Die Konfiguration des Einsatzradius im Pilotprojekt ist in Tab. 2 dargestellt. Zunächst wurde der Einsatzradius für voraussichtliche Fahrzeiten bis zu 5 min auf 1000 m festgelegt. Weiterhin wurde bei Fahrzeiten von über 12 min der Einsatzradius auf 3000 m erhöht.
Anfang 2020 wurde bei stark gestiegener Anzahl registrierter Ersthelfer der Einsatzradius für sehr kurze Eintreffzeiten des Rettungsdiensts weiter reduziert auf 600 m. Dies führte nicht zu einer Reduktion der Einsatzübernahmen; die Einsatzübernahmen ließen sich – bei steigender Helferzahl – erhöhen.
Um die Wahrscheinlichkeit zu reduzieren, dass ein Ersthelfer eine Alarmierung nicht bemerkt, weil das Smartphone auf lautlos oder Vibrationsalarm gestellt ist, wurde für die Android- und iOS-Apps die Möglichkeit entwickelt, dass das Smartphone trotz dieser Einstellung laut alarmiert. Für Android-Smartphones stand das neue Feature im zweiten Halbjahr 2019 zur Verfügung. Für die Critical-alert-Funktion in der iOS-App war ein Update der Serversoftware notwendig, das mit Umzug des Systems auf einen neuen Server im ersten Halbjahr 2020 verfügbar wurde.
2020 wurde von FirstAED eine Schnittstelle zur AED-Datenbank DEFI-Map (www.defi-map.de) etabliert. Zusätzlich zum Standort können dadurch auch die Zeiten der Zutrittsbeschränkung eingetragen werden.
Die Besitzer von AED wurden kontaktiert und darum gebeten, den AED ohne Beschränkungen zugänglich zu machen. Auch wurde in den lokalen Medien dazu aufgerufen, öffentlich zugängliche AED zu etablieren, damit sie für die Ersthelfereinsätze verfügbar sind. Zum 30.06.2020 war die Anzahl der AED von 190 Geräten auf insgesamt 270 gestiegen. Die Anzahl der AED ohne Zutrittsbeschränkung war von 50 auf 79 Geräte gestiegen.
Im ersten Halbjahr 2020 wurde ein Ersthelferausweis für die App entwickelt. Bei Eintreffen an der Einsatzstelle zeigt dieser den Namen und ein Profilfoto des Ersthelfers sowie die Einsatznummer und den Hinweis, bei Unklarheiten die 112 anzurufen.
Anfang 2020 wurde eine Funktion entwickelt, bei der der Ersthelfer dem System unmittelbar nach Annahme eines Alarms über die App mitteilen muss, ob er zu Fuß, mit dem Fahrrad oder mit dem Pkw unterwegs ist. Damit ist es möglich, Entfernung, Transportmittel und Eintreffzeit in Bezug zu setzen und mit diesen Daten den Algorithmus für Alarmradius und Auswahl der Ersthelfer bzw. Aufgabenverteilung zwischen den Ersthelfern zu optimieren.
Häufig war im System keine GPS-basierte Eintreffzeit dokumentiert, obwohl von Ersthelfern im Einsatzreport gemeldet wurde, dass diese die Einsatzstelle erreicht hatten. Um valide Daten für die Eintreffzeiten erheben zu können, wurde Ende Juni 2020 die Möglichkeit programmiert, die Statusmeldung „Ankunft beim Patienten“ innerhalb der App abzugeben. Im Juli wurden alle Einsätze hinsichtlich GPS-basierter Eintreffzeit und echter Eintreffzeit (= Statusmeldung) ausgewertet (mittlere Helferzahl: 870).
Bei insgesamt 129 Alarmierungen meldeten sich in 71 Fällen Ersthelfer (55 %). Insgesamt haben 130 Ersthelfer den Alarm akzeptiert. Über Statusmeldung wurde in 98 Fällen das Eintreffen dokumentiert. Die GPS-basierte Eintreffzeit wurde hingegen nur in 43 Fällen erfasst. In 32 Einsätzen wurde sowohl die GPS-basierte Eintreffzeit als auch die Statusmeldung dokumentiert. In 17 Fällen wurde das Eintreffen gemeldet, bevor die GPS-Position an der Einsatzstelle erfasst wurde (Abweichung −04:22 ± 02:58 min [MW ± SD]). In 15 Fällen wurde der Status „eingetroffen“ nach dem Erfassen der GPS-basierten Zeit dokumentiert (Abweichung +04:26 ± 05:49 min [MW ± SD]).
Die Smartphone-basierte Ersthelferalarmierung stellt im Hinblick auf die Verkürzung reanimationsfreier Intervalle nur einen Teil eines zu optimierenden Systems dar. Durch Aktivieren von geschulten Ersthelfern in der Umgebung des Notfallorts können sehr kurze reanimationsfreie Intervalle resultieren. Ringh und Kollegen arbeiteten bereits vor fast 10 Jahren an einem System, welches Ersthelfer über Mobilfunkmasten orten und per Textnachricht (SMS) alarmieren kann [11]. Dieses System führte zu einer Reduktion des reanimationsfreien Intervalls, allerdings ohne signifikanten Einfluss auf die Überlebensrate [12]. Im Schweizer Kanton Tessin wurde ein SMS-basiertes Alarmierungssystem für Ersthelfer mit der Alarmierung über eine Smartphone-App verglichen. Das Smartphone-basierte System führte zu einer Verkürzung der Eintreffzeiten und einer höheren Überlebensrate [2]. Mittlerweile sind verschiedene App-basierte Systeme etabliert und evaluiert [14]. Bisher besteht kein Konsens über die Indikation zum Ersthelfereinsatz. Erfolgt die Alarmierung nur bei Verdacht auf Herz-Kreislauf-Stillstand, so würde das System in der Region Freiburg/Breisgau – Hochschwarzwald 200- bis 300-mal pro Jahr aktiviert werden. Bei 800 registrierten Helfern und 4 alarmierten Helfern pro Einsatz würde jeder Helfer im Schnitt 1‑mal pro Jahr alarmiert werden. Das zusätzliche Einsatzstichwort „bewusstlos“ resultiert in einer etwa 5‑fachen Einsatzhäufigkeit und schafft damit eine gewisse Routine in diesen Einsätzen. Weiterhin ist die Notrufmeldung oft ungenau und der Herz-Kreislauf-Stillstand wird als „bewusstlos“ eingeordnet. Andere Ersthelferalarmierungssysteme werden auch bei weiteren Indikationen wie Atemnot oder Brustschmerz aktiviert [17]. Diese Einsatzindikationen wurden im vorliegenden Projekt ausgeschlossen, da ein Überlebensvorteil für die Patienten durch den Einsatz der Ersthelfer bei geringem Zeitvorteil und fehlender medizinischer Ausstattung der Helfer als unwahrscheinlich angenommen wurde und eine zu häufige Alarmierung die Motivation der Ersthelfer senken könnte.
Die Frage nach der benötigten Anzahl an Ersthelfern kann mit den vorliegenden Daten nicht beantwortet werden. Es ist fraglich, ob hier überhaupt Kennzahlen oder Empfehlungen erarbeitet werden können. Das Mobile-Retter-System in Gütersloh hatte bei einem Anteil registrierter Ersthelfer von 1,3 ‰ der Bevölkerung eine Einsatzübernahme in 45 % der Fälle [18]. Eine Steigerung der Ersthelferzahlen führte im hier beschriebenen Projekt zu einer Erhöhung der Einsatzübernahmen. Gerade in Regionen mit geringer Bevölkerungsdichte lässt sich die Anzahl der Ersthelfer jedoch nicht beliebig steigern. Hier kann das System mittels technologischer Innovationen verbessert werden. Die Autoren halten die Anpassung des Alarmierungsradius für Ersthelfer entsprechend der voraussichtlichen Fahrtzeit des Rettungsdiensts für essenziell. Durch die Reduzierung des Radius bei kurzen Fahrtzeiten des Rettungsdiensts profitiert das System: Es werden seltener Ersthelfer alarmiert, die erst nach dem Rettungsdienst eintreffen. Dies hat im Pilotprojekt zu einer deutlichen Steigerung der Motivation der Ersthelfer geführt. Weiterhin werden bei längeren Anfahrtszeiten Ersthelfer alarmiert, die zwar weiter vom Einsatzort entfernt sind, diesen allerdings immer noch vor dem Rettungsdienst erreichen können. Die Ergebnisse der vorliegenden Untersuchung zeigen auch, dass vor allem in den Randbereichen des Einsatzgebiets häufig kein Ersthelfer verfügbar war (Abb. 2). Die Autoren vermuten, dass ein Anschluss der Nachbarkreise an das System zu einer höheren Helferdichte in der Grenzregion führen dürfte. Die leitstellengrenzen- bzw. landkreisgrenzenübergreifende Alarmierung von Ersthelfern könnte auch durch Schnittstellen der verschiedenen Systeme untereinander erreicht werden. Die Hersteller der Systeme sind hier aufgefordert, entsprechende Schnittstellen zu etablieren. Im Projektzeitraum wurden die Ersthelferzahlen gesteigert und das System wurde zeitgleich technologisch weiterentwickelt. Dementsprechend lässt sich die Zunahme der Einsatzübernahmen nicht eindeutig der Implementierung des dynamischen Alarmradius einerseits oder den steigenden Ersthelferzahlen andererseits zuschreiben. Durch den dynamischen Alarmradius bedingt wurden bei Einsätzen mit voraussichtlich langen Eintreffzeiten Ersthelfer in wesentlich größerer Entfernung zum Einsatzort alarmiert. Dies könnte die etwas längeren Eintreffzeiten im 2. Halbjahr 2019 und im 1. Halbjahr 2020 erklären.
Im Pilotprojekt sollte auch die frühe Defibrillation vor Eintreffen des Rettungsdiensts realisiert werden. Deshalb wurde ein Softwaresystem ausgewählt, in welchem öffentlich zugängliche AED nicht nur sichtbar sind, sondern konkret einem Ersthelfer die Aufgabe zugeteilt wird, den AED zum Notfallort zu bringen. Werden die AED nur angezeigt, überlässt unter Umständen jeder Ersthelfer diese Aufgabe den anderen. In anderen Fällen bringen mehrere Ersthelfer einen AED zur Einsatzstelle. Das Abholen eines AED führte im System im Tessin zu einer Verzögerung von 97 (Anfahrt mit PKW) bzw. 555 s (fußläufige Ersthelfer; [1]). Im vorliegenden Projekt reichte die Dichte an öffentlich zugänglichen AED nicht aus. Dementsprechend wurde begonnen, neue AED strategisch zu positionieren. Der Verein Region der Lebensretter hat hierzu einen mit den Geräten im Rettungsdienst kompatiblen AED ausgewählt, so dass bei jedem Einsatz die Elektroden des AED durch den Rettungsdienst ersetzt werden, damit das Gerät sofort wieder einsatzbereit ist. Der Verein kauft die neuen Geräte, betreibt sie und kümmert sich um die Wartung im Sinne eines ganzheitlichen Ansatzes. Damit haben spendenbereite Bürger oder Firmen minimalen Aufwand. Eine genauere Untersuchung zur Verwendung der AED ist geplant.
Die Frage, ob die Ersthelferalarmierung über Smartphone die Überlebenswahrscheinlichkeit nach Herz-Kreislauf-Stillstand erhöht, kann noch nicht beantwortet werden [14]. Reanimationsregister und Datenbanken wie beispielsweise die Stelle für die Qualitätssicherung im Rettungsdienst (SQR-BW), in denen rettungsdienstliche Einsatzdaten erfasst werden, sollten zukünftig aufnehmen, ob ein Ersthelferalarmierungssystem aktiviert wurde, und die Einsatzzeiten (Alarmzeit, Eintreffzeit) erfassen. Voraussetzung hierfür ist die valide Datenerhebung. Dies ist jedoch zumindest in Deutschland bislang nicht etabliert. Für das Mobile-Retter-System in Gütersloh wurden sehr kurze Eintreffzeiten (Median: 4 min) publiziert [17]. Die Methode zur Bestimmung der Eintreffzeiten wird nicht angegeben [9]. Die Autoren schreiben auf Nachfrage, dass eine automatisierte Erfassung der Eintreffzeiten erfolgte [7]. In einer anderen Arbeit geben dieselben Autoren an, der Ersthelfer würde als eingetroffen erfasst, sobald das Smartphone keine Ortsbewegung mehr erfasst [16]. In der aktuellsten Arbeit aus der Arbeitsgruppe wird letzten Endes erklärt, dass eine Smartphone-basierte Erfassung der Eintreffzeiten nicht zuverlässig zur Verfügung steht [15]. Diese Arbeit stellt die anhand einer Google-Maps-Kalkulation geschätzten Eintreffzeiten der Mobilen Retter in 7 Regionen dar. Die tatsächlichen Eintreffzeiten dürften deutlich länger sein. In der vorliegenden Untersuchung konnte gezeigt werden, dass auch die Erfassung der Eintreffzeit über die GPS-Position nur unzuverlässig funktioniert. Dies liegt unter anderem auch daran, dass die verwendete Hardware (Smartphone der Ersthelfer) sehr uneinheitlich ist. Auch die Festlegung eines Radius um die Einsatzstelle, innerhalb dessen der Ersthelfer als „eingetroffen“ im System erfasst wird, stellt eine unlösbare Herausforderung dar. Mit größerem Radius steigt die Zuverlässigkeit, mit der der Helfer als eingetroffen erfasst wird. Zeitgleich sinkt die Genauigkeit der Dokumentation, denn der Ersthelfer wird unter Umständen schon als eingetroffen erfasst, wenn er noch 100 m von dem Einsatzort entfernt ist. Bei kleinerem Radius steigt die Genauigkeit. Es kann jedoch vorkommen, dass der Helfer den Kreis nicht betritt (Patient befindet sich nicht im Kreis mit Mittelpunkt der Einsatzadresse) oder die Position durch das Smartphone nicht ausreichend genau ermittelt wird (z. B. in Gebäuden). Im Freiburger System dokumentieren die Ersthelfer den Status S4 („eingetroffen“) beim ersten Patientenkontakt und nicht wie im Rettungsdienst üblich beim Eintreffen an der Postadresse. Dies bildet eine valide Datengrundlage für Qualitätssicherung und Forschung.
Das Mitwirken aller am Rettungsdienst beteiligten Institutionen (Hilfsorganisationen, ILS, Landkreis, Krankenhäuser, Kostenträger) und der Austausch zwischen Betreibern, Leitstelle sowie Softwareanbieter ist eine wichtige Voraussetzung, um eine erfolgreiche Implementierung und einen nachhaltigen Betrieb zu gewährleisten.

Smartphone-basierte Alarmierungssysteme bieten die Möglichkeit, das reanimationsfreie Intervall durch den Einsatz von in der Wiederbelebung geschulten Ersthelfern zu verkürzen.Entgegen der häufig kommunizierten Meinung handelt es sich bei den Alarmierungssystemen nicht ausschließlich um eine App, sondern um ein komplexes System, welches aus einem Server mit entsprechender Systemsoftware, den angebundenen Smartphones der Ersthelfer sowie der Ersthelfer-App besteht.Das System ist über Schnittstellen mit dem Einsatzleitsystem, ggf. noch mit einer AED-Datenbank und weiteren Systemen verbunden. Für das Erreichen bestmöglicher Ergebnisse sollte ein ganzheitlicher Ansatz mit optimaler Anpassung des Systems an die Anforderungen und regionalen Gegebenheiten bestehen.Das System muss in der Lage sein, valide Daten für Qualitätssicherung, Weiterentwicklung und Bearbeitung wissenschaftlicher Fragestellungen zu liefern.
",Notf Rett Med
PMC7809237,Prone position in wards for spontaneous breathing Covid-19 patients: a retrospective study,"The coronavirus disease 2019 (Covid-19) pandemia expansion was responsible for an overload of patients who developed an acute respiratory failure [1]. Many critical hypoxemic patients were treated in wards due to lack of intensive care units (ICU) bed availability. Despite the data scarcity in conscious non-mechanically ventilated patients, prone positioning was broadly suggested in this context. The aim of our study was to evaluate the efficiency and tolerance of prone positioning in non-ICU patients.
We conducted a retrospective study in Groupe Hospitalier Paris Saint-Joseph wards between March 15 and July 6, 2020. Confirmed Covid-19 hypoxemic patients who benefited from at least one prone position were included. Patients were not included if they had less than 4 L/min oxygen flow. This study was approved by the Groupe Hospitalier Paris Saint-Joseph Institutional Review Board and registered following the French Reference Methodology MR-004. Anonymous data were collected in the absence of opposition of the patients to the use of their data.
The main outcome was the SpO2/FiO2 evolution, estimated by pulse oximetry (SpO2) and inspired oxygen fraction (FiO2) collected immediately before, during, and after each set up. We also compared patients who responded and those who did not: responders were defined as an improvement of SpO2/FiO2 of more than 50. Secondary outcomes were (i) immediate failure to sustain posture, (ii) adverse events (desaturation, modification in blood pressure or heart rate, vomiting) during prone position, and (iii) poor-tolerance (impossibility to withstand the position due to subjective reasons such as onset or increase of pain, worsening of dyspnea, uncomfort, or anxiety).
Main outcome analysis was made using Friedman paired tests and Dunn’s post-test. Continuous variables were presented as median with interquartile range (IQR) due to their distribution. Categorical variables were expressed as numbers with percentages. Statistics were processed using the R software with a two-sided 5% significance threshold. When necessary, 95% confidence intervals (95% CI) are presented. Figures were created using GraphPad Prism 8 software.
We included 27 patients out of 38 eligible patients: 11 patients were not included because flow oxygen was under 4 L/min at the first prone position.
The median age of patients was 73 years (IQR, 60–79). Fifty-nine percent were male (n = 16) and the median body mass index (BMI) was 28.1 (IQR, 25.4–32.8). The most common comorbidities were arterial hypertension (n = 13, 48%), chronic obstructive pulmonary disease (n = 7, 26%), and type II diabetes (n = 6, 22%). One patient (4%) was an active smoker while 13 patients were former smokers (48 %). The remaining patients had never smoked (n = 13, 48%).
Lesion severity on computerized tomography scan was moderate (10–25%) for 7 patients (26%), extensive (25–50%) for 10 patients (37%), severe (50–75%) for 8 patients (30%), and critical (over 75%) for one patient (4%). The first prone position was achieved at a median duration of 2 days after hospital admission. Seventy-four percent of patients (n = 20) were on oxygen flow rates of at least 6 L/min and SpO2/FiO2 median ratio was 187.5 (IQR, 161.6–211.2). Median duration of hospital length of stay was 16 days (IQR, 9–24). One patient died during hospitalization.
Twenty-four patients completed the first prone position: the median SpO2/FiO2 ratio was 342.5 (238.9–438.1) which was significantly higher than the 188.5 (162.5–216.9) before prone position (p < 0.0001). There was no difference in SpO2/FiO2 before and after posturing: 188.5 (162.5–216.9) vs 200.0 (173.4–234.4). Similar results were found during the next posture sessions. Results are presented in Fig. 1.
During the first posture, 18 patients were responders. Moreover, responder and non-responder patients did not differ from one another, except for length of hospital stay, which is shorter for responders (Table 1).
Considering the 64 episodes of postures, no serious adverse event has occurred. Three postures were impossible to sustain immediately, 2 for anxiety, and 1 for desaturation: the failure rate of prone position was estimated to be 5% (95% CI, 1–13%). Among the 61 sessions, 7 desaturations have occurred: the adverse event rate was estimated to be 7% (95% CI, 2–16%). Finally, the prone position poor-tolerance frequency was estimated to be 8% (95% CI, 3–18%): 2 for onset of pain and 3 for severe uncomfort.
Our results confirm that prone position improved Covid-19 patients’ alveolar oxygen exchange in ward patients and is well tolerated.
Several studies have been recently published about prone position in Covid-19 patients. Elharrar et al. have yet ascertained that only 25% were responders to prone position [2]. However, our study showed more promising results: other studies have found the same trends as ours in oxygenation improvement during the posture [3–5]. Sartini et al. found that 12 of 15 patients had persistent oxygenation improvement after the posture’s end [3]. In our study, oxygenation improvement did not seem to persist when the position was stopped; therefore, our results seem consistent with findings from previous studies [2, 4]. There is some heterogeneity in literature regarding oxygenation improvement during and after posture: this could be due to a substantial difference in time measurement itself or because outcomes, populations (e.g., age and body mass index), and associated treatments (e.g., non-invasive ventilation during posture) were different.
The results of our secondary outcomes were consistent with previous findings and suggested that difficulties encountered are rather scarce and mild [2–4, 6].
There are several limitations in this study. Firstly, it was a retrospective study from a single center. Moreover, homogeneity of patients and unicity of the pathology made the results transposable in other locations. Secondarily, the SpO2/FiO2 ratio probably lacks precision but is correlated with PaO2/FiO2 ratio [7] and is quite less invasive for conscious patients. Finally, the absence of randomization reduced our level of evidence; nonetheless, the variations of SpO2/FiO2 during and after prone position tend to confirm the efficiency and the transient nature of the effect.
In conclusion, prone position is easy to implement in wards, improves alveolar exchange during posture, and is well tolerated. Results need confirmation in randomized and high-quality studies. Moreover, the benefit of this technique on intubation or mortality is currently unknown.",Ir J Med Sci
PMC7809238,French survey on a cohort of emergency general surgery modifications induced by lockdown of the SARS-CoV-2 pandemic,"Over a few weeks, SARS-CoV-2, an emerging disease localized to a region of China, became a global pandemic [1]. The brutality of this pandemic and the large number of patients suffering from severe forms of the disease has had a major impact on populations and health systems, regardless of health facilities and geographical location [2]. France was one of the earliest and most affected countries in the world, and its national health system was severely strained while undergoing deep and rapid reorganization to face this unprecedented crisis.
The French national lockdown recommended home confinement beginning March 17, 2020, shutting schools, forcing the population to work from home, and restricting movement with minor exceptions for essential needs [3]. The population was urged not to overload hospital services, and concern was communicated that they could be contaminated in emergency departments overwhelmed by cases of COVID-19. Additionally, emergency care pathways were dedicated to treating COVID-19, providing screening by polymerase chain reaction (PCR) tests and/or thoracic computed tomography (CT). This situation may have increased the time between admission and surgical care (door-to-surgery time). Surgeons also sustained radical changes in their practices [4, 5] through massive deprogramming of non-emergency procedures to decrease disease transmission and spare anesthesia drugs and personal protective equipment [6]. These changes decreased the number of patients consulting for abdominal pain and digestive emergencies and resulted in severe clinical presentations [7, 8]. This survey aimed to assess changes in emergency surgical practice within the community of French digestive surgeons critically.
The survey was designed with two separate questionnaires that were sent to the community of French digestive and general surgeons in the Societe Francaise de Chirurgie Digestive (SFCD). The questionnaires were both concerned with the French lockdown from March 17 to May 11, 2020 (which corresponded to the study period). The first generic e-survey focused on daily surgical activities during the pandemic, including the type of facility, daily presence of the surgeon, reduction of surgical activity, care of COVID-19 patients, participation in non-surgical COVID-19 care, and use of teleconsultation. The geographic area of each facility was considered as exposed to high or low pandemic pressure according to the public authorities’ definition (considering the circulation rate of the virus and the number of hospitalized patients) [9]. The second questionnaire investigated changes in patients’ management. For each patient with a deviation in care during the period, an anonymous questionnaire was filled out with the following items: age, gender, ASA score [10], COVID-19 status (positive, negative, unknown), diagnosis, date of admission (for ease of analysis, a three-level categorical variable “confinement period” was created), surgical procedure, postoperative complications (according to the Dindo-Clavien classification [11]), and length of hospital stay. The centers were also asked to report the total number of patients admitted for acute abdominal care during the same period.
Deviation from standard care was classified into three categories, and each patient could fulfill one to three categories. The categories were as follows:Delay of management was considered as a deviation when the date of admission was intentionally delayed from the onset of symptoms. Reasons for this delay could include the patient’s fear of being hospitalized or a practitioner’s advice (general practitioner [GP] or surgeon) against early admission. The duration was quantified in days and was considered to be major when ≥ 5 days.Modification of treatment strategy included any change in treatment class (surgical to medical or the reverse), surgical procedure (laparoscopic to open approach, no drain, damage control, etc.), degree of emergency (e.g., patients requiring emergency surgery for a canceled elective procedure), and access to an intensive care unit (ICU; i.e., non-admission to an ICU for monitoring because of limited access).Modification of logistical organization concerned all inter-facility transfers, modification of the usual admission mode, implementation of specific prevention procedures in the operating room for patients with a suspected COVID-19 infection, and any delay within the hospital (e.g., the supplementary time required for SARS-CoV-2 diagnostic procedure with CT-thorax and PCR sampling).
Each surgeon was required to estimate the impact of these deviations on the patients’ loss of chance (LOC) using a subjective scale (no loss, moderate, or high). The overall LOC was considered moderate to high.
Statistical analyses were performed using IBM SPSS 23.0 (IBM Inc., New York, NY, USA). Categorical variables were described in terms of frequency (percentages), and continuous variables were described as mean ± range (SD). Univariate analyses were conducted using a Student’s t test or the Mann–Whitney test for continuous variables and the chi-square test or Fisher’s exact test for categorical variables. A two-tailed p value ≤ 0.05 was considered statistically significant. Multivariate analyses were performed using a backward stepwise logistic regression model adjusted for covariates significant at p ≤ 0.1 based on univariate analysis.
Responses concerning changes in global surgical activities were obtained from 67 hospitals (Table 1). The responders were mostly located in general hospitals (n = 47, 70.1%) from low-pressure areas. A reduction in surgical elective activity greater than 75% was observed in 50 centers (74.6% of responders), and significantly more COVID-19 patients underwent surgery in high-pressure areas compared with low-pressure areas (83% vs. 53%, p = 0.03). The daily presence of surgeons varied widely across the centers, with 22.3% (n = 15) of them performing surgical procedures in another facility. Of the surgeons, 48 (71.6%) reported receiving COVID-19 patients in their surgical unit, and 41 (61.2%) operated on infected patients. Additionally, 45 (67.2%) turned their consultations into teleconsultations. Most of them partially shifted their daily activity toward non-surgical management of COVID-19 patients, as follows: 22 (32.8%) in COVID units, 13 (19.4%) in an ICU, 41 (61.2%) in emergency units, and 32 (47.8%) in the management of hospital reorganization.
Six centers reported the total number of patients admitted for digestive emergencies during this period, and a deviation from usual care was observed in 10% of them (53 out of 532). The other centers reported deviations without providing the total number of patients admitted. In total, the description of deviations concerned 140 patients. The patients’ characteristics are reported in Table 2.
In the centers, 11 patients (7.8%) were positive for COVID-19. The three most common abdominal diseases were appendicitis (n = 34, 24.3%), occlusion (n = 32, 22.9%), and biliary disease (n = 27, 19.3%). Of the patients, 96 (68.6%) patients required surgery, and the surgeries for 25 of them (17.9%) included complementary protection for SARS-CoV-2. Twenty-seven (19.3%) patients presented severe complications (Clavien ≥ 3), including 7 (5.0%) deaths during hospitalization.
The deviations from standard care were classified into three categories: delay of management, modification of treatment strategy, and modification of organization (Fig. 1). Of the patients, 33 presented two or three deviations. The characteristics of the patients according to the type of deviation are shown in Table 3.Delay of management was the most common reported deviation and concerned 74 (52.9%) patients. Among 40 patients (28.6%) who waited for 5 days or more, 19 had received previous consultation from a GP, while 21 had not consulted at all. This led to a high LOC of 2 and 6, respectively. Among 34 patients (24.3%) who waited for 4 days or less, 12 had received previous consultation from a GP, while 22 had not consulted at all, leading to a high LOC of 0 and 3, respectively.Concerning the modification of strategy, medical treatment instead of surgical treatment was decided for 37 (26.4%) patients. Of these patients, 12 eventually underwent surgery. The two pathologies most frequently affected by this modification were cholecystitis (n = 15) and appendicitis (n = 10). This generated no LOC for 3 patients (one biliary disease, one appendicitis, and one digestive occlusion) but a high LOC for 6 patients (two biliary diseases, two occlusions, one mesenteric ischemia, and one Fournier’s gangrene). In the subgroup of patients affected by biliary disease and treated by medical instead of surgical treatment, 2 died, 4 were re-hospitalized for medical treatment failure, and 3 underwent surgery. The medical treatment of appendicitis resulted in no LOC for 1 patient and moderate LOC for 9 patients; 4 patients eventually underwent surgery. Seven (5.0%) patients underwent surgery after a canceled procedure, including 4 patients with biliary disease.Regarding management of organization, 24 (17.1%) patients were impacted by a delay within the hospital, and 25 (17.9%) were operated on with complementary protection for COVID-19. The median delay within the hospital was 9 h (range 2–72). The most common reason for this delay was waiting for the patient’s COVID-19 status results. Furthermore, 19 (13.6%) patients were transferred to another hospital because of limited access to the ICU or upgraded medical technical platforms. The patients who suffered the most from organizational deviations had occlusion (n = 17) or appendicitis (n = 17). Among the patients with occlusion, 2 died, 2 were transferred to the ICU, and another one had no access to the ICU even when admission to the ICU was indicated. The treatment of occlusion for 13 patients was surgery, including 6 patients who received complementary protection for COVID-19. Among the 17 patients with appendicitis, 2 (11.8%) developed severe complications (Clavien ≥ 3), 10 were operated on with complementary protection for COVID-19, and 3 were transferred to another hospital.
The surgeons estimated that the deviations from usual care were responsible for an overall LOC in 80% of patients (moderate LOC in 82 patients [58.6%] and high LOC in 30 patients [21.4%]). Only 28 patients (20%) had no consequence from the deviations. Moderate LOC was significantly associated with the patient’s age (p = 0.002), intentional delay before consultation (p = 0.001), switch from surgical treatment to medical treatment (p = 0.027), and complementary protection for SARS-CoV-2 during surgery (p = 0.027). High LOC was significantly associated with the patient’s age (p = 0.002), ASA score (p = 0.001), the type of pathology (p = 0.002), and being in a high-pressure area (p = 0.014). Peritonitis and mesenteric ischemia were more often associated with high LOC: 0% and 0% versus 13.3% and 10.0%, respectively. Considering overall LOC, intentional delay before consultation (p = 0.004) and complementary protection for SARS-CoV-2 during surgery (p = 0.027) showed a statistical significance. In the multivariate analysis, variables that independently correlated with overall LOC were an ASA score of 1–2 (p = 0.014, OR = 0.21, 95% IC 0.06–0.73), medical treatment instead of surgical treatment (p = 0.002, OR = 9.14, 95% IC 2.29–36.49), and intentional delay before consultation (p < 0.001, OR = 6.59, 95% IC 2.40–18.14).
The brutal COVID-19 pandemic saturated and disorganized French hospitals. Non-emergency surgeries were canceled, and the number of consultations dramatically decreased [4, 6]. For these reasons, surgeons’ daily activity was modified, with a reduction in surgical elective activity greater than 75% for 74.6% of hospitals. Teleconsultation was used as an adaptation to ensure continuity of care; it was decided on and applied by most hospitals (67.2%).
Access to care was maintained, but patients’ fear of contracting COVID-19 and the saturation of hospitals and their reorganization induced deviations from usual care [7, 12, 13]. This study highlighted this fact by identifying 140 deviations from usual care classified as delay in consultation (52.9%), change in therapeutic strategy, and modified organization. To measure the effect of these deviations on patients’ outcomes, the LOC, which is subjective but relevant for surgeons, was used. Three independent factors predicting LOC were identified: an ASA score of 3–4, medical treatment instead of surgical treatment, and intentional delay before consultation. Organization deviation did not appear to have an impact on the severity of complications or LOC for patients.
As expected, fragile patients with serious abdominal pathologies (e.g., mesenteric ischemia, peritonitis) were more impacted by any deviation than younger patients with deferrable emergencies, such as appendicitis or proctologic diseases. Intentional delay before consultation was an expected pejorative factor since acute abdominal pathology outcomes are conditioned by the delay of management. However, a previous consultation by a GP limited its impact through a better selection and orientation of the patients. The change in therapeutic strategy was a one-way change, and some patients received medical treatment instead of an indicated surgery to spare them from complications, COVID infection, transfer to ICU, or a longer stay. Successes in the medical treatment of appendicitis were observed, but patients with biliary diseases experienced more medical treatment failures and thus more LOC. Therefore, surgeons should be cautious when making this decision, as delayed surgery in case of failure can be deleterious and represent a real LOC.
During national lockdown, each country witnessed a brutal drop in emergency department visits of at least 25% of usual activity[14]. Moreover, Patriti et al. described a decrease in surgical emergencies [12, 15]. Some patients were able to be treated and monitored by their GP at home, but late admission was probably responsible for an ICU transfer for 3 patients [15].
Ignorance of certain modes of transmission routes or symptoms of SARS-CoV-2 was also responsible for surgical changes. Indeed, COVID-19 digestive symptoms complicated diagnoses [16, 17]. Moreover, the virus has a fecal tropism that may be responsible for contamination during exposure [18, 19], and additional protective measures had to be established in operating theaters in case of an infected patient [20]. These measures were observed 25 times in this study. Furthermore, the use of laparoscopy has been contraindicated during the pandemic because of the potential vaporization of the virus, especially during gas exsufflation [21, 22]; in the present study, 3 patients were preferably operated by laparotomy for this reason. These novel specificities complicated the management and circuits of infected and non-infected patients.
This work analyzed the deviations in usual care to improve the management of patients in case of a second wave. Patients should be reassured about the continuity of care and hospital safety, should be informed of excess loss of chance and morbidity if waiting to consult, and should have ease of medical access. The possible response to a long-term disaster is telehealth visits, whose access must be extended [15]. Moreover, the delay within hospitals must be improved. Hospitals need to adapt to increasing patient flow, and serious situations need to be identified early. Therefore, surgeons must be involved in reorganization and triage. Additionally, clinicians should be cautious when changing therapeutic strategy, especially for biliary disease.
This work has several limitations: (i) unequal response rate of centers (high vs. low pressure, and university vs. general and private hospitals) leading to under-estimation; (ii) no comparison to the usual situation limit extrapolation; (iii) no normal consultation time for abdominal pain, which is a bias for delay deviation; and (iv) the subjective nature of LOC, which nonetheless seemed to reflect the real situation.
This work showed an excellent portrayal of usual surgical activity and emergency management. The major deviations to usual care were identified, and the necessary adaptations were proposed. Patients must be reassured of the safety of disaster management to limit delays in the management of serious pathologies, and clinicians should carefully select management strategy changes, especially for biliary disease.",Ir J Med Sci
PMC7809240,"An investigation of risk factors of in-hospital death due to COVID-19: a case-control study in Rasht, Iran","From the onset of the coronavirus disease 2019 (COVID-19) worldwide outbreak, approximately 41,570,883 patients have been diagnosed with the disorder. According to the WHO report, about 1,134,940 patients were reported to have died until October 23, 2020 (https://covid19.who.int/?gclid=CjwKCAjw_sn8BRBrEiwAnUGJDnToj4uxvzG9fm5s4201MBEj1NL0enL28io7p9SOSMh6-6PBVcegjRoCT_wQAvD_BwE).
A wide spectrum of COVID-19 manifestations has been recognized, from asymptomatic infection or mild symptoms in most subjects to severe deleterious respiratory infection in approximately one-fifth of the patients [1, 2].
Even though much research has been conducted on the COVID-19 patients’ characteristics on admission and the factors affecting their hospitalization duration, mortality, and morbidity, there is no clearly defined risk factor. Advance ages (≥ 65 years), using immunosuppressive medications, smoking, having a history of type 2 diabetes mellitus, dyslipidemia, obesity or increased body weight (body mass index (BMI) ≥ 40 kg/m2), cardiovascular disease (CVD), particularly hypertension (HTN), and ischemic heart diseases and renal disorders are among the most known risk factors for increasing the severity and death rates related to the novel RNA coronavirus (acute respiratory syndrome coronavirus 2 (SARS-CoV-2)) [1, 3–12].
Humoral and cellular immunity systems are activated after intracellular replication of the virus. Augmented inflammatory responses, as indicated by increased release of pro-inflammatory cytokines including interleukin (IL)-6, IL-10, and tumor necrosis factor (TNF)-α, and hyperstimulation of the immune system, which is known as “cytokine storm,” occur then after. “Cytokine storm” could lead to acute respiratory distress syndrome (ARDS), massive bilateral viral pneumonia, hypercoagulation, stroke, pancreatic islets infection, cardiac, renal, or liver injury, and eventually multiple organ failure [4, 13]. Moreover, elevated angiotensin-converting enzyme 2 (ACE2) expression in the lower respiratory tract and increased contact of the virus with the cells via binding to ACE2 in the lungs could cause systemic infection. These events worsen the inflammatory state and activate immune responses that make the patients vulnerable to develop the more severe type of SARS-CoV-2 infection [2, 4].
Unfortunately, until the present, no definite treatment or vaccine has been recognized for SARS-CoV-2. Therefore, exploring the non-survived patients’ characteristics compared to survived subjects and introducing the critical risk factors of COVID-19 mortality applying multivariable logistic regression would further our knowledge of this virulent disorder’s treatment and enhance patients prognosis. In particular, such studies facilitate the early identification of most at-risk subjects for mortality in an emergency condition, monitoring these patients accurately and making therapy decisions and hospital discharge accordingly [1, 5]. However, due to the differences in demographic and genetic features of the various population, the generalizability of previous reported pathophysiological parameters to COVID-19 patients from all over the world may be limited. Besides, to our knowledge, the current evidence on characteristics of patients with COVID-19 in our region and their mortality risk does not seem to provide enough information and requires further evidence.
 Therefore, the primary objective of the current study was to explore the differences in clinical and laboratory assessments of a sample of survived and non-survived patients with COVID-19 admitted to an academic referral hospital in Rasht, Iran. We also aimed to investigate the risk factors of COVID-19 mortality.
In the current single-center case-control study, we selected 250 adult COVID-19 patients aged older than 18 years who were admitted to Razi university hospital, the COVID-19 referral hospital in Rasht, Guilan, Northern Iran, from April 21 to August 21, 2020. The subjects younger than 18 years and those whose anthropometric or laboratory findings had not been recorded were not enrolled. Case group included 103 patients who were reported to dye due to COVID-19 (which are analyzed as non-survivors), and control group included 147 sex-matched patients who were discharges or recovered (which are analyzed as survivors).
Upon admission, the diagnosis of COVID-19 was performed according to WHO interim guidance and national protocols published by the Ministry of Health and Medical Education, Iran. Chest computed tomography (CT) scan results were used for determining abnormalities on chest CT imaging. Nasopharyngeal or oropharyngeal swab samples real-time reverse transcriptase-polymerase chain reaction (RT-PCR) test was applied for SARS-CoV-2 detection. The COVID-19 infection well-known or typical symptoms were also considered, including fever, cough, diarrhea, and respiratory symptoms (i.e., dyspnea, cough).
The patients or a member of their family were provided informed consent. Also, the research was performed based on the guidelines of the 2013 version of the Helsinki Declaration. It was approved by the review board of Cardiovascular Diseases Research Center, Department of Cardiology, Heshmat Hospital, School of Medicine (research number = 99012701), and Ethics Committee of Guilan University of Medical Sciences (ethical code number = IR.GUMS.REC.1399.017).
The information on demographic data (age and sex), underlying disorders, and past medical history (diabetes, HTN, previous CVD, coronary artery disease, or other conditions), the length of hospitalization, having gastrointestinal symptoms at admission, anthropometric measures (height and weight), and the clinical outcome (died or discharged alive) was extracted from the hospital electronic medical records. An experienced clinician reviewed and verified the data. A third researcher resolved the discrepancies in case of any differences in interpreting the data between the two primary reviewers.
After collecting blood samples within 48 h of admission, laboratory assessments were performed. Serum levels of C-reactive protein (CRP), was assessed using the immunoturbidimetric method according to the manufacture’s guide (APTEC diagnostics NV, Belgium; Novin Biokit, Ref. No. R130, Tehran, Iran). Besides, serum D-dimer concentration was investigated by applying an immunoturbidimetric assay (Diagnostica Stago, Asnières, France).
Fasting blood glucose (FBG) and total cholesterol (TC) levels were assessed by the enzymatic method using glucose oxidase and cholesterol esterase and cholesterol oxidase, respectively, applying commercial kits manufactured by MAN Co. (Tehran, Iran) and Auto-Analyzer (Hitachi, Japan) based on manufacturer’s instructions. In terms of assessing triglyceride (TG), the same method was applied, but with glycerol phosphate oxidase using the commercial kit manufactured by Bionic Corporation and Auto-Analyzer (Hitachi, Japan). High-density lipoprotein (HDL) level was additionally evaluated based on enzymatic method (MAN Co., Tehran, Iran), and low-density lipoprotein (LDL) was estimated by Friedewald formula. Serum creatinine level was also investigated according to the manual instruction of the kit from MAN Co. (Tehran, Iran).
All commercial kits were confirmed by the Iran Health Reference Laboratory. All analyses were carried out in a certified clinical laboratory affiliated to Guilan University of medical sciences.
Electrocardiography (ECG) paper tracing recorded at 25 mm/s paper speed at 10 mm/mV gain setting was applied to determine the QT interval. The QT interval defined as the average interval between Q wave onset to the T wave end was evaluated using a single lead, representing the most prolonged QT with a prominent absence of U wave. Also, Bazett formulas (corrected QT interval (QTc) = QT/√ RR) was applied for modifying the evaluated QT interval (or QTc) for the effects of rate. The heart size defined as the transverse diameter of heart shadow (TDH) was estimated by applying chest posterior-anterior radiographs (PA chest X-ray). TDH was assessed via sketching a line near the heart shadow middle and the spine with a line from the heart’s right border to the last line. A different line from the heart’s left edge was drawn from the line in the heart shadow middle. The two lengths were summed up to calculate the TDH. Also, the ratio between the chest diameter and the heart widest portion that was estimated by drawing a line at the level of diaphragm right leaf to the inner border of the rib cage on the right and on the left was considered as the cardiothoracic ratio (CTR). A CTR was regarded as abnormal if it was > 1:2 (50%).
Normal distribution was assessed by the Shapiro-Wilk test. Between-group differences of skewed and normally distributed data were determined using the Mann-Whitney U test or independent sample T test, respectively. Continuous variables were reported as mean (standard deviation, SD) in normally distributed data or median (interquartile range, IQR) in case of data with skewed distribution. Chi-square or Fisher’s exact test evaluated between-group differences of categorical variables, and the data were presented as proportions (%). To estimate the association between variables of interest and mortality, odds due to COVID-19 infection the logistic regression model was applied, and odds ratios (ORs) and 95% confidence intervals (95% CIs) were presented. Age, sex, length of hospitalization, and BMI levels [for analyzing laboratory data] were considered the second regression model (multivariable logistic regression analysis). Test for trend (P for trend) was carried out considering each quartile’s median value as a continuous variable in the regression analysis. All analyses were performed applying IBM SPSS version 24 software (version 24.0; SPSS, Chicago, IL).
A total of 250 hospitalized patients with confirmed COVID-19 with a mean (SD) age of 59.61 (16.55) years (of whom about 76 (30.4%) were < 50 years) were enrolled in the current analysis. About 124 (49.6%) >patients were women, and 126 (50.4%) were men. Overall, the mean duration of hospitalization was about 8.65 (5.49 days). Regarding the methods of SARS-CoV-2 infection diagnosis, 40 patients (16.0%) showed abnormal chest CT images, 169 (67.6%) had two RT-PCR assay positive findings, and 41 (46.4%) experienced severe clinical manifestation of upper respiratory symptoms upon admission. Overall, nearly 20% of the admitted subjects reported nausea, vomiting, and diarrhea, with vomiting as the most common on-admission gastrointestinal complaint.
The comparison of demographics and baseline features of included COVID-19 cases according to survival status is demonstrated in Table 1. Non-survived patients (n = 103) were considered as cases and survivors (n = 147) were included as sex-matched controls. The patients who died were significantly older than the discharged patients (mean age = 62.87 (16.74) vs. 57.33 (16.07) years, respectively; P value = 0.009). The proportion of the patients older than 50 years old tended to be higher among the non-survived group than the discharged patients (78 (75.7%) vs. 96 (65.3%), respectively), though no statistically significant differences were detected.
Concerning the history of comorbidities, there was a significant difference between the two studied groups. Overall, the proportion of non-survivors with any documented history of a medical condition (n = 89; 86.5%) was greater than that of survivors (n = 97; 65.1%) (P value = 0.011; Table 1). Having a history of HTN alone (n = 17 (16.5%)), HTN and diabetes (n = 15 (14.6%)) and coronary artery disease (n = 33 (32.1%)) were more prevalent among non-survivors, while having diabetes alone was nearly more prevalent among survived patients (n = 13 (8.8%)) (Table 1).
Upon-admission BMI and the clinical findings of the enrolled patients are presented in Table 2. Compared with the discharged patients, the subjects who died were more likely to be obese as evidenced by higher median BMI levels (median (IQR) = 27.68 (4.04) vs 25.71 (3.84) kg/m2, P value = 0.01). Regarding on-admission serum biomarkers, non-survivor patients were demonstrated to have less favorable levels of serum levels of inflammatory and glycaemia markers, lipid profile, and renal function marker, including higher levels of CRP (median (IQR) = 105.00 (143.00) vs. 99.00 (62.00) mg/l, P value = 0.016), FBS (median (IQR) = 133.50 (158.50) vs. 110.00 (45.00) mg/dl, P value < 0.001), TC (median (IQR) = 132.00 (55.00) vs. 123.00 (46.00) mg/dl, P value = 0.033), TG (median (IQR) = 138.00 (83.00) vs. 113.00 (71.00) mg/dl, P value = 0.001), and creatinine (median (IQR) = 1.30 (1.10) vs. 1.00 (1.31) mg/dl, P value = 0.005). However, there was no between-group difference in serum LDL and HDL levels. Furthermore, the two studied groups of patients exhibited similar findings on serum D-dimer levels and cardiac function biomarkers including QTc interval and heart size (Table 2).
In order to further investigate the predictors of COVID-19-related mortality, the logistic regression model (crude and multivariable) was run and the results are presented in Table 3. According to the crude logistic regression analysis, anthropometric indices and serum biomarkers that were demonstrated to be positively associated with COVID-19-related death risk when comparing the highest quartile compared to the lowest were as follows: increased BMI (OR = 2.66; 95% CI = 1.27–5.58), and higher serum concentrations of CRP (OR = 2.52; 95% CI = 1.23–5.16), FBS (OR = 3.16; 95% CI = 1.52–6.56), TC (OR = 2.12; 95% CI = 1.03–4.36), TG (OR = 4.06; 95% CI = 1.90–8.68), creatinine (OR = 2.31; 95% CI = 1.12–4.76), and D-dimer (the 2nd and 3rd quartile compared to the lowest: OR = 0.11; 95% CI = 0.01–0.93; OR = 4.34; 95% CI = 1.85–10.19, respectively) (Table 3).
The multivariable logistic regression analysis adjusted for age, sex, length of hospitalization, and BMI levels [in terms of laboratory values], revealed similar results except for LDL, HDL, and creatinine serum levels in relation to COVID-19 mortality. It was found that compared to the lowest values, elevated BMI levels and higher levels of CRP increased the odds of COVID-19 fatality by about 2 times (OR = 2.49; 95% CI = 1.15–5.41; OR = 2.28; 95% CI = 1.08–4.78, respectively); increased FBS levels raised the COVID-19-related death odds by about 3-fold (OR = 2.88; 95% CI = 1.35–6.17); higher levels of TC and LDL elevated the odds of COVID-19 fatality by about 2 times (OR = 2.55; 95% CI = 1.19–5.45; OR = 2.27; 95% CI = 1.07–4.79, respectively); TG elevated the odds of COVID-19 mortality by approximately 2–5 times (the 2nd and 4th quartile compared to the lowest: OR = 2.51; 95% CI = 1.13–5.60; OR = 5.14; 95% CI = 2.28–11.56, respectively); raised levels of D-dimer also tended to increase the death odds due to COVID-19 by about 5-fold (the 3rd quartile compared to the lowest: OR = 5.68; 95% CI = 2.22–14.49). No significant association was detected regarding QTc interval or heart size and COVID-19 fatality odds neither in crude nor in multivariable regression. Although elevated serum HDL level was likely to be a protective factor against COVID-19-related mortality odds according to the crude regression model (the 3rd quartile compared to the lowest: OR = 0.47; 95% CI = 0.22–0.98), this association did not remain significant anymore in the multivariable regression model (Table 3).
Based on the current results, obesity, as indicated by elevated BMI levels, could be accompanied by increasing the mortality risk of COVID-19. In line with our findings, a retrospective cohort study was conducted by Simonnet et al. on the association between clinical features, such as BMI, and the need for invasive mechanical ventilation (IMV) in 124 hospitalized COVID-19 patients. It was indicated that having a BMI higher than 35 kg/m2 was associated with about seven times increased need for in-hospital mechanical ventilation (OR: 7.36; 95% CI = 1.63–33.14) compared to normal-weight individuals with BMI of less than 25 kg/m2 [14]. Likewise, in another retrospective study on 3615 COVID-19 patients younger than 60 years old, in comparison with those with a BMI of less than 30 kg/m2, grade I of obese subjects (with a BMI of 30–34 kg/m2) have been suggested to be at about 2 times greater risk of being admitted to both acute and critical care OR = 2.0 (95% CI = 1.6–2.6) and OR = 1.8 (95% CI = 1.2–2.7), respectively). Similarly, grade II of obese individuals (with a BMI of ≥ 35 kg/m2) have been proposed to be at about 2 (OR = 2.2; 95% CI, 1.7–2.9) and 3.5 times (OR = 3.6; 95% CI = 2.5–5.3) greater risk of being admitted to acute and critical care, respectively [14, 15]. Similarly, another retrospective research on 280 COVID-19 cases reported that the patients who suffer from severe/critical symptoms had significantly higher BMI levels than the patients with mild and moderate symptoms (25.8 vs. 23.6, respectively). They also showed that BMI was a risk factor for increased severity of SARS-CoV-2 (OR = 1.30; 95% CI = 1.09–1.54) [16].
Multiple mechanistic pathways may explain the adverse effects of obesity on death due to COVID-19. The concentrations of leptin (as a pro-inflammatory adipokine), oxidative stress and pro-inflammatory cytokines (i.e., IL-6, TNF-α, and CRP) have been shown to be higher among obese individuals. It is noteworthy that leptin is thought to be a certain modifier of maturation, development, and activity of B cells. On the other hand, the concentration of adiponectin (as anti-inflammatory adipokine) is reported to be lower in these patients. The imbalances in the mentioned factors could cause dysregulation of immune cells function that in turn may affect the viral infection progression. Besides, both obese patients and COVID-19 cases have an increased risk of hypercoagulation and thrombosis [2, 17–19].
The majority of prior research has focused on the association between having diabetes history instead of blood sugar levels and COVID-19 fatality risk. Therefore, almost similar to our findings, some research and review articles found a negative association between hyperglycemia, weak glycemic control, and diabetes with COVID-19 fatality [3, 7, 12, 20–25]. As such, a recent systematic review recommended that health care providers consider monitoring blood glucose levels to be lower than 180 mg/dl (without triggering hypoglycemia) in most diabetic patients who have COVID-19 [7]. In a recent population-based cohort study by Holman et al., it was reported that COVID-19 in-hospital death odds ratios among type 1 and type 2 diabetic patients were 3.51 (95% CI = 3.16–3.90), and 2.03 (95% CI = 1.97–2.09), respectively, in comparison with those who had no diabetes. However, because of data limitation, the confounding variables were not considered in their regression analysis [3]. Likewise, Ciardullo et al. [26] observed having pre-existing diabetes was linked to an increased risk of COVID-19-related hospital death (RR = 1.56; 95% CI = 1.05–2.02) through a retrospective study performed in Italy on 373 COVID-19 hospitalized patients [26]. In a similar way, a systematic review and meta-analysis [20] on 83 observational studies of 78,874 hospitalized COVID-19 pointed out that the risk of suffering severe/critical COVID-19 infection and its related in-hospital fatality increased by about 2-fold (OR = 2.10, 95% CI 1.71–2.57) and 2.7-fold (OR = 2.68, 95% CI = 2.09–3.44), respectively, in the case of having pre-existing diabetes [20]. Likewise, another meta-analysis on six studies (included 1558 COVID-19 subjects) diabetes was introduced as a risk factor (OR = 2.47; 95% CI = 1.67–3.66) for COVID-19 infection [21]. Similarly, another more extensive meta-analysis (n = 30 studies with 6452 patients) reported subjects with diabetes were shown to have elevated risk of both severe types of COVID-19 (RR = 2.45; 1.79, 3.35), its complications including ARDS (RR = 4.64; 1.86, 11.58) disease progression (RR = 2.38; 1.88, 3.03) and its related death (RR = 2.12; 1.44, 3.11). However, the study did not find a significant association between diabetes and COVID-19 patients’ ICU admission [23].
Thus, having a history of diabetes mellitus, insulin resistance, and chronic hyperglycemia render the COVID-19-infected patients more susceptible to developing severe infection types, probably through metabolic disruption, triggering a pro-inflammatory state and oxidative stress in addition to immunosuppression [9]. Increased blood sugar may also link to deterioration in T cell responses, disruption in immune function, and cytokine release. Moreover, those with diabetes might exert modified microenvironment and higher expression of ACE-2, elevated platelet aggregation, hypercoagulation, and thrombosis, increasing the likelihood of viral uptake, infection progression, “cytokine storm,” and severe COVID-19 outcomes. Diabetics are also at elevated risk of endothelial dysfunction, cardiovascular and renal complications, and peripheral neuropathy. Hence, this may have an additive effect of being more susceptible to COVID-19 complications (i.e., ARDS, intensive care unit admission, and mechanical ventilation), severe COVID-19, and death. On the other hand, COVID-19 intensifies the complications and prognosis of diabetes, such as diabetic ketoacidosis. However, it is not well-understood whether blood sugar directly affects SARS-CoV-2 infection progression or the virus changes carbohydrates’ metabolism [9, 12, 13, 20, 26].
Consistent with our findings, a recent study by Wang L. demonstrated that patients with moderate SARS-CoV-2 infection had higher CRP concentrations than mild patients. Also, the patients had greater CRP levels than those in the moderate. Similarly, the critical patients’ group had greater CRP levels compared to severe patients. Besides, as the infection progressed, the serum levels of CRP and the largest lung lesion diameter get raised. Interestingly, they also suggested a significant positive correlation between serum levels of CRP and the diameter of lung lesions as well as severe manifestations of the disease (correlation coefficient = 0.873, 0.734) [27]. Additionally, in a retrospective cohort study comprised of 2957 hospitalized Iranian COVID-19 cases (2656 were cured, and 301 died), consistent with our findings, it was demonstrated that cured or discharged subjects had significantly lower serum CRP levels (median = 16 mg/l) than the patients who died (median = 45 mg/l). Also, after considering confounding factors including sex, age, and laboratory values in the multivariable model, it was revealed that CRP levels raised the risk of death from SARS-CoV-2 infection among those who had diabetes with or without other comorbidities (n = 267) (OR = 1.02; 95% = 1.0–1.04), or CVDs with or without other comorbidities (n = 168) (OR = 1.09; 95% CI = 1.04–1.14) [12]. The positive correlation between disease severity and serum CRP concentrations and the value of this inflammatory marker as a predictor of CIVID-19 progression and its complications, including respiratory failure and requiring ventilator support, have additionally been confirmed in further studies [26, 28–31]. A systematic review and meta-analysis on 16 studies, including 1896 survivors and 849 non-survivors COVID-19 cases, documented that serum levels of CRP of non-survivor patients was significantly greater than the survivors (standard difference in means = 1.371) [30]. A retrospective cohort study of 176 patients with COVID-19 showed partially similar results to the present findings [32]. Although no significant differences in serum CRP levels of COVID-19 survivors and non-survivors were found on admission, on day 7, a greater mean CRP was related to elevated mortality. Furthermore, mean CRP levels were significantly higher in the groups of patients needing critical care than those with the less progressed disorder at admission and on day 7. Although, in contrast to our results, the researchers failed to find a significant relationship between on-admission CRP levels and the odds of mortality, increased levels of this factor (> 101 mg/dl) on day 7 was associated with elevated COVID-19 mortality risk (OR = 3.7; 95% CI = 1.1–12.5) than the patients with < 100 mg/dl CRP levels after adjusting for comorbidities at baseline and medications consumption [32].
In pulmonary disorders with pro-inflammatory properties, serum CRP level usually increases as a result of elevated inflammatory factors such as IL-6, IL-1, or TNF-α [27, 28]. On the other hand, it has been well-known that excessive inflammatory responses may be primarily involved in SARS-CoV-2-related organ damage and infection progression [27, 28]. Hence, it can be proposed that elevated CRP levels may represent a marker for augmented inflammatory state, and disease severity in the early stage of SARS-CoV-2 infection, particularly among non-survivors of the cases with severe/critical COVID-19. Due to the prompt elevation in CRP production by the initiation of an inflammatory state in the body, cell damage, or injury of the tissues, this acute phase reactant level may also contribute to the stimulation of the complement function and enhancement of phagocytosis [27, 28]. Hence, since elevated CRP levels may indicate response to inflammation, and host defense systems function, its upon-admission levels should be considered an important biomarker of disease progression/death risk due to COVID-19.
In contrast to previous studies results [12, 33] and the present crude regression model, we failed to detect a statistically significant relationship between upon-admission serum creatinine level and COVID-19-related death odds. There was only a significant difference between the non-survived and survived patients concerning creatinine concentration in serum.
In a recently published prospective cohort study on 701 hospitalized COVID-19 cases, it was proposed that after considering confounding factors including age, gender, the severity of the disease, comorbidities, and leukocyte count in the COX regression models, raised baseline serum creatinine (hazard ratio: 2.10, 95% CI: 1.36–3.26), and increased baseline blood urea nitrogen (3.97, 2.57–6.14) were accompanied by an increased risk of COVID-19-related in-hospital fatality risk [33]. Furthermore, in a retrospective cohort study described earlier, similarly with our results, it was demonstrated that cured or discharged subjects had significantly lower creatinine serum levels (median = 1.00 mg/dl) than the patients who died (median = 1.20 mg/dl). However, contrary to the current findings, it was reported that creatinine levels elevated SARS-CoV-2-related mortality risk among those who had diabetes with or without other comorbidities (n = 267) (OR = 12.72; 95% = 1.87–86.70) after considering confounding factors including sex, age, and laboratory values in the multivariable model [12]. It is of note that augmented pro-inflammatory factors and disturbed immune cells function as consequences of abnormal kidney function and increased creatinine levels may render the patients at a greater risk of COVID-19 [34].
Although the information on D-dimer levels was available for 59 patients in case group and 100 patients in control group, our findings suggested those with increased levels of this biomarker (median=518.00 ng/mL) compared to those who had a median of 200.00 ng/mL are about five times more likely to die due to COVID-19. The current findings further confirmed previous evidence that suggested increased levels of D-dimer could be associated with high severity and death risk due to COVID-19, nearly always concurrent with augmented levels of pro-inflammatory factors (i.e., ferritin, lactate dehydrogenase, troponin I and TNF-α, IL-1b, and IL-6) [35]. In accordance with our results, the results of a recent systematic review of 6 articles on 1355 hospitalized subjects with moderate to severe COVID-19 (of which 391 were non-survivors and 964 were survivors) showed D-dimer levels are more likely to be greater in non-survivors compared to the survivors (SMD = 3.59 ng/l; 95% CI 2.79–4.40 ng/l) [35]. Also, in line with these results, in retrospective research on 248 COVID-19 cases, it was reported that the median D-dimer level of non-survivors (n = 17; 6.21 mg/l) was significantly greater than that of survivors (n = 231; 1.02 mg/l). Multivariable regression revealed that on admission, D-dimer higher than 2.0 mg/l was related to higher odds of mortality (OR = 10.17; 95% = CI 1.10–94.38). Furthermore, the D-dimer level was also shown to be significantly elevated by increasing COVID-19 severity [36]. Likewise, Tang et al. [37] showed a group of COVID-19 survivors (n = 162) had a significantly lower D-dimer level (0.61 μg/ml) compared the non-survivors patients (n = 21) (2.12 μg/ml). Similarly, Gao and cols reported that a group of patients with critical COVID-19 infection had significantly lower levels of the mild group (median level = 0.21 μg/l) compared to those in the severe group (median level = 0.49 μg/l). Besides, a higher D-dimer level (> 0.28 μg/l) was accompanied by an increased risk of severe COVID-19 in comparison with those who had a lower level (≤ 0.28 μg/l) (OR = 12.139; 95% CI = 1.716, 85.86) [38]. Another study investigated the variation of the D-dimer level through 10 days. Improved and poor patients were reported to have higher on-admission D-dimer concentration than those in the ordinary group with ORs of 1.42 (95% CI = 1.04–1.96) and 1.35 (95% CI: 1.02–1.80), respectively. While the level remained raised in the poor group by disease progression, it constantly reduced among the improved group [39]. Similarly, another group of researchers aimed to assess the D-dimer levels dynamic changes and risk for venous thromboembolism (VTE) throughout the infection’s progression through a study on 57 COVID-19 patients with pneumonia and 46 patients suffering from community-acquired bacterial pneumonia (CAP). They observed that D-dimer levels were significantly elevated at admission in both groups of studied patients though COVID-19 patients had significantly higher levels of this biomarker than the CAP patients. Also, it was found that there was a significant correlation between D-dimer and inflammation indicators including hs-CRP (R = 0.426) among the patients with COVID-19. Interestingly, D-dimer levels concurrent with hs-CRP levels were likely to be lower after treatments in majority of patients with acceptable clinical prognosis [40]. Moreover, in contrast to our study, no significant difference in the mean levels of D-dimer of survivors and non-survivors neither on day 1 nor on day 7 of hospitalization was detected in a retrospective cohort study [32] which is described earlier. They showed that mean levels of this factor was related to a raised need for critical care on day 7. Although there was not any significant association between D-dimer levels at admission and mortality odds due to COVID-19, increased level of this biomarker (higher than 501 ng/ml) was shown to be related to a decreased mortality odds on and day 7 of hospitalization compared to the patients with D-dimer levels < 500 ng/ml (OR = 11.9; 95% CI = 1.2–109.9) [32].
The available evidence provided an extensive account of a relationship between pre-existing CVDs, the common comorbid disorders with COVID-19, and SARS-CoV-2 pathology. It has been found that even asymptomatic or mildly symptomatic COVID-19 subjects may manifest cardiovascular abnormalities including myocardial inflammation, hyperthrombosis, and hypercoagulation, even after recuperation from the infection [41, 42]. On the other hand, hypercoagulation may contribute to the pathogenesis of severe COVID-19 infection progression, probably due to persistently raised production of pro-inflammatory cytokines release following virus invasion. Besides, increased secretion of pro-inflammatory factors may raise the expression of tissue factor (TF) on the endothelial cells and monocytes, leading to stimulating a procoagulant activity. Additionally, thrombosis of the pulmonary vasculature might also occur because of the severe hypoxia as a certain stimulant of coagulation associated with an elevated risk of VTE. Hence, as a biomarker for coagulation, probably thrombosis, and pulmonary thromboembolism, D-dimer levels were widely investigated related to COVID-19 mortality risk [35, 36, 40, 43, 44]. Thus, as shown in our study, elevated D-dimer and CRP levels may serve as indicators of a severe pro-inflammatory state accompanied by a secondary hypercoagulation in COVID-19 cases [35, 36, 40, 43, 44].
Like the present findings, a retrospective, observational cohort study on 3988 COVID-19 critically ill patients admitted to ICU reported that those who had hypercholesterolemia were at a higher risk of death due to viral infection normocholesterolemic patients (HR = 1.25; 95% CI = 1.02–1.52) [45]. Our current findings, which demonstrate serum levels of TC and TG could be robust predictors of COVID-19-related death, are partly in line with several previous researches [45, 46]. However, the negative association between serum LDL and COVID-19 fatality risk somewhat contradicted the earlier findings [46–49]. We failed to detect any significant relationship between serum HDL levels and COVID-19-related death risk, which refuted previous results that highlighted a protective role for this factor against COVID-19 mortality risk or severity [49, 50]. Partly in contrast to the present results, through a retrospective analysis, 228 COVID-19 cases were shown to have significantly lower serum concentrations of TG (median = 1.08 vs 1.21 mmol/l), HDL (median = 0.78 vs 1.37 mmol/l), LDL (median = 2.63 vs 2.83 mmol/l), and TC (median = 3.76 vs 4.65 mmol/l) compared to 1140 healthy age and sex-matched individuals [50]. In a similar way to this article and unlike our findings, mean serum levels of TC (126 mg/dl), LDL (69.5 mg/dl), and HDL (29.9 mg/dl) of 102 COVID-19 cases were reported to be lower than that of the healthy control group (mean levels of TG: 157.7 mg/dl, LDL: 100.6 mg/dl and 41.43 mg/dl, respectively). However, higher mean TG levels observed (155.4 mg/dl) COVID-19 cases in comparison with healthy individuals (115 mg/dl) were partly similar to those obtained in the current research [46]. When the researchers compared COVID-19 cases according to disease severity, the LDL level was lower among critical than non-critical patients (median = 50 mg/dl vs LDL: 69 mg/dl). LDL level less than 48 mg/dl was also suggested to be a risk factor of critical COVID-19 (OR = 2.07; 95% IC = 1.18–3.63); Additionally, nearly similar to our results, this study researchers demonstrated that median TG levels (145 mg/dl) of patients with critical COVID-19 infection were greater than median TG of in no-critical cases (138 mg/dl) [46].
Collectively, the abnormal lipid profile in COVID-19 cases may result from the increased inflammatory responses or “cytokine storm” and its associated immune dysfunction as well as disturbed lipid metabolism due to viral infection. In this regard and considering the role of eicosanoid increment and hypercoagulation in COVID-19 pathogenesis, many recent pieces of research have focused on prescribing omega-3 fatty acids+ aspirin due to the anticoagulant features of these agents and reducing eicosanoids [47, 51]. Moreover, since increased levels of TC, TG, and LDL are notable risk factors of CVDs, including HTN, considering the increased prevalence of these chronic disorders among SARS-CoV-2-infected patients, this issue may further explain the predictive role of these lipid markers in the COVID-19 case fatality. Besides, it has been indicated that tissue cholesterol concentration may contribute to the enhancement of ACE2 localization with viral entry into the cells and hence might affect COVID19 severity [52]. However, due to inconsistencies in literature reports, more well-designed cohort and experimental studies are required to fully determine the effects of lipid profile on COVID-19-related death and its progression [47, 51].
Based on the current findings, we failed to detect any significant association regarding QTc interval or heart size and COVID-19 fatality odds neither in crude nor in multivariable regression. This may be due to the low accuracy of left ventricular size recorded by chest X-ray in diagnosing COVID-19 myocarditis, a condition that has been proven to be accompanied by an increased risk of mortality due to this viral infection [53, 54]. Therefore, according to the present results, it can be hypothesized that the estimation of heart size using a chest X-ray may not be a reliable way for COVID-19-associated myocarditis and mortality risk assessment. Hence, other imaging modalities, including echocardiography and cardiac magnetic resonance (CMR), could be recommended. However, it should be noted that only 46 patients in case group and 64 patients in control group had PA chest X-ray results. Thus, due to the lack of data on heart size for majority of included patients, these results should be interpreted with caution. 
Based on the present results, the prevalence of elevated BMI and obesity, HTN, and diabetes, in addition to coronary artery diseases, were likely to be higher among non-survived compared to survived patients. These findings corroborate the previous reports highlighting these chronic diseases as risk factors for COVID-19 severity or death [11, 12, 16, 21, 24–26, 42]. Considering the strong relationship between comorbidities and COVID-19 high mortality rate, tissue damage, and functional status of different organs, patients’ past medical history should be tightly controlled in these patients. Hence the clinical data related to comorbidities must be considered in drafting the treatment and monitoring guidelines of COVID-19 subjects [1, 5].
The present study was subject to a few limitations that should be mentioned. First, the study’s cross-sectional design might increase the risk of bias in data collection and impose some limits. Moreover, since the non-survived group included only subjects who died in a hospital, whereas at-home deaths that may occur following a long time after discharge were not considered in the analysis, the conclusions drew by the study should be interpreted with caution. Therefore, although the present findings are still useful as evidence for the factors related to mortality risk due to this novel coronavirus, large cohort studies will be needed to confirm the current findings.
In conclusion, the present findings demonstrated that higher levels of the inflammatory marker, CRP,  blood sugar, D-dimer, and lipid markers’ levels except for HDL level were likely to be independent predictive factors of COVID-19-related mortality odds regardless of the patient’s age, sex, length of hospitalization, and BMI. Also, obesity increased the odds of mortality due to this novel coronavirus. Furthermore, patients who died due to COVID-19 infection had a higher history of chronic disorders, remarkably HTN, diabetes, and coronary artery disease than survived patients. These findings are a source of concern and highlight the need for precise evaluation of BMI, and serum biomarkers, including CRP, FBS, D-dimer, TC, TG, and LDL at triage and monitoring during hospitalization. Assessment of these factors could also be beneficial in the early detection of the most vulnerable patients who are at the highest risk of COVID-19 death, assigning the available limited care resources to them, and planning the most suitable treatment strategy.
Therefore, clinicians and health care providers should consider obesity and cardiovascular risk factors as serious risk factors for COVID-19 severe outcomes. Hence, these patients should receive careful observation, an appropriate therapeutic approach, and tight monitoring. Also, a healthy dietary strategy with regular physical activity may assist the patients to get proper therapeutic responses faster as these approaches attenuate pro-inflammatory state and modify the immune function, thus protect against viral infection progression and even reinforcement of response to vaccine administration.
However, extensive prospective cohort studies are required to validate the prognostic values of the present detected risk factors of COVID-19 death.",Ir J Med Sci
PMC7809241,Does instillation of lidocaine gel following flexible cystoscopy decrease the severity of post procedure symptoms? A randomised controlled trial assessing the efficacy of lidocaine gel post flexible cystoscopy,"Flexible cystoscopy is one of the most important diagnostic tools available to the urologist. The technique of using a flexible fibre optic camera to visualise bladder mucosa was first described by Harry Wilbur in 1981, using a pre-existing choledochoscope [1]. The first dedicated flexible cystoscope was presented by Clare Fowler in Dublin, at the 1984 BAUS Annual Scientific Meeting at the Royal College of Surgeons in Ireland [1]. Since then, flexible cystoscopy has become the gold-standard first-line investigation in detecting bladder cancer and is one of the most commonly performed urological procedures [2]. Flexible cystoscopy is usually performed in the ambulatory setting using topical local anaesthetic lubricating gel and takes only a matter of minutes to perform. It represents a cheaper, faster, more readily available alternative to rigid cystoscopy and eliminates the need for admission to hospital and a general anaesthetic.
Despite the well-described advantages of flexible cystoscopy, it has some limitations also, with patients often experiencing troublesome post-procedural sequelae. Common symptoms after flexible cystoscopy include dysuria, urgency and frequency of urination, haematuria and suprapubic pain [3]. A recent survey highlighted the reduction of pain associated with flexible cystoscopy as a research priority for patients [4].
The use of primitive urethral lubricants such as olive oil has been reported for centuries, and the addition of local anaesthetic agents to improve tolerability of flexible cystoscopy has been debated for well over 100 years. Cocaine was the first product used for urethral anaesthesia in 1884 [5]. Since then, silicone, tetracaine, dyclonine, tripelennamine and most recently lidocaine have been used for this purpose [6]. There remains no consensus still on optimum agent, dwell time, quantity and instillation rate, and the product used various widely between different institutions [7].
Lidocaine gel is commonly administered as a lubricant prior to flexible cystoscopy due to its well-recognised anaesthetic and antiseptic properties. Despite its widespread acceptance and use amongst the urological community, numerous trials have failed to show that lidocaine gel is significantly better at reducing the symptoms experienced following cystoscopy than other lubricants which do not contain anaesthetic [8–13]. Indeed, three meta-analyses identified in a search of the literature on the topic have yielded conflicting results as to the benefit of using lidocaine gel for flexible cystoscopy [8, 9, 14]. The era of evidence-based medicine has seen a migration away from simply doing things because they have been done previously towards performing interventions that are proven to be of benefit for patients.
Although lidocaine gel has a low side effect profile and is generally well tolerated, should we be routinely using it for urethral anaesthesia without good evidence to support its use? Should we be searching for novel methods to improve tolerability of flexible cystoscopy? Or, should we look to use this well-known anaesthetic in a more effective way?
We hypothesise that inadequate urethral dwell time and dilution of lidocaine gel by the irrigation fluid during flexible cystoscopy limits its anaesthetic efficacy, and that it may be more beneficial to administer the gel after the person has emptied their bladder following the procedure. The aim of this study is to investigate whether administration of lidocaine gel both before and after flexible cystoscopy can reduce post procedure symptoms.
This was a prospective randomised controlled trial. Ethical approval was obtained from the Tallaght University Hospital/St James Hospital Joint Research and Ethics Committee (2019-01 List 3 (02)). All patients undergoing flexible cystoscopy in Tallaght University Hospital between September and December 2019 were considered for enrolment in the study. Exclusion criteria included the presence of microbiological evidence of urinary tract infection on urinalysis, intellectual disability and the presence of an indwelling urethral catheter.
Patients were given a patient information leaflet explaining the purpose of the study and an information booklet explaining the procedure to read in the waiting room. Patients who agreed to take part in the trial were then counselled and consented by the doctor performing the procedure, and a written consent form was included in the patient’s chart.
Patients were randomised into 2 groups using a simple computerised randomisation tool. The treatment arm received intra-urethral lidocaine gel pre and post flexible cystoscopy. The control arm received intra-urethral lidocaine gel pre flexible cystoscopy only. The control arm represents current accepted practice in our institution. The lubricating gel used in all subjects was a pre-loaded syringe (11 ml men, 6 ml women) containing 2% lidocaine and 0.05% chlorhexidine. The external genitalia were sterilised using a chlorhexidine-based solution, and warm saline was used for irrigation. A 15.5-fr flexible cystoscope was used in all procedures. Flexible cystoscopies in the trial were performed by 5 urology trainees and 1 consultant urologist. All operators had significant experience in performing flexible cystoscopy before the trial commenced.
All patients had pre-procedural 2% lidocaine gel inserted urethrally in the same fashion: slow steady push with milking of the gel down the male urethra. Urethral dwell time prior to commencement of cystoscopy was 30 s, with pinching of the urethral meatus to retain the gel. Following the procedure, both study arms were instructed to empty their bladder. The treatment arm were instructed to return to the examination table following bladder emptying where they had 2% lidocaine gel inserted again in the same fashion as before the procedure. Patients were given wound pads to prevent soiling of undergarments after leaving the cystoscopy suite.
All participants completed validated symptom and quality of life questionnaires prior to cystoscopy, on day 2 and day 7 post cystoscopy (Fig. 1). The 14-point UTISA questionnaire assessed 7 of the most common symptoms experienced by patients following flexible cystoscopy in terms of severity and bothersomeness. Symptoms assessed were frequency of urination, urinary urgency, dysuria, haematuria, suprapubic discomfort, low back pain and incomplete bladder emptying. Each symptom was evaluated using a Likert-type response scale. The severity response options were ‘did not have’, ‘mild’, ‘moderate’ and ‘severe’ (scored 0-3), and the bothersome response options were ‘not at all’, ‘a little’, ‘moderately’ and ‘a lot’(scored 0–3) [15].
A data collection sheet was completed by the performing urologist following cystoscopy, noting patient demographics, study arm, findings at cystoscopy, first cystoscopy or repeat procedure and whether and intervention was performed, e.g. removal of ureteric stent.
A symptom questionnaire was given to participants in the two groups at baseline, and also 2 and 7 days after the flexible cystoscopy. The severity and bothersomeness of 7 symptoms were measured, namely, frequency, urgency, dysuria, incomplete bladder emptying, supra-pubic tenderness, low back pain and haematuria, using a series of questions each with 4 categories, coded as below (severity/bothersomeness):0: Did not have the symptom/Not at all1: Mild/A little2: Moderate/Moderately3: Severe/A lot
A series of Mann-Whitney’s tests were performed to assess any differences in the distribution of the responses at each time point (baseline, 2 days and 7 days after the flexible cystoscopy) between the two groups. As a result, 3 tests were carried out for each symptom. Therefore, a new threshold was calculated using a Bonferroni correction, by dividing the initial significance level of 5% (0.05) by 3, yielding a threshold of 0.017; hence, any p value < 0.017 was considered significant. However, no significant difference was found between the treatment group and control group as the p values were mostly quite large. The results for symptoms severity are shown on Table 2, and for symptoms bothersome on Table 3.
An overall symptoms variable was also measured, though no significant difference was found in the distribution of responses between the groups at baseline, 2 or 7 days after the flexible cystoscopy with p values of 0.423, 0.651 and 0.735 respectively.
As mentioned, our lubricating gel contained 2% lidocaine and 0.05% chlorhexidine. A study by Jayathillake et al. suggests that chlorhexidine directly contributes to urinary urgency and dysuria flowing cystoscopy. Chlorhexidine precipitates in salt-based solutions such as saline which is commonly used for irrigation during flexible cystoscopy. Furthermore, intact mucosal membranes may be penetrated by chlorhexidine directly causing irritation [26, 27]. Alarmingly, there has been reports of anaphylactic shock following intra-urethral instillation of gel containing chlorhexidine [28]. Without strong evidence supporting its role in prevention of urinary tract infection post flexible cystoscopy and the potential for directly causing urinary symptoms and possibly life threatening adverse drug events, does this represent safe practice?
We did not use penile clamps in our study to ensure lidocaine gel was retained within the urethra due to implications for patient convenience and time constraints of cystoscopy lists. There is potential that the gel leaked out of the urethra before it could be absorbed.
Two studies have shown that the most painful part of flexible cystoscopy is when the cystoscope initially passes through the contracted external sphincter in the membranous urethra [12, 29]. This is potentially due to the abundance of afferent nerves in this area. Song et al. identified that the dorsal nerve of the penis and the terminal branch of the pudendal nerve innervate the membranous urethra in 53.3% of male cadavers [30]. Thus, a potentially more effective intervention would be to alter the site local anaesthetic is given perhaps in the form of a dorsal penile block.
Our initial study results suggest that post-operative lidocaine gel does not limit the exacerbation of urinary symptoms following flexible cystoscopy; however, our preliminary results are not powered to detect a small effect. Further assessment with a larger sample size is warranted to determine conclusively whether no benefit is gained from instillation of urethral local anaesthetic following flexible cystoscopy. However, currently, we do not recommend change of practise based on our results.",Ir J Med Sci
PMC7698656,Effect of SARS-CoV-2 coinfection was not apparent on the dynamics of chronic hepatitis B infection,"Elevated aminotransferases and bilirubin were common in COVID-19 patients (Hao et al., 2020; Fu et al., 2020) and typical characteristics of patients with chronic hepatitis B(CHB). In patients coinfected with SARS-CoV-2 and HBV, Zou et al. reported a proportion of 27.62% with elevated liver function tests (Zou et al., 2020), which were similar to SARS-CoV-2 infection alone (Huang et al., 2020). However, these reports failed to focus on the direct interactions between SARS-CoV-2 and HBV coinfection. Especially, to what degree the viral kinetics, immune response, or natural history of the two viruses and their impact on disease progression would be influenced remained unknown.
Sixty-seven COVID-19 patients from our previous prospective cohort (Tan et al., 2020) were enrolled in this study. According to the status of HBsAg, they were classified as HBsAg + group (n = 7) and HBsAg- group (n = 60). COVID-19 was confirmed by real-time PCR assay. Clinical and laboratory data were collected on day 1, 4, 7, 14, 18, 21, 28, if available, after admission and at discharge. All 7 HBsAg + COVID-19 patients had reported chronic HBV infection (anti-virus treatment-free) for more than 20 years with normal liver function tests always, except that patient 37 developed HBV-related decompensation liver cirrhosis 3 years ago.
The basic characteristics were described in Table S1. Briefly, there were 3 males and 4 females enrolled, including 1 critical case, 3 severe cases, and 3 mild/moderate cases, with the median age of 57 yrs (39–70). In the HBsAg + group, 6 of them were HBeAg-negative chronic infection based on EASL recommendation (6) and 1 of them were HBV-related cirrhosis There were no significant differences in demographic and epidemiological characteristics between the two groups, except median CRP levels. But there was no difference in the rate of patients with CRP elevation. Besides, there were no significant differences in the clinical severities, duration of hospitalization, incubation periods, and treatment response, either. At admission, levels of alanine transaminase (ALT) in 17 (25.4%) cases were over 50IU/L, while 28.4% had a TBil level over 17.1 μmol/L. However, no significant difference was detected between patients with HBsAg positive and negative (Table S1). At discharge, levels of ALT and TBil decreased to 32.3 ± 21.9U/L and 13.3 ± 6.7 μmol/L, but there were still about 15% of patients with abnormal liver indices. Likewise, there was no difference in clinical indices between the two groups at discharge (Table S2). Extreme values (peak or trough values) of each index were also compared, but no significant differences were detected (Table S3).
HBV-related markers were measured at both admission and discharge, but there were no significant differences in all markers, including HBsAg, HBsAb, HBeAg, HBeAb, HBcAb, and HBV-DNA (Table S4) at the beginning of and after recovery from COVID-19 for chronic hepatitis B (CHB) cases. Apart from that, sequential serum levels of HBV- and SARS-CoV-2-related parameters along with hepatic enzyme markers were analyzed in each of the 7 patients (Fig. 1
). Firstly, there were no obvious changes in the serum level of HBsAg/Ab, HBeAg/Ab, or HBV-DNA viral load been observed during the course of acute SARS-CoV-2 infection and/or the anti-nucleocapsid protein (NP) antibody development in these 7 patients. Secondly, serum levels of ALT and TBil in CHB patients did not change before and after hospitalization either. Particularly, patient 53 presented a liver injury since day 18, which was considered just as the side-effect of lopinavir/ritonavir (LPV/RTV), and ALT decreased to normal after LPV/RTV withdrawal. Patient 37 had an abnormal serum TBil level, which we thought was attributed to HBV-related decompensated liver cirrhosis for more than 3 years. Thirdly, our results showed that the administration of antiviral drugs, like LPV/RTV, arbidol, and interferon-α 1b, which were prescribed by clinicians attempting to inhibit SARS-CoV-2 in the initial stage, seemed to have no affection on the replication of HBV. The other way round, the pre-existing HBV in the host body seemed to have no effect on COVID-19 progression, anti-NP antibody development, the intensity of anti-NP response, and even the liver injury after acute SARS-CoV-2 infection (Table 1
). All 67 patients were discharged from the hospital with recovery.
In this study, we reported the sequential levels of HBV-related markers during the acute infection of SARS-CoV-2. Previous studies on patients coinfected with SARS-CoV-2 and HBV have shown that the existence of coinfection could not aggravate the liver injury or extend the duration of hospitalization compared with HBV infection alone (Chen et al., 2020; Liu et al., 2020). However, these studies failed to depict levels of all HBV-related markers during the infection and clearance of SARS-CoV-2 infection. In this study, although just 7 cases were enrolled, we described the intact dynamics of these markers, indicating that SARS-CoV-2 infection had a limited influence on HBV-DNA replication or the natural history of HBV infection. Firstly, the quantitative levels of HBsAg/Ab, HBeAg/Ab, and HBV-DNA did not extensively fluctuate during the infection or clearance of SARS-CoV-2, suggesting that SARS-CoV-2 had no impact on HBV kinetics. Secondly, the coinfection of SARS-CoV-2 did not trigger the reactivation or the seroconversion of chronic hepatitis B, which is also reported in Rodríguez-Tajes S et al.’s study (Rodríguez-Tajes Sergio et al., 2020). Consequently, SARS-CoV-2 infection would not be the source of HBV reactivation in these individuals. On the other hand, the existence of HBV did not influence SARS-CoV-2, either. Virologically, coinfection with HBV did not extend the viral shedding cycle or incubation periods of SARS-CoV-2 infection. Clinically, the coinfection of HBV did not increase the severity of diseases or duration of hospitalization. At discharge, no significant differences could be detected between the two groups in disease recovery, either. Besides, it has been reported that HBV antiviral therapy had a limited effect on COVID-19 incidence and outcomes (Sabela et al., 2020). From both sides, we discussed the interactions between HBV and SARS-CoV-2 infection.
Apparently, hepatic impairment could be detected in some COVID-19 patients. But we thought it was more likely to be the consequence of illness severity, rather than the direct cytotoxic effect of SARS-CoV-2 on the liver. Consistent with our conclusions, previous larger sample studies also found that there was no significant difference in liver enzymes between coinfection and HBV infection alone (7,8). The elevations of the liver enzyme in COVID-19 patients could also happen in many respiratory viruses infection, which might be related to immune interactions involving systematic cytokine storms (Adams and Hubscher, 2006). Apart from that, sarcolysis during acute viral infection (Wang and Medzhitov, 2019) and drug-induced liver injury (Marta et al., 2020) could also explain the elevation of liver enzymes.
However, it's undeniable that this is a preliminary study enrolling just 7 patients coinfected with SARS-CoV-2 and HBV in a single center. Although detailed patients' information was collected, retrospective design restricted the further analysis. For example, only 1 out of 7 patients had a history of liver cirrhosis, and COVID-19 is reported to be associated with liver function deterioration and elevated mortality in patients with cirrhosis and COVID-19 (Massimo et al., 2020). As a result, we could hardly know whether coinfection had a different story in patients with liver cirrhosis in our study. Consequently, further large-scale studies should be conducted to reveal the exact interactions between SARS-CoV-2 and HBV coinfection.
Above all, our study suggested that the effects of SARS-CoV-2 on the dynamics of chronic HBV infection seemed not apparent. SARS-CoV-2 infection would not be the source of HBV reactivation in these individuals. More attention should be paid to viral control, immune modulation, and reasonable medication in the therapy of patients coinfected with HBV and SARS-CoV-2.
GD, WT, YC; Acquisition of data: ST, YD, YL, JZ, ZT, XH, XX, YZ, YG, WT, YC; Statistical analysis: WT; Interpretation of data: RY, WT, GD; Drafting and critical revision of manuscript: RY, WT, GD. All authors checked and approved the final draft of the letter.
Wenting Tan, Ph.D., Yaokai Chen, Ph.D., and Guohong Deng, Ph.D.
This work is supported by 10.13039/100009437PLA Youth Talent Project 17QNP010, Chongqing Health Commission COVID-19 Project 2020NCPZX01, 10.13039/501100007055TMMU project 2020-2017-033, and the Chinese State Key Project Specialized for Infectious Diseases (2018ZX10302206). And we appreciate the supports of the 10.13039/501100000691Academy of Medical Sciences Newton International Fellowship (Tan W).

Potential competing interest: None to report.",Virology
PMC7758734,Auswirkungen von COVID-19 auf die männliche Fertilität,"Zu Beginn der Pandemie wurde über den Nachweis von SARS-CoV-2 in menschlichem Sperma bei sechs von 38 untersuchten COVID-19-Patienten in China berichtet [9]. Diese Publikation wurde inzwischen aber wegen methodischer Mängel und entsprechender Zweifel an den Ergebnissen wieder zurückgezogen, sodass auch die darauf basierenden Empfehlungen und Interpretationen kritisch hinterfragt werden müssen. 
In folgenden Studien gelang es nicht mehr, SARS-CoV-2-RNA in menschlichem Sperma nachzuweisen. Das gilt insbesondere für Männer, die sich gerade im Anschluss an eine COVID-19-Erkrankung erholen: Bei 34 Patienten konnte innerhalb eines Monats nach Diagnose von COVD-19 keine Virus-RNA nachgewiesen werden. Bemerkenswert ist aber, dass sechs der 34 Männer über Beschwerden im Bereich der Hoden berichteten, sodass eine Begleitorchitis nicht ausgeschlossen werden kann [10]. Die Spermaqualität wurde in dieser Studie nicht mitberücksichtigt.
Eine etwas differenziertere Auswertung von 74 Männern, die zuvor an COVID-19 erkrankt waren, führte in einer weiteren Studie zu vergleichbaren Ergebnissen; SARS-CoV-2 konnte in keinem der Ejakulate nachgewiesen werden, die von den betroffenen Patienten in bis zu drei Monaten nach Diagnosestellung produziert wurden. Gleiches galt auch für deren Urin und Prostataexprimat [11]. Nur einer der Patienten berichtete über Hodenschmerzen; bei ihm konnte durch Kernspintomografie eine Orchitis diagnostiziert werden. Die Spermaqualität der Männer lag innerhalb der WHO-Referenzwerte; im Vergleich zu gesunden Kontrollen waren die Werte aber niedriger [11]. Dabei zeigte sich keine Assoziation mit der Schwere der Verläufe von COVID-19. Allerdings war die Spermiengesamtzahl bei den Patienten niedriger, die eine längere Erholungsphase nach durchgestandener Erkrankung benötigten. Die Serumwerte für Luteinisierendes Hormon (LH), Follikel-stimulierendes Hormon (FSH) und Testosteron waren unauffällig.
Auch bei Untersuchungen in einem kürzeren Zeitraum (6-17 Tage) nach Diagnosestellung gelang kein Nachweis von SARS-CoV-2-RNA im Sperma [12]. Selbst im akuten Zustand der Infektion (0-7 Tage nach Erstdiagnose) fand sich bei symptomatischen Männern mit positivem Nachweis von SARS-CoV-2 im Nasen-Rachen-Raum keine Virus-RNA im Sperma [13]. Die oben aufgeführten Ergebnisse stehen in Einklang mit anderen Studien [14, 15, 16].
Systemische Virusinfektionen sind als Auslöser testikulärer und/oder epididymaler Entzündungsreaktionen mit entsprechenden Auswirkungen auf die Fertilität bis hin zu einer persistierenden Azoospermie bekannt [17]. Auch Infektionen mit SARS-CoV-2 können offensichtlich zu Orchitiden oder Beschwerden, die diese Diagnose nahelegen, führen [10, 11].
In einem Fallbericht wurde eine bilaterale Orchitis bei einem 37-jährigen Mann als wesentliches Symptom einer COVID-19-Erkrankung beschrieben [18]. Autopsiepräparate von Hoden und Nebenhoden von Patienten, die in Folge von COVID-19 verstorben waren, zeigten ein interstitielles Ödem, Verschmälerung des Keimepithels mit Abschilferung von Spermatogenesezellen und vermehrte Durchblutung mit Exsudation von Erythrozyten [19]. In derselben Studie wurde auch die Spermaqualität von 23 Männern mit COVD-19 untersucht. Hierbei fand sich bei neun Patienten (39,1 %) eine Oligozoospermie mit Spermienzahlen unter 15 × 10/ml und bei 14 Patienten (60,9 %) eine erhöhte Zahl Peroxidase-positiver Zellen im Ejakulat.
Mildere Verläufe einer Infektion mit SARS-CoV-2 scheinen geringeren Einfluss auf die Spermaqualität zu haben als schwerer verlaufende Erkrankungen [14]. Fieber als Begleitsymptom wirkt sich erwartungsgemäß zusätzlich auf die Spermatogenese aus [5]. Auch eine längere Rekonvaleszenzzeit nach der Infektion scheint mit einer geringeren Spermiengesamtzahl assoziiert zu sein [11]. Die bisherigen Studien sind aber in ihrer Aussagekraft limitiert, da die Fallzahlen gering sind und die Nachbeobachtungszeit noch kurz ist. Auch wurden in den Studien nicht mehrere Spermiogramme pro Patient untersucht, um intraindividuelle Schwankungen zu erfassen. Vergleichsspermiogramme vor Beginn der Erkrankung liegen nur in Einzelfällen vor und zeigen, dass die Spermaqualität teilweise schon zuvor eingeschränkt war [20].
Der bisher fehlende eindeutige Nachweis von SARS-CoV-2 in Spermaproben von infizierten oder genesenden Männern zu verschiedenen Zeitpunkten nach Diagnosestellung hat Relevanz für die Kryospermakonservierung unter den Bedingungen der derzeitigen Pandemie.
Bei Tumorpatienten werden vor der Kryospermakonservierung eine klinische Untersuchung auf Symptome einer Infektion mit SARS-CoV-2, eine sorgfältige Kontaktanamnese und Untersuchung des Spermas auf einen eventuellen Nachweis des Virus empfohlen [21]. Die Society for Male Reproduction and Urology (SMRU), eine Gruppierung der American Society for Reproductive Medicine (ASRM), führt in ihrer Stellungnahme aus, dass eine Kryospermakonservierung bei Männern mit Tumorerkrankungen auch unter den Bedingungen der Pandemie indiziert ist und durchgeführt werden kann [22].
Nur wenige Studien haben bisher den Einfluss einer Infektion mit SARS-CoV-2 auf die Hypothalamus-Hypophysen-Gonadenachse beziehungsweise Leydigzellfunktionen untersucht. Die Fallzahlen sind noch gering und zeigen teilweise keine Effekte [11].
In einer Untersuchung mit 119 Männern zwischen 20 und 49 Jahren mit unterschiedlich stark ausgeprägter COVID-19-Erkrankung fand sich allerdings ein im Vergleich zur gesunden Gruppe signifikant erhöhter LH-Wert, der auf eine gestörte Leydigzellfunktion hindeutet. Testosteron und FSH zeigten keine signifikanten Unterschiede [20]. Die eingeschränkte Leydigzellfunktion steht wahrscheinlich mit der systemischen Entzündung in Zusammenhang, da das Verhältnis Testosteron/LH negativ mit C-reaktivem Protein (CRP) und Leukozyten im Blut assoziiert war.
Die Erhöhung des LH-Wertes bei COVID-19-Patienten konnte in anderen Untersuchungen nicht bestätigt werden. Unterschiede zeigten sich auch nicht, wenn Männer nach der Zeitdauer des Nachweises von SARS-CoV-2 und der Schwere der Erkrankung gesondert ausgewertet wurden [23]. 
Besonderes Augenmerk muss auf den Zusammenhang zwischen Testosteron und dem Verlauf von COVID-19 gerichtet werden [24]. Die Mortalität von Männern bei dieser Infektion ist größer als bei Frauen [25]. Möglicherweise ist dies darauf zurückzuführen, dass die an der Infektion der Pneumozyten beteiligten ACE-2-Rezeptoren und die transmembrane Serinprotease 2 beziehungsweise deren Funktionen unter dem Einfluss von Androgenen stehen [26].
Untersuchungen zum Zusammenhang zwischen einer COVID-19-Erkrankung und Fertilität des Mannes beruhen noch auf kleinen Fallzahlen und kurzen Beobachtungszeiträumen. Die Interpretation der verfügbaren Daten muss daher unter Vorbehalt gesehen werden.
Bisher konnte das Virus nicht zweifelsfrei in menschlichem Sperma nachgewiesen werden. Es ist aber nicht ausgeschlossen, dass eine Infektion mit SARS-CoV-2 die Spermaqualität beeinträchtigen kann. Männliche Tumorpatienten sollten dennoch auch während der Pandemie mit SARS-CoV-2 die Möglichkeit zur Kryospermakonservierung wahrnehmen.
Neben unspezifischen Effekten der Infektion sind direkte Auswirkungen von SARS-CoV-2 wie testikuläre Entzündungsreaktionen als Ursache von Spermatogenese-Störungen möglich. Untersuchungen der Hormonspiegel deuten auf eine Beeinträchtigung der Leydigzell-Funktion im Rahmen einer COVID-19-Erkrankung hin.",Uro-News
PMC7808882,High-Density Lipoproteins and Serum Amyloid A (SAA),"Serum amyloid A (SAA) comprises a family of low molecular weight proteins (104–112 amino acid residues) first described almost 50 years ago (for a recent comprehensive review, see [1]). SAA was identified as the circulating protein that forms amyloid deposits in tissues of certain individuals suffering from chronic or recurrent inflammation [2, 3]. Although a rare disorder, secondary amyloidosis can cause severe clinical complications, such as kidney failure. While its physiological function(s) remain an enigma, SAA is remarkably conserved through millions of years of evolution, suggesting it plays an important role in primordial host defense. The human genome encodes two acute phase SAA proteins, SAA1 and SAA2, which are 96% homologous over their entire length and correspond to mouse SAA1.1 and SAA2.1. Mice encode a third conserved acute phase SAA gene, Saa3. Saa3 is generally thought to be a pseudogene in humans due to an early stop codon [4]. In addition to the acute phase isoforms, humans and mice also encode another gene family member, Saa4. This isoform contains an insertion of 8 amino acids between residues 69 and 70 of SAA1/SAA1.1 and SAA2/SAA2.1. While the SAA4 protein is expressed in the liver at low levels and is not induced during inflammation, it likely comprises the major SAA isoform in the circulation under basal conditions [5, 6]. The constitutive SAAs are generally understudied members of the gene family and will not be covered in this review, which focuses on liver-derived acute phase SAAs.
In both humans and mice, the acute phase SAAs are transcriptionally regulated in hepatocytes by a variety of inflammatory cytokines including tumor necrosis factor-α, interleukin-1β, interleukin-6, and interferon-γ, which are all likely produced by macrophages during an acute inflammatory response (reviewed in [7]). SAA can transiently increase > 1000-fold in the circulation and, as such, is considered one of the most highly induced acute phase reactants in vertebrates. Indeed, it has been estimated that SAA represents ~2.5% of total hepatic protein synthesized in mice during endotoxemic shock [8]. There is also evidence that hepatic SAA production may be regulated through posttranscriptional mechanisms [9, 10]. Notably, SAA appears to be not only a key soluble mediator in the acute phase response but also likely plays a role in a negative feedback loop that serves to shut down inflammation [11].
Given its profound induction and evolutionary conservation, acute phase SAAs likely play a key role in survival during traumatic injury or acute infection. Circulating SAA is also known to be persistently elevated, albeit at lower levels, in individuals with chronic inflammation. This “inappropriate” expression of SAA has been associated with increased risk or poor prognosis for numerous chronic diseases, including atherosclerotic cardiovascular disease and cancer [12, 13]. Whether SAA plays a direct role in the pathogenesis of these chronic diseases, or is merely a marker of increased risk, has been the topic of intense investigations over the past several decades. One obstacle has been the lack of knockout mice deficient in all three acute phase SAAs. The development of SAA-deficient mice was challenging, due to the length of the gene cluster encoding the three acute phase SAAs (~45 kb) on mouse chromosome 7 [14], which made it difficult to target all three genes simultaneously by conventional homologous recombination approaches. With the advent of CRISPR-Cas9 technology, mice deficient in SAA1.1, SAA2.1, and SAA3 have recently been generated [15, 16••].
It is well-recognized that elevated SAA is associated with increased risk for atherosclerosis in humans [17•]. In some reports, plasma SAA levels were a better predictor of future cardiovascular events than the widely used clinical biomarker of inflammation, hsCRP [18–20]. It has recently been suggested that SAA contributes to atherosclerosis and its complications at least in part through its prothrombotic effects [21•]. Several gain-of-function studies in mice using viral vector-mediated SAA overexpression demonstrated that SAA contributes to atherosclerotic processes and is not merely a biomarker reflecting the burden of the disease [22, 23]. Paradoxically, an early study by our group investigating the role of endogenous SAA in atherosclerotic lipid deposition showed no reduction in APOE−/− mice that were deficient in SAA1.1 and SAA2.1 compared to control APOE−/− mice [24]. However, in a follow-up study, we determined that suppression of SAA3 expression in APOE−/− mice lacking SAA1.1 and SAA2.1 had significantly reduced atherosclerosis compared to APOE−/− mice expressing all three SAAs [15], highlighting that SAA1.1, SAA2.1, and SAA3 likely play redundant roles in atherogenesis and that deficiency/suppression of all three acute phase isoforms is necessary to reduce atherosclerosis in mice. On the other hand, our group has shown that deficiency of SAA1.1 and SAA2.1 is sufficient to protect APOE−/− mice from angiotensin II-induced abdominal aortic aneurysms [25]. Taken together, human epidemiological data and results from genetically altered mice support a causal role for SAA in cardiovascular disease, although the precise mechanisms remain unclear.
While dozens of publications spanning more than three decades report an association between circulating SAA levels and a spectrum of neoplastic diseases in humans, direct evidence that SAA promotes tumorigenic processes has been limited. A number of years ago, Sung et al. reported that forced overexpression of SAA in Lewis lung carcinoma cells increases the cells’ capacity to colonize the lung and form tumors in mice, indicating that SAA may be a tumor-intrinsic factor that promotes tumor cell metastasis [26]. A more recent study by Beatty and colleagues demonstrated for the first time that inflammatory responses mounted by hepatocytes are critical for the establishment of a metastatic niche in the liver, with SAA playing a key role [27••]. In a mouse model of pancreatic ductal adenocarcinoma, the authors showed that pancreatic tumors activate IL-6/STAT3 signaling in hepatocytes, leading to the induction of SAA, which in turn orchestrates local changes in the inflammatory and extracellular matrix milieu that supports tumor cell spread to the liver. Thus, current data suggest that targeting SAA may provide a novel strategy for preventing tumor metastasis to the liver.
In the blood, the vast majority (~95%) of liver-derived SAA is typically found associated with the high-density lipoprotein (HDL) fraction [28, 29, 30••]. During a severe inflammatory response, SAA can become the major apolipoprotein on HDL [31]. The SAA monomer is predicted to comprise four α helices arranged in a cone-shaped array [32], with helices 1 and 3 containing both hydrophobic and hydrophilic faces. According to one model, SAA assumes a topology that allows it to act as a “hub” in macromolecular interactions by associating with the lipid surface of the HDL particle as well as cellular receptors and extracellular components [33]. Extensive research has focused on whether the presence of SAA impacts HDL function during inflammation. Of particular interest is whether SAA alters HDL’s ability to mediate reverse cholesterol transport (RCT), the pathway by which excess cholesterol in peripheral tissues is delivered to the liver for excretion in bile and feces, and a major mechanism by which HDL is thought to be cardioprotective. Over the years, results from studies investigating the impact of SAA on HDL-mediated RCT have been conflicting. In a number of studies, SAA, either associated with HDL or in a lipid-free form, was reported to promote cellular cholesterol efflux through both ABCA1-dependent and ABCA1-independent mechanisms [34–37]. On the other hand, HDL isolated from human subjects undergoing acute sepsis [38] or experimental endotoxemia [39] showed a reduced capacity to promote cholesterol efflux, suggesting that SAA may impede RCT. According to several reports, fecal excretion of macrophage-derived cholesterol is reduced during inflammation in mice [38–40]. However, our studies in SAA-deficient mice suggest that this impairment of macrophage-to-feces RCT during inflammation is not dependent on SAA [40].
It has been suggested that SAA reduces the anti-inflammatory and antioxidative properties of HDL and thus renders HDL dysfunctional [41, 42•, 43•]. The extent to which an impairment in the anti-inflammatory or antioxidant activity of HDL contributes to chronic inflammatory disease is not clear; however, it is notable that HDL contributes only a minor portion (1–2%) of the total antioxidant capacity of plasma [44]. Although the antioxidative capacity of HDL has been shown to be reduced in a number of disease states (reviewed in [45]), it does not appear that SAA plays a direct role in this impairment. Jayaraman et al. [46] demonstrated that SAA enrichment of HDL actually impedes lipoprotein oxidation and that mild oxidation of SAA-enriched HDL leads to the release of SAA that exhibits antioxidant effects. This study, together with the work of Sato et al. [47], indicates that SAA does not produce a prooxidant effect on lipoproteins and may have antioxidant effects. Further support for an antioxidant effect of SAA is provided by a population study indicating that HDLs from patients with higher SAA levels exhibit enhanced antioxidant activity compared to controls [48]. In summary, while it has been extensively documented through the use of a variety of in vitro assays that HDL function is impaired in inflammation, a role for SAA in mediating HDL dysfunction in vivo is not well substantiated. Based on current evidence, it seems unlikely that the massive enrichment of HDL with SAA during an acute inflammatory response has evolved for the purpose of altering HDL function. Rather, the association of systemic SAA with HDL likely serves as a mechanism for increasing SAA stability [49•], or as discussed below, dampening SAA’s pro-inflammatory activities in the circulation.
Given the accumulating evidence that SAA plays a causative role in a variety of chronic inflammatory diseases, there is a critical need to understand SAA’s biological functions. As summarized in a recent review [50], SAA has been shown to evoke a variety of activities consistent with its putative role as an innate immune molecule, including cytokine induction, leukocyte chemotaxis, and upregulation of genes involved in the remodeling of the extracellular matrix, including TGF-β and matrix metalloproteinases. These activities have been attributed to signaling through a number of “pattern recognition receptors” (PRRs) including formyl peptide receptor-like 1 (FPRL-1), FPRL-2, TLR2, TLR4, SR-BI, and CD36 [50]. More recently, SAA was shown to stimulate secretion of IL-1β by human and mouse macrophages by activating the NLRP3 inflammasome [51•]. However, it should be noted that many of the reports on SAA’s activities in vitro are unfortunately confounded by the recent recognition that a widely used, commercially available hybrid form of SAA exerts activities not shared by native SAA [52–55]. Thus, results from some earlier studies investigating the pro-inflammatory functions of SAA and its role in innate immunity must be interpreted with caution. Nevertheless, a preponderance of in vitro data supports the conclusion that SAA plays a key role in innate immunity by stimulating multiple inflammatory pathways during acute infection or tissue injury. In the setting of chronic inflammation, SAA may contribute to pathological processes by inappropriately activating inflammatory signaling.
A puzzling aspect of SAA biology is that the robust effects of SAA reported from in vitro studies do not appear to be easily recapitulated in vivo [53, 56]. This paradox is perhaps most clearly demonstrated by the work of Simons and colleagues, who developed transgenic mice with liver-specific, doxycycline-inducible expression of SAA [56]. Interestingly, when treated with doxycline, the transgenic mice failed to mount a systemic inflammatory response, despite a remarkable induction of SAA to plasma levels that correspond to a robust acute phase response (i.e., > 1 mg/ml). On the other hand, Chami et al. reported that administering SAA by i.p. injection produced a prothrombotic and pro-inflammatory phenotype in APOE−/− mice that was accompanied by indices of renal dysfunction [57•]. However, in a subsequent study, the same group demonstrated that SAA’s pathological effects were ameliorated when the injected SAA was supplemented with HDL [58••]. All of these findings raise important questions about the mechanisms that influence SAA activities in vivo. To protect the host from tissue damage under homeostatic conditions, it seems likely there are mechanisms to blunt the inflammatory effects of circulating SAA unless it is present in the appropriate context. Without such mechanisms, profound induction of SAA during a robust acute phase response would be expected to lead to unrestrained tissue damage throughout the body, rather than targeted inflammation at the site of tissue injury or infection. As discussed above, under normal circumstances, virtually all of SAA in plasma is associated with HDL. Moreover, most in vitro studies have examined the effect of lipid-free SAA, not HDL-associated SAA, which may be a limitation since emerging literature indicates that many of the effects attributed to SAA are lost when SAA is HDL-bound [51•, 53, 59, 60]. Thus, the relationship of SAA with HDL must be taken into account when considering SAA’s pathophysiological effects in vivo.
As noted above, recent findings clearly establish that lipid-free and HDL-associated SAA are functionally distinct and highlight the intriguing possibility that processes leading to the association and/or dissociation of SAA with HDL may represent a mechanism for modulating the biological activities of systemic SAA. Until recently, few studies have addressed how the equilibrium between lipid-free and HDL-associated SAA might be regulated. To determine whether SAA incorporates into HDL as HDL is formed, our laboratory recently investigated the lipidation of SAA by primary mouse hepatocytes, the major site of HDL biogenesis [61••]. We determined that SAA is efficiently lipidated by hepatocytes in an ABCA1-dependent manner to form nascent particles that are distinct from apoA-I-containing particles, indicating that SAA is not incorporated into HDL during HDL biogenesis. Our results are in line with earlier studies [36, 62, 63]. The finding that the initial lipidation of SAA does not give rise to particles containing both apoA-I and SAA raises questions as to how SAA associates with apoA-I-containing HDL in vivo. It is known that lipid-free SAA can be incorporated into HDL particles ex vivo, leading to displacement of apoA-I from HDL [63]. Whether lipidated SAA species generated by ABCA1 efficiently incorporate into mature HDL particles in the circulation, and whether this leads to the dissociation of apoA-I, requires further investigation.
While the vast majority of circulating SAA is normally found associated with HDL, a small fraction of lipid-free SAA exists in equilibrium. Factors that modulate this equilibrium and facilitate the liberation of lipid-free SAA might be expected to regulate the bioactivity of circulating SAA. HDL in the circulation is acted on by a number of remodeling factors, including lipases and lipid transfer proteins that alter the lipid and protein composition of the HDL particle. Several of these factors have been shown to destabilize the HDL particle, leading to the release of lipid-poor APOA1 [64–66]. One such factor is cholesteryl ester transfer protein (CETP), which facilitates the exchange of triglycerides on triglyceride-enriched lipoproteins with cholesteryl ester on HDL. We have shown that CETP-mediated remodeling of HDL facilitates the release of lipid-poor SAA from HDL [30••, 67] as well as the transfer of SAA from HDL to apoB-containing lipoproteins [30••]. We further showed that the presence of SAA on apoB-containing lipoproteins was associated with increased binding to vascular proteoglycans. Thus, SAA is an exchangeable HDL apolipoprotein, and factors that enhance SAA exchange may have functional consequences by increasing the amount of bioactive lipid-free SAA and by enhancing the atherogenicity of apoB-containing lipoproteins. Interestingly, SAA has been documented to be on apoB-containing lipoproteins, especially LDL, in human subpopulations known to be at increased risk for cardiovascular disease despite the absence of elevated LDL [68–70].
Additional mechanisms for liberating SAA from HDL have been documented. For example, Gursky and colleagues demonstrated that mild oxidation of SAA-enriched HDL liberates lipid-poor/free SAA [47]. Our group reported that hydrolysis by Group IIa secretory phospholipase A2 also leads to SAA release from HDL [67]. Whether oxidative modification or phospholipase A2 remodeling of SAA-enriched HDL leads to the release of biologically active SAA has not been investigated and may be particularly relevant to the oxidative and lipolytic environment characteristic of atherosclerotic plaques and other sites of tissue injury. Another potential mechanism for liberating HDL-associated SAA in damaged tissue is through interactions with specific components of the extracellular matrix, which is known to occur during amyloid formation [71]. HDL remodeling by phospholipid transfer protein (PLTP) and cholesteryl ester uptake mediated by scavenger receptor B1 (SR-B1) have been documented to generate lipid-poor APOA1 [64–66]. Whether the action of PLTP or SR-BI also leads to the liberation of lipid-poor SAA from HDL has not been reported.
While the liver is the major source of circulating SAA during an acute phase response, SAA is also expressed in many non-hepatic tissues, including the intestine, adipose tissue, kidney, and lung, among others [72]. The lipidation state of locally produced SAA within a tissue microenvironment is not known. One possibility is that SAA in extra-hepatic tissues exists in an oligomeric form and changes in the organization of SAA oligomers influence its bioactivity. This scenario is suggested by the elegant work of Smole et al., who recently investigated the role of SAA in asthma pathogenesis [73••]. The authors provide a model, whereby SAA1 produced by airway epithelial cells is activated through its interaction with dust mite allergen, which triggers the dissociation of biologically inactive SAA1 hexamers, leading to the generation of bioactive SAA capable of stimulating type 2 immune responses. Other recent studies highlight a role for SAA in both homeostatic functions and pathogenic, pro-inflammatory functions, depending on its tissue source. For example, in the gut, ileum epithelial cell-derived SAA1/2 is thought to support barrier integrity by orchestrating homeostatic Th17 cell responses [74]. On the other hand, systemic SAA is also thought to promote pathogenic Th17 programming in models of colitis and experimental autoimmune encephalomyelitis [16••]. Clearly, we are just beginning to appreciate the complex interplay between systemic liver-derived SAA that is induced during an acute phase response and the locally produced SAA present in tissues under homeostatic and/or inflammatory conditions.
While earlier research focused on the impact of liver-derived SAA on HDL function during an acute inflammatory response, more recent studies highlight how HDL profoundly influences the function of SAA. To fully understand SAA biology, a more complete understanding of the factors that modulate SAA’s association with HDL is needed. During an acute phase response, HDL may serve as a vehicle to transport SAA to sites of tissue injury but, in the circulation, sequesters SAA to protect the host from unrestrained inflammation and generalized tissue damage [30••, 75]. Given that HDL-associated SAA appears to be biologically inert, a fundamental question is how SAA might be liberated from HDL to exert pro-inflammatory effects during an acute phase response. Understanding the mechanisms that influence the equilibrium between HDL-associated SAA and other forms of SAA may provide insights into factors leading to SAA-driven disease in individuals with chronic inflammation. Another important aspect of SAA that merits future investigation is the interplay between systemic, liver-derived SAA and locally produced SAA that is present in non-hepatic tissues under both homeostatic and inflammatory conditions. It was recognized more than 50 years ago that one pathological consequence of SAA’s dissociation from HDL is the formation of amyloid deposits in tissues of certain individuals with chronic or recurrent inflammation. Understanding the features of tissue microenvironments that facilitate the disassociation of SAA from HDL may provide insights into SAA’s pathological effects in chronic diseases, including atherosclerosis, abdominal aortic aneurysms, and cancer. The recent link between SAA and an emerging infectious disease, COVID-19 [76, 77], underscores the importance of understanding SAA’s bioactivities in both acute and chronic inflammation. Future research will uncover new insights into this ancient molecule and how it contributes to modern maladies.",Curr Atheroscler Rep
PMC7809431,Effect of Wearing a Face Mask on fMRI BOLD Contrast,"The widespread incidence of infection from the novel coronavirus SARS-CoV-2 has prompted many research MRI scanning facilities to require continuous facial covering (wearing a mask) by scan subjects during scanning in order to diminish the risk of virus transmission, especially since many of those infected are asymptomatic. The purpose is primarily to contain respiratory droplets that can harbor the virus so they avoid landing on surfaces or remain in the air potentially to infect others. There are numerous styles of masks (CDC 2020), ranging from cloth and surgical procedure masks to N95 respirators, having various degrees to which expired air is retained for one or more respiration cycles. Wearing an efficacious mask will mix some expired air with fresh air, and lead to increased carbon dioxide concentration [CO2] in inspired air. The question we approached is: Since CO2 is a potent vasodilator, does this elevation in [CO2] alter functional MRI (fMRI)? fMRI is an epiphenomenological indicator of neural activity, relying on changes in blood oxygenation to depict metabolism changes consequent to neuronal modulation, demonstrated in gradient-recalled echo (GRE) imaging as changes in the susceptibility weighted relaxation rate R2*. The resulting Blood Oxygen Level Dependent (BOLD) contrast (Ogawa et al., 1990) is subject to confounds that can alter the oxygen content independent of neural metabolism including, for example, changes in baseline cerebral blood flow (CBF) (Davis et al., 1998, Kastrup et al., 1999, Buxton and Frank, 1997). Oxygen content of arterial blood is affected by air exchange in the lungs; thus concentrations of oxygen [O2] and carbon dioxide [CO2] in inspired air will be represented in blood chemistry delivered to the brain. In particular, breathing air with increased [CO2] will cause increased arterial blood flow to vascularized brain tissue, mainly in gray matter (Wise et al., 2007).
The purpose of this study is to examine the effect of wearing a mask on BOLD contrast while subjects perform a robust sensory-motor (visual, auditory, sensorimotor) task as the gas content in inspired air is manipulated by periodically supplying fresh air through a nasal cannula. We hypothesize that without a mask, supply of fresh air in the nasal cannula will have minimal effect on air content and cause little change in BOLD contrast due to CO2 (except for cognitive changes induced by the air flow). On the other hand, any change in BOLD contrast due to fresh air supply while wearing a mask is readily explained by the change in air content (i.e. less CO2 accumulation during fresh air supply).
We first model the change in BOLD contrast that results from elevated end tidal CO2 (ETCO2), and then describe fMRI scans to test the degree and character of alterations that are observed while wearing a mask. In separate measurements using capnography, we quantify the change in ETCO2 levels induced by wearing a mask.
Hypercapnia causes an increase in BOLD signal (Wise et al., 2007), due to elevated Cerebral Blood Flow (CBF), resulting from the vasodilatory response to increased arterial blood [CO2]. The increase in blood flow causes reduced deoxyhemoglobin concentration and a decrease in R2*. The relationship between BOLD signal (ΔS), Cerebral Metabolic Rate of Oxygen (CMRO2), and CBF is given in the Davis model (Davis et al., 1998) as a function of time (t) by(1)ΔS(t)ΔS0=M{1−(CMRO2(t)CMRO20)β·(CBF(t)CBF0)α−β}where M is the maximum BOLD contrast that can be obtained in the given brain region, α ∼0.4 is Grubb's constant expressing an empirically-derived power law relationship between blood volume and CBF (Grubb et al., 1974), β ∼1.5 is a constant relating signal change to concentration of deoxyhemoglobin determined by Davis, et. al, and the subscript 0 represents baseline values. We modeled the task-elicited change in metabolism as(2a)CMRO2(t)CMRO20=1+cF(t)where(2b)F(t)={sin(2πtT),sin(2πtT)>00,sin(2πtT)≤0where c is a constant, and T is the period of the task. Because the task design we used has an intentionally short block duration (15s), the evoked hemodynamic response can be well modeled by a sine wave with frequency 1/T. F(t)describes only positive increases in metabolism during on blocks.
Total change in CBF(t)comprises the task-elicited change and the change from turning air on:(3)CBF(t)CBF0=1+dF(t)+A(t)where d is a constant which describes the amplitude of the task-elicited change and A(t) is a square wave representing an additional positive modulation of CBF due to air flow.
This model assumes that modulating [CO2] by airflow in the mask does not in itself cause BOLD changes from a potential cognitive influence of sensing airflow in the nose. Simulation results are shown in Fig. 1
A for T=30s, 270 time frames, 2s sampling interval (TR), A=0.02, d=0.45, c=0.16 (Davis et al., 1998). The [CO2]-induced CBF increase occurs during time frames 100 – 210 and leads to an elevated BOLD baseline signal, but only an insignificantly decreased BOLD amplitude.
In order to characterize the effect on BOLD contrast due to air manipulation in the measured BOLD timeseries data, ΔS(t), a sliding window analysis was performed to test for a baseline shift in the BOLD timeseries as well as for task contrast change. The baseline shift is(4a)ΔS¯(t)=1nT∫t−nT/2t+nT/2ΔS(t′)dt′

The task design regressor is modeled by a sine wave with frequency 1/T. Therefore the sliding window task contrast change is approximated as(4b)ΔC(t)=1nT∫t−nT/2t+nT/2ΔS(t′)sin(2πt′T)dt′

By setting window width to an integer multiple of the task period, ΔS¯(t) is therefore an estimate of slowly varying task signal amplitude. Similarly, changes in ΔC(t) represent alterations in timeseries signal at the task frequency and can be taken to infer task contrast changes during the scan.
This analysis was applied to a simulated timeseries with window duration=T (n=1). We intentionally chose a small value for CBF change (A=0.02) to mimic the small hypercapnic effects of wearing a mask. The result is shown in Fig. 1B,C. As predicted, with elevated CBF hypothesized to occur due to increased ETCO2 with mask on and no added fresh air, there is a baseline shift ΔS¯(t) but not a substantial task contrast change ΔC(t) in BOLD signal. Note, however, if a subject's breathing rate or mask efficacy changes during the scan, hypercapnia levels could change. Consequent CBF variation would lead to added noise in the BOLD signal, which could result in reduced statistical power in predicting task activation.
We sought to study whether wearing a mask would induce enough hypercapnia from rebreathing expired air to affect BOLD activation in a task. To activate visual, auditory, and sensorimotor regions, we chose a robust block design sensory-sensorimotor (SM) task: the on-block consisting of a contrast-reversing (flashing at 3Hz) checkerboard, synchronously changing tones spanning one octave presented in pseudo-random order, and subject sequentially tapping thumb to four digits on the right hand synchronous in time with the tones and flashing checkerboard. The off-block is a fixation cross. The on and off blocks are intentionally short (15s) so that the BOLD response is well represented by a sine wave at the fundamental task frequency of 1/30Hz. During this task, medical-grade air (air-on/off blocks; AIR) was supplied to the subject through a nasal cannula, in 90s duration on and off blocks (Fig. 2
A). The SM and AIR designs are nearly orthogonal to each other (correlation coefficient=0.013), which allows their characterization using a general linear model (GLM).
A GLM with two design regressors is used to separately generate activation maps of the sensory-motor (SM) task and hypercapnia (AIR) effect. The sensory-motor task regressor is a square wave convolved with hemodynamic response function (Glover, 1999), while the AIR regressor uses an exponential response function (30s time constant suggested during pilot scans) convolved with a square wave (Fig. 2B). The 9 minute-long scan was repeated with mask removed, which was expected to eliminate hypercapnic modulation of BOLD signal.
Eight healthy subjects (3 males, 5 females, age 44±16 years) from Stanford University community were enrolled in the study after giving informed consent for a research protocol approved by the Stanford University IRB. A nasal cannula (Hudson RCI flared, Teleflex Medical, Research Triangle Park, NC) was placed in the subject's nose and tubing cinched comfortably around the back of the head. A pleated surgical procedure mask with the metal nose strip removed (for RF and magnetic safety) was placed over the cannula and face, covering the nose and extending to the chin. With the metal strip removed the mask did not fit snugly to the face, so surgical tape was used to affix mask to face, attempting to seal the gap. During the “mask-off’ scan the mask was slid downward to uncover the nose and mouth. In this mode expired air was not rebreathed because of the flow in the bore from the scanner's bore fan. The subject was able to perform the “mask-off” or “mask-on” maneuver between scans, with minimal head motion. The order of mask-on and mask-off scans was counterbalanced between subjects.
Air was supplied to the cannula at a rate of 5.8L/min from a tank of medical-grade air through a regulator and solenoid valve controlled by a computer also presenting the sensory-motor task stimuli with Eprime software (Psychology Software Tools, Sharpsburg, PA). During both “mask-on” and “mask-off” scanning, the airflow was cycled in 90s off-on blocks (AIR) while subjects performed the SM task. The flow rate was sufficient to provide fresh air within the mask approximately equal to the average human breathing rate (Warner and Patel, 2018), displacing expired air.
A 3T MRI scanner with 48-channel head coil (GE Premier, Milwaukee, WI) was employed. The scanner's bore fan was turned on at low. Anatomic scans were acquired with a 3D T1-weighted (BRAVO) sequence with 22 cm FOV, 192 × 256 matrix, 32 4mm thick slices, in axial plane. Functional scans employed a gradient echo R2*-weighted spiral-in/out pulse sequence (Glover and Law, 2001) with the same slice prescription as the anatomic scan, 64 × 64 matrix, TR/TE 2000/30ms, 77 degree flip angle, 270 time frames (9 minute scan duration). Physiological data were acquired with the scanner's respiration belt on the upper abdomen and pulse oximeter on the subject's left index finger. Pneumatic earphones and padding stabilized the head to diminish head motion. No-mask fMRI data were not obtained for subject #8 (Table 1
) due to technical failure and inability to repeat the scan.
Postprocessing of timeseries images was performed with conventional, homemade software, which included 6-parameter motion correction, correction of cardiac and respiration confounds using RETROICOR (Glover et al., 2000) and RVHRCOR (Chang et al., 2009), and spatial smoothing with a 1.5 pixel FWHM 3D Gaussian kernel. RETROICOR and RVHRCOR were not applied to subject #7 whose physiological data were heavily correlated with the SM task. The GLM analysis used quadratic detrending together with design regressors shown in Fig. 2B. For generating group activation maps, FSL v6.0 software (Jenkinson et al., 2012) was used to normalize activation maps to a common MNI atlas.
Timeseries were extracted from each scan using an ROI consisting of those voxels with sensory-motor task activation T-scores exceeding 5.0, (i.e, uncorrected p-values of 5e-7). The resulting timeseries was submitted to the sliding window analysis in Eq. 4(a,b) for scans with and without mask for each subject.
To quantify the degree to which the time varying task contrast ΔC(t)and baseline shift ΔS¯(t) were affected by the airflow modulation, covariation of these signals with the AIR regressor (shown in Fig. 2B) were calculated for each subject's mask-on and mask-off data. The results were expressed as fractional changes with integrations covered the scan duration:(5a)ΔSf=∫ΔS¯(t)AIR(t)dtmean(ΔC(t))∫AIR(t)dt
(5b)ΔCf=∫ΔC(t)AIR(t)dtmean(ΔC(t))∫AIR(t)dt

Subject motion was estimated by calculating the brain centroid of each volume before removing baseline drift or motion correction. Root-mean-square (RMS) values of motion in x, y, and z dimensions were computed. Total RMS motion is the square root of sum of squares of RMS motions in x, y, and z.
End tidal CO2 measurements were made in separate sessions with subjects outside the scanner, employing the identical or same type of mask and cannula as utilized during scanning. The cannula was connected to a patient monitor (Medrad Veris 8600, JZ Imaging, Willoughby, OH) employing infrared gas capnography. Readings were obtained every 15s for 5 minutes with mask in place as during scanning, and with the mask removed. Two to three minutes of stabilization time was employed before and between measurement blocks. The normalized difference between mask-on and mask-off ETCO2 was computed as(6)ΔETCO2=(ETCO2¯on−ETCO2¯off)/ETCO2¯offwhere ETCO2¯on,off denote the 5-minute-average readings with and without the mask, respectively. A heteroscedastic T-test was employed to determine the significance of the ΔETCO2in each subject, and a paired T-test was employed to test the overall significance across the cohort. To examine the possibility that breathing conditions could be different in the magnet from the bore fan and confinement, the measurements were repeated with subject #7 in the magnet performing the SM task (but without scanning).

Fig. 3
shows single-subject activation results for the sensory-motor task and for air-on/off blocks, each with and without mask. Task activation in Fig. 3A,B focused in visual, auditory, and sensorimotor cortices, remains robust with or without mask. The difference between mask and no mask task activation (maps not shown) is not significant. Supplying air while wearing mask (Fig. 3C) reduces mask-induced hypercapnia, resulting in widespread deactivation of BOLD signal predominantly in gray matter, as expected. When the mask is removed (Fig. 3D), BOLD signal related to air-on/off blocks demonstrates marked reduction, as expected with normoxia. Deactivation was observed for the mask-off condition in some individual subjects; for example, insula cortex and frontal region in Fig. 3D. This suggests a cognitive influence derived from sensation of airflow induced by the nasal cannula. With mask on, some subjects reported a sense of nasal airflow. Some cognitive effect of sensing nasal cannula airflow could be retained with the mask off. Fig. 3E,F blue plots show timeseries of highly activated voxels, obtained by averaging all voxels with SM activation having T scores > 5.0 (uncorrected p-value 5E-7), from scans shown in Fig. 3A,B. Also shown is the AIR regressor, inverted to demonstrate that baseline signal is elevated during air off periods with mask (Fig. 3E) but correlates negligibly with AIR without mask (Fig. 3F).
The timeseries for each subject (as calculated for subject #3 in Fig. 3E,F) was submitted to the sliding window analysis in Eq. 4(a,b). Fig. 4
shows the result of averaging these sliding-window timeseries across subjects to obtain the effect of air-on cycles on task contrast change ΔC and baseline signal offset ΔS¯(t)


Table 1 provides a summary of the sliding window analysis for each subject presented as fractional changes in SM task contrast ΔCfand fractional changes in baseline shift ΔSfcalculated by covariation with the AIR regressor (Eq. 5a,b) as well as subjects head motion information. With mask on, the average baseline shift was 30.0% (p<0.0141) while the average task contrast change was not significant (2.50%, p=0.43) from covariation with AIR. With mask removed, there was no significant covariation of task contrast (2.0%, p=0.45) or baseline shift (6.5%, p=0.21) with AIR. Subject motion was small in this cohort of motivated volunteers, and not correlated with the AIR blocks. Paired-sample T-test shows no significant difference in motion with and without mask.

Table 1: Fractional change in task contrast ΔCfand baseline shift ΔSffor each subject. The AIR-related average task contrast changes with or without mask (2.5%, 2.0%, respectively) were not significant while the average baseline signal shift with mask-on (30.0%) was significant. The average baseline signal shift of 6.5% (without mask) was not significant. No data were obtained on subject 8 without mask due to technical failure. No significant difference in subject motion is noted between scans with and without mask.
Sensory-motor task and air-on/off responses for single-subject maps in Fig. 3 are as robust as responses averaged across subjects in Fig. 5
. Sensory-motor task activation can be detected reliably under both mask-on and mask-off conditions (Fig. 5A,B) with no significant activation difference between conditions. Global gray matter deactivation is seen under mask-on and lack of airflow (Fig. 5C). Comparing to the entire gray matter volume, the amount of deactivation (due to mild hypercapnic or cognitive effects from airflow) is insignificant without mask at group level (Fig. 5D).

Table 2
shows ETCO2 measurements on subjects outside the magnet, as well as results on subject #7 in the magnet performing SM task but without scanning. The average change in ETCO2 was 7.4% increase when wearing a mask. A paired T-test across subjects confirmed that this difference is significant at p<0.0014. Our measurement of ETCO2 increase from wearing a surgical mask is similar to that when wearing N-95 masks (Bharatendu et al., 2020).
The experiments in this study employed a nasal cannula to replace expired air with fresh air in a block design, thereby allowing controlled manipulation of endogenous [CO2] levels during a sensory-motor task in two separate scans (one with mask and one without mask). The results, while wearing a mask, demonstrated good qualitative agreement with the model; showing no significant change in task activation (p=0.43) but significant change in baseline signal compared to the condition when fresh air was introduced into nasal passages (p<0.0141). These results confirm that wearing a mask increases the BOLD baseline signal (30% on average, Table 1) through reduced R2*, but the effect does not substantively alter gain of task-induced changes in signal; i.e, estimates of task activation with and without mask (Table 1). Results with no mask demonstrated negligible alteration to task activation, although some subjects showed localized baseline signal shift correlated with air-on (Fig. 3D). This result was unexpected because there should not be a hypercapnic change with mask removed and air flowing. We speculate that such a baseline shift could be due to cognitive effects of airflow sensation or a result of mild hypocapnia from fresh air being introduced in the nose. Nevertheless, Figs 3D and 5D illustrate that hypercapnic effect is largely absent with mask removed, as expected.
The measurements of end tidal CO2 were made outside the scanner, as quantitation was not possible while scanning and modulating the air using a cannula, because of mixing of the delivered air with the sampled expired air. Using a gas mask with rebreathing valve instead of nasal cannula would prevent the mixing effect and allow ETCO2 measurement while delivering air, but the substantial complexity would violate the concept of simply wearing a facial covering during fMRI. Results showed that reliable mild hypercapnia was induced with mask on (average 7.4% increase in ETCO2 relative to no-mask condition). Differences with and without mask were significant within subjects (shown in Table 2) and in the cohort (p<0.0014, paired T-test). However, to suggest that changes in ETCO2 measured in the control room were similar to those during scanning, the measurements were repeated in the scanner (without fMRI but performing the SM task) on one subject. The capnography measurement on subject #7 inside and outside the scanner were comparable as shown in Table 2.
While there were individual differences in BOLD signal amplitude and ETCO2 across subjects, we estimated the average BOLD reactivity to ΔETCO2. For each subject, we calculated an individual AIR-activation gray matter mask (mask-on data correlated with AIR regressor having Z-score>4 within gray matter). Each subject's BOLD signal data was filtered by their masks to calculate percent signal change. Averaging each individual's percent signal change per mmHg gave an estimate of BOLD reactivity to ΔETCO2of 0.36%/mmHg. This value is slightly less than that observed in gray matter by Prisman, et al. (Prisman et al., 2008) (0.44%/mmHg) in 4 participants during controlled hypercapnia. The difference may be due to lack of precision control of the mask and cannula in our study. However, with limited number of subjects in both studies, quantitation is underpowered.
While wearing a facial covering during fMRI does not substantially alter task activation, it may create sensitivity to changes in respiration or mask placement through variations in inspired [CO2] that are absent without a mask. Some subjects may have experienced facial discomfort, for example, prompting adjustments of their mask during scan. This effect would manifest as a difference between sliding-window timeseries noise levels with and without mask. In the present study, no significant differences were found in the task contrast change ΔC(t) between scans with and without mask (Table 1), suggesting that wearing a mask contributes a negligible effect to BOLD activation in our sensory-motor experiments.
Our study is subject to a number of limitations: Only a small cohort (8 subjects) could be recruited from within our lab because of institutional regulations prompted by the pandemic. Of these, only 7 no-mask scans were obtained for technical reasons. Only one type of mask was evaluated. Different respirators may confine expired air more tightly and exacerbate baseline signal change, although our results were similar to observations made with N-95 masks (Bharatendu et al., 2020). Only a robust sensory-motor task was evaluated, although effects on verbal working memory were anecdotally tested and found to be congruent with the SM results. In addition, we gathered three resting-state data sets and analyzed the connectivity in the default mode network. Although our initial results in functional connectivity, ALFF, FALFF, and global signal show no significant effect from wearing a mask, a substantially larger sample size would be needed to reliably detect small resting state signal changes.
Because of recruitment limitations on the size of our subject cohort, we used block-design air manipulations in an attempt to more robustly estimate mask effects within a single scan than calculating differences between separate scans with different airflow. In preliminary studies, several subjects wearing a mask performed SM during separate scans, twice each with and without continuous air supply (4 scans total). We found that in the two repetitions without changing the air flow condition, the SM task amplitude was not reproducible enough to make reliable estimates of the difference of adding air to the cannula. Poor reproducibility between scans, could presumably due to variations in task performance, vigilance, and habituation, is consistent with earlier studies of fMRI reproducibility (Voyvodic, 2006).
In summary, wearing a mask increases ETCO2 by 7.4% measured by gas capnography. Increased [CO2] causes increased CBF and reduced R2*, and induces global gray matter activation changes as in a CO2 gas challenge (Wise et al., 2007) or breath holding (Kastrup et al., 1999). This hypercapnic effect causes a change in signal baseline level but no significant change in task activation.
This work was supported by NIH grants R01 NS109450, P41 EB0015891.
Data reported in this manuscript can be made available with permission from Stanford University.
Christine S W Law: Conceptualization, Methodology, Formal analysis, Investigation, Writing – Review & Editing, Visualization
Patricia S Lan: Conceptualization, Methodology, Investigation, Writing – Review & Editing
Gary H Glover: Conceptualization, Methodology, Formal analysis, Investigation, Writing – Review & Editing, Visualization, Writing – Original Draft, Project administration, Funding acquisition
The authors declare no conflict of interest.",Neuroimage
PMC7809439,NCSBN’s Environmental Scan COVID-19 and Its Impact on Nursing and Regulation,"NCSBN’s National Nursing Database tracks the number of U.S. licensed nurses from 57 boards of nursing (BONs) and is updated daily (excluding Michigan). There were 4,204,723 registered nurses (RNs) and 934,245 licensed practical or licensed vocational nurses (LPNs/LVNs) in the United States as of September 30, 2020. (NCSBN, 2020a). The most recent Occupational Employment Statistics data from May 2019 indicate that 2,982,280 RNs and 697,510 LPNs/LVNs were employed in the United States (U.S. Bureau of Labor Statistics [BLS], 2020a). Figure 1, Figure 2
illustrate growing RN employment and steady LPN/LVN employment.
The number of employed RNs per 100,000 people in each state varies widely across the country, from fewer than 700 RNs per 100,000 people in Utah to nearly 1,550 RNs per 100,000 in the District of Columbia (Figure 3
) (BLS, 2020a; U.S. Census Bureau, 2019). States in the upper Midwest—specifically South Dakota (1,464 RNs per 100,000), North Dakota (1,279 RNs per 100,000), and Minnesota (1,259 RNs per 100,000)—have among the highest ratios of employed RNs per population. States in the West and Southwest regions have among the lowest ratios, though Georgia and Virginia, in the Southeast have the lowest ration. The ratio of employed LPNs/LVNs is lowest (between 50 and 75 LPNs/LVNs per 100,000 people) in Alaska, Utah, and Hawaii and highest (more than 400 LPNs/LVNs per 100,000) in Louisiana (Figure 4
).
The maps in Figure 3, Figure 4 provide a quick state-level snapshot of the supply of employed nurses; however, there are regional differences within each state that could be different from the overall state-level view. These regional differences within states are often the main concern for individuals involved in studying and monitoring the nursing workforce. For instance, California has one of the lowest employed nurse-to-population ratios, but city centers like San Francisco may have very high nurse-to-population ratios whereas rural areas may have very low nurse-to-population ratios. Within-state regional nurse employment data are available from the BLS (2020a).
The Occupational Outlook Handbook (BLS, 2020b) reported that the median pay for RNs in 2019 was $73,300. The RN workforce is expected to grow in the United States by a faster-than-average pace of 7% from 2019 through 2029, adding an additional 221,900 jobs. The median pay for LPNs/LVNs in 2019 was reported to be $47,480. The LPN/LVN workforce is expected to grow by a much faster-than-average pace of 9% from 2019 through 2029, adding an additional 65,700 jobs.

Figure 5
(NCSBN, 2020b) extends the narrative of the nursing workforce. As shown in this graph, 171,387 nurses took the NCLEX in 2019. This number does not mean all those nurses were licensed and entered the U.S. workforce, but it does reveal that the number of individuals graduating from nursing programs has steadily risen since 2010. The question remains as to whether the pipeline is adequate to supply the present and future needs of the U.S. healthcare system.
The advanced practice registered nurse (APRN) profession consists of four roles: the certified nurse practitioner (CNP), certified nurse midwife (CNM), clinical nurse specialist (CNS), and certified registered nurse anesthetist (CRNA). An exact census of the APRN profession is difficult to accomplish due to variances in title and classification between the states, but all indicators suggest that this fast-growing profession will continue to grow. According to the latest data from May 2019, the BLS (2020b) estimates a total of 263,400 APRNs in the United States, though this number excludes the CNS role, which is not tracked independently by the BLS at this time.
The largest of these roles continues to be the CNP, and the number of CNPs in the United States has nearly doubled since the BLS began collecting data on the role in 2012. At that time, the BLS reported just over 100,000 CNPs in the United States. As of 2019, BLS estimates show that the number of CNPs has crossed the 200,000 threshold (BLS, 2020a) (Figure 6
).
The number of CNMs and CRNAs, in contrast, increased only slightly according to 2019 estimates. CRNAs now number 43,570 across the entire Unites States (BLS, 2020b), and CNMs are estimated to number 6,930 (BLS, 2020c).
The BLS calculates employment projections for the three APRN professions it currently tracks—CNPs, CNMs, and CRNAs—in aggregate, and latest predictions indicate explosive growth. In 2018, BLS predicted the professions would grow 26% by 2028 (BLS, 2019). Based on 2019 data, that number was revised upward and is now expected to increase 45% by 2029, adding over 117,000 individuals to the profession within that 10-year span (BLS, 2020d).
In December 2019, results from the U.S. Department of Health and Human Services (HHS) Health Resources Services Administration’s (HRSA’s) 2018 National Sample Survey of Registered Nurses (NSSRN) were released (HRSA, 2019). The average age of an RN was 50 years; however, most nurses (53%) were younger than 50 years. The RN population was more diverse than it was in 2008, with proportions of both minority groups and men slightly increasing within the RN population.
The survey found that most of the RN workforce (63.9%) is college educated, with APRNs accounting for approximately 11.5% of the nursing workforce. Telehealth capabilities were reported in 32.9% of nurses’ workplaces. Among those with capabilities, 50.3% of nurses used telehealth in their practice.
In spring 2020, HRSA evaluated the NSSRN data in light of the COVID-19 pandemic (HRSA, 2020). The report found that among the nearly 4 million RNs, 2.7 million were involved in patient care. The most common work setting for nurses with patient care responsibilities across the inpatient-subacute-outpatient spectrum was non-critical inpatient care for RNs (more than 710,000, or 29.6%) and ambulatory care for APRNs (more than 127,000, or 38.6%).
The two most common categories of clinical specialty for RNs and APRNs with patient care responsibilities were general medical-surgical care and ambulatory and primary care. Less than 1% of RNs and APRNs worked in pulmonary/respiratory or infectious/communicable disease specialties, both of which are relevant and needed for addressing infectious disease pandemics.
The highest number of RNs and APRNs with patient care responsibilities per capita nationally were in the West North-Central Census Division (958 RNs per 100,000 population) and the New England and East South-Central Census Divisions (157 and 153 APRNs per 100,000 population, respectively) (HRSA, 2020).
COVID-19 has demonstrated an even greater need for workforce data collection, planning, and mobility. In the future, researchers, policymakers, and public health planners will expect that state and national workforce databases will help deploy nurses in future emergencies to areas of need. Pressure may increase on BONs to add workforce data collection to the licensure renewal process. Currently, workforce data are collected and analyzed by both NCSBN and HRSA. The data, however, are based on national samples. While accurate, the ideal remains a national workforce repository of data from all nurses in the United States.
NCSBN’s E-Notify allows nurses to self-enroll and receive licensure expiration reminders. When enrolling, the nurse enters workforce information into the database. Currently, over 580,000 nurses have self-enrolled and entered their workforce data. NCSBN continues its work to expand this database.
On July 1, 2020, the U.S. Department of Education implemented new regulations that nursing programs (LPN/LVN, RN, and APRN) must adhere to if they participate in funding from Title IV of the Higher Education Act of 1965. This new regulation applies to programs using all learning modalities, including online, in-person, or a combination of both. The proposed amended regulation (34 C.F.R. § 668.43[a][5][v]) reads as follows:If an educational program is designed to meet educational requirements for a specific professional license or certification that is required for employment in an occupation, or is advertised as meeting such requirements, information regarding whether completion of that program would be sufficient to meet licensure requirements in a State for that occupation, including—(A) A list of all States for which the institution has determined that its (A) curriculum meets the State educational requirements for licensure or (A) certification;(B) A list of all States for which the institution has determined that its curriculum does not meet the State educational requirements for licensure or certification; and(C) A list of all States for which the institution has not made a determination that its curriculum meets the State educational requirements for licensure or certification (Student Assistance General Provisions, 2019, p. 58932)

Additionally, a direct disclosure to the student in writing is required in this regulation by the educational institution if the program leading to professional licensure or certification falls in one of the latter two categories above. The nursing program, not the BON, makes this determination based on the state’s licensure requirements and their curriculum. To assist programs in meeting these requirements, NCSBN has developed a website with each BON’s licensure requirements for LPNs/LVNs, RNs, and APRNs (NCSBN, 2020a).
The NCSBN monitors the number of nursing programs across the country. The growth since 2003 for RN programs is 61% and LPN programs is 17%. Comparable to the workforce data, RN program growth continues to increase, though growth has been slower since 2015. LPN program growth has decreased steadily since 2013 and has remained moderately stagnant since 2017 (Figure 7
and Table 3
) (Hong Qian, NCSBN psychometrician, personal communication, October 2020).
A 10-year analysis of U.S. RN first-time NCLEX takers by program type indicated that ADN graduates still account for the largest number of nursing program graduates; however, the number of bachelor degree (bachelor of science [BS] and bachelor of science in nursing [BSN]) graduates has grown considerably during the past year, almost reaching the same level. Additionally, the growth rate of BS/BSN graduates (52%) has surpassed the rate of growth of ADN graduates over the 10-year period (4%) (Table 4
) (NCSBN, 2020b).
The national NCLEX pass rates in 2019 were 91.2% for BSN graduates, 87.9% for diploma graduates, and 85.2% for ADN graduates.
Currently, 31 U.S. BONs require national nursing accreditation and 27 do not. In 2020, NCSBN surveyed programs to learn how many were accredited. As can be seen in Figure 8
, 88.8% of BSN programs, 53.2% of ADN programs, and 10.6% of LPN/LVN programs are nationally accredited (Silvestre, 2020).
When NCSBN studied the percentages of accredited programs in 2012, 96% of BS/BSN programs were accredited, whereas 52% of ADN programs and 10% of LPN/LVN programs were accredited. While there have been slight increases in the percentage of accredited ADN and LPN/LVN programs, there has been a decrease in the percentage of accredited BS/BSN programs (88.8%) (Silvestre, 2020).
The American Association of Colleges of Nursing (AACN) Special Survey on Vacant Faculty Positions for Academic Year 2020–2021 (Fang et al., 2020) reports the issues and trends related to nursing faculty in baccalaureate or higher nursing education. The total number of budgeted faculty positions has continued to increase since 2008 (Table 5
). This year’s survey data show a gradual improvement in the faculty vacancy rate (6.5% in 2020 compared to 7.2% in 2019), with fewer schools overall with faculty vacancies (n = 461 in 2020 compared to n = 475 in 2019). Regional data indicate that the Midwest is experiencing the lowest vacancy rate (Figure 9
).
According to the faculty vacancy survey (Fang et al., 2020), the nursing programs’ major barriers to hiring new faculty members are in line with previous years’ data and include the following:•insufficient funds to hire additional faculty•administration is unwilling to commit to additional full-time positions•competition in other marketplaces causes an inability to recruit qualified faculty•qualified applicants for faculty positions are unavailable in the geographic area.

Additionally, nursing programs continue to report the following critical issues related to faculty recruitment (Fang et al., 2020):•finding faculty with the right specialty mix•noncompetitive salaries•limited pool of doctorally-prepared faculty•finding faculty willing and able to conduct research•finding faculty willing and able to teach clinical courses•high faculty workload.

Other significant critical issues regarding faculty recruitment include the following (Fang et al., 2020):•challenging location (rural areas or areas with a high cost of living)•institutional budget cuts, restrictions, or hiring freezes due to COVID-19•finding faculty who fit well with school culture•recruitment from historically underrepresented populations.

For some nursing programs, COVID-19 forced budget cuts and faculty hiring freezes (Fang et al., 2020). The impact of this remains to be seen; however, the major barriers contributing to faculty vacancies remain the same as previous years’ barriers, and the most critical issues related to faculty recruitment align with previous years’ data.
In 2020, NCSBN’s national mixed methods study on nursing program outcome metrics was published and provided quality indicators for nursing education programs as well as warning signs that a program may be experiencing difficulties and falling below standards (Spector et al., 2020). The study results were subsequently analyzed by a panel of experts, including educators, regulators, researchers, and attorneys, to develop evidence-based and legally defensible regulatory guidelines for BONs to use during the nursing education program approval process and as guidance for nursing programs. The guidelines serve as an early intervention and assist nursing programs in acting before NCLEX pass rates fall below the state requirement and/or receives BON sanctions or program closures, thus allowing the programs to graduate safe and competent nurses in adequate numbers.
From these data, new annual report templates for nursing programs have been developed to bring uniformity to nursing education data collection. These data will be entered into a national database for nursing education—the first of its kind in the United States.
Competency-based education has gained popularity in higher education over the past 10 years. It requires graduates to have a consistent set of skills and core knowledge, which employers and consumers expect (Giddens, 2020). In 2020, AACN released their draft of The Essentials: Core Competencies for Professional Nursing Education (AACN, 2020). In this new model, competency-based education provides the structure for nursing across degrees and identifies concepts, competency domains (broad areas of competency), competencies, and subcompetencies (AACN, 2020). Concepts and competencies have a complementary relationship: concepts are the disciplinary knowledge, while competencies are observable and measurable expectations for learners (Giddens, 2020). Giddens states that a common misunderstanding of competencies is that they refer simply to a skills checkoff. While checking off skills may be a part of competency assessment, competency assessment is much broader. The eight featured concepts identified in the new AACN Essentials document include (a) clinical judgment, (b) communication, (c) compassionate care, (d) determinants of health, (e) diversity, equity and inclusion, (f) ethics, (g) evidence-based practice, and (h) health policy. The 10 competency domains include: (a) knowledge for nursing practice, (b) person-centered care, (c) population health, (d) scholarship for nursing practice, (e) quality and safety, (f) interprofessional partnerships, (g) systems-based practice, (h) information and healthcare technologies, (i) professionalism, and (j) personal, professional, and leadership development.
Reflecting the nation over the past few years, nursing and higher education in the United States have been increasingly focused on identifying and eliminating structural systemic racism (DeWitty & Murray, 2020; Koschmann et al., 2020; Ritter & Raphael, 2020; Villarruel & Broome, 2020). DeWitty and Murray provide statistics elucidating the problem in higher education: Although White people make up 60% of the U.S. population, they hold 81% of the full-time professorships. African Americans and Hispanics comprise approximately 31% of the population, but they only represent 4% and 3%, respectively, of full-time professorships. In nursing, minority faculty make up 17% of all faculty positions, with more than half of these serving as associate or assistant professors or instructors, rather than as full professors (DeWitty & Murray, 2020). On a positive note, the nursing profession has seen an increase in the number of minorities in doctor of philosophy (PhD) programs (23.3% to 33.6%) and doctor of nursing practice (DNP) programs (21.1% to 36.0%) (DeWitty & Murray, 2020).
While DeWitty and Murray (2020) report a lack of research regarding why academic nursing has a limited number of minority professors, some themes emerge from the literature, such as minority populations feeling underappreciated/marginalized. Some have experienced tokenism, microaggressions, and an unwelcome climate, and there have also been reports of racism, exclusion, and alienation. Metzger et al. (2020) conducted a scoping literature review of inclusivity in baccalaureate nursing education. Three themes emerged from this review, including the following: (1) minority students experienced discrimination from peers, faculty, the clinical setting, and the larger institutional and community setting; (2) the cumulative effect of discrimination is a lack of belongingness, which is associated with adverse academic outcomes; and (3) all aspects of the learning community (peers, faculty, those in the clinical setting, the larger institutional culture, family, and friends) act as facilitators or barriers to inclusivity. With the latter theme, when the learning community was supportive, students had more positive academic outcomes than those in communities that did not foster inclusivity.

Villarruel and Broome (2020) call it a “watershed moment” in which we can no longer be silent. They call on leaders in nursing education to change policies, practices, and traditions that diminish people of color in nursing programs and challenge leaders to move from simply naming racism to dismantling it. Likewise, Koschmann et al. (2020) call on nursing education to increase diversity in the nursing workforce by providing financial and academic resources to support student retention and success. Additionally, faculty must confront their own biases by intentionally incorporating difficult conversations into the classroom.
Despite challenges such as the COVID-19 pandemic, immigration policies, and high tuition, the United States likely will remain a leading destination for international students. In a 2020 survey of prospective international students, with 78,578 respondents across eight countries,*
19,608 were interested in studying in the United States (Quacquarelli Symonds, 2020a). Fifty-five percent of respondents indicated the most important reason for choosing to study in another country is the high quality of teaching. When looking toward the future, 46% of the respondents predicted that in 10 years, more students will be attending universities, thus increasing the number of students coming to the United States. When assessing quality, 64% of respondents rated the university’s staff as the most important attribute, which illustrates the importance of a qualified faculty.
Considering new education approaches, 58% would most like to experience personalized learning using artificial intelligence, while the next two popular choices were blended learning and interactive simulation. This finding emphasizes the need for continued development of education technologies, as well as faculty who are prepared to use them (Quacquarelli Symonds, 2020a).

Thibault (2020) analyzed future trends in healthcare professions education based on his 4 decades as a faculty member at Harvard Medical School and a decade of leading the Josiah Macy Jr. Foundation, which is the only national foundation devoted to improving health through innovations in healthcare professions education. The six trends he identified include (1) interprofessional education to better prepare students for collaborative practice; (2) integrated clinical education with more of a focus on the patient, community, and chronic diseases; (3) education in the social determinants of health and the social and humanistic missions of the healthcare professions; (4) more emphasis on lifelong learning and long-term well-being of healthcare professionals; (5) a shift to competency-based education; and (6) the integration of artificial intelligence and new educational and information technologies into the healthcare professions education and practice. While many of these trends are well on their way in nursing education, as Thibault (2020) observed, we are poised for a decade of “explosive innovation.”
Regulators are encouraged to review the AACN Essentials document and the competency-based education model (AACN, 2020), as these will impact nursing education in the near future. Also, regulators are encouraged to use the NCSBN “Guidelines for Evidence-Based Program Approval” and the annual report template that was developed based on the outcomes and metrics study (Spector et al, 2020). These tools allow for a consistent and uniform assessment of programs and data collection in addition to building a national database that will provide regulators, educators, and researchers access to a plethora of data about nursing education.
Collaboration between academia and practice should be encouraged to develop methods for allowing students to continue their education under these extraordinary circumstances. Innovation and flexibility are imperative. As an example, the practice-academic partnerships described previously allow students to serve as support staff in healthcare facilities, to be paid, and to receive academic credit. When imagining future lessons from this pandemic, Maryann Alexander, PhD, RN, FAAN, in an editorial of the Journal of Nursing Regulation, asked:What if education and practice became true academic partners? And, healthcare facilities made a true commitment to participate in the education and mentoring of the next generation of nurses? Instead of shutting their doors to students during an emergency, students and faculty would be integrated into the workforce (Alexander, 2020, p. 3).This practice/academic model is a true reflection of that imagination.

COVID-19 has provided regulators and nursing educators the opportunity to examine new ways of educating students. To prepare regulators for future decisions that involve substituting traditional clinical experiences with virtual simulation and more than 50% high-fidelity simulation, NCSBN has embarked upon a series of studies. The Prelicensure Nursing Cohort Study is following the 2022 class of nursing students through their program and into their first 6 months of practice to determine the effects of the pandemic and the effects of the abrupt changes made in clinical and didactic teaching on their education outcomes. In addition, beginning in 2021, NCSBN will be conducting a study examining the role of virtual simulation and whether high-fidelity simulation can be substituted for more than 50% of a traditional clinical experience. As Barton et al. (2020) observed, it is time to co-create a new world order within nursing education. At the same time, research is needed that will support and help direct these strategies (Barton et al., 2020; Fauteux, 2020).
COVID-19, seemingly overnight, changed how healthcare was delivered and increased the focus on the technologies used to provide care. Globally, healthcare providers and systems used technology in novel ways to help combat the virus and its spread.
The United States has focused technology on the expansion of telehealth, the delivery of healthcare services at the bedside, and the monitoring of patients at home. Other countries used big data, artificial intelligence and mobile devices in new ways as a method of prevention and reduction of transmission. Many of the countries that used these tools have the lowest rates of transmission and death rates in the world; however, there is a trade-off in benefits. The methods used carry many privacy implications and may violate security and U.S. privacy and confidentiality laws. The following examples are discussed in this report to illustrate how technology is being used and likely will be used in the future to address crises and other healthcare situations.
China used migration maps of data collected from mobile phones, mobile payment applications, and social media to track and collect real-time data on the movement of people throughout the country. These data were then translated into machine-learning models that portrayed regional transmission. China also used machine learning and developed algorithms for CT scanners to predict the possibility of a patient acquiring severe disease and acute respiratory distress syndrome. These prediction models were used to enhance clinical decisions and identify areas and facilities in need of critical care resources and medical supplies (Whitelaw et al, 2020).
Taiwan used big data for surveillance and testing. Immigration records were combined with the national health insurance database. Health authorities then identified who recently traveled to Wuhan, China, and pinpointed individuals who needed to be tested. Even before visitors to Taiwan entered the country, their health status was monitored. High-performance infrared thermal cameras at airports displayed thermal images of travelers and allowed authorities to quickly identify individuals with a fever. Singapore took this methodology one step further. Like many places in the United States, temperatures are taken at the entries of workplaces, schools, and public transport. These data, however, were tracked, analyzed, and used to detect emerging COVID-19 hot spots in Singapore. Testing was then focused on these areas (Whitelaw et al., 2020).
In Iceland, the symptoms of COVID-19 patients were combined with clinical and genomic sequencing data to learn more about the pathologic process and spread of the virus. These data helped scientists to learn more about the prevalence and transmission of asymptomatic COVID-19 (Whitelaw et al., 2020).
In Korea, new COVID-19 cases are reported via emergency text alerts to all people in the region of an infected individual. Those who were possibly exposed to infected individuals are requested to get tested and quarantine (Whitelaw et al., 2020).
Despite the benefits and success of these methods, gathering data from individuals’ digital devices, tracking their mobility, requesting testing, and enforcing quarantine is often seen as an infringement on privacy and a threat to civil liberties. To balance the need for contact tracing and privacy, European authorities suggested the data be discarded after 14 days, the timeframe of possible viral transmission. Whitelaw et al. (2020) suggested that privacy and data security concerns were offset because “they facilitate a return to normal routine without a rebound in infections.”
Among the many lessons the COVID-19 pandemic has imparted is the need for a common regulatory terminology that facilitates communication and stimulates research. In 2014, the NCSBN Delegate Assembly updated a 1997 position paper in which NCSBN defined “telehealth nursing practice…as the practice of nursing delivered through various telecommunications technologies, including high speed Internet, wireless, satellite and televideo communications” (NCSBN, 2014). At that time, the American Telemedicine Association defined telehealth as “the remote delivery of healthcare services and clinical information using telecommunications technology. This includes a wide array of clinical services using internet, wireless, satellite and telephone media” (NCSBN, 2014). However, the term “telehealth” is not yet universal, and the events of the pandemic have accentuated the ways in which existing policies, particularly related to reimbursement frameworks, have not kept pace with the proliferation of telehealth services. Bashshur et al. (2020), for example, acknowledged the state of confusion then they commented that “it is no surprise that health systems within the United States and globally are now resorting to telemedicine and (whatever else it is called) to provide care while keeping patients in their homes” (p. 571). Ohannessian et al. (2020) called for “the definition of national regulations and funding frameworks for telemedicine in the context of public health emergencies.”
In the United States, the slow pace of change for regulation related to telehealth was rapidly mitigated in 2020 by the use of state and federal public health emergency powers. The Centers for Disease Control and Prevention (CDC) noted that “recent policy changes during the COVID-19 pandemic have reduced barriers to telehealth access and have promoted the use of telehealth as a way to deliver acute, chronic, primary and specialty care” (CDC, 2020c).
In many healthcare delivery systems, all members of the outpatient care team, including nurses, have transitioned to virtual visit workflows during or even before the pandemic (Lau et al., 2020). However, curricula in many healthcare professions have provided limited training in telehealth (Cottrell et al., 2018; Edirippulige et al., 2018; Smith et al., 2020; ).
Among the changes were a number of executive orders that affected the ability of NPs to provide telehealth services. In an August 2020 national survey by the American Association of Nurse Practitioners (AANP), respondents “overwhelmingly report[ed] that federal telehealth waivers and state policy waivers aimed at temporarily suspending practice barriers and expanding access to NP-provided care have proven highly beneficial or beneficial in fighting COVID-19” (PR Newswire, 2020). Specifically, the NP respondents named changes to telehealth reimbursement (76%) and expansion of covered telehealth services (68%) as instrumental to combatting the pandemic (Heath, 2020).
It is hoped that the extraordinary circumstances of the pandemic have shed more light on the need for a compact nation. Telehealth services, nurse staffing, and access to care will be maximally facilitated when all states and U.S. territories are a part of the NLC and APRN Compact. For telehealth services within the United States, the NLC allows nurses in compact states to communicate and provide digital and telehealth services to patients across state boundaries. Like many other changes that have resulted from COVID-19, telehealth services will continue long after the pandemic.
The importance of a clear and cohesive regulatory framework for telehealth has never been more paramount. Issues regarding licensure and patient care across international boundaries will increasingly become more prevalent and warrant development. NCSBN has targeted telehealth regulations as part of its strategic plan.
While CSCs are not routinely a consideration by nurse regulators, in the time of a pandemic, ethical decision-making by a nurse may come into question. Although many states have developed, updated, or are in the process of creating CSCs for the COVID-19 pandemic, the development of these should be a collaborative process with “broad input from the affected community” (Cleveland Manchanda et al., 2020; p. 10). For those interested in accessing their state’s CSC, links are provided in the systematic review by Cleveland Manchanda et al. (2020).
Although the extraordinary conditions of the current healthcare climate have, to some extent, led to the suspension of norms, it is in fact more vital than ever that outcomes measurement continues. Data collected and lessons learned during this time of public health crisis will have enormous implications for the future, both in terms of being better prepared for any future public health crises and in the systemic weaknesses that have now been exposed as ripe for process improvement, even in normal conditions.
The mission of nurse regulators during this time—to hold nurses to standards of professionalism, competence, and ethical practice—has not changed. Although execution of this mission takes a different form during the current public health emergency, regulators can be proactive through transparent communication with nurses in the clinical setting and positive partnership with clinical facilities.
Much of the 2020 legislative session was dominated by states’ urgent needs to respond to the pandemic. Quickly, governors and state legislatures were forced to tackle barriers to practice to address the healthcare worker shortages across the country. These barriers were addressed primarily in three ways: (1) expanding the scope of practice for select practitioners; (2) allowing for easier access to practice via telehealth; and (3) allowing out-of-state licensees to provide the urgent care that was so badly needed.
To prepare for the administration of a COVID-19 vaccine, there have been bills authorizing pharmacists to independently administer COVID-19 vaccines and tests. California recently enacted A.B. 1710 (2020), which authorized pharmacists to independently initiate and administer any COVID-19 vaccines approved by the U.S. Food and Drug Administration (FDA). Similar legislation was also enacted in New York (S.B. 8182) and New Jersey (S.B. 2436).
Additionally, telehealth has been vital during the pandemic. Most telehealth bills focus on increasing access to telehealth services, expanding the telehealth services available, and expanding insurance coverage of these services. Indeed, many telehealth bills have codified governors’ executive orders that expanded telehealth in order to ensure that access and coverage of services remain available through the duration of the state of emergency. Both Delaware (H.B. 348, 2020) and Michigan (H.B. 5412, 2020), enacted legislation that no longer requires patients be present in person before telehealth services may be used. Furthermore, New Jersey enacted Senate Bill 2467, which requires health benefits coverage for COVID-19 testing and healthcare services provided via telehealth to continue until 90 days after the emergency declaration is lifted (A.B. 2467, 2020).
In addition to expanding scope of practice and telehealth services, states have almost universally addressed their healthcare licensure laws by executive order or legislation. COVID-19 has demonstrated how critical licensure portability is during a national healthcare emergency. When a state’s COVID-19 infection rate surged, that state would be in dire need of nurses to fill staffing shortages. For many states, the answer to this problem was simple. States that are members of the NLC were immediately able to recruit nurses from out of state to assist during a COVID-19 surge. Additionally, because the NLC requires criminal background checks and 10 other universal licensure requirements, those NLC states were assured that the compact nurses were already vetted and free of any discipline when they arrived to help (NCSBN, 2015). In fact, New Jersey, which was in the midst of implementing the NLC legislation, fast-tracked the process to allow compact nurses to practice in New Jersey because they recognized what an asset the NLC is for states during a pandemic (New Jersey State Board of Nursing, 2020).
For the 2020 legislative session, the NLC increased to 34 member states, and 11 more states filed legislation to join the NLC, including two states, California and Ohio, that filed NLC legislation for the first time that year. As of October 2020, five states and the territory of Guam still had pending legislation (NCSBN, 2020e).
Many other healthcare professions have interstate licensure compacts. The Interstate Medical Licensure Compact (n.d.), a licensure compact for physicians, is currently enacted in 29 states, the District of Columbia, and Guam. Additionally, the Physical Therapy Compact (n.d.) is in effect in 28 states (Physical Therapy Compact, n.d.). The Recognition of EMS Personnel Licensure Interstate CompAct has been enacted by legislation in 21 states (Interstate Commission for EMS Personnel Practice, n.d.). The Psychology Interjurisdictional Compact (n.d.) has been enacted by 15 state legislatures. Finally, the Audiology and Speech-Language Pathology Interstate Compact (n.d.) has been enacted in 5 states and will become operational when 10 states have enacted compact legislation. The Emergency Management Assistance Compact (n.d.) granted states the ability to facilitate private telehealth, reducing the strain on their healthcare system.
While compacts have been a crucial tool for many states to address healthcare worker shortages, many other states are not currently a member of the various healthcare compacts. For this reason, almost all states issued executive orders to address licensure laws during the pandemic. Typically, orders waived licensure requirements for their state if the practitioner currently had a license in good standing in another state (NCSBN, 2020f). States differed in the way they waived these requirements; for instance, some states issued expedited licensure, others offered temporary permits to practice, and others issued nothing at all with no vetting process (NCSBN, 2020f).
Some states also codified executive orders that allowed for expedited or reciprocal licensure as well as permitted previously licensed practitioners to provide healthcare services both in person and through telehealth without meeting state licensure requirements (NCSBN, 2020f). For example, New Jersey enacted A.B. 3862 (2020) to grant expedited licenses to individuals who are currently licensed in good standing in another state. New Jersey also enacted A.B. 3901 (2020), which permits occupational licensing boards to reactivate the license of any individual who held a corresponding license in good standing at the time that the individual retired from active practice or was placed on the inactive status, within the past 3 years, during a state of emergency or public health emergency. Similarly, Wisconsin enacted A.B. 1038 (2019) authorizing former healthcare providers and healthcare providers licensed in another state to obtain a temporary credential granted by the Department of Safety and Professional Services to provide healthcare services for which they had been previously licensed.
In addition to the waivers issued by many state governments, the Centers for Medicare and Medicaid Services (CMS) also issued temporary waivers to allow providers to bill for services delivered to patients located outside of their state of licensure. CMS does not have the authority to make this waiver permanent, so it will be rescinded following the end of the federal public health emergency declaration. CMS also issued waivers regarding full practice authority for CRNAs, allowing these practitioners to practice independently of a physician and to practice to the full extent of their education and training. Additionally, under these waivers, nurse aide exams were waived, allowing those who completed the required education to enter the field without examination (CMS, 2020).
Members of Congress, in a further effort to address the challenges presented by the COVID-19 pandemic, have introduced pieces of legislation that would temporarily allow providers to practice across state lines when a public health emergency has been declared.
The Equal Access to Care Act (2020), sponsored by Senators Ted Cruz (R-TX) and Marsha Blackburn (R-TN), would allow healthcare providers to deliver telehealth services in any U.S. jurisdiction with only one license. The provider would not need to be licensed in the state where the patient is located to deliver telehealth services. It would move the location of care to the location of the provider, requiring the provider to follow the practice laws and regulations in the state where they are licensed as opposed to the state where the patient is located.
The Temporary Reciprocity to Ensure Access to Treatment (TREAT) Act (2020), sponsored by Senators Chris Murphy (D-CT) and Roy Blunt (R-MO) and Representatives Bob Latta (R-OH) and Debbie Dingell (D-MI), seeks to provide temporary licensing authority for healthcare professionals to practice in person or via telehealth anywhere in the United States with a license in good standing in only one jurisdiction during a period in which both a public health emergency has been declared by the secretary of the HHS and a national emergency has been declared by the president. This bill has taken steps to address concerns related to state-based licensure through provisions that address investigative and disciplinary concerns related to multistate practice, which clarify that providers must practice under the laws and regulations of the state where the patient is located. Providers practicing under an already-established interstate compact, such as the NLC, would not be subject to the provisions of this act. The TREAT Act has been endorsed by academic medical institutions, staffing organizations, and hospital associations (Murphy, 2020).
As of December 2020, none of these bills had yet been passed into law.
There have also been conversations regarding the role of state licensing boards in determining the qualifications of providers. Some conservative think tanks have been calling for a private certification system that would determine the quality of providers as well as the scope of practice for each level of provider (Svorny & Cannon, 2020). Those who argue for this system believe that malpractice insurance provides enough protection for patients and that reviews from patients help individuals determine which providers are safe and competent. Although these arguments have been made for many years, COVID-19 has renewed calls for a national or federal license for occupations such as nursing.
APRNs continue to play a vital role during the COVID-19 pandemic. State emergency declarations in response to COVID-19 often include temporary suspensions or waivers of practice agreement requirements for APRNs. Both NCSBN and the AANP—the largest national association of NPs of all specialties—have tracked these executive orders throughout the pandemic (AANP, 2020; NCSBN, 2020g). Outside of the 22 full practice authority states, the District of Columbia, Guam, and the Northern Mariana Islands, 21 states have issued some form of executive order relating to APRN practice.
CRNAs, with their specialty skills and critical care background, are on the front lines of caring for the sickest COVID-19 patients in rural and urban areas (Ciaramella, 2020). In states where CRNAs practice without state and federal restrictions, CRNAs were able to immediately mobilize to meet the patient surges in intensive care units (Ciaramella, 2020). Recognizing the importance of access to CRNA care at this critical time, the federal government and several state governors used emergency powers to reduce the restrictive practice environments for CRNAs. West Virginia Governor Jim Justice issued an executive order permitting the West Virginia Registered Nursing Board to suspend or modify regulations governing anesthesia administration (State of West Virginia Executive Department, 2020). In subsequent emergency rulemaking, the board suspended the requirements for supervision or presence of a healthcare provider when anesthesia is administered by a CRNA (AANA, n.d.).
Other APRN roles provided vital primary and specialty care during the pandemic, often moving their practice to a telehealth platform due to facility or state and local orders that required closure of nonessential healthcare services. In Mississippi, Governor Tate Reeves issued a proclamation on March 14, 2020, invoking the emergency powers to suspend or modify rules and regulations that would “hinder or delay necessary action in coping with the emergency” (Mississippi State Board of Nursing, 2020). The Mississippi BON subsequently complied and, on March 16, 2020, issued a proclamation that in part suspended the need for an APRN providing telehealth services in Mississippi from another state to hold licensure in Mississippi as long as they were licensed in good standing in a different jurisdiction (Mississippi State Board of Nursing, 2020). In addition, the proclamation allowed APRNs to prescribe controlled substances over telehealth without any regulations that would require an in-person visit (Mississippi State Board of Nursing, 2020).
Although various barriers were removed for APRNs practicing telehealth, many APRNs, including those in Mississippi, continue to be restricted by collaborative practice agreements with physicians in order to practice to the full extent of their education. Various states, however, took proactive steps to waive these restrictions during the COVID-19 pandemic to facilitate access to care and remove unnecessary barriers for APRNs responding to the crisis (Wilson, 2020). The policies included waiving physician collaboration or supervision entirely, waiving collaboration or supervision in certain settings or circumstances, or suspending some restrictions associated with the collaborative practice agreement (Wilson, 2020). Most of these actions took place through executive action by governors; however, in Kentucky, both legislative and executive action led to the suspension of the collaborative agreement required for APRNs to prescribe controlled substances. On March 30, 2020, the state passed legislation authorizing the Kentucky BON to relax scope-of-practice regulations (S.B. 150, 2020). Subsequently, the governor’s executive cabinet issued an order to suspend the collaborative agreements during the State of Emergency (Brown, 2020). An APRN coming to Kentucky to aid in the state’s response to COVID-19 would not need to enter a collaborative agreement with a physician in order to prescribe controlled substances as part of patient care. The greater mobility allowed by waiving these restrictions allows these crucial providers to provide care faster.
In the coming 2021 legislative session, COVID-19 and its economic and public health implications are likely to be front and center. Stakeholder groups, including those advocating for greater access to care and APRN practice issues are sure to advocate for permanent removal of these unnecessary barriers.
On August 12, 2020, the NCSBN Delegate Assembly voted to approve a new APRN Compact. The previous compact had failed to gain traction, seeing enactments in only Idaho, North Dakota, and Wyoming. The compact was short of the 10 state enactments needed for the compact to become effective, and no state had enacted the legislation after the 2017 legislative session. One of the key roadblocks for success was the continued variation among state laws and regulations governing APRN practice. Although states are moving toward adoption of the Consensus Model for APRN Regulation (Consensus Model), state-specific issues and political compromises often result in variations in APRN regulation and practice across the states. A taskforce appointed by NCSBN’s Board of Directors was formed to explore the roadblocks to the APRN Compact’s success and make recommendations for a way forward.
The three major changes in the newly adopted APRN Compact include (1) reducing the number of state enactments needed for the compact to become effective; (2) codifying elements of the Consensus Model into the compact’s uniform licensure requirements (ULRs); and (3) requiring 2,080 hours of clinical practice before eligibility for a multistate license (NCSBN, 2020h).
It is common for compacts to set a threshold number of states needed before a compact becomes effective (National Center for Interstate Compacts, n.d.). The newly adopted compact requires seven states to enact the legislation before the compact goes into effect—a decrease from 10 states in the previous compact legislation. This reduction will allow for APRN licensure mobility to become effective sooner while additional states work toward enactment (NCSBN, 2020h).
ULRs set the minimum requirements needed for a practitioner to obtain a multistate license. Like the NLC, the APRN Compact provides for ULRs, which include meeting the home state licensure requirements, submitting to a federal criminal background check, not having any felonies or any misdemeanors related to the practice of nursing, and not currently participating in an alternative-to-discipline program (NCSBN, 2015). The ULRs specific to the APRN Compact include codifying elements of the Consensus Model, such as graduate education, RN licensure, licensure in one of the four APRN roles and population foci, national certification, and passage of a national certification examination (NCSBN, 2020h). In addition to assuring multistate licensees meet the same uniform standards to practice under the compact, the ULRs provide added transparency to lawmakers and the public and further advance the elements of the Consensus Model.
In addition to the ULRs above, the newly adopted APRN Compact requires all applicants for multistate licensure to have “practiced for at least 2,080 hours as an APRN in a role and population focus congruent with the applicant’s education and training” (NCSBN, 2020h). The practice hour requirement was inserted into the APRN Compact as a response to states, beginning in 1995, adopting into statute what are referred to as “transitions-to-practice” for newly licensed APRNs (ANA, 2020). These transitions generally require an APRN to have a set number of hours or years of practice under a supervisory or collaborative relationship with a physician prior to independent practice. The transitions are predominately negotiated during the legislative process by stakeholder groups to appease physician groups and legislators opposing a full practice bill—there is no evidence that they increase safety or quality of APRN care (ANA, 2020). The APRN Compact looks to address this growing policy trend with a practical compromise—2,080 hours of practice (without requiring physician supervision or collaboration) in order to be eligible for a multistate license.
As the COVID-19 pandemic increases calls for licensure mobility for both in-person and telehealth practice, state legislatures are likely to consider the APRN Compact in the upcoming 2021 legislative session (Wilson, 2020).
Strides forward and some troubling precedents were outcomes of enacted APRN legislation in the 2020 legislative session. Bills in Colorado, South Dakota, and Virginia succeeded in further adoption of the Consensus Model. In Colorado, House Bill 1216 carried the nursing sunset review recommendations. The bill modernized the Colorado “advanced practice nurse” title to “APRN” and reduced the number of transition hours needed for a Colorado APRN from 1,000 to 750 (H.B. 1216, 2020). South Dakota continued its success in granting full practice authority to APRN roles. Senate Bill 50 was championed by Senator Deb Soholt, the lawmaker who carried the 2017 legislation that granted full practice authority for CNPs and CNMs and removed regulatory authority of the roles from the state’s board of medicine. Senate Bill 50 removed restrictive collaborative agreements with physicians that were required of CRNAs and expanded their prescriptive authority (S.B. 50, 2020). The CRNAs also had a legislative victory in Virginia, where Senate Bill 264 granted prescriptive authority to CRNAs, a practice other APRNs had been previously granted. Although the practitioners remain under physician supervision in Virginia, the bill will increase access to care for those patients needing anesthesia services (Code of Virginia, 1991/2020).
Progress was also made in Florida in the 2020 session, though its potential was stunted by late-session amendments. The legislation in Florida advanced through the State House of Representatives as a priority bill of then-House Speaker Jose Oliva. Despite strong support in the house, the bill took on troubling amendments in the Senate that will lessen the benefits of APRN full practice authority for Florida’s patients, healthcare workforce, and economy. House Bill 607 created a path for APRNs to apply for “autonomous practice” by meeting specific education and discipline requirements as well as a 3,000-hour transition period (H.B. 607, 2020). The bill was limited to apply to only those APRNs engaged in “primary care practice” and CNMs. Pending administrative rulemaking and the impact of a new council composed of both physicians and APRNs, the impact of the bill is unknown but will surely reveal that additional work is needed to move Florida toward full consensus.
In California, Assembly Bill 890 was signed into law in late September 2020. The bill, a multiyear effort carried by Representative Jim Wood, was introduced as a full practice authority bill for NPs in the state, but it quickly took on troubling amendments (A.B. 890, 2020). One such amendment established a Nurse Practitioner Advisory Committee comprised of four CNPs, two physicians, and a public member (A.B. 890, 2020). The Committee is charged with making recommendations to the BON on matters pertaining to CNPs, including disciplinary matters (A.B. 890, 2020). Although it created a pathway for CNPs to practice without physician oversight, the CNPs must complete a 3-year transition period, and those CNPs who own their own business or practice in a CNP-owned business must complete an additional 3 years under physician oversight (A.B. 890, 2020). Additionally, the possibility exists for CNPs in the state to be required to take a state-based examination in order to be licensed—a first-of-its-kind statute. The California Office of Professional Examination Services is tasked with conducting an analysis to determine whether there are CNP competencies that are needed to perform their scope of practice in the state that the national certification examination does not adequately evaluate. If those are found, the Office of Professional Examination Services shall “identify and develop a supplemental exam that properly validates identified competencies” (A.B. 890, 2020).
Troubling provisions in these bills are sure to surface from physician groups opposing APRN full practice legislation. Stakeholder groups supporting greater access to care by removing barriers to APRN practice will need to be ready to combat these proposals and look to the successes in Colorado, South Dakota, and Virginia, which have moved APRN progress forward in 2020.
Continuing a trend from the past few years, several states in the 2020 session enacted legislation to expedite the occupational licensure process for military spouses. Upon frequent relocation, military families are faced with countless burdens, chief among these being both the financial and administrative burden of applying for a new occupational license (National Military Family Association, n.d.). By enacting legislation that expedites the licensure process, allows for licensure by endorsement, or provides for temporary licensure for members of the military and their spouses, military families will no longer face an unnecessary delay to their healthcare practice when relocating to a new state.
In July 2020, North Carolina enacted H.B. 1053, which required that an occupational licensing board issue a license or notify an applicant that their experience and training do not satisfy the licensure requirement no later than 15 days after an application from a military spouse is received (H.B. 1053/SL2020-87, 2020). With more than 100,000 activity-duty military personnel residing in North Carolina as of June 30, 2020, such legislation is crucial to ensure that relocation does not result in economic strain and unemployment for military families (Department of Defense, 2020). Seven other states (Georgia, Kentucky, Louisiana, Mississippi, Ohio, South Carolina, and Virginia) also enacted similar legislation in 2020 to ease the licensure process for military spouses (H.B. 914, 2020; H.B. 357, 2020; H.B. 613, 2020; S.B. 2117, 2020; S.B. 7, 2020; S.B. 455, 2020; S.B. 981, 2020).
Because SAMHSA data do not reflect real-time changes in opioid use, it is difficult for researchers to know the true extent to which the COVID-19 pandemic has affected the opioid epidemic. However, a number of indicators suggest the pandemic has exacerbated what SAMHSA data indicate was already a growing problem. Studies comparing random drug test samples during the 4 months before the national emergency declaration in March 2020 and the 4 months after it found increases in both fentanyl and heroin among the samples, although researchers acknowledged that the nature of the sample—those at risk for drug use—may not accurately reflect the entire population (Wainwright et al., 2020; Millennium Health, 2020). One hospital emergency room saw opioid overdose cases more than double when comparing March–June 2019 to March–June 2020 (Ochalek et al., 2020). More than 40 states have reported increases in opioid-related deaths (AMA, 2020). Haley and Saitz (2020) suggest that while these and other circumstantial indicators point to an adverse effect on the opioid epidemic by COVID-19, “a more definitive answer … will require linked patient data (before and after COVID-19) to examine changes in an individual’s substance use or overdose over time.”
Anecdotally, researchers have noted the many dangerous factors that increase vulnerability to OUD during the pandemic, including the isolation of social distancing and the economic uncertainty as many businesses reduce their personnel or close entirely, as drug use typically increases during economic downturns (Nagelhout et al., 2017). Treatment facilities may have closed, and those vulnerable to OUD may also fear risking exposure to the virus to seek treatment for their disorder (Weiner, 2020). Furthermore, “individuals with a [SUD] are more likely to experience homelessness or incarceration than those in the general population, and these circumstances pose unique challenges regarding transmission of the virus that causes COVID-19” (Volkow, 2020). In addition to the heightened danger of overdose, recent evidence suggests that COVID-19 patients with SUD face a heightened risk of both hospitalization and death from the virus due to the effect of opioids on respiratory and pulmonary health (Volkow, 2020; Wang et al., 2020). The National Academy of Medicine released a statement noting that individuals with SUD “are among the most at risk and susceptible to COVID-19, and their care and treatment are among the most disrupted by physical distancing and other measures that have been put into place to prevent the spread of the virus” (National Academy of Medicine, 2020).
The declaration of the COVID-19 public health emergency triggered the allowance for the expanded use of telemedicine in prescribing controlled substances for the duration of the emergency. The U.S. Drug Enforcement Administration (DEA) outlined conditions that must be met in order to prescribe controlled substances in the absence of an in-person medical evaluation, including that the prescription is issued for a legitimate medical purpose by a practitioner acting in the usual course of his/her professional practice, that telemedicine communication is conducted using an audio-visual, real-time, two-way, interactive communication system, and that the practitioner is acting in accordance with applicable federal and state laws (DEA, 2020).
SAMHSA and the DEA provided increased flexibility for clinicians providing buprenorphine and methadone to patients with OUD during the COVID-19 pandemic (AMA, 2020). The DEA issued a letter “informing qualifying practitioners that beginning March 31, 2020, during the public health emergency, buprenorphine can be prescribed to new and existing patients with OUD for maintenance or detoxification treatment on the basis of a telephone evaluation” (Prevoznik, 2020). A decision tree was developed by the DEA that was intended to help DEA-registered practitioners prescribe controlled substances without having to interact with their patients. The DEA notes that the “chart only addresses prescribing controlled substances and does not address administering or direct dispensing of controlled substances, including by narcotic treatment programs or hospitals” (DEA, 2020).
The National Academy for State Health Policy featured several state strategies that support providers in increasing telehealth access for providing OUD treatment during COVID-19. They note:State policymakers are quickly restructuring OUD treatment, including the administration of medications for opioid use disorder that include buprenorphine and methadone, and addressing barriers to telehealth for OUD by coordinating with providers to streamline processes and adapt to a rapidly changing landscape in accordance with federal guidance (Long, 2020).


Haley and Saitz (2020) point out that many of the changes in care delivery brought about by various emergency orders might also be instrumental in mitigating the opioid epidemic. The emergency expansion of Medicaid, changes to methadone dispensing to reduce social contact (allowing patients to take home several weeks’ worth of doses instead of being observed receiving a dose directly each day), and expansion of telehealth, among other changes, all promote access to care and remove barriers to use disorder treatment. “COVID-19,” the authors write, “has ushered in the introduction of policies that, if made permanent, have the potential to not only mitigate the effect of the COVID-19 pandemic on overdoses, but also address long-standing structural barriers to accessing proven treatments” (Haley & Saitz, 2020).
The federal government initiated several programs that address the opioid epidemic, including increasing funding, mandating electronic prescribing of opioids, and requiring labeling and prescription of opioids to include recommendations for naloxone.
The Substance Use-Disorder Prevention that Promotes Opioid Recovery and Treatment (SUPPORT) for Patients and Communities Act of 2018 mandated a move toward electronic prescribing with the intention of deterring fraud and allowing better tracking through prescription drug monitoring programs. Clinicians will be required to electronically submit prescriptions for opioids covered by Medicare’s Part D pharmacy benefit starting January 1, 2021. According to a CMS request for information, a significant number of clinicians may be unprepared for this transition, despite significant progress in the electronic prescribing of controlled substances. In a published report of 2019 data on prescribing activities across the United States, CMS noted that “97% of U.S. pharmacies were capable of processing electronic prescriptions for controlled substances, yet only 49% of prescribers were capable of electronically prescribing controlled substances” (Young, 2020).
In a drug safety communication, the FDA (2020a) recommended that healthcare professionals discuss naloxone with all patients when prescribing opioid pain relievers or other medicines to treat OUD. The FDA (2020a) also requires that:…labeling for opioid pain medicine and medicine to treat [OUD] be updated to recommend that as a routine part of prescribing these medicines, health care professionals should discuss the availability of naloxone with patients and caregivers, both when beginning and renewing treatment.

Additionally, the FDA requires that the new labeling requirements be applied to manufacturers of OUD treatments, including buprenorphine, methadone, and naltrexone (FDA, 2020b).
Recent cannabis legislation, the Secure and Fair Enforcement Banking Act of 2019 (2019–2020) and the Marijuana Opportunity Reinvestment and Expungement (MORE) Act of 2019, have stalled in Congress this year. The MORE Act of 2019 seeks to decriminalize marijuana by removing marijuana from the list of scheduled substances under the Controlled Substances Act and eliminating criminal penalties for an individual who manufactures, distributes, or possesses marijuana. The bill, which was introduced in July 2019 and moved through various committees, seeks to make other changes, including to:•replace statutory references to marijuana and marihuana with cannabis
•regularly publish demographic data on cannabis business owners and employees•establish a trust fund to support various programs and services for individuals and businesses in communities impacted by the war on drugs•impose a 5% tax on cannabis products and require revenues to be deposited into the trust fund•make Small Business Administration loans and services available to entities that are cannabis-related legitimate businesses or service providers•prohibit the denial of federal public benefits to a person based on certain cannabis-related conduct or convictions•prohibit the denial of benefits and protections under immigration laws based on a cannabis-related event (e.g., conduct or a conviction) and establish a process to expunge convictions and conduct sentencing.

Occupational hazards are often some of the environmental factors related to the causation of SUD in nurses. In the healthcare setting, some well-known occupational hazards may influence the nurse, including role strain, lifestyle disruption due to work schedule, and access to prescription medications (Bettinardi-Angres, Pickett, & Patrick, 2012).
The COVID-19 pandemic has certainly increased the occupational hazards for nurses. Healthcare workers, especially nurses, have been challenged during this pandemic with the unprecedented influx of patients and their acuity, multiple simultaneous treatment modalities, increased complexity of care, uncertainty of the duration and progression of the disease process, grim patient prognosis, and subsequent deaths (Caroselli, 2020). The added stress, fear, and anxiety associated with the COVID-19 pandemic and with caring for those with COVID-19 may be just the influencing factor to cause a relapse of SUD or entry into SUD.
Some nursing leaders met the challenge to care not only for their patients but also to care for their staff, providing emotional support, celebrations and rewards, ethical decision-making discussions, formalized referrals for assistance, and sometimes just a “listening ear” (Caroselli, 2020). However, others may not have been able to meet that additional challenge.
Acknowledging the challenge for nurses and nursing leaders alike, the ANA provided a variety of resources to assist nurses and other healthcare providers with mental health resources and later created their Well-Being Initiative (ANA Enterprise, 2020) with the goal of providing free tools to support the mental health and resilience of all nurses.
Once the COVID-19 pandemic has passed, the mark left on healthcare workers may not disappear. Many who cared for COVID-19 will suffer from post-traumatic stress disorder. Nurses have been “first in line facing the clinical challenges intrinsically linked to the course of the disease while under the constant personal threat of being infected or representing a source of infection” (Carmassi et al., 2020). Timely response to this psychological pressure on nurses in order to prevent negative mental health outcomes such as SUD requires development of specific intervention strategies.
The COVID-19 pandemic has greatly impacted the nursing workforce, nursing education, healthcare delivery, policy and legislative issues, and social issues.

Nursing Workforce. COVID-19 has exposed a need for increased workforce data collection, planning, and mobility. The pandemic has highlighted the critical need for a flexible and mobile nursing workforce, which requires state and national workforce databases to be current and comprehensive. Research, policy, and public health stakeholders will expect this type of real-time data that can assist in deploying nurses during future emergencies. BONs may begin to feel increasing pressure to add workforce data collection to their licensure renewal processes.

Nursing Education. Stronger collaboration between academia and clinical practice, which were needed prior to the pandemic, needs to be fostered to help develop innovative and flexible methods that allow students to continue their education. The practice-academic partnerships that permit students to serve as support staff in healthcare facilities, receive payment, and earn academic credit serve as a model example of education and practice becoming true academic partners.
Nursing educators and regulators have an opportunity to examine novel methods of educating students during the pandemic. Regulators will need to be prepared to make future decisions involving increased reliance on virtual simulation and high-fidelity simulation rather than traditional clinical experiences. Further research is needed to help support these strategies, but the time to co-create a new world order within nursing education may be at hand (Barton et al., 2020; Fauteux, 2020).

Healthcare Delivery. The number of disproportionate cases of COVID-19 affecting minority and disadvantaged populations shines a light on the shortfalls of the U.S. healthcare delivery system. Addressing the social determinants of health must become part of standard practice. Patient access to care, chronic condition management, and fulfilling basic needs such as food and housing needs greater attention (Blumenthal et al., 2020).
The need for a compact nation has been evident during these extraordinary circumstances of the pandemic. Telehealth services, nurse staffing, and access to care can only be fully facilitated when all states and territories are a part of the NLC and APRN Compact. It is expected that telehealth services will continue long after COVID-19; thus, a clear and cohesive regulatory framework for telehealth is vital. Solutions to the increasingly prevalent issues surrounding licensure and patient care across international boundaries are needed.
It is more vital than ever to continue measuring outcomes despite the suspension of norms due to COVID-19. Data collection and subsequent analysis should better inform, improve, and prepare the healthcare system for any future public health crises.
Holding nurses to standards of professionalism, competence, and ethical practice has not changed during the pandemic. Yet, the situation remains a public health emergency and regulators help by communicating transparently with nurses and creating positive partnership with clinical facilities.

Legislation and Policy Issues. In the beginning of 2020, the occupational licensing conversation focused on licensure reform, particularly criminal justice reform, reducing regulatory barriers to employment, and state legislation related to universal licensing aimed at improving portability (Carpenter, 2020; Peterson & Slabinski, 2020; Arnold, 2020). COVID-19 shifted the focus to licensing issues and how to get nurses to go where they were needed the most. State emergency declarations included temporary suspensions or waivers of practice agreement requirements for APRNs. Additionally, the NCSBN Delegate Assembly approved a new APRN Compact Model Act, and three states adopted the Consensus Model.
In the coming 2021 legislative session, the economic and public health impacts of COVID-19 are likely to be paramount. Stakeholders advocating for greater access to care are sure to promote the permanent removal of unnecessary barriers. To triumph over COVID-19 and to surmount future healthcare issues, nurses—who have made highly valuable academic, clinical, and leadership contributions during the COVID-19 crisis—need to have “a stronger voice in influencing future policy and practice” (Bennet, James, & Kelly, 2020, p. 2754).

Social Issues Impacting the Nursing Workforce and Regulation. The COVID-19 pandemic has undoubtedly placed nurses in harm’s way. Nurses are challenged with the unprecedented number of patients who present with dire and complex care needs. Stress, fear, and anxiety associated with being infected or representing a source of infection and with caring for patients may lead to a relapse of SUD or entry into SUD. COVID-19 will leave an indelible mark on healthcare workers. Timely intervention strategies for the psychological pressure on nurses are needed to help prevent negative mental health outcomes such as SUD.
Nurses, nurse educators, regulators, legislators, and many others have worked tirelessly to address the numerous challenges present by the COVID-19 pandemic. We learned that being prepared and having systems and resources ready to meet a public health crisis is vital (Benton et al., 2020). As vaccines begin to rollout, there will be a gradual return to everyday life; however, nurses, regulators and educators will be forever changed. COVID_19 will have a lasting impact on all dimensions of health care.
A review of position statements, practice statements, clinical practice advisories, advisory/declaratory rulings, advisory opinions, and interpretive guidelines developed by boards of nursing (BONs) was conducted. Eight states (Kentucky, Nevada, Ohio, Oklahoma, Oregon, South Carolina, Texas, and Washington) revised or adopted new statements on the role and scope of practice of the RN. Six states (Arizona, Idaho, Nebraska, Ohio, South Carolina, and West Virginia) adopted or revised rulings/opinions related to administration of sedation, anesthesia, or analgesia. Five States (Nevada, Oregon, South Carolina, Texas, and Washington) made changes to LPN/LVN scope of practice by revising or adopting statements on the topic. Five states (Arizona, Colorado, Kentucky, Oregon, and South Carolina) amended statements/opinions on the role and scope of practice for advanced practice registered nurses (APRNs). The purpose of these guidance documents is to provide direction to practicing nurses. They reflect the decisions made by the BONs regarding specific nursing practice concerns. BONs can review the existing guidance documents with the intent of anticipating any emerging issues and trends that may affect their BON in the upcoming year.
The following is a list of the position/practice statements, clinical practice advisories, advisory/declaratory rulings, advisory opinions, and interpretive guidelines issued or revised by BONs between October 2019 and September 2020:
Arizona•Adopted the following advisory opinions: Administration of Radioisotope for Subtraction Ictal SPECT Co-Registered to MRI (SISCOM), APRN Care for Transsexual, Transgender, and Gender Nonconforming Populations, Auricular Acupuncture, Administration of Intrapleural Medications, Sedation: Deep, Moderate, Palliative and Analgesia•Revised the following advisory opinions: Nitrous Oxide Administration, Intraventricular Implanted Devices Temporary Intracranial Catheters, Ketamine Administration, Nitrous Oxide Administration, Peripherally Inserted Central Catheter (PICC) Insertion, Suturing, Maintenance, Removal & Verification of Tip Placement, Scope of Practice Decision Tree, Sheath Removal, Placement of Mechanical Compression Devices, & Deployment of Vascular Closure Devices

Arkansas•Adopted the following position statement: Role of the Licensed Nurse in Nurse Driven Standing Orders Working in Hospitals That Have Adopted and Are Subject to the Center for Medicare and Medicaid Conditions of Participation

Colorado•Adopted the following rule: Guidance to Physicians/Dentists/Advance Practice Nurses Who Make Medical Marijuana Recommendations, in Light of Executive Action Taken Pursuant to COVID-19

Connecticut•Adopted the following declaratory ruling: Scope of Practice for School Nurses to Adjust Insulin Doses for School Children With Parental Input

Georgia•Adopted the following position statement: Telephonic Nursing

Idaho•Adopted the following position statement: Certified Registered Nurse Anesthesiologist Title

Kentucky•Approved the following advisory opinion: Telehealth and Nursing•Revised the following advisory opinions: Resuscitation Orders, Pronouncement of Death, and Death Certificates, Scope of Registered Nursing Practice in the Deactivation of Implanted Cardioverter Defibrillators (ICDS) and Ventricular Assist Devices (VADS), Nurses Practicing in the Perioperative Setting, School Nursing Practice, Implementation of Patient Care Orders, Supervision and Delegation of Nursing Tasks to Unlicensed Personnel, Administration of “PRN” Medication and Placebos•Posted the following practice opinions: APRNs – Cannabidiol or CBD Oil, Scope of Practice APRN CRNAs in the Independent Practice of Cosmetic and Dermatologic Procedures, Scope of Practice of an RN in the Removal of Scope of Practice of an RN in the Removal of a Laryngeal Mask Airway (LMA), Scope of Practice of Nurses in the Removal of Chest Tubes, Role of Nurses in the Placement of Arterial Lines

Maine•Released the following statement on Prescribing Chloroquine, Hydroxychloroquine, and Azithromycin

Missouri•Revised the following position statement on Patient Abandonment

Nebraska•Adopted the following advisory opinion: Safe Practice: Fitness to Practice•Revised the following advisory opinions: Patient Abandonment, Analgesia/Anesthesia by Catheter, Nurse’s Accountability to Perform Cardiopulmonary Resuscitation, Sub-Anesthetic Ketamine, Team-Based Nursing Care Services, Verbal Orders, Wound Debridement

Nevada•Adopted the following practice decisions: Role of the RN in Intubation, Role of the RN in Thrombolytic Therapy, LPN Scope of Practice Regarding Suprapubic Catheter Replacement

North Carolina•Adopted the following joint position statement: Alternative Practice Settings for EMS Personnel•Revised the following position statements: Complementary Therapies, Infusion Therapy/Insertion/Access Procedures, Medication Aide Education & Role in Long Term Care/Skilled Nursing Facilities vs Adult Care Settings, Staffing and Patient/Client Safety

North Dakota•Approved the following guidance statement: Role of the Licensed Nurse in Aesthetic Practices•Revised the following practice guidance statements: Safety to Practice, Temporary Reassignment, Sexual Assault Forensic Examination Procedure

Ohio•Adopted the following joint statement: Nurses and Emergency Use of Naloxone•Revised the following interpretive guidelines: Guidelines for Registered Nurse Filling and Un-filling a Patient’s Gastric Band, Registered Nurse Care of Patients Receiving Intravenous Moderate Sedation for Medical and/or Surgical Procedures, Registered Nurse Role in Emergency Intubation Performed by an Authorized Provider, Registered Nurse Role in the Care of Patients Undergoing Exercise Cardiac Stress Training, Registered Nurse Role in the Care of Patients Receiving Intravitreal Injectable Medications

Oklahoma•Revised the following position statements and guidelines: Licensure Verification of Nursing Licenses, Patient Assessment Guidelines, Placement of Nasogastric Tubes by Registered Nurses in Post Bariatric of Anatomy Altering (Upper Gastrointestinal Tract and Stomach) Surgical Patient Guidelines, Policy on Names

Oregon•Approved the following interpretative statements: Clinical Education Roles and Responsibilities for Clinical Faculty and Nursing Staff at Clinical Facilities, Counseling Clients About the Use of Marijuana (Including CBD Oil) for the Alleviation of Symptoms Related to Illness or Injury, “Delegation Process” and “Assignment and Supervision,” APRN Scope of Practice Decisioning Algorithm•Amended the following interpretive statements: Foot Care Provided by the Registered Nurse, Foot Care Provided by the Licensed Practical Nurse, Practice Requirements for the Licensed Practice Nurse, Registered Nurse & Advanced Practice Registered Nurse

South Carolina•Approved the following position statements: Practicing at Level Other Than Highest Licensure/Approval/Recognition for RN, LPN, and APRN Practice•Formulated the following advisory opinions: Registered Nurse (RN) Scope and Role when Assisting Physician With Injecting Botox, Role and Scope of Registered Nurse (RN) in Regards to Precepting Emergency Medical Technicians (EMTs) and Paramedics (AEMT) During Student Clinical Training•Revised the following advisory opinions: Scope of Practice of Licensed Nurse Performing Acupuncture, Role and Scope of Practice of a Registered Nurse (RN) or Licensed Practical Nurse (LPN) Practicing in a School Setting to Train Unlicensed School Personnel for Assisting Students with Medications Taken on a Routine Schedule, Role and Scope of Responsibilities of Unlicensed Assistive Personnel to Perform Digital Intervention for Treatment of Fecal Impaction, Role and Scope of Responsibilities of Licensed Practical Nurse (LPN) to Evaluate and/or Stage Vascular, Diabetic/Neuropathic of Pressure Ulcers, Registered Nurse (RN) Performing Endotracheal Intubation and/or Insertion of a Supraglottic Airway in an Emergency Situation, Registered Nurses (RN) Performing Duties of Registered Nurse First Assistant (RNFA) in the Operating Room Setting, Can a Registered Nurse (RN) Determine if a Patient is in Labor, Registered Nurse (RN) Role and Scope in Regards to Administering Pharmacological Agents Intravenously for Sedation•Revised the following joint advisory opinion: Regarding the Presence of a Pharmacist in a Methadone Clinic with Nurses During Dosing Hours

Texas•Revised the following position statements: LVNs Engaging in Intravenous Therapy, Venipuncture, or Peripherally Inserted Central Catheter (PICC) Lines, Role of LVNs &RNs in Management and/or Administration of Medications via Epidural or Intrathecal Catheter Routes, Nurses Carrying Out Orders From Pharmacists for Drug Therapy Management, LVN Role in Pronouncement of Death, LVN Scope of Practice, RN Scope of Practice

Vermont•Revised the following position statement: Role of the Nurse in Delegating Nursing Interventions

Virginia•Adopted the following guidance document: Practice of Conversion Therapy•Reaffirmed the following guidance document: Attachment of Scalp Leads for Internal Fetal Monitoring

Washington•Adopted the following interpretive statement: Clarification on Opioid Prescribing Rules•Adopted the following advisory opinions: Death with Dignity (Aid-in-Dying): Role of the Nurse, Delegation of Blood Glucose Monitoring to Nursing Assistants or Health Care Aides in Community-Based Settings, Registered Nurse (RN) and Licensed Practical Nurse (LPN) Scope of Practice, Naloxone Prescribing Clarification, Role of the Nurse in Supervised Injection Services (SIS) Facilities

West Virginia•Revised the following position statement: Administration of Anesthetic Agents

Wyoming•Approved the following advisory opinions: Practice During COVID-19 Declared State of Emergency, Temporary Permits During COVID-19 Declared State of Emergency, Emergency Direct Care Worker, Nursing and Electronic Delivery of Care, Emergency Direct Care Worker
",J Nurs Regul
PMC7809533,Age is not the only risk factor in COVID-19: the role of comorbidities and of long staying in residential care homes,"The COVID 19 outbreak represents an historically unprecedented pandemic, particularly dangerous and potentially lethal for elderly population. Since the beginning of the actual SARS-CoV-2 outbreak it was evident that older people, compared to younger ones, were at higher risk to get the infection and to develop a more severe disease with unfavorable prognosis. In Italy, the National Healthcare Service, registered 418,142 total cases of COVID-19 and 39,412 deaths, as of November 3, 2020 [1]. The mean age of patients that died was 80 years, at least 20 years higher than that registered in infected people. The majority of those who are infected, that have a self-limiting infection and do recover are, in fact, younger. Conversely, those that suffer a more severe disease, that require intensive care unit admission and eventually pass away are older [2, 3].
Many reports indicate that elderly patients with COVID-19 are more likely to progress to severe disease compared to young and middle-aged ones [2]. These observations have a particular and relevant negative impact in Europe. Of the top 30 countries with the largest percentage of older people, all but one (Japan) are States in Europe and Italy is considered “a country of old people” because the life expectancy is over 80 years of age [4]. The situation is critical in the long-stay residential care homes (LSRCHs), where many elderly people and people with disabilities and severe cardiovascular and neurological diseases live all together in close contact, facilitating the dynamics of virus transmission. Residents in LSRCHs are a vulnerable population group and it has been reported that the proportion of COVID-19 cases who have died in these LSRCHs has exceeded 60% of all reported deaths [5].
In a recent report by the Organization for Economic Cooperation and Development (OECD) [6] over 75,000 deaths have been registered across 13 European countries amongst residents in long term care institutions (as of early October 2020), accounting for almost half of the total deaths caused by COVID-19. In Italy there are more than 3000 of such facilities, with 186,872 beds. That is why the Istituto Superiore di Sanità (ISS) launched a National survey on COVID-19 infection in LSRCHs, to monitor the situation and to solicit special strategies against spreading of infection [7]. The results of this Survey have been described in a final report posted on May 5th 2020 [8]. The data obtained from a total of 3292 LSRCHs in different Italian regions indicated that the mortality rate of patients, with proved infection plus those with symptoms that suggested positivity, was equal to 3.1%, but, in some regions, it reached the value of 6.5%. The main problems reported by the personnel in facing the pandemic were related to the difficulties in isolating the positive patients and in transfer the critical ones to the hospital. In addition, they complained about the scarcity of tests, adequate information and personal protective equipment.
However, despite the huge amount of data on COVID-19 worldwide, the reasons why older people are at significantly increased risk of severe disease following infection from COVID-19 are not clear. Age could not be the only risk for severe disease. It has been reported that people in their teens or twenties may develop a severe form of the disease, may require intensive care and may die as well [9]. On the other side, people who age healthily seems to be less at risk. Besides the physiological changes associated with ageing, other factors could be involved, including the decreased immune function and the occurrence of multimorbidity [10].
To date there is little information on COVID-19 in patients over 80 years of age. Therefore, in this study, we focused our attention on very elderly population (> 80 years of age) [11, 12] that referred to our University Hospital during the actual SARS-CoV-2 outbreak and we have analyzed the differences between elderly people and very elderly ones. Our aim was to try to figure out the reason why elderly and very elderly people are more prone to be infected and to develop a more severe form of the disease. We considered clinical aspects, presence of comorbidities, laboratory and radiological findings as well as their outcome, including the length of stay, mortality and viral shedding in nasal/oropharyngeal swabs.
This is a single-center, retrospective study performed in the Sant’Andrea University Hospital of Rome. We included patients older than 65 years of age with a diagnosis of COVID-19 from March 2020 to May 2020. The diagnosis was based on the Chinese Clinical Guidance For COVID-19 Pneumonia Diagnosis and Treatment published and updated by the National Health Commission of China (NHFPC, 2020). All the COVID-19 patients had either positive real-time reverse transcription polymerase chain reaction (rRT-PCR) from respiratory samples [13] or positive serological test of specific IgM antibody to SARS-CoV-2. Eighty-one patients were divided into two groups according to their age. Forty-one patients with ages ranging from 65 to 79 years were included in Elderly Group, the remaining forty patients with ages > 80 years were included in group named Very Elderly.
Data extracted from the each patient record included age, sex, comorbidities, symptoms at onset, the Pneumonia Severity Index (PSI), the ratio of the partial pressure of oxygen in arterial blood (PaO2) to the inspired oxygen fraction (FiO2) (P/F) on admission, laboratory tests, radiological findings on computer tomography (CT), length of hospital stay (LOS), mortality rate and the viral shedding.
We analyzed several different serum markers of systemic inflammation and sepsis, including the neutrophil to lymphocyte ratio (NLR), the Platelets to Lymphocytes Ratio (PLR), the pro-calcitonin (PCT) and the high-sensitive C-Reactive Protein (hs-CRP).
Chest CT were obtained on a 128-slice scanner (GE Revolution EVO CT Scanner, GE Medical Systems, Milwaukee, WI, USA), with patients in supine position and during end-inspiration, without iodinated contrast medium injection. The following technical parameters were used: tube voltage: 120 kV; tube current modulation: 100–250 mAs; spiral pitch factor: 0.98; collimation width: 0.625. Images were reconstructed with a sharp convolution kernel (BONEPLUS) at a slice thickness of 1.25 mm.
DICOM data have been transferred onto a PACS workstation (Centricity Universal Viewer v.6.0, GE Medical Systems, Milwaukee, WI, USA) and independently evaluated by two expert radiologists, using a dedicated software (Thoracic VCAR v13.1, GE). Only imaging features related to COVID-19, according to the most recent literature [14, 15] have been considered valid for image analysis.
Length of stay and death were both analyzed.
During hospitalization, an RT-PCR assay was conducted every other day after the remission of clinical symptoms or radiography of patients, and the corresponding date was recorded. The duration of viral shedding was defined as the number of days from the onset of the symptoms until the successive negative detection of SARS-CoV-2 RNA, which was consistent with other studies of COVID-19 [16, 17].
Continuous variables were summarized as either means and standard deviations. Categorical variables were described as frequencies and percentages. The differences between the two groups were analyzed by the Fisher’s exact test or the Wilcoxon signed-rank test for categorical variables and the Mann-Whitney U test for continuous variables. We performed pairwise comparisons with a Bonferroni correction for multiple comparisons. The statistical adjusted significance was accepted at the adjusted p value < 0.0008.
The survival time was estimated by Kaplan-Meier method and Log Rank Test. Univariable Cox proportional hazard regression was performed to estimate associations between age, comorbidities and provenance from LSRCHs and clinical outcomes of mortality. Hazard ratios (HR), odds ratio (OR) and 95% confidence intervals (CI) were reported. A p < 0.05 was considered statistically significant. Age, comorbidities and provenance from residential care homes were used as predictors in a multivariable logistic regression model, with a binary outcome (mortality). Two model were created (Model 1: all of them; Model 2: only age). Calibration of agreement between the predicted and observed probabilities was assessed using the Hosmer-Lemeshow goodness-of-fit test, indicating a poor fit for p < 0.05.
All analyses were performed using the GraphPad Prism software (version 8.4.1) (GraphPad Software, San Diego, CA).
A written informed consent was obtained by participant to the study. The study was approved by our Institutional Ethical Committee (Sapienza University of Rome, Italy) (Prot.# 52SA_2020, RIF. CE 5773_2020), on the basis that it complied with the declaration of Helsinki and that the protocol followed existing good clinical practice guidelines.
A total of 81 consecutive patients, referred to our hospital for COVID-19 and identified as laboratory-confirmed SARS-CoV-2 infection, have been included in the study. They were 37 men and 44 women. Their median age is 79.7 years (ranging from 65 to 94 years). Demographic and clinical characteristics are listed in Table 1. On admission, most patients had shortness of breath (61%). There were differences in cough and fever between two groups. Both the respiratory scores (P/F and PSI) were higher in Very Elderly patients.

Among comorbidities, the more representative were neurological and cardiovascular diseases. The incidence of both were more in Very Elderly patients.
All data obtained from Laboratory results are resumed in Table 2.

All of our COVID-19 patients, showed normal values of red blood cells (RBC), white blood cell (WBC) and platelets (PLT), measured on admission. Among the different serum markers of systemic inflammation and sepsis measured, we observed a higher value of the NLR and hs-CRP in Very Elderly compared to Elderly.
Results of the radiological evaluation of our elderly patients are reported in Table 3. On admission, the abnormalities in chest CT images detected in COVID-19 patients consisted in acute lung inflammatory lesions, involving one or multiple lobes. The proportion of bilateral and multiple lobes involvement is high in both groups and no difference was found. Most of the patients presented on CT scan ground glass opacity (82%), whereas pleural effusion has been found in 38.3% of them and difference between the two groups was significant.

The duration of hospitalizations (LOS), measured in days, was longer for Very Elderly compared with Elderly but the difference is not statistically significant.
The median duration of viral shedding in the current study was 22 days. Based on the median as the cut-off point, the prolonged period of viral shedding was defined as a duration of more than 21 days. Among Very Elderly, 31 patients were still positive after 21 days respect 23 patients of Elderly patients (p < 0.05).
The Kaplan–Meier method was used to estimate the proportion of patients into two groups with a positive detection of SARS-CoV-2 RNA after 30 days from the onset of the symptoms (Fig.1). Very elderly patients showed a longer viral shedding compared to elderly one (HR 2.86; 95% CI 0.69–11.81; p value = 0.03).

By the end of May 19 patients (23%) died. Most of them belonged to the Very Elderly group. The mortality rate was significantly higher in Very Elderly (37.5%) than in Elderly (9.8%). Kaplan-Meier is shown in Fig. 2 (HR 4.5; 95% CI 1.8–11.14; p value = 0.003).

To explore the risk factors of death, univariate and multivariate logistics regression was conducted. Independently of age there are other factors that influence the outcome of COVID-19 patients. In particular, the presence and the number of comorbidities is a critical factor in predicting death in both elderly and very elderly patients. Another factor is the type of emergency admission to the hospital. A higher mortality rate was registered in patients admitted to the hospital from LSRCHs nearby Rome compared to those coming from their home and admitted directly via a general practitioner.
Table 4 reported the univariate logistic regression model suggesting that age (OR, 1.109; 95% CI: 1.031 to 1.206; p = 0.004), comorbidities (OR, 1.69; 95% CI: 1.124 to 2.652; p = 0.01) and provenience from LSRCHs (OR, 3.29; 95% CI: 1.057 to 12.58; p = 0.03) were a risk factors for death.

Table 5 showed the multivariate logistic regression analysis. It was found that the model with age, comorbidities and data regarding provenience from LSRCHs was preferred compared to the model that considered only age in predicting mortality (Hosmer and Lemeshow goodness-of-fit test, p = 0.79).

Elderly are generally defined as having a chronological age of 65 years or older [18]. In Japan, where many elderly people live, this definition was reviewed [19]. Thanks to the advances in medical and health science the lifespan has recently increased in Japan as well as in Italy. The simple chronological age appears to be no longer appropriate to the actual situation, in both Countries, where life expectancy is of 80 years and where there is an increased number of bright and energetic elderly people. Therefore, in Japan, the term of “late elderly” was introduced to indicate a new class of people, older than 75 years of age [18]. Other factors besides the chronological age appear to play a major role in affecting the health status and the expectance of life and a careful assessment of the “elderly frailty” is required to determine the biological, functional, cognitive and clinical aspects of the elderly subjects [20]. Previous reports indicate that elderly people are particularly susceptible to Community-Acquired Pneumonia [21–23]. When a community-acquired pneumonia is diagnosed in very elderly people, there is a significant increase in morbidity and mortality [24]. It has been observed that these patients often develop hospital-acquired complications and mortality occurs more frequently compared to younger people and to elderly ones. Moreover, the occurrence of pneumonia in elderly people is often the terminal event that complicates a long-term illness, such as dementia, cardiovascular disease, cancer, or prolonged immobilization syndrome [25]. However, it is not always easy to dissect the relative contribution of other factors, including disability, frailty, comorbidities and the health status of these patients, prior to the development of the disease. COVID-19 is a severe disease, caused by the SARS-CoV-2 virus, mostly affecting the lung where an interstitial viral pneumonia is frequently observed, with typical patchy bilateral ground glass opacities and peripheral consolidations. Elderly people appear to be more susceptible, especially to the more severe forms of the disease [26]. However, little information is available so far regarding the course of COVID 19 in very elderly people. It is well established that COVID-19 occurs more frequently among elderly people, with higher susceptibility to mortality and ICU admission [27], but a limited number of studies and of patients has focused the attention on a population over eighty years of age [3].
Our very elderly patients, showed a more severe disease, with higher level of serum marker of inflammation (hs-CRP and NLR) and higher severity respiratory indexes (PSI and P/F). This could be due to the increased inflammatory activity, associated with aging, reflected by increased circulating levels of TNF-alpha, IL-6, cytokine antagonists and acute phase proteins in vivo [28].
Experimental observations in mice, indicate that the SARS-CoV viral replication in aged mice is associated with clinical illness and pneumonia, demonstrating an age-related susceptibility to SARS disease in animals that parallels the human experience [29]. Moreover, they demonstrated that replication of SARS CoV is enhanced in aged mice compared to younger and enhanced viral replication is accompanied by evidence of clinical illness, alveolar damage, and interstitial pneumonitis [29].
Besides to be stroked by a more severe disease, median duration of viral shedding in our very elderly patients is higher compared to that recently reported in younger and symptomatic (14 days) or asymptomatic patients (19 days) [30] and there is a statistically significant difference between the two groups. This also affects the length of the stay (LOS) in the hospital which result higher in Very Elderly. We don’t have data regarding the immune response in terms of cytokine production and production of specific immunoglobulins in our very elderly patients. However, the increased duration of viral shedding suggests that they may have a weaker immune response to SARS-CoV-2 infection, compared to younger patients. Increasing age has been defined as a predictive factor for mortality in pneumonia patients in many studies, especially among patients aged 65 years or older [31, 32]. Several studies, suggested that age ≥ 85 years was an independent predictive factor for mortality in patients affected with community acquired pneumonia [33, 34]. Calle et al. reported that age ≥ 90 years was markedly associated with mortality [35]. Ageing is associated with a progressively weakened immune system and decreased lung performance. For patients of extreme age (≥ 85 years in our study), these changes alone are probably drastic, which independently increases the risk of death due to pneumonia [34]. In the study by Zunyou Wu et al., the overall case-fatality rate of those aged 70 to 79 years was 8.0% compared to aged 80 years and older where it was 14.8% [36]. However, in this study only 3% of the total number of cases were 80 years of age or older. In another study by Niu et al., the mortality rate in patients over 80 was equal to 18% [3]. Also Yan et al. reported that older patients (> 65 years) with comorbidities and ARDS are at increased risk of death, although even in this study patients over 80 years of age were a small number [37].
In our study the number of patients with more than 80 years of age is similar to that with 65–79. The mortality rate in Very Elderly was 37.5% and this percentage was significantly higher compared to that observed in Elderly. Our findings suggest that, similarly with other severe acute respiratory outbreaks, age is a fundamental risk factor for mortality. These results also emphasize the importance of the very advanced age (i.e. ≥ 85 years).
When we try to identify which factors other than age may influence the course and outcome of the disease in these patients, two conditions appear to play a major role. The first is represented by the pre-existing health conditions or comorbidities. Patients with pre-existing pathological diseases, and in particular those affected by multiple comorbidities die more frequently than those with no or few comorbidities. In other words, COVID-19, as other community-acquired pneumonias, acts as terminal event that complicates long-term illnesses. This is in agreement with previous studies demonstrating that the presence of any comorbidity is associated with increased risk of poorer clinical outcomes [38].
The second one consisted in the observation that patients admitted to the hospital coming from previous LSRCHs, were in worst clinical conditions and died more frequently compared to those admitted coming from their homes. There are many possible explanations to that. Patients in LSRCHs may suffer of more comorbidities and fragilities, and as previously observed they are more prone to accumulate complications, thus resulting in unfavorable outcome. Another explanation is that, staying in a close environment, makes these patients more susceptible to infections. In this regard, the results of the Italian National Survey indicated that one of the major difficulties was to obtain an adequate isolation of the positive patients. Finally, the disease could be more severe because of a delay in its recognition, that, according to this survey, was due to insufficient availability of the nasal/oropharyngeal tests. Considering all these factors and based on our observations, it is necessary to obtain a better evaluation of the frailties of elderly and very elderly people that represent a population more prone to the condition of risk and vulnerability, characterized by an unstable equilibrium, if facing negative events.
Because of the rapid evolving outbreak globally, ongoing studies with the inclusion of more patients would be needed to increase the statistical power of our results.
In conclusion, the heightened susceptibility of the elderly to COVID 19, led us to demonstrate that there were considerable differences between Elderly and Very Elderly in terms of inflammatory activity, severity of disease and adverse clinical outcomes. Although age is one of the major risk factors for mortality, a thorough assessment of comorbidities and information about the provenience from residential care homes may help establishing risk stratification of patients with COVID-19 upon hospital admission and may furnish valuable information for planning adequate programs of intervention at the sanitary-assistential levels.",BMC Geriatr
PMC7809651,Kombination von simulationsbasiertem Lernen und Online-Learning in der Augenheilkunde: Effizienz von Simulation in Kombination mit eigenständigem Online-Learning im Rahmen von EyesiNet in der studentischen Ausbildung,"Wie wichtig es für alle Studierende ist, Basisfertigkeiten in der Ophthalmologie zu erlernen, konnte eine Umfrage von 93 Studierenden zeigen [1]; 53 % dieser Gruppe sind später neben der Ophthalmologie in Fachbereichen wie Innere Medizin, Pädiatrie, Gynäkologie, Allgemeinmedizin, Neurologie oder Notfallmedizin tätig, in denen ein Screening des Auges eine essenzielle Fertigkeit darstellt. Die Ausbildung mithilfe von echtem Instrumentarium wird jedoch seit Jahren dadurch erschwert, dass zum Zeitpunkt des Praktikums nicht genügend Patienten mit verschiedenen Erkrankungsbildern zur Verfügung stehen und darüber hinaus Zeitdruck in den Ambulanzen besteht. Die typische Alternative – die Auszubildenden untersuchen sich gegenseitig – ist meist nicht kompatibel mit deren Tagesablauf (Pupillenerweiterung, Lese- und Fahruntüchtigkeit), zudem wird hierdurch systematisches Lernen von Pathologien und deren Behandlungsoptionen [2] erschwert. Für eine systematischere und effektivere Lehre wurden bereits verschiedene Anstrengungen unternommen. So wurde neben dem klinischen Training von Lippa et al. [1] der Fundoskopiesimulator CLEO (Clinical Learning Experience in Ophthalmoscopy) verwendet. CLEO ist ein anatomisch korrekter Simulator, bei dem ein Schaufensterpuppenkopf mit einem erweiterten und einem nicht erweiterten Auge verwendet wird. Die Netzhäute dieser beiden Modellaugen werden durch einen Diabetrachter mit dem Dia einer Fundusfotografie (35-mm-Weitwinkeloptik [60°]) mit bekannter Pathologie simuliert [1].
Kelly et al. [3] beschreiben ein Styropormodell, bei dem fotografische Aufnahmen echter Retinae auf dem Innenboden eines weißen Polyethylenzylinders (ähnlich eines Kleinbildfilmdöschens) angebracht sind. Eine Linse, die in die Öffnung des Polyethylenzylinders eingesetzt ist, reproduziert die optischen Abbildungsverhältnisse des echten Auges. Das Training verschiedener Erkrankungsbilder mithilfe dieser Anordnung führt zu einer signifikanten Leistungsverbesserung.
Die Möglichkeit, typische Krankheitsbilder anhand von Fundusfotografien zu erlernen, wird mit den Simulatoren Eyesi Direct und Eyesi Indirect mit Virtual-Reality-Techniken weitergeführt und mithilfe der von uns entwickelten Online-Plattform EyesiNet um klassische text- und bildbasierte Lehrinhalte ergänzt. In dieser Kombination werden definierte Lerninhalte reproduzierbar und für alle gleichermaßen zur Verfügung gestellt, sodass – unabhängig von personellen Schwankungen – allen Auszubildenden die gleichen Möglichkeiten geboten werden. Der durch das standardisierte Training erzielte individuelle Lernerfolg wird mess- und vergleichbar. Ein sehr nützlicher Nebeneffekt des computergestützten Trainings ist, dass die Studierenden im Bedarfsfall ihren Lernprozess unabhängig von Lehrveranstaltungsorten und festgelegten Zeiten eigenverantwortlich weiterführen können.
Der angehende Mediziner lernt, typische Krankheitsbilder auf Abruf kennenzulernen und diese ggf. später in Diensten und in Stresssituationen – unabhängig von der Fachdisziplin – wiederzuerkennen, richtig einzuschätzen und die Behandlung korrekt einzuleiten. Dies kann je nach Erkrankungsbild ausschlaggebend für den Erhalt der Sehkraft werden.
Die von uns verwendeten Simulatoren Eyesi Indirect und Eyesi Direct (Firma VRmagic, Mannheim, Deutschland, Softwareversion 1.8) bestehen aus der Nachbildung des jeweiligen Instruments (direkte bzw. indirekte Ophthalmoskopie mit binokularer Hutophthalmoskopie), einem Patientenmodell, einem Touchscreen-Monitor sowie einem PC (Abb. 1).
Im Okular des simulierten direkten Ophthalmoskops (Eyesi Direct) sieht der Untersuchende eine rein virtuelle Darstellung der beobachteten Strukturen, insbesondere des Augenhintergrunds.
Im Unterschied dazu erfolgt bei Eyesi Indirect die Darstellung mittels virtueller und erweiterter Realität („virtual and augmented reality“), d. h. der Untersuchende sieht das reale Bild seiner Umgebung über ein Videosignal auf Displays im Hutophthalmoskop, allerdings wird anstelle der physisch vorhandenen Patientenmaske ein virtueller Patient in das Bild gemischt. Auf diese Weise kann der Untersuchende seine eigene Hand unter Ophthalmoskopsicht weiterhin kontrollieren und – für diese Untersuchungsmethode sehr wichtig – sich unter Sicht am Kopf des Patienten abstützen, um eine stabile Position für die Untersuchungslupe zu finden. In dieser Mischung aus echter und virtueller Situation entsteht eine realistische und dynamische 3‑D-Lernumgebung.
Bei beiden Simulatoren werden die virtuellen Patienten auf täuschend echte Weise dargestellt. Passend zum dargestellten Erkrankungsbild können sie unterschiedlichen Alters und ethnischer Herkunft sein. Durch die korrekte Bedienung des Ophthalmoskops (Einstellung von Licht und Refraktionsausgleich, Abstand vom Patientenauge, Rotreflex, ggf. Positionierung und Orientierung der Ophthalmoskopierlupe) ist es möglich, ein realistisches Bild der Retina zu sehen [4, 5]. Die von der Software angezeigten Fallbeschreibungen wurden im Rahmen des Projekts an die Bedürfnisse der Studierenden angepasst und mit den theoretischen EyesiNet-Inhalten abgeglichen: Neben einer kurzen Darstellung der Anamnese des virtuellen Patienten, seines Sehvermögens und Augeninnendrucks sind es v. a. die Multiple-Choice-Fragen für Befundung und Diagnose, die Bezug auf die Krankheitsbilder nehmen, die im webbasierten Theorieteil beschrieben werden (EyesiNet, s. unten).
Der Hersteller der Simulatoren stellt bereits ein webbasierte Schulungsportal zur Verfügung (VRmNet, Version 8.0), bei dem die Teilnehmer nach dem Einloggen von einem beliebigen Computer oder Mobilgerät aus Zugang zu einem Orientierungskurs für die Simulatoren haben, ihre Trainingsdaten einsehen können und eine Bibliothek mit ihren am Eyesi Direct und Indirect gefundenen anatomischen und pathologischen Befunden im Laufe des Trainings anlegen können.
Die medizinischen Inhalte dieser Online-Plattform wurden von uns im Rahmen des Lehrprojektes weiterentwickelt und so strukturiert, dass sie die Bedürfnisse der Studierenden und den Lernzielkatalog widerspiegeln (z. B. hypertensive Retinopathie, diabetische Retinopathie, Aderhauttumore) und auch für die Spezialisierung in anderen Fachgebieten relevant sind (Innere Medizin, Gynäkologie, Pädiatrie, Neurologie u. a.). Hierzu wurden in der von uns angepassten Plattform („EyesiNet“) 14 Fälle und deren Pathologien im Karteikartenformat nach Definition, Klassifikation, Epidemiologie, Risikofaktoren, Histopathologie, Symptomen und klinischen Zeichen, Diagnostik, Therapie und Prognose gegliedert und die jeweiligen Unterpunkte mit Bildern versehen (Abb. 2).
Das Besondere ist, dass die dargestellten Pathologien in EyesiNet anhand von Screenshots aus den Simulatoren erklärt werden, sodass während der praktischen Übungen an simulierten Patienten die Studierenden diejenigen Befunde wiederfinden, die sie sich zuvor im Netz angeschaut haben. Auf diese Weise sind der Wiedererkennungseffekt und die damit einhergehende Lernmotivation deutlich höher. Jeder Student erhält seinen eigenen EyesiNet- und Simulatorzugang. Mithilfe der Online-Inhalte kann das simulatorgestützte Training zu Hause per PC oder Smartphone vor- und nachbereitet sowie der individuelle Trainingsfortschritt überprüft werden.
Nach Erstellen der notwendigen Lerninhalte und deren Integration in die Online-Plattform wurde eine prospektive Studie durchgeführt, genehmigt durch die Ethikkommission des Fachbereichs Medizin der Goethe-Universität Frankfurt (Beschlussnummer E 205/19, Geschäftsnummer 19-327). Ziel der Studie war es, die Effizienz des Lehransatzes zu überprüfen. Dazu wurde die Bewertung der durchgeführten Fälle am Simulator mit der Lernzeit im EyesiNet korreliert, um zu prüfen, ob es eine Abhängigkeit der Lernerfolgskurve bei der Befundung von Krankheitsbildern von der Beschäftigungsdauer in EyesiNet gibt.
Die Teilnahme an der Studie erfolgte freiwillig. Eingeschlossen wurden Studierende im 10. Semester, welche bereits die Vorlesungen der Augenheilkunde besucht hatten und das Augenheilkundepraktikum im Rahmen ihres klinischen Studienabschnittes durchliefen. Es wurde bei allen Studienteilnehmern vor Einschluss in die Studie deren Einverständniserklärung eingeholt. Die Studienteilnehmer wurden darüber aufgeklärt, dass ihre Zeit im EyesiNet pseudonymisiert gemessen und mit den Ergebnissen an den Simulatoren korreliert wird.
Am ersten Praktikumstag hörten die Studierenden zunächst einen 10minütigen Einführungsvortrag über die grundsätzliche Technik der Untersuchungen und bekamen eine kurze Demonstration der Simulatoren. Über eine Gesamtzugangszeit von 2 h konnten sie anschließend Fälle am Simulator untersuchen. Mithilfe ihres individuellen Zugangscodes konnten sie sich auf der Online-Plattform EyesiNet auf freiwilliger Basis begleitend weiter mit den dort aufgezeigten Pathologien beschäftigen. Am letzten Praktikumstag wurden am Simulator (Zugangszeit erneut 2 h) die erlernten Kenntnisse überprüft und die praktischen Fähigkeiten weiter vertieft. Bei jeder Einheit wurden den Studierenden dabei zufällig ausgewählte Fälle vorgestellt. Am Ende jedes Falles wurde am Simulator ein „Quiz“ mit Multiple-Choice-Fragen, Befundung und Diagnose bearbeitet, das sich auf in EyesiNet behandelte Inhalte bezog. Nach Bearbeitung des jeweiligen Falles wurde den Studierenden ihr Befundungsergebnis aufgezeigt (Abb. 3a, b), und sie hatten die Möglichkeit, den virtuellen Patienten nochmals zu spiegeln, um sich die Blickdiagnosen besser einprägen zu können. Mittels eines Fragebogens wurden EyesiNet sowie das Simulatortraining von den Studierenden nach Absolvierung ihres Praktikums bewertet.
Die Gesamtbewertung basiert auf folgenden Kriterien, die während der Untersuchung berechnet werden:
Lichtbelastung („light exposure“), Gesamtzeit der Untersuchung („examination time“), Fläche der untersuchten Netzhaut („examined retina“), Befunde („classification“) und Diagnose („diagnosis“) in Form von Multiple-Choice-Fragen [6].
Lichtbelastung:
Hier wird die Dauer von zu starkem und damit schädigendem Licht auf der Retina gemessen.
Gesamtzeit der Untersuchung:
Dies ist die Zeit, die ein Student für die Untersuchung benötigt. Bei der Untersuchungsdauer werden die Minuten gezählt.
Fläche der untersuchten Netzhaut:
Hier wird die untersuchte Fläche der Retina berechnet. Dabei wird die Retina als Fläche mit dem Wert 100 % angenommen und die relative Ausleuchtung berechnet.
Multiple-Choice-Fragen (Befunde und Diagnosen):
Hier wird zuerst anhand der richtigen und falschen Angaben der aktuelle Wert ermittelt, der dann zur Berechnung der Punktzahl dient:\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\textit{Aktueller}\,Wert=\frac{\textit{Anzahl}\,\textit{richtige}\,\textit{Antworten}-\textit{Anzahl}\,\textit{falsche}\,\textit{Antworten}}{\textit{vorgegebene}\,\textit{Gesamtanzahl}\,\textit{richtiger}\,\textit{Antworten}}$$\end{document}AktuellerWert= Anzahl richtige Antworten-Anzahl falsche Antwortenvorgegebene Gesamtanzahl richtiger Antworten
Für jedes Bewertungskriterium sind Wertebereiche und Punktzahlen definiert, um den Messwert in eine Punktzahl zu transformieren. Dies wird gemäß der folgenden Formel linear interpoliert:\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\textit{Relativer}\,Wert=\frac{\textit{Aktueller}\,Wert-\textit{Startwert}}{\textit{Endwert}-\textit{Startwert}}$$\end{document}RelativerWert=Aktueller Wert-StartwertEndwert-Startwert\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\textit{Punktzahl}=\textit{Startpunktzahl}+\textit{Relativer}\,\textit{Wert*}\left(\textit{Endpunktzahl}-\textit{Startpunktzahl}\,\right)$$\end{document}Punktzahl=Startpunktzahl+Relativer Wert*Endpunktzahl-Startpunktzahl
Falls der aktuelle Wert außerhalb des Wertebereichs liegt, wird stattdessen die Minimal- bzw. Maximalpunktzahl angenommen. Da keine negativen Punkte vergeben werden, erhalten die Studierenden am Ende eine Gesamtpunktzahl von mindestens 0 Punkten und höchstens 100 Punkten (Abb. 3).
Die Werte- und Punktebereichte für die einzelnen Bewertungskriterien sind in Tab. 1 dargestellt und mit einem Musterprobanden versehen.
In dieser nicht randomisierten prospektiven Studie wurde gemäß den Vorgaben der Ethikkommission keine Kontrollgruppe gebildet, sodass alle Studierenden gleichermaßen die Möglichkeit hatten, sich in EyesiNet weiterzubilden. Ob und wie lange die Studierenden die Plattform nutzten, wurde ihnen auf freiwilliger Basis selbst überlassen. So konnte bei Abschluss der Studie eine nicht randomisierte Kontrollgruppe gebildet werden mit denjenigen Studierenden, die die Plattform nicht nutzten (Gruppe OHNE Training).
Die Daten wurden mithilfe der individuellen Zugänge an den Eyesi-Simulatoren erfasst und in Microsoft Excel 2016 sowie in BiAS Version 11.12 für Windows (epsilon-Verlag, Dr. rer. med. Hanns Ackermann, Goethe-Universität Frankfurt, Deutschland) ausgewertet.
Zum Vergleich, ob eine signifikante Verbesserung durch die EyesiNet-gestützte Weiterbildung erreicht werden konnte, wurde bei Vorlage einer nicht parametrischen Datenlage ein Wilcoxon-matched-pairs-Test für beide Gruppen angewendet sowie deren Effektstärke nach Rosenthal [7] bewertet. Die Abhängigkeit der Verbesserung von der in EyesiNet verbrachten Zeit wurde mittels Spearman-Rangkorrelation überprüft. Zum Vergleich der Vor-Werte beider Gruppen wurde ein Wilcoxon-Mann-Whitney-U-Test angewendet, um zeigen zu können, dass beide Gruppen die gleichen Startvoraussetzungen nach Besuch der Vorlesung und der Klausur hatten.
Es konnten insgesamt 86 Studierende ausgewertet werden, wovon 32 Studierende das freiwillige Angebot nutzten und in ihrer freien Zeit während des Praktikums an der Online-Plattform EyesiNet trainierten (Gruppe MIT Training). Die aufgezeichnete Aktivität ergab, dass im Durchschnitt 28-mal (min. 1, max. 85) die Übersichtsseiten der 14 Pathologien aufgerufen wurde. Die Unterseiten (mit Detailinformationen) wurden im Durchschnitt von den Trainierenden 14-mal (min. 0, max. 42) aufgerufen.
Aus den Nicht-Trainierenden (n = 54) konnte bei der Auswertung eine nicht randomisierte Kontrollgruppe gebildet werden (Gruppe OHNE Training). Ein Loss-to-Follow-up trat bei 14 Studierenden auf.
Prüft man die Startvoraussetzungen der beiden Gruppen (OHNE vs. MIT Training) mittels Wilcoxon-Mann-Whitney-U-Test, so zeigt sich, dass beide Gruppen keinen signifikanten Unterschied aufwiesen (p = 0,29). Dies bedeutet, dass keine der beiden Gruppen vor dem Training mit EyesiNet einen Wissensvorsprung hatte.
Von den n = 54 Studierenden, welche nicht am EyesiNet-Training teilnahmen, wurden am Beginn des Praktikums 141 Fälle und am Ende des Praktikums insgesamt n = 138 Fälle am Eyesi Direct bearbeitet. Dabei lag bei einer Gesamtpunktzahl von 100 Punkten vor dem Training der Median bei 37 Punkten, danach konnte eine Steigerung auf einen Median von 44 Punkten erreicht werden. Beim Test der Nullhypothese konnte mit p = 0,02 im Wilcoxon-Matched-Pairs-Test eine signifikante Verbesserung mit einer Effektgröße von 0,1 festgestellt werden. Dies entspricht nach Rosenthal einem geringen Effekt.
Von den n = 32 Studierenden, welche am EyesiNet-Training teilnahmen, wurden am Beginn des Praktikums 93 Fälle und am Ende des Praktikums n = 83 Fälle am Eyesi Direct bearbeitet. Dabei lag bei einer Gesamtpunktzahl von 100 Punkten vor dem Training der Median bei 35 Punkten, danach konnte eine Steigerung auf einen Median von 45 Punkten aufgezeigt werden. Beim Test der Nullhypothese konnte mit p = 0,0004 im Wilcoxon-Matched-Pairs-Test eine hoch signifikante Verbesserung mit einer nach Rosenthal mittleren Effektgröße von 0,3 festgestellt werden.
Die Zeit des Trainings am EyesiNet korreliert dabei nach der Spearman-Rang-Korrelation mit p = 0,05 (Korrelationskoeffizient rho= 0,36) mit der Verbesserung am Eyesi Direct (Gesamtpunktzahl nachher – Gesamtpunktzahl vorher).
Im Wilcoxon-Mann-Whitney-U-Test zeigt sich, dass beide Gruppen zu Beginn des Praktikums wie im Eyesi Direct keinen signifikanten Unterschied in den Ergebnissen am Eyesi Indirect aufwiesen (p = 0,10).
Von den n = 54 Nicht-Trainierenden wurden am Beginn des Praktikums 147 und am Ende des Praktikums 133 Fälle am Eyesi Indirect bearbeitet. Dabei lag bei einer Gesamtpunktzahl von 100 Punkten vor dem Training der Median bei 22 Punkten, danach konnte eine minimale Steigerung auf einen Median von 23 Punkten erreicht werden. Dies entspricht mit p = 0,41 im Wilcoxon-Matched-Pairs-Test keiner signifikanten Verbesserung im Verlauf.
Von den n = 32 Trainierenden wurden am Beginn des Praktikums 87 Fälle und am Ende des Praktikums n = 85 Fälle am Eyesi Indirect bearbeitet. Dabei lag bei einer Gesamtpunktzahl von 100 Punkten vor dem Training der Median bei 25 Punkten, danach konnte eine Steigerung auf einen Median von 26 Punkten erreicht werden. Damit konnte mit p = 0,17 im Wilcoxon-Matched-Pairs-Test keine signifikante Verbesserung aufgezeigt werden.
Nach der Spearman-Rang-Korrelation korreliert die Zeit des EyesiNet-Trainings mit p = 0,12 knapp nicht mit der Verbesserung am Eyesi Indirect (Gesamtpunktzahl nachher – Gesamtpunktzahl vorher).
Die Auswertung der einzelnen Bewertungskriterien, welche zur Gesamtbewertung am Eyesi Direct und Indirect führen, ist in Tab. 2 und 3 dargestellt.
Hier befinden sich die Studierenden immer in der erlaubten Gesamtzeit. Von Beginn an wird sowohl am Eyesi Direct als auch am Eyesi Indirect mit einer geringen Lichtbelastung für die Netzhaut gearbeitet. Während die Ergebnisse der Fläche der untersuchten Retina am Eyesi Direct im oberen Bereich liegen, liegen die Ergebnisse am Eyesi Indirect deutlich darunter. Eine Steigerung der Punktzahl kann v. a. im Bereich der Befundung und Diagnosestellung aufgezeigt werden.
Nach Auswertung der Fragebögen zeigt sich, dass die Mehrheit der Studierenden sowohl das Training am Simulator als auch an EyesiNet überzeugt hat (Abb. 4) und sie auch subjektiv das Gefühl hatten, dadurch ihre ophthalmologischen Kenntnisse verbessern zu können. Zudem zeigte sich, dass das Interesse an dem im Studium eher kleinen Fachgebiet „Ophthalmologie“ durch ein an die Bedürfnisse der Studierenden angepasstes Training weiter gesteigert werden kann.
Es konnte gezeigt werden, dass die Kombination aus praktischem Training an Simulatoren und begleitender, in das praktische Training auf geeignete Weise verwobener Theorie im Rahmen von Online-Plattformen nicht nur subjektiv das Interesse und die ophthalmologischen Kenntnisse der Studierenden steigert, sondern auch nachweislich zu besseren Ergebnissen in der Ausbildung führt.
Gerade die praktischen Fertigkeiten dürfen im Rahmen eines Medizinstudiums nicht zu stark in den Hintergrund rücken. Oft fehlt den Assistenzärzten dann in der Praxis die Fähigkeit, ihr theoretisches Wissen anzuwenden, die erforderlichen diagnostischen Tätigkeiten selbst umzusetzen und nach Erstellung der richtigen Diagnose die zutreffenden Behandlungsmethoden einzuleiten.
Anhand der Simulation erhalten die Studierenden am ersten Praktikumstag ein objektives Bild über ihren aktuellen Wissensstand in der Ophthalmologie und durch das Erlernen der Fertigkeiten auch die Motivation, dadurch bei genügend theoretischem Wissen auch selbstständig die richtige Diagnose stellen zu können.
Wie sich anhand der oben genannten Ergebnisse zeigt, ist gerade die direkte Ophthalmoskopie eine relativ einfache Untersuchungsmethode, die verstärkt im Unterricht der Studierenden eingesetzt werden sollte.
Hier ist bereits ein Lerneffekt allein durch die Praxis am Simulator für die direkte Ophthalmoskopie nachweisbar. Deutlich höher fällt er jedoch aus, wenn die Studierenden in der Zwischenzeit die Befunde an der Online-Plattform aufgearbeitet haben.
Das Erlernen dieser Fertigkeiten zeigt sich als wesentlich einfacher als das Erlernen der indirekten Ophthalmoskopie und sollte gefördert werden, da die direkte Ophthalmoskopie in der späteren beruflichen Laufbahn auch von Internisten, Pädiatern und Hausärzten einfach durchgeführt werden kann. Sie kann dabei helfen, Notfälle zu filtrieren (wie u. a. Zentralarterienverschluss, Stauungspapille …) und den richtigen Fachdisziplinen zuzuordnen [8].
Bei der indirekten Ophthalmoskopie konnte keine signifikante Verbesserung während des Praktikums erreicht werden: Die Ergebnisse am Eyesi Indirect sind sowohl beim primären als auch sekundären Simulationstraining bei beiden Gruppen deutlich schlechter als die Trainingsergebnisse am Eyesi Direct, was die Vermutung nahelegt, dass bei der indirekten Ophthalmoskopie eine bedeutend höhere Lernzeit bei der Anwendung benötigt wird, um Strukturen darzustellen und dann auch richtig bewerten zu können. Dies liegt mutmaßlich daran, dass die Studierenden erst ein Gefühl für die Augen-Hand-Koordination sowie für das invertierte Bild entwickeln müssen. Die hier vorhandene Trainingszeit von insgesamt 4 h kann aber den Studierenden zumindest helfen, ein Gefühl für diese Methodik zu entwickeln [9] und ggf. weiteres Interesse an der Augenheilkunde wecken und damit auch zur Entscheidungsfindung für die individuell richtige Fachdisziplin beitragen.
Die Kombination, dies mit jederzeit zugänglichen Online-Inhalten zu verknüpfen (welche z. B. auch über Mobiltelefon und Tablet zugänglich sind), ergibt die Möglichkeit, dass die Studierenden auch nach dem Praktikum immer wieder auf diese Informationen zurückgreifen und die erarbeiteten Lerninhalte als eine Art Nachschlagewerk nutzen können.
Dies kann z. B. dann helfen, wenn Studierende ein Erkrankungsbild zwar als bekannt erkennen, aber die Zuordnung zur Pathologie nicht mehr herstellen können.
Dass diese Funktion genutzt wird, konnte in dieser Studie aufgezeigt werden. So wurde das Portal auch nach dem abgeschlossenen Praktikum von 10 der 32 Studierenden in der Trainierenden-Gruppe weiter aufgerufen. Dagegen wurde das Portal nur von einer studierenden Person aus der Gruppe derjenigen genutzt, die sich in der Praktikumszeit nicht mit EyesiNet beschäftigt hatten. Eine Schwäche dieser Studie ist die begrenzte Zeit, die den Studierenden in 1 Woche zur Erlernung dieser Fähigkeiten zur Verfügung steht. Dementsprechend ist es überraschend, dass in der direkten Ophthalmoskopie trotzdem eine signifikante Verbesserung der Ergebnisse erreicht werden konnte. Es konnte jedoch nur eine studierende Person nach dem Training am Eyesi Direct die Maximalpunktzahl von 100 Punkten in einem Fall erreichen. Die Maximalpunktzahl am Eyesi Indirect waren 88 Punkte. Ausbildungsziel sollte sein, einen Großteil der Studierenden auf dieses hohe Niveau bringen zu können. Hierbei ist der Lernaufwand eines jeden Studierenden individuell einzustufen. Gerade aber hierfür sind Simulatoren vorteilhaft, da sie den Studierenden ermöglichen, nach Beendigung ihres Praktikums eigenständig weiter zu trainieren. Hierfür bieten wir den Studierenden Trainingszeiten an den Simulatoren an – und natürlich auch die Möglichkeit, im Wahlfach Ophthalmologie weiter ihre Kenntnisse zu vertiefen.
Mit n = 14 kam es zu einer relativ hohen Loss-to-Follow-up-Rate. Diese Rate basiert unter anderem auf dem sehr umfangreich curricular verankerten Ausbildungsprogramm. So kam es zu Überschneidungen mit anderen Fächern, was dazu führte, dass einige der Studierenden ihren Fehltag am letzten Praktikumstag nahmen. Dies kann neben mangelndem Interesse auch der Grund dafür sein, dass es nicht zu einer idealen Teilnahme der Studierenden an dem freiwilligen Angebot der Online-Courseware EyesiNet kam. Von den 86 Studierenden machten nur 32 Studierende davon aktiven Gebrauch. Es ist zu überlegen, ob das bisher freiwillige Online-Training in einen Pflichtteil während des Praktikums umstrukturiert werden sollte, sodass alle Studierenden auf den gleichen Stand gebracht werden können. Des Weiteren muss stärker auf eine sinnvolle Anordnung der Praktika und Prüfungen geachtet werden. Hierbei werden wir auch dem Wunsch der Studierenden nachkommen und in Zukunft die Online-Plattform bereits während der Vorlesungszeiten zur Verfügung stellen, sodass diese sowohl zur Klausur- als auch zur Praktikumsvorbereitung genutzt werden kann.
Die Kombination aus realistischer Simulation und den dazu passenden Lerninhalten auf Online-Plattformen ist motivierend und effizient. Sie führt sowohl subjektiv als auch objektiv zu verbesserten ophthalmologischen Kenntnissen.Es ergibt sich daraus die Möglichkeit, die Ausbildung sowohl vor, während als auch nach der Absolvierung des Praktikums fortzuführen, da der Zugang den Studierenden weiterhin zur Verfügung steht und das „Modul“ sowohl vor dem abschließenden Examen mit in die Vorbereitungen integriert werden kann oder als mobile App im Berufsleben jederzeit und an jedem Ort wieder aufrufbar ist.An der Augenklinik der Goethe Universität Frankfurt am Main ist die Kombination aus dem Angebot des Online-Trainings in Kombination mit der Simulationsausbildung ein fester Bestandteil des Praktikums geworden und soll in einem weiteren Lehrantrag auf die Befundung am Vorderabschnitt ausgeweitet werden.In Zeiten der COVID-19-Pandemie kann durch Simulatortraining eine sichere Umgebung für praktische Übungen geschaffen werden. Überdies können mit EyesiNet auf digitale Weise interaktive Zusatzinformationen zu den Lehrbüchern zur Verfügung gestellt werden. Bei Bedarf bieten wir an, EyesiNet auch anderen Weiterbildungshäusern zur Verfügung zu stellen.",Ophthalmologe
PMC7809649,Why Death Need Not Be “Reasonably Foreseeable”—The Proposed Legislative Response to Truchon and Gladu v Attorney General (Canada) and Attorney General (Quebec) [2019] QCCS 3792,"Medical Assistance in Dying (MAID) has become an inescapable reality in Canada since the Supreme Court of Canada (SCC) declared in Carter v Canada (Attorney General) ([2015] 1 S.C.R. 331) (Carter) that the blanket prohibition on physician assisted dying was unconstitutional. Instead of prescribing the regulatory criteria to control the provision of MAID, the SCC invited the respective federal and provincial governments to establish the legislative framework (Carter, [127]). After months of deliberation, the Medical Assistance in Dying Act (MAID Act) (Criminal Code, R.S.C. (1985), c. C-46, ss 241.1-241.4, An Act to Amend the Criminal Code and to Make Related Amendments to Other Acts (Medical Assistance in Dying)) came into force on 17 June 2016.
The passing of the MAID Act failed to quell the controversies surrounding MAID. Shortly after it came into force, proceedings were once again initiated against the Attorney General of Canada, this time joined by the Attorney General of Quebec, on the grounds that selected eligibility criteria that restricted access to MAID were unconstitutional and inconsistent with the declaration issued in Carter (Truchon and Gladu v Attorney General (Canada) and Attorney General (Quebec), [2019] QCCS 3792, [5]-[7]) (Truchon). This Recent Developments article will consider Baudouin J’s judgment in, and the proposed legislative response to, Truchon. This development is worthy of discussion as removing the requirement that death occur within a defined period has significantly broadened the class of persons eligible to access MAID in Canada.
The applicants’ contended that these requirements, which deemed them ineligible to access MAID, were invalid as they:violated the principles set out in Carter; andinfringed their section 7 rights to life, liberty, and security of the person and their section 15 right to equality guaranteed by the Canadian Charter of Rights and Freedoms (Canada Act 1982 (U.K.), 1982, Sch B, c.11) (CCRF).
Thus, the issues for determination before the court were whether the impugned provisions:were inconsistent with the declaration issued in Carter; andinfringed sections 7 and 15 of the CCRF and, if so, whether the infringements were justified under s 1 of the CCRF.
First, in determining that the reasonable foreseeability of natural death requirement was inconsistent with Carter, Baudouin J stated that the declaration “should be construed as providing access to any person who meets the Supreme Court’s clear requirements, whether or not death is reasonably foreseeable” [499].
Second, in concluding that the challenged provision infringed the applicants’ s 7 right to life, Baudouin J observed that this requirement “exposes individuals such as Mr Truchon and Ms Gladu, to a heightened risk of death” [522]. In determining that their s 7 rights to liberty and security of the person were violated, her Honour concluded that this criterion “directly interferes with their physical integrity, causes them physical and psychological pain and deprives them of the opportunity to make a fundamental decision that respects their personal dignity and integrity” [534].
Justice Baudouin turned to the objects of the provision to determine whether the infringement of rights was inconsistent with principles of fundamental justice. Finding that object was to protect vulnerable persons from ending their life in a moment of weakness [561]-[564], her Honour concluded that the provision was overbroad and grossly disproportionate to its object [574, 582], and indeed inconsistent with the principles of fundamental justice [587].
Her Honour further determined that the infringement of rights was not justified. The object of protecting vulnerable persons from ending their life in a moment of weakness, although pressing and substantial [601], was not the least drastic means available to achieve parliament’s objective [617]-[618]. Moreover, the deleterious effects of the restriction on people in similar situations to the applicants were disproportionate to the expected benefits of the requirement that natural death be reasonably foreseeable [637]. This reasoning was based on the finding that physicians were capable of diligently assessing the capacity of patients who requested MAID and were able to identify vitiating factors such as coercion, external pressure, and suicidality [466, 619].
In concluding that the restriction infringed the right to equality, her Honour remarked that it created a distinction based on the type or nature of a disability which perpetuated prejudice and disadvantage for Mr Truchon and Ms Gladu [674]. Justice Baudouin articulated that the “type of physical disability, which does not have the effect of rendering their natural death reasonably foreseeable, thus prevents them from choosing their end of life, whereas other people just as physically disabled but whose death is close have that legal option” [663]. In determining that the infringement on the right to equality was not justified, the Court referred to its previous analysis and conclusion on this issue [685]-[690].
In applying the same legal principles and reasons to the ELC Act, mutatis mutandis, it was concluded that the end of life criterion violated s 15 of the CCRF and the infringement was not justified [705, 732]. Her Honour decided not to consider whether section 26(3) of the ELC Act infringed section 7 of the Canadian Charter of Rights and Freedoms [733].
The Court suspended the declaration of invalidity of s 241.2(2)(d) of the MAID Act and s 26(3) of the ELC Act for 10 months, until 11 July 2020 (Department of Justice 2020b). Although the declaration in Truchon was only in force in Quebec, the federal government committed to responding to the court’s ruling by amending the MAID Act nationwide (Department of Justice 2020a). On February 24 2020, Bill C-7: An Act to Amend the Criminal Code (Medical Assistance in Dying), was introduced in parliament.
Bill C-7 seeks to repeal the requirement that a person’s natural death be reasonably foreseeable. However, in recognition of the fact that removing this restriction could pave the way for persons with mental illness as the sole underlying condition to access MAID, Bill C-7 expressly states that “mental illness is not an illness, disease or disability,” thus reinforcing the position that psychiatric conditions alone are not a basis to request MAID (cl 1(2)).
The Bill maintains a strong protective position proposing two different sets of safeguards depending on whether the person’s natural death is reasonably foreseeable or not. The impetus behind this continued protective position was that greater care and protection were required for persons who were not at the end of life, which includes increasing the waiting period to receive MAID to 90 days (cl 1(3)). Furthermore, amendments were included to ensure that a specialist, expert in the area of the person’s illness, is consulted and the person is informed of alternatives to MAID such as counselling and support services.4
Due to the unprecedented challenges and widespread disruptions caused by COVID-19, the court granted an extension to the federal government, suspending the declaration of invalidity for 5 months, until 18 December 2020 (Truchon and Gladu v Attorney General (Canada) and Attorney General (Quebec), [2020] QCCS 2019 [25]-[26]). The application for an extension was heard before Bachand J, who declared that authorized persons, who meet all the criteria to access MAID except s 241.2(2)(d) of the MAID Act, can apply to a court to receive judicial authorization to access MAID [28]. Bill C-7 passed the House of Commons on December 10, 2020 and was referred to the Standing Senate Committee on Legal and Constitutional Affairs on December 17, 2020. It, therefore, remains to be implemented and is still progressing through the federal parliament (LegisInfo 2020). In response to Truchon, Quebec simply removed the criterion that the person be at the end of life, which became operational on March 12, 2020 (Gouvernement du Québec 2020).
The impact of Carter continues to be felt throughout Canada. Removal of the requirement that the person be nearing death to access MAID has inevitably opened MAID up to a wider cohort of persons. This development may have broader appeal for jurisdictions where legalisation of physician-assisted dying is a live issue, as questions concerning eligibility often prove divisive.5 Whilst it is clear that this development will result in a wider pool of persons eligible to access MAID, what remains to be seen is just how wide the pool will become. This is a question for which only time can tell.",J Bioeth Inq
PMC7809536,COVID-19 and dental nursing,"2020 will be a memorable year for all of us. The COVID-19 pandemic has had huge impacts on our personal and social lives but as dental professionals we have also seen substantial changes to our working lives. Dental nurses in both NHS and private settings have contributed to the pandemic response in many ways including, but not limited to, being redeployed to other NHS services, working in Urgent Dental Care Centres, and getting dental practices reorganised and ready to restart non-urgent care. The importance of good quality dental research has been highlighted by the pandemic and this article interviews two dental nurses contributing to different parts of the research pathway during the pandemic. 
As a dental care professional my involvement has been working in collaboration with a large research group at the School of Dental Sciences, Newcastle University, comprising of clinicians, academics and basic scientists eg microbiologists. As a collective, our overall aim is to improve understanding of dental aerosols and splatter to allow the safest practice of dentistry. At the start of the pandemic our work focused on updating old research methodologies (mainly used in the 1980s and 1990s) by adding in modern techniques and research methods. The methods used a tracer dye (fluorescein) and two techniques for measuring it. Next, we tested a range of procedures and checked the effect of suction and opening the windows. We looked at contamination close by and also over an open plan clinic such as here in the dental hospital. Figures 1 and 2 illustrate the experimental set up. 
We found that:'Water spray' from dental instruments can travel large distances and distribution of contamination (shown by fluorescein) varied widely across our experimental area (Fig. 3) Across all our experiments we found that the areas which received the most contamination ('hot spots') were down the length of the patient (toward the feet) and opposite the operator (the operator was right handed). This highlights the importance of good quality patient coverings (aprons) and PPE of the dental assistantAs a dental nurse it was reassuring to find that dental suction (with a wide aspirator tip) substantially reduces contamination. Also, the levels of contamination were much lower on the assistant compared to the operator - the highest sites were on my left arm and chest (I was holding the suction with this hand)We were able to compare different procedures and found that using a high-speed drill or an ultrasonic scaler produced the most splatter and aerosol. Using a slow hand piece (without irrigation) during an orthodontic debonding procedure produced very low levels of contamination and was a low risk procedure for aerosol generationWe have also conducted a study in an open plan clinic, such as those you might find in a dental hospital. The findings of this study have helped establish safe working practices in these clinics, including data on fallow times. 
The findings of our research have now been published in a series of papers.1,2,3
Firstly, I am very delighted to have been given the opportunity to work alongside the team. No matter what level of expertise you bring, I felt a massive involvement and my work contribution was valued. I enjoyed the entire journey of the study, from problem solving in the development phase, to learning new skills in the laboratory. You may think this is silly, but the most challenging part for me was my introduction to a pipette and trying not to drop the sample plate before it went into the plater reader for analysis. I particularly enjoyed the leadership role experience I gained in this project - I was in charge of running some of the experiments on the clinic once I had mastered the process. 
You may think this is silly, but the most challenging part for me was my introduction to a pipette and trying not to drop the sample plate before it went into the plater reader for analysis.
Dental services have been seriously reduced during the pandemic and there has been an urgent need to look to the safe remobilisation against the backdrop of uncertainty and uniqueness of the virus. The implications and risk factors surrounding the use of aerosol generated procedures (AGPs) and the transmission of SARS-CoV-2 therefore became a priority of much needed research. 
With this in mind, the SDCEP recently undertook a 'Rapid Review' of evidence relating to the generation and mitigation of aerosols in dental practice.4 The aims of the review were to:Determine which dental procedures constitute AGPsDetermine measures likely to mitigate the risk of transmission of SARS-CoV-2 via dental AGPsInform procedures for environmental cleaning between patients following a dental AGP.
It was a privilege to be invited to contribute to this work as part of the working group. My role as part of the working group was to represent the views of a wider group; apply professional knowledge, experience and expertise; to consider summarised evidence and to contribute to considered judgement outcomes; and to provide feedback on any drafts of the review. This was a fast pace review with huge support from the methodology team and multiple virtual meetings.
Dental nurses are key members of the dental team and quite often are responsible for infection prevention and control and as such, are well placed to not only inform and implement new ways of working but to help in the training of others. Nevertheless, the pandemic has taken the profession into new territory and unique times and everyone has had to adapt and respond to the rapidly evolving and urgent situation that we have found ourselves in. Everything happened very quickly in March 2020 and urgent safety measures had to be implemented in order that patients and the team were kept safe. What the dental teams looked for was guidance - this after all is what has always happened - but this time it was different. Dental nurses were not unique in not knowing what to do at the time, but they were certainly at the forefront when it came to adapting to new ways of working and volunteering to work in emergency and medical settings. This review has given long awaited clarity to some of the more complex matters and allowed all members of the dental team including dental nurses to make sensible and safe judgement calls. 
In summary this review has considered evidence relating to the generation of AGPs and the potential mitigation of aerosols, as well as the risk factors of the transmission of SARS-CoV-2. The considered judgements were based on the balance of benefits and harm, acceptability and feasibility. Its whole purpose was to inform policy makers and those developing clinical guidance for the dental team. Whilst this appears to be a rather large document, given the enormity of the task and the extent of the comprehensive literature considered, the industry is incredibly lucky that it is just 36 pages long. The research group were acutely aware that the dental industry was eagerly awaiting the publication of the Rapid Review and relying on it to an extent, to potentially play a part in the reduction in fallow times and therefore a change in the current level of services that they could offer. 
The Review was undertaken as a response to the evolving pandemic and was compiled with contributors from the four nations and from a multidisciplinary working group; focus groups also played a part in this work. In short, the review determines what is meant by aerosol generating procedures (AGPs), it determines which procedures produce bioaerosols and the associated level of risks to the procedures. This then allowed for the categorisation of dental procedures into three groups and a broader picture formed of how air changes could be influential in determining 'down time'. Figure 4 is a flow chart presenting recommended fallow times in different conditions. 
The review discusses the various mitigations ie 'Procedural and Environmental' and the recommendations are noted below.

Procedural mitigations
High volume suction - recommended for universal adoptionRubber Dam - recommended for universal adoptionPre-procedural mouth rinses - not recommended for universal adoptionAntimicrobial coolants - not recommended for universal adoption.


Environmental mitigations
Fallow time - recommended for universal adoptionAir cleaners - not recommended universal adoption.

These of course are conditional statements, and some practitioners may choose to use them after considering all of the factors. This is based on current available evidence and new evidence will continue to inform this work. 
It was an incredible privilege to be involved in this work; it has provided great insight into the mechanisms of conducting a Rapid Review at pace, but also in the unique situation of a pandemic. The whole group considered and listened to the points of view aired and it was fabulous to be able to work collaboratively with such esteemed members of the dental world and beyond, and then have a part to play ensuring colleagues understood the contents and the relevance and application to practice. Following the constant ream of papers and observing the appraisal and synthesis of relevant evidence and the analysis of the findings was incredible. The group used anonymous virtual polling to form consensus on the issues. Although we had regular weekly scheduled meetings there was a need, as we approached the deadline, to conduct additional evening meetings and every time we logged on, the minutes and updates were in front of us. We had presentations of ongoing and recently published research by research groups such as the team at Newcastle University, which Kimberley is a member of, which were really insightful. We knew that this review was going out on 25 September 2020 and that a first and potential second iteration would have to appear prior to this and whilst that added an element of pressure, it also helped to keep us on track. This brought a whole new dimension to my research experience and has certainly broadened my outlook on what is possible in emergency/urgent and evolving situations when applying and considering a methodology and methodological approach to research. I know it would not have been for everyone but I truly embraced the work in hand and look forward to the future workstreams.
I want to reassure any dental nurse/dental care professional who is interested in research that such a career pathway does exist and provides exciting challenges and opportunities.
Well, I was born and brought up in Fiji. However, after finishing school I served in the British Army, achieving the rank of sergeant. After eight years of military service, I gained British citizenship and settled in England, retraining as a dental nurse and qualifying in 2012. I still currently serve in the Army Medical Services Reserves, 201 Field Hospital Unit, with the Royal Army Dental Corps. In 2013, after a year working in a dental practice, I progressed my career by joining the Dental Clinical Research Facility (Dental CRF) at the Newcastle upon Tyne Dental Hospital. The post was for a research dental nurse with my primary role being to support a wide range of NIHR portfolio research studies. I also have additional responsibilities as the nominated link person for the Oral and Dental Patient, Carer and Public Involvement (PCPI) group, and have recently been promoted to senior research dental nurse. I have assisted with over 20 different research studies (quantitative/qualitative) and am joint co-author on several research project publications (British Medical Journal, Journal of Dentistry).In 2016 I decided to consolidate my professional research experiences with academic study to develop further my knowledge of research methods, research approvals, and ethics and governance when conducting research trials and interpreting data. To achieve this, I enrolled in an MSc clinical research programme, part-time, completing with Merit in 2019. My MSc project was funded via a Dental Care Professional research award (October 2018) and this has recently been published in BDJ Open (my first lead author paper!).5
And so here I am today, a dental nurse, with the current research involvement in light of the issues surrounding COVID-19 pandemic and the implications it has on dentistry. Throughout my journey I have been warmly supported and encouraged by my colleagues to expand my involvement in the research programme. I urge others who wish to learn new skills and tackle new and interesting problems to think about a career in research. Research qualifications and extended duties are not normally presented, or in some cases structured, as an alternative career route for dental nurses. However, I want to reassure any dental nurse/dental care professional who is interested in research that such a career pathway does exist and provides exciting challenges and opportunities. 

Editor's note

A special issue of BDJ Team focused on DCP research will be published later on in 2021. To propose or submit an article or for more information, please contact the Editor on k.quinlan@nature.com.",BDJ Team
PMC7809542,"Social Sciences, Bioethics, and the Question of Population","The deep interconnections between biology, population politics, and ethics have been strongly brought to the fore by the ongoing COVID-19 pandemic. The virus has highlighted the ways in which governments and state machineries calculate, control, and manage entire populations and demographic groupings, akin to what Foucault refers to as ‘biopolitics’ (Burchell et al. 1991): through measures such as complete or partial lockdowns, contact tracing, clinical trials, and vaccination. These steps immediately raise several important ethical concerns around questions of discrimination, inequality, surveillance, security, privacy, right to healthcare, and social protection. In this special issue, we foreground the discussion of bioethics in relation to demography and population politics by focusing on the two most populous countries in the world, India and China. In the process, we seek to enhance our understanding of the ways in which biology is enmeshed with population politics and the nature of bioethical concerns this generates. In doing this, we are guided by the conceptualisation that population as bioresource is not only ‘bioavailable’ (Cohen 2007) but can be rendered into ‘biocapital’ as Rajan (2006) articulates in his study of clinical trial patients.
As the most populous countries in the world, India and China have come to mark our collective conscience in significant ways (Eklund and Purewal 2017; Kaur 2020). The stance has, however, shifted considerably from fears of overpopulation and high fertility rates, to policies encouraging childbearing and addressing infertility through assisted reproduction. As a superpower, China is interested in facilitating birth amongst a chosen few; while India continues with its ambivalent posture on the domestic use of in vitro fertilization and other reproductive technologies, prohibiting the transnational traffic of ‘unsuitable foreigners’ and ‘non-heteronormative families’ to avail of the same. Most importantly, by aggressively participating in regulating the use of these technologies, the Indian and Chinese states are also keenly redefining the intimate lives of their citizenry. This is seen most pointedly in the recent change in the one-child policy of the Chinese state, and the newly drafted Indian Surrogacy Bill (soon to be an Act). In China, there are fears of environmental and industrial pollution leading to a diminution in sperm quality (Wahlberg 2018); in India, ethnically varying fertility transitions are deployed to further religious and political agendas (Chatterjee and Riley 2001; Singh 2020); globally, there is the spectre of ‘surplus’ men and ‘scarce’ women in rising Asia (John et al. 2008; Hudson and den Boer 2004; Kaur 2018; Purewal 2016). Additionally, with crucial generational shifts posing a threat to the earlier stability of marriage and child-centeredness, reproduction and reproductive processes are provoking yet newer moral and cultural anxieties. Resulting familial, kinship, and policy shifts are paramount in the ways in which China and India are approaching reproductive technologies and demographic transformation. Here, cultural peculiarities are beginning to provide new forms of engagement with the decade-long state, research, and policy obsessions with population control. There is little doubt that we need newer and more nuanced research paradigms than the ones informed by earlier understandings of population rhetoric. We need to understand the emerging familial configurations of third-party donor families facilitated through IVF, commercial surrogacy, and bride-shortage-related marriage migration and inter-generational care deficit among the many other social phenomena that are resulting from newer demographic trends.
The papers presented in this special issue emerged from a conference on ‘Reproduction, Demography and Cultural Anxieties in India and China in the 21st Century’ held at New Delhi, India, in February 2020. The contributors reflect on the value of ethics and ethical practices in relation to biological issues of demographic transformations and changing reproductive landscapes in the emergence of New Reproductive Technologies (NRTs). We further the discussions at the conference through three primary focus areas.The Social Sciences in Conversation with Bioethics: This special issue is firmly embedded in a social science focus that aims to reflect upon bioethics from the vantage point of how social practices intermingle with reproductive practices and technology in China and India. Here, the arguments and structure of the research papers highlight the need for greater engagement between society and medicine, especially medical technologies that have far-reaching consequences for people and populations. Thus, the special issue sheds light on practices and processes that may be offshoots of technological interventions into bodies and biologies: such as sex selective abortions and assisted reproduction.Reproductive Technologies and Bioethics: The focus on reproduction and reproductive technologies helps hone our discussion on bioethics and how it can be framed in terms of socio-medical practices and ideas, especially in the Global South where changing ideas regarding demography and population are spearheading medical innovations. Thus, ‘selective reproductive technologies’ (Wahlberg and Gammeltoft 2018) such as conceptive technologies, sex selection, and assisted reproductive technologies (ART) (for instance IVF) bring to the fore emerging questions of bioethical inquiry in relation to ‘population management’ (Brunson 2016; Chatterjee and Riley 2001; Gammeltoft 2014; Greenhalgh 2008; Murphy 2012; Wahlberg 2018). The special issue broadens the scope of looking at reproductive technologies to spheres of operation including changes in demographic culture and character through female-selective abortions, or pursuing preconception selection (the technological intervention into ‘designing’ a foetus to be of a particular sex, racial, and other characteristics).Social Demography and Bioethical Questions: One of our innovative approaches in this special issue brings together research linking bioethics to social practices such as marriage, family making, care provision, legal injunctions, and state policies. The focus is on how populations and demographic predictions are intimately intertwined with state policies regarding reproduction and reproductive technologies, such as family planning, surrogacy, assisted reproductive technologies, and sex selective abortions. Such state interventions happen through law and policies at one level and at another through the mapping of emerging social practices involving family making and marriage. Marriage (or the lack of it) is an important subtext to some of the papers in the issue, reflecting upon the ways in which reproduction and procreation not only remain an important goal of socially mandated intimacy but also become a vehicle for social reproduction of individuals, families, and communities. The questions we are asking here interrogate the forms of interventions that communities and states undertake in ‘fashioning’ populations through particular social practices.
These three vantage points come together in Bhatia’s (2021), Majumdar’s (2021), and Weis’s (2021) papers on reproductive technologies and the reconfiguring of populations through specific biological markers. In Bhatia’s (2021) paper, China and India are situated within the globally stratified landscape of sex selection through ARTs, challenging the understanding of sex selection as ‘unethical’ in some societies and as ‘choice’ in other societies. She examines this practice as a part of a ‘global form’ of family balancing and construction of a particular ‘lifestyle’ in some Western countries, being dubbed as patently unethical in other non-Western countries where sex selection happens in the context of son preference and state anti-natalist policies. Majumdar (2021) presents (un)ethical underpinnings of the ways in which ARTs are used by medical practitioners in India to circumvent the ‘biological clock’ and ‘manage’ declining reproduction of female bodies, young and old. The intrusive techno-medical approach, with its exclusive focus on eggs and wombs, and a rhetoric of ‘decline’ and viable pregnancy not only disaggregates women’s bodies into parts but also erases the possibility of any engagement with women’s agency and choice. The question of choice and ethics is also central in Weis’s (2021) examination of cross-border fertility landscapes between China and Russia. Here, Chinese fertility travellers are actively appropriating ARTs to ‘fashion’ progeny by either creating phenotypical resemblance in them by using Asian donors or by selecting ‘white’ donors to engineer ‘enhanced’, ‘superior’ children, thereby fuelling racialized imaginaries and exacerbating inherent inequalities in global reproductive care chains.
Are certain populations compromised in the practice and social potency surrounding reproductive technologies? One of the questions we are examining through a bioethical lens is centred on the identification of emerging demographies as ‘residues’ of sex selection and assisted reproduction. By ‘residues’, we are keen to understand how certain sets of age and gender demographies are threatened into forms of social debility due to certain biotechnological processes. Thus, in Mishra’s (2021) paper, adult unmarried sons and their debilitated ageing parents have become threatened as a result of new forms of bioregimes that have eliminated female foetuses in the protection and pursuit of male babies in north India, creating bride-shortages, complicating and shifting local ethics of care within the family-household. In Meng et al.’s (2021) paper, foetal sex-determination technology and sex-selective abortions have put ageing bachelors—alone through no choice of their own—at a heightened risk of having less or no familial care. This is caused by a conflict between the individual’s family life and societal family ethics. The inability to marry becomes a trope of the ways in which certain populations become liabilities for those nation states and communities that are actively involved in ‘designing’ desired families, and by extension, populations. Similarly, Gu (2021) shows how unmarried women become part of a population marked by the imaginings around pronatalism and the biological clock. Gender is a very important marker of bioethics here, both in how it is manufactured socially and marked physiologically through pronatalist conversations around suitable progeny.
In our final paper, population itself is the biocapital, which is valued through its demographic returns. In Kaur and Kapoor’s (2021) paper, populations move and change not only through identified processes of demographic movement, but through concerted and orchestrated social processes wherein genders become valued as commodities to be invested in, and or harvested, raising questions of gender justice. The use of sex selection technologies to eliminate girls is constructed as rational and scientific (and hence ethical) while being enmeshed in state policies and family biosocial strategies of social mobility. This final paper concludes the discussion that the previous papers began to look at, viz. the imaginings around populations: whether through ‘restrained natalism’ as Wahlberg (2019) calls it, in the case of China, or through investment in women and girl children, to rethink sex ratio imbalances in India. Here, bioethics is part of real-time community, state, and individual investments into thinking about the future of social demographics.",Asian Bioeth Rev
PMC7809235,Online lockdown diaries as endurance art,"After the city of Wuhan was shut down on January 23, 2020 due to the coronavirus outbreak, many residents in Wuhan started writing “lockdown diaries” (封城日记), which they shared on social media. Initially, there were only a few, but then some became viral. Within weeks, there was an explosion of diary-writing and posting online. Some of the diarists stopped writing when the lockdown was lifted on April 8; others continued. By August, 2020, I had collected several thousand diary entries produced by hundreds of writers. Some of these were written by residents in other cities; most were produced by Wuhan residents, ranging from teachers, medical workers, COVID-19 patients, government officials, and IT professionals to students, poets, novelists, and community volunteers.
Most of these diaries were written in a traditional diary form. Entries typically started with information about dates, weather, and in some cases, and the latest tally of COVID-19 cases. They were one to two pages long, although some entries ran much longer, often because they contained many photographs. The most popular online platforms for posting lockdown diaries were WeChat and Sina Weibo: some authors posted their diaries simultaneously on both platforms. Video diarists (or vloggers) typically shot short videos on cell phones and then uploaded the videos to video platforms, such as YY, Red, and Douyin (the Chinese version of TikTok).
These forms of lockdown diaries documented both personal and collective struggles. The abrupt shutdown of a city of 11 million people stunned China and the world, and lockdown diaries brought home the visceral reality of the closed city, and the pandemic. As soon as they appeared, these diaries began to attract scholarly attention (Yang 2020; Bao 2020). Bao (2020) has studied three women’s diaries in Wuhan, China, with a focus on their engagement in feminist issues. A team of Polish scholars have used pandemic diaries to study life in isolation in Polish society (Łukianow et al. 2020). Anthropologists have been studying the disruptions to life and work caused by the pandemic as well as how people use pandemic diaries to make sense of the disruptions (Manley 2020). Diaries have long been studied as a form of personal writing and life narrative (Ben-Amos and Ben-Amos 2020; Lejeune 2009a, b; Martínez García 2020; Plummer 2001; Rak 2020). The COVID-19 pandemic presents a set of new circumstances for the production, reception, and study of diaries. The appearance of large numbers of pandemic diaries in different parts of the world is unprecedented. From Valencia, Spain and St. Petersburg, Russia to Pittsburgh in the U.S., pandemic (or quarantine) diaries were written and shared online (Nierenberg 2020, March 30). The most remarkable feature of this phenomenon, which distinguishes it from the conventional diary, is the online publishing and sharing (Lejeune 2009a). Posting diaries on social media gives them audiences unavailable to the traditional diary. The audiences themselves are networked (boyd 2010; Marwick and boyd 2011). Interactions and engagement with the networked audiences are a writing incentive to diary writers, but as we will see in the case of Wuhan lockdown diaries, they may also bring unwanted attention and scrutiny.
In the U.S., according to one account (Rettberg 2020), the earliest online diaries appeared around 1994. In China, the personal home pages (Yang 2009) which blossomed in the late 1990s often published diary-like writings of their editors. The first well-known online diary appeared in 2000, when the popular online literature website Under the Banyan Tree serialized the online diary of Lu Youqing (陆幼青), who was dying of cancer. Lu’s diary chronicled his struggle with cancer and won a large following (Hochx 2015). Online diary-writing became widely known with the introduction of blogs to China in 2002. The Chinese translation for blog, 博客, is credited to one of China’s internet pioneers Fang Xingdong. But the concept of the blog and the practice of blogging owe much of their initial popularity to one blogger’s online diary—Muzimei. A young woman based in Guangzhou, Muzimei began to serialize her diary about her sexual exploits on her blog hosted by blogchina.com on June 19, 2003. These blog entries were explicit in sexual content, a daring challenge to mainstream mores of sexuality, marriage, and freedom of expression. Muzimei’s online diaries not only brought fame (or infamy for her critics) to her own blog and the website blogchina.com, but they also boosted web traffic in many other web sites where the controversies about her diaries raged (Farrer 2007).
If Muzimei’s online diaries were popular in 2003, the size of their popularity was limited by the size of the internet population. But the internet developed rapidly in China (Guo 2020; Han 2018; Hu 2008; Negro 2017; Qiu 2009; Yang 2009). China had only about 80 million internet users in 2003, compared with 940 million as of June 2020 (CNNIC, 2020). The most popular social media platforms today, Sina Weibo and the “super-sticky” WeChat (Chen et al. 2018), appeared only after 2009. And Weibo and WeChat were the main platforms for posting lockdown diaries.
Even in ordinary times, keeping a diary takes efforts; it requires self-discipline and perseverance. A pandemic-induced lockdown exacerbated the hardship. Wuhan diarists had to overcome obstacles of time management, boredom, mental and physical exhaustion, and censorship. Writing and posting diaries during the lockdown was an ordeal and an accomplishment. In addition to enduring the lockdown like others around them, diarists were also enduring the consequences of their commitment to iterative online publishing: keeping up with repeated posting on social media and managing responses. Each iteration carried forward and partially re-enacted the entries that came before it, so that the whole series of diary entries became an ongoing dialogue with both the self and the diarist's networked audiences. The fact of iteration itself became its own motivator. Writing lockdown diaries became a practice of endurance art.
In ‘Performing Endurance: Art and Politics since 1960′, Lara Shalson (2018) examines the intentional performance of endurance in both art and life. Conventional wisdom associates endurance with pain, ordeal, and hardship: Shalson directs attention to endurance as a form. Using Chris Burden’s 1971 “Shoot” as an example, she suggests that all endurance art has a simple structure: “it involves a plan and a following through of that plan… (except that) the plan, like all plans, can never guarantee its outcome in advance” (Shalson 2018, p 9). She continues:Endurance is built on a plan, then, but this plan does not fully dictate what the work becomes. The artist designs and then endures an unfolding of events that can never be fixed from the start. This indeterminacy arises from another essential element of endurance: namely, that it is always performed in relation to forces that are beyond the performer’s control. (Shalson 2018, p12).
The indeterminacy here is key to the parallels with the uncertain promise of digitally-mediated social connectivity. Posting publicly, repeatedly, has no guarantee of result, and is therefore its own end—an offer, or performance, with no guaranteed outcome. This is arguably also a status or condition of traditional handwritten diaries: the French diary scholar Philippe Lejeune defined a diary as “a series of dated traces.”(Lejeune 2009b, p 179): a “series,” because it is kept over a period of time, the accumulation of entries over time transforming the status of individual entries into more than constituent parts. The effort to sustain the act of iteration turns diary-writing into an act of endurance. At the same time, the digital sphere gave individuals under lockdown a unique opportunity to lay down a record of what was happening to them as it happened.
The acts of writing and posting a diary were acts of personal agency in an otherwise contingent, uncontrollable reality, one that depended on the ability to make this repeated gesture in a consciously collective context—in this case, social media.
I started collecting lockdown and pandemic diaries as soon as Wuhan was shut down. I followed some of the diarists on Weibo and WeChat, and searched for diaries using the Chinese search engine Sogou. Reader comments on diary posts were also selectively saved. The diaries cited in this article come from this personal research archive. For diarists cited in this article, I use real names if they are already well-known public figures (e.g. Fang Fang 2020; Guo 2020) or if I have permission from their authors. Otherwise, I use pseudonyms to protect their anonymity. Chinese names mentioned here follow the Chinese convention of family name first, given name second. All diary quotations are translated into English by myself. Many of the diaries have since disappeared from the web, making it unhelpful to provide their original URLs. Instead, I have used the following citation format: Diary name (or pseudonym), followed by the date of the entry, as in: Guo Jing Diary, February 7, 2020.
Although citizens in many countries have had lockdown experiences during the COVID-19 pandemic, the lockdown experience in Wuhan had its unique features. No other city in China or the world was sealed off as abruptly, decisively, and tightly as Wuhan. Beginning on January 23, 2020, all outbound and inbound traffic—air, railway, highway, waterways, was simultaneously suspended; traffic within the city was similarly highly controlled. From February 16 to April 8, 2020, all residents were forbidden from leaving their residential communities. Although community workers and volunteers helped to deliver medical and daily necessities during this period (Mei 2020, p. 319), grocery shopping was especially challenging and residents often had to organize their own ways of purchasing grocery. Many lockdown diarists, almost all women, documented in detail how they managed shopping for grocery when they could no longer leave home. The typical method was group shopping, because grocery stores stopped taking individual orders online and did not allow in-person shopping. WeChat groups, which had always been a popular feature of the instant messaging platform, became a convenient way of organizing grocery shopping. Li Meng and Qin Yin wrote that they and their friends in Wuhan all set up and joined multiple WeChat groups for grocery shopping; one person joined about 20 such groups (Li Meng’s Diary, February 17, 2020; Qin Yin’s Diary, February 17, 2020). Ning, a psychology counselor, wrote frequently about her WeChat group shopping experiences. On February 25, 2020, she reported her new daily routine: the first thing she would do when she woke up in the morning was to check the WeChat grocery shopping groups for shopping information. Because there were so many groups, she would have to go through long threads to find the information she needed (Ning’s Diary, February 25, 2020).
Diarists were aware of the unprecedented nature of the Wuhan lockdown. As witnesses, they wanted to document personal history in an extraordinary historical event, and leave a personal record. Mr. Amber, a Wuhan native and prolific diarist, was staying with his parents in Wuhan during the lockdown. In his last entry, written on the last day of the lockdown, he summed up his total output: 76 diary entries for 76 days of the lockdown, totaling 143,000 words, in addition to 40 poems and some occasional essays. A self-conscious diarist, he explained to himself repeatedly why he was keeping a diary and reminded himself again and again to persevere to the end of the lockdown. On January 28, the sixth day of the lockdown, he wrote that his original intention in keeping a diary was to document his and his family’s life:My diaries are a running account, but the records are true. Therefore, in my heart I feel that my “Lockdown Diary” is meaningful. Maybe meaningful only to myself. One day when I look back in my old age, it will be the “Grand Historical Record” (史记) of part of my life.1 It is said that there are two most valuable words in the world. One is “self-discipline.” The other is “persevere.” Self-disciplined people keep changing themselves. People who persevere change fate. I must persevere. I will persevere [in my diary writing] till the end of the anti-coronavirus and stay-home life! (Mr. Amber’s Diary, March 28, 2020).A Ms. L wrote:To do one thing well requires a strong will. It requires a clear goal as guidance. Giving up is easy. When there are hardships, obstacles, and one difficulty after another, one must overcome laziness and cheer oneself on, in order to persevere. Only in this way can one act more effectively. Neither the continuation of the pandemic nor the busy work schedule after the resumption of class has caused me to skip even a single day of diary. I have written close to 100,000 words. The daily habit of writing makes me overcome all difficulties. Nothing can stop me from writing, rain or wind. (Ms L’s Diary, May 22, 2020).
A sense of community developed through the sharing of pandemic diaries and the encouragement from readers. Lena Buford’s (2020) study online diaries in the early years of the internet history in the U.S. finds that people who posted online diaries built personal connections in online spaces, leading to the appearance of online diary communities. Diarists derive satisfaction from being recognized by readers or viewers. Readers cheer diary-writers on by sharing supportive comments. Mr. Zhang, for example, often reported how happy he was to see that a particular day’s entry had reached hundreds of views, or how flattered he was to receive compliments from his friends or former teachers.
The contents of the lockdown diaries reflect the changing circumstances of the efforts to control COVID-19 and the impact of these measures on personal lives. In the first week of the lockdown, initial reactions include panic shopping and feelings of personal helplessness. For example, a diary entry dated January 27 2020 by feminist activist Guo Jing says:Today, the weather was a bit clearer, but still cloudy. After walking for only a few steps outside, I saw two cats on a pile of debris. We stared at each other. The scene had such a strong sense of the apocalypse. When we stared at each other, it seemed as if there were only me and the two cats left in this world. (Guo Jing’s Diary, January 27, 2020).
February in Wuhan saw the peak number of daily confirmed cases of coronavirus and daily deaths. Diarists writing on February 7 usually mentioned the death of Dr. Li Wenliang on that day. Li Wenliang had been widely reported as an early whistleblower who then contracted the disease on the job. February was also the month when the efforts to contain COVID-19 were at their most austere, and many diaries record a rigid regimen of community isolation and quarantine. A graduate student who volunteered to work as a guard at the entrance of a residential community reported that she started work at around noon.
At 12:30 p.m., two lunch boxes were delivered to the volunteers at the gate. At 1:08 p.m., a man in his 30 s passed by and asked for a pair of gloves. The man told her he was going to visit his wife in the hospital, and he had to wear gloves to be let in. She gave him the gloves. At 2:35 p.m., a white-haired elderly woman in her 80 s appeared and said she was going out to buy some lunch. Instead of letting the elderly lady out, she gave her a free lunch meal and persuaded her to return to her apartment. (Ms Hu’s Diary, February 20, 2020).
A most extraordinary aspect of the fight against COVID-19 in Wuhan was the rapid construction of specialized and fangcang temporary shelter hospitals. Health care workers and COVID-19 patients provided rich personal documentation of life in these facilities in diaries, social media postings, and video blogs. One of the viral video blogs showed medical workers and patients cheerfully performing public square dances inside one of the temporary hospitals. Square dancing was ubiquitous in China’s pre-COVID-19 urban landscape. For some, seeing it again boosted morale, while others saw it as inappropriate for a time of national suffering.
Ah Nian (阿念) is the web name of Wu Shangzhe (吴尚哲). A 26-year-old Wuhan native who works in Beijing, she traveled back home to Wuhan on January 19, 2020 for the Lunar New Year holiday. She was diagnosed with COVID-19 on February 13, 2020 and moved to a temporary shelter hospital the same day. The next day, An Nian started posting diaries on Sina Weibo and vlogs on Douyin. Her Weibo postings were mostly short, some as brief as one phrase or one sentence, but their brevity conveyed a special urgency and force. Thus her first posting on Weibo starts with:Shelter Hospital Diary Day 1: #Valentine’sDay#. My residential community sent a police car to take me to the shelter hospital… I will try to be the most optimistic girl in the hospital. (Ah Nian Weibo Diary, February 14, 2020).Her second posting on Weibo, put up on the same day, goes:Shelter Hospital diary: The patient in #72 bed suddenly burst into loud howling with her hands reaching forward. She was not speaking clearly and was trembling. My heart sank. I hurried to the help desk to get a nurse. I thought she must be suffering badly from the disease, but it turned out it was because of her personal relationships. (Ah Nian Weibo Diary, February 14, 2020).
By March, COVID-19 had been contained in China, but was getting worse in other countries. In the U.S., incidents of racism against ethnic Chinese and Asian Americans increased significantly (Cheung et al. 2020). Far-right conservative protests to defend their liberty of not wearing face masks were widely reported (Wilson 2020, April 17). These stories were translated into Chinese and circulated on Chinese social media, causing great fear and trepidation. Many diarists took note of these changes. Mr. Zhang, for example, who started posting diary entries on January 27, by March 18 had posted 49 entries, and wrote he would now turn his attention to the outside world. His son was studying in the United Kingdom and incidents of racism against Chinese students there worried him. For several days he posted diaries in the form of letters to his son, offering advice about how to manage his stay-at-home life in a foreign country. These diaries attracted other parents with children studying abroad. Ms. Ma noted in her diary on March 1, 2020 that 58 countries in the world had now reported cases of COVID-19. She commented that in northern Italy, although multiple towns were locked down, residents in one town rallied in a plaza to demand freedom. After enumerating a long list of such COVID-19-related activities in foreign countries, she summed up her thoughts with these words from Yuval Harari: “Never underestimate human stupidity” (Ms Ma’s Diary, March 1, 2020). Sentiments of nationalism were arising.
Initially, diarists had no idea how long the lockdown would last, and few expected it would last as long as it did (76 days). The unknowable nature of the end point caused anxiety. Diarists were highly conscious of the number of days the city had been under lockdown, and counted the number of entries they had written by numbering them. Writing down numbers and dates were an important part of the activity. “Lockdown Diary 12, 12th day of lockdown, February 3, 2020,” Tao Tao wrote at the top of her entry for that day (Tao Tao Diary, February 3, 2020). “Lockdown Diary (60), March 22, 2020, Sunday,” wrote Chu Ma and Xuan Yue (Diary of Two Walking Trees, March 22, 2020). February 21, the thirtieth day of the lockdown, was taken as a milestone by many. Fang Fang started her diary for that day by saying: “The thirtieth day of the lockdown. My Heavens. It’s been so long.” (Fang Fang Diary, February 21, 2020). Tao Tao wrote, “It’s been 30 long days. If I hadn’t been writing a diary, I would not know how many days it has been. Thinking back to a month ago feels like another world.” (Tao Tao Diary, February 21, 2020). To live with this intense awareness of the passage of time, reflected in the counting of every passing day, while completely incapable of knowing when such days would come to an end, was to endure. In this sense, endurance was to constantly remind oneself one was living with an unknown future.
Another kind of endurance was self-doubt. Some authors felt that life was disrupted by the pandemic on such a scale that keeping a daily account of one’s personal life might seem trivial. Others experienced an acute sense of powerlessness induced by a quarantined life, and fought to resist self-pity. Guo Jing was initially hesitant when a friend encouraged her to start a diary. She did not wish to be seen as a victim and did not feel she was among the most unfortunate, saying “it took courage to recognize one’s powerlessness.” She pondered the meaning of keeping a diary from the perspective of a feminist activist:As an advocate of gender equality, I know better than others that to solve a social problem, it is first necessary to tell it. I decided to try to keep a diary, because I do need support now. (Guo Jing Diary, January 25, 2020).
Telling her personal story and sharing her diaries with others became a way of managing her self-doubt and powerlessness.
A further type of endurance was practical: mental and physical exhaustion. Writing up a one-page diary in Chinese characters can be remarkably time-consuming. Publishing one’s diary on social media requires additional attention and labor. Some diarists commented on the hardship of this work. After finishing writing her diary on January 27, 2020, Guo Jing was so exhausted she had to lie in bed for a couple of hours: “It never occurred to me before that writing a diary was so mentally and physically exhausting. The lockdown freezes time and space, but at the same time magnifies our emotions and feelings. I’ve never paid so much attention to myself.” (Guo Jing Diary, January 25, 2020) For Mr Zhang, writing had long been a habit and an essential part of life, “as important as breathing and sleep,” (Mr. Zhang’s Diary, February 14, 2020), but during the pandemic he felt that he could now not write every day. Under lockdown, he found he lacked time, energy and focus to properly revise, proof-read, insert photo images, and prepare posts for sharing every day. It was a vicious circle: at one point he lost sleep because he had spent so much time trying to write his diary that he had not had enough time to do physical exercise. And lacking sleep, he could not always keep up with his daily writing…. (Mr. Zhang’s Diary, February 1, 2020).
This practical endurance was a feature of diarists who were frontline health care workers, COVID-19 patients, or volunteers who only had time to write after a day’s work. Dr. Zha, a physician sent from Shanghai to Wuhan, wrote 67 diary entries during her 68 days in Wuhan. In her entry on February 18, she wrote that she was too exhausted to write anything that day:It is so hard to balance between all kinds of good wishes and reality. Today was the most exhausting day for me since I came to Wuhan. I don’t want to do a thing. Don’t even have the strength to talk. (Dr. Zha’s Diary, February 18, 2020).
Diarists had to endure both attention and its absence. To post entries on social media is an invitation for reader engagement: some diaries had few readers while others went viral. Neglect and/or fame was a constant source of anxiety. While diarists wanted their works to be read, they could not control readers’ reaction. Tao Tao, a mother of a 12-year-old son, wrote:There are many things I want to write about—dreams, love, and even my trivial everyday life. Some things I wrote, I later cut. I want to be known, but fear to be known. I want to be understood, but do not want to be controlled. There are some secrets in the notes I make and musings to myself that will stay in my draft folder. I’m open-hearted and frank, but that brings the fear of being misunderstood. (Tao Tao Diary, April 1, 2020).
Finally, diarists had to endure the risks and realities of the ephemeral nature of cyberspace. Web sites and the information on them are constantly refreshed and updated, which would mean information constantly degenerates and is erased. There is something fundamentally ephemeral about the web (Chun 2008). Many websites and web postings disappear quickly, not the least because of censorship in China (Yang and Wu 2017). On February 1, the poet Xiao Yin wrote that he had archived ten postings for future use on his WeChat, but when he opened them again in the evening, five of the ten were gone, a “death rate” of 50 percent (Xiao Yin Diary, February 1, 2020). On February 28, he noted that he had written 38 diary entries about the Wuhan epidemic. Yet only about a dozen of them survived censorship; others were all censored for unknown reasons. Even so, he continued to post his diary entries. On March 2, 2020, Xiao Yin told his readers that it took him an hour and a half to publish his diary for that day. It simply would not go through after repeated attempts to post it. He checked his use of words meticulously. In the end, it went through after he changed one word in the following passage:Even when the epidemic situation is so grave, we still see that some people are lax and lazy in doing their job. There are always people who depend on the operations of the monster machine and benefit from the dividend of the rules. The same danger has another manifestation. To make sure that they don’t get into trouble, some people would rather move further to the left [of the ideological spectrum]. You never get into trouble for singing praise. (Xiao Yin Diary, March 2, 2020).
The next day, Xiao Yin revealed the one-word secret. The original text that prevented his diary from being published was the word “left” in “further to the left” (左一点). It worked after he changed “left” to “radical” (激进). Even Xiao Yin did not understand exactly why “left” was a more sensitive word than “radical.”
The other side of the coin of ephemerality was the unforeseen consequence of virality. As the pandemic evolved beyond Wuhan, words written in one set of circumstances took on new meanings. Fang Fang’s diary became the best known of all lockdown diaries, perhaps unsurprisingly because she was a famous Wuhan novelist. From late January to late March she posted 60 diary entries on social media, mostly her observations and reflections about the pandemic and the havoc it was wreaking on her native city. She felt the pain of her fellow Wuhan residents, and called on the public to hold government officials accountable for their actions or inaction. She mourned the dead in moving language, and her sharpness, empathy, and insights endeared her to millions of readers in China and beyond. Each of Fang Fang’s diary entry became a social media sensation, with her readers waiting up late to read the new post, sometimes as late as 2:00 or 3:00 a.m. Reporting on April 10, 2020, about two weeks after Fang Fang had stopped writing her lockdown diary, a story in the The Guardian states that “On Weibo, ‘Fang Fang Diary’ has had 380 m views, 94,000 discussions, and 8,210 original posts, peaking last week” (Davidson 2020, April 10).
The viral success of Fang Fang’s diary brought on scrutiny and personal attacks. Initially, her detractors blasted her diaries for being too critical and “negative,” complaining that they lacked “positive energy.” Then, in late March when news came that an English version of Fang Fang’s diary would be published in the United States, she began to be called a traitor. By making her diaries available to US readers, the accusation went, she had “handed over ammunition” to US politicians who were already blaming their own pandemic failures on China. Fang Fang had criticized government leaders for mishandling the pandemic, and her critics could now point out that China had done much better than that of the United States. Her diary drew the special ire of Chinese nationalists, and she became the target of verbal abuse and even death threats. Fang Fang fought back on Weibo, and continues to this day to endure the ongoing consequences of her lockdown diaries, whose meaning retroactively transformed as the suffering of the rest of the world followed, and exceeded, that of Wuhan.
As online diary communities extended over time and geographical space, the affordances of platforms caused their character as friendly/unfriendly to change. Fang Fang posted her diaries both on Sina Weibo and on WeChat.2 On Weibo, postings are open to viewing and commenting, unless the account holder turns off the comment function. For most of the time she was posting diaries during the lockdown, Fang Fang did not close this function: her posts would often receive thousands of comments. Although most were positive and supportive, critics and trolls also used the space to ferociously attack her. Comments on WeChat are moderated and less likely to be offensive. It was also here that more closely-knit communities formed. After Fang Fang decided to stop writing in late March, her fans on WeChat started writing and posting their own diaries as “relay diaries” to carry on her cause. Reading Fang Fang’s diary had become such a daily ritual that many found its absence unbearable. From March 27 to May 29, 60 people wrote 60 “relay diaries” to match the output Fang Fang’s diary entries had maintained—an explicit example of the priority of the performance of community as the offer and product of the lockdown diary-writing.
These “relay diaries” raise a question of the span—a preoccupation of recent scholarship about a work of endurance art. Does it consist only in its live performance? In that case, how can it be repeated (conserved, preserved)? The fact that the life of Wuhan lockdown diaries did not 'end' when their authors stopped writing offers an interesting analogy for this question. The lockdown diaries' reification by repetition (a condition that is ongoing in the case of Fang Fang) resonates productively with some of the paradoxes scholars have associated with performance art.
Scholars in performance studies were initially fascinated with the ephemerality of performance art. Phelan, for example, considered “disappearance” as the most distinctive feature of performance art:Performance’s only life is in the present. Performance cannot be saved, recorded, documented, or otherwise participate in the circulation of representations of representations: once it does so, it becomes something other than performance. (Phelan 1993, p 146).
Others have highlighted the messy relationship between performance and disappearance, arguing that performance is not that which disappears, but is “an act of remaining, and a means of reappearance.” (Schneider 2001, p 103). Schneider continues: “performance becomes itself through messy and eruptive reappearance, challenging, via the performative trace, any neat antinomy between appearance and disappearance, or presence and absence.” On the basis of his study of Chris Burden’s “Shoot,” for example, Christopher Bedford (2012, p 86) expands this thinking in ways that could almost be describing Fang Fang's diaries and the various stages of their interactive reception:Performance is a myth-making medium and as such essentially viral in nature. It extends indefinitely through history, its auratic charge often gaining traction and potency, just as the originary act recedes and recedes. It is the absence of the event, the absence of an object, which makes the work available for rewriting, and it is this quality that permits the work to travel through time and space, absorbing and assimilating the conditions of history. The moment of performance, then, is simply the beginning point, the source of the myth, one of its functions being the foundation of a viral chain, the ontology of which is predicated on perpetual revision, by historians and practitioners.
Shalson (2018, pp 32–33) argues that the performance of endurance art is bound to live beyond the live event, because it already engages with multiple temporalities:Endurance works begin with decisions and plans made beforehand… and they continue afterward through the circulation of documents and accounts that generate powerful effects on viewers long after the performances are over. This is as true for performances that last a few minutes as it is for performances that last years. Hence, the time of endurance is multiple.
As an endurance art, lockdown diaries both are of, and seek to transcend, their moment. For many of the diarists who stopped writing when the lockdown ended, what they endured while writing their digital diaries lived on in other forms. But in what forms was a matter beyond their control, in the same way as the following through of their original plan of writing was hard to control, because, to repeat Shalson’s (2020, p 12) point, the implementation of a plan happens in relation to other forces. All diarists practiced the art of endurance in their own ways to the extent that they persevered in writing and publishing diaries on social media despite the uncertainties about how and when the lockdown would end.
But Fang Fang’s diary is the most dramatic example of this lack of control. As mentioned earlier, Fang Fang endured personal attacks while she was writing and posting her diaries: these attacks did not stop when she stopped writing but became even more vehement. The main reason for the heightened animosity toward her was the publication of the English translation of her diary in the United States. The English version of Fang Fang’s diary continued (or reperformed) the life of her diary in a different time–space—outside China, after the pandemic had been contained in China. The consequences of the translation spawned complicated new plots. Even the English translator Michael Berry, a professor of Chinese literature at the University of California-Los Angeles, became the target of personal attacks from Chinese netizens on Sina Weibo. Professor Berry wrote in his “Translator’s Afterword”:After receiving a series of texts from friends warning me about what was happening, I checked my Weibo account to find more than 600 messages and comments filled with hateful comments and threats against my family and me. These were all in response to news that an English edition of Fang Fang’s Wuhan Diary was to be published and that I was the translator. (Berry 2020, p. 312).
Faced with growing hostility, Fang Fang carried on a fearless verbal battle with her attackers on Weibo. From April 29 to May 9, she posted a series of 9 new essays entitled “About” (关于), each the length of another diary entry. In them, she responded in painstaking patience and excruciating detail to all the accusations made against her. She had already given many of these explanations in her diaries or Weibo postings. But she decided to give her responses again and in greater detail by addressing all the issues one by one. For example, one accusation was that she did not personally experience or witness all the bad things she wrote about in her diaries; she had merely heard about them from other people while she never even left her house. In the second essay of the series, entitled “Hearsay,” she countered: “In their view, there could be no truth without personally going to the site to investigate. Then let me ask: You didn’t come to investigate me in my home. How did you know I never left my house?” (Fang Fang, “About,” April 30, 2020). She reasoned:The entire Wuhan is a live scene to me. I’m in the middle of it. I’m one of the victims of the catastrophe. I can genuinely feel the fear and harm the epidemic brought to the people. Many of the things happened around me, within my sight. Sure, many of the small scenes I didn’t visit nor could I. But I can still document them. For example, about Li Wenliang’s death. I wasn’t in Wuhan Central Hospital, but I could write about him. I never visited the fangcang temporary hospitals either, but I could also write about them…. I can use modern technologies to interview them and find out about their situation. In fact, many journalists did interviews in the same way. When they interviewed doctors about emergency care, they could not possibly be there on the scene. They could only listen to physicians’ stories. Many journalists interviewed me through the internet. They never met me in person. You cannot say these interviews are fake or rumors….[…]…After all, I have lived in Wuhan for over 60 years. I went to elementary school, middle school, and college here. I worked as a factory worker, a journalist, a writer, and an editor. I know people from all walks of life in Wuhan. Many of them are my WeChat friends and in my contact list. Is it difficult for me to obtain information? … My diaries were read by countless numbers of people. Many of them sent me all sorts of information. I have the names of all these informants. The information they gave me was almost always about their own family members or things that happened around them.
Fang Fang enumerated five sources of information for her diaries to refute the accusation that what she wrote about was hearsay. The point here is less about what Fang Fang wrote about, than how she did it. She explained in painstaking detail what it means to write about one’s experiences while staying at home during the lockdown and why interviews and informants can provide legitimate information for her musings in her diary. It is almost as if she was explaining how to do investigative reporting or qualitative social science research during a pandemic. Doing this again and again amounts to a critical pedagogy of repetition in a school of endurance.
Fang Fang’s repeated explanations, however, did not stop the attacks. One challenge for her was that forces beyond her control shaped reader responses. The attacks on her became especially venomous after Western politicians and media began using racist headlines, such as the “China virus” and “China is the real sick man of Asia” (Mead 2020) to scapegoat China as their countries struggled to control the virus. Sensationalist demands for China to pay reparations were made in the U.S. to deflect the administration’s responsibility for failing to tackle the crisis (Shear et al 2020). These claims touched a deep historical nerve for Chinese who were reminded of humiliations imposed on China by Western powers through unequal treaties in the nineteenth century (Esherick 1987; Gries 2004; Wang 2012). All this led to a surge of patriotism among the Chinese public. Some diarists wrote that they felt so fortunate to be citizens in China (Sister Ma’s Diary, April 22, 2020). It was under these circumstances that some readers who initially supported Fang Fang changed sides and began to call her a “traitor.” If China was scapegoated for the policy failures in the U.S. in handling the pandemic, Fang Fang was scapegoated by Chinese nationalists for making China vulnerable to attacks from foreign countries. Fang Fang was forced to endure the rage of a nation, or at least part of it. Like a religious martyr, she was sacrificed by the community on the altar of the nation. Thus long after she has stopped her diary-writing, she must continue to endure the fact that her diaries, through iteration in a digital sphere, have a life of their own, in the same way that performance art is a prompt whose reactions will vary with different times, places and audiences. Stopping her lockdown diary was less an end than the beginning of her endurance, an outcome she could not have envisaged when she first started it.",AI Soc
PMC7809547,More skilled clinical management of COVID-19 patients modified mortality in an intermediate respiratory intensive care unit in Italy,"The need to determine the full spectrum and natural history of the pandemic of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the virus causing coronavirus disease 2019 (COVID-19), is to inform clinical management and public health decision making. In Italy, the outbreak of COVID-19 officially started on 30 January 2020, and in less than two weeks, the number of cases increased beyond expectations, putting the Italian health service under considerable strain [1]. On 11 March 2020, the World Health Organization (WHO) declared the current COVID-19 outbreak a pandemic, with the outbreak resulting in more than 21 million cases and over 760,000 deaths worldwide as of 16 August 2020 [2, 3]. COVID-19 patients develop acute respiratory distress syndrome (ARDS), require respiratory support [4], and may require hospitalization in Intensive Care Unit (ICU). Defined as Type 1 respiratory failure, there is hypoxia (PaO2 < 8 kPa), without hypercapnia (carbon dioxide retention or PaCO2), with patients commonly presenting with hypoxia worsening, and additional signs such as tachypnoea, increased use of accessory muscles, tachycardia, pale and cold peripheries, sweating, confusion, agitation or reduced level of consciousness and cyanosis [5]. In China, the percentage of COVID-19 patients who required ICU hospitalization varied from 5 to 32% [6]. However, findings from China and Italy suggested high mortality and stressed ICU capacity of care [7, 8]. Recently, Siddiqi and Mehra proposed a staged progression model based on observed clinical courses in published studies [9]. This 3-stage clinical classification system suggested that COVID-19 illness may exhibit 3 grades of increasing severity, which correspond with distinct clinical findings, response to therapy, and clinical outcome [9]. In Stage I, or the mild phase, the virus multiplies and establishes residence in the host, predominantly in the respiratory tract. In Stage II, or the moderate phase, there is viral multiplication and localized inflammation in the lungs without (Stage IIa) and with hypoxia (Stage IIb). Stage III is marked by extra-pulmonary systemic hyperinflammation syndrome [9]. The prognosis and recovery from Stage 3 is generally poor. Rapid recognition of which stage the patient is and the development of appropriate therapy may have the greatest yield [9].
Although previous studies focused on clinical management with non-invasive respiratory support of COVID-19 patients in ICU [6–8], there is no evidence coming from an intermediate Respiratory Intensive Care Unit (RICU) or noninvasive respiratory care unit [8], a model of care designed for monitoring and treating respiratory patients whose illness is at a level of severity that is intermediate between that which requires ICU facilities and that which can be managed on a conventional ward. An intermediate RICU is an area for monitoring and treating patients with acute or exacerbated respiratory failure caused by a disease that is primarily respiratory [10, 11]. While some studies investigated epidemiological and clinical features of laboratory-confirmed COVID-19 patients [6, 12], limited attention has been paid to the follow-up of hospitalized patients on the basis of clinical setting and the expertise of clinical management.
In the present single-centered, retrospective, observational study, we reported findings from 87 consecutive laboratory-confirmed COVID-19 patients, all with moderate-to-severe ARDS, hospitalized in an intermediate RICU [10, 11], Policlinico University Hospital, Bari, Italy and collected from March 11 to April 17, 2020. The present study adhered to the Strengthening the Reporting of Observational Studies in Epidemiology” (STROBE) guidelines (https://www.strobe-statement.org/index.php?id=strobe-home), the “Standards for Reporting Diagnostic Accuracy Studies” (STARD) guidelines (http://www.stard-statement.org/), and was conducted in accordance with the Helsinki Declaration of 1975. After initial screening at the Emergency Department, the patients were admitted to our intermediate RICU or in an ICU accordingly to the illness severity. The present study was approved by the Policlinico Hospital of University of Bari “Aldo Moro” institutional review board and informed consent was obtained from all subjects involved in the present analyses.
Laboratory-confirmed COVID-19 patients were affected by ARDS defined according to the Berlin definition, so a respiratory failure characterized by arterial oxygen partial pressure to fractional inspired oxygen ratio (PaO2/FiO2) < 300 mmHg despite PEEP > 5 cmH2O, associated to bilateral chest opacities (not fully explained by effusions, lobar/lung collapse or nodules) with an acute onset, within 1 week of a known clinical insult or new or worsening respiratory symptoms [13]. In these laboratory-confirmed COVID-19 patients, apart from moderate to severe hypercapnic patients, who clearly needed the bilevel positive airway pressure (BPAP) respiratory support rather than continuous positive airway pressure (CPAP) respiratory support, our choice was driven by patient’s clinical evaluation. After a CPAP trial with a progressive pressure raising up to 12–15 cmH2O (when needed), if respiratory rate still > 30 we decided to switch CPAP to BPAP. High respiratory rate in ARDS patients is an indicator of respiratory fatigue, and BPAP can reduce work of breathing giving relief in these patients [14]. Laboratory-confirmed COVID-19 patients affected by severe ARDS, non responding to NIV, in which intubation and ICU transfer would not modify their outcome according to resuscitator counseling, remained in our intermediate RICU. Therefore, all patients who did not respond to NIV were asked for resuscitator counseling, whose opinion determined the possibility of an ICU transfer or not. Sociodemographic and health characteristics were presented as numbers, mean, and standard deviations (SDs) values, and percentages. Differences in sociodemographic and health characteristics between who died and who survived were analyzed using t-test for differences in means for independent-sample and chi-square test for proportions.
Mean age of this hospital-based sample was 69.1 ± 14.5 years, men were largely more represented than women (73.6% vs. 26.4%), and both gender groups showed a higher percentage of patients aged > 70 years compared to patients aged < 50 years (41.3% vs. 9.3%). Main comorbidity was hypertension (64.5%) followed by cardiovascular disease (54.5%), chronic kidney disease (47.45%), and diabetes mellitus type 2 (30.5%). We subdivided the patients in two groups according to the admission date (before and after March 29, 2020). The first group (T1) was characterized by our relative limited knowledge about clinical features and adverse health-related outcomes of COVID-19, while for the second group (T2), our skill in the clinical management of these patients improved, with a more strategic organization of clinical and human resources.
Table 1 shows sociodemographic and clinical characteristics, therapeutic approaches and clinical outcomes of these two groups. The number of patients, age, and the gender distribution were similar in the two groups. At admission, both groups had the same illness severity: T1 group had a mean arterial oxygen partial pressure to fractional inspired oxygen) of 192 ± 77.2 vs. 198.1 ± 86 of the T2 group. Similarly, there is no statistically significant difference between the two groups about comorbidities. A different therapeutic approach was also evident in the two groups. In the T2 group, most of patients (56.9%) were treated with the therapeutic dose of enoxaparin compared with only 43.1% of patients in the T1 group (p < 0.19). For the T2 group, we used less lopinavir-ritonavir (2.1% vs. 96.9%, p < 0.01), more dexamethasone (73.9% vs. 26.1%, p < 0.01), and more hydroxychloroquine (92.1% vs. 78.9%, p = 0.15) compared with the T1 group. About non-invasive respiratory supports, continuous positive airway pressure was used much more while bilevel positive airway pressure was used less in T2 group (65.0% and 19.2%, respectively) than in T1 group (36.0% and 37.8%, respectively) (p < 0.05). Higher percentages of COVID-19 patients were transferred from T1 group in ICU (32.6% vs. 22%), without statistically significant difference respect to T2 group, but we observed a statistically significant lower mortality in the T2 group compared with the T1 group (17.1% vs. 52.2%, p < 0.01) (Table 1). More patients from T1 group died in our intermediate RICU, but without statistically significant difference compared with the T2 group (19.6% vs. 9.76% p < 0.33). Finally, we observed a significantly difference in terms of mortality among the patients transferred in ICU from intermediate RICU (100% in T1 group vs. 33.3% in T2 group, p < 005) and the average length of stay in intermediate RICU of ICU-transferred patients who survived in T1 and T2 was significantly longer than those who died (who died 3.3 ± 2.8 days vs. who survived 6.4 ± 3.3 days, p < 0.05). The average length of stay in ICU of patients who were transferred from intermediate RICU but died was 12.2 ± 7.6 days. Table 2 shows differences in the setup of intermediate RICU between T1 and T2.
The findings of the present study obtained in a hospital-based sample suggested that an intermediate level of hospital care may have the potential to modify survival in COVID-19 patients. Several reasons could explain the improved major clinical outcomes in the T2 group, i.e., mortality and length of stay in intermediate RICU of ICU-transferred patients. First, we improved the allocation of our intermediate RICU (Table 2). For the T1 group, we were at the ground floor of a building not still completely dedicated to COVID-19 patients, far from the ICU allocated in another building, and with the routes used for patient repositioning not completely safe. For the T2 group, we occupied the first floor of a building completely dedicated to COVID-19 patients, with better and quickly connection with ICU [3] and major possibility to access to care in safe way, using the same working protocol also with ED. Furthermore, there was a best use of human resources, with several new pneumologists, nurses and health’s workers hired thanks to regional funds allocated for the emergency (1 medical doctor for 6 patients and 1 nurse for 3 patients, and a multidisciplinary staff with pneumologists expert of lung failure, physiotherapists, and intensivists). For the T2 group, we also improved the organization of our clinical practice thanks to the expertise accumulated during the first days. It could be also hypothesized that a greater length of stay and evaluation in our intermediate RICU with non-invasive respiratory supports could favor a wait-and-see clinical approach that in selected patients could avoid the transfer in ICU, where mortality is linked not only to COVID-18 infection and its complications.
Moreover, also our therapeutic approach changed in the T2 group and most of patients (56.9%) were treated with the therapeutic dose of enoxaparin compared with only 43.1% of patients in the T1 group [15]. For the T2 group, we used less lopinavir-ritonavir [16], more dexamethasone [17], and more hydroxychloroquine [18] compared with the T1 group. Therefore, in the T2 group, we preferred to use dexamethasone over lopinavir-ritonavir in consideration of favourable clinical outcomes reached in recent studies. The combination of lopinavir-ritonavir used in HIV therapy and prevention has been widely administered during the first phase of COVID-19 pandemic, especially in mild patients (Stage I) [9] and during the first days after hospital admission. In the first phase, when the viral replication plays a pivotal pathogenetic role, antiviral drugs could be crucial in limiting viral-induced organ damage. In previous retrospective single-center studies, lopinavir-ritonavir was utilized in 90% of the patients hospitalized in South Korea [19] and in 82% of the critical ill patients hospitalized in Italy [20], confirming how this anti-viral drug was widely used in clinical practice worldwide. Nevertheless, some recent observational studies and randomized clinical trials (RCTs) have raised some concerns about its usefulness. In fact, Cao and colleagues, in the first controlled, open-label trial of anti-viral therapy, showed that in patients with severe COVID-19, lopinavir-ritonavir administration was not associated with a statistically significant difference in the time to clinical improvement compared with the standard-care control group and the short-term mortality rates were not statistically significant different between the two groups [16]. One reason explaining these findings could be that the patients were enrolled during the pulmonary stage with hypoxia (Stage IIb) [9], when the viral pathogenicity may be only one lesser dominant aspect of the overall pathophysiology, and host inflammatory responses were the predominant pathophysiology. Moreover, a recent meta-analysis concluded that treatment with lopinavir-ritonavir had no significant benefit in modifying mortality and ARDS rates in COVID-19 patients, but, on subgroups analysis, the lopinavir-ritonavir group had a lower rate of ARDS, although this difference was not statistically significant [21]. However, it should also be remembered that numerous ongoing RCTs around the world are currently evaluating the efficacy of lopinavir-ritonavir in COVID-19 patients.
Regarding the use of corticosteroids in COVID-19, there was great uncertainty about its administration during the first part of the pandemic due to lack of reliable clinical studies demonstrating its efficacy. In COVID-19, corticosteroids have primary been thought about as a mean to stave off the “cytokine storm” and his consequences like ARDS. As this usually happens in the first 5–7 days, ideally, steroid therapy should be tried in this period, particularly at the onset of dyspnea or even earlier to prevent the progression of “cytokine storm”. However, most of the studies on the use of corticosteroids in COVID-19 have shown variable findings, principally because of marked heterogeneity in the methodology used with considerable variations in the timing of initiation of steroid treatment, type, and dosage of steroids. The principal corticosteroids used in most of these studies and other ongoing RCTs have been methylprednisolone and dexamethasone because of their high bioavailability in the lung. Theoretically, methylprednisolone has the advantage of parenteral administration, a quicker onset of action and a shorter duration of action compared to dexamethasone. However, the most robust data on corticosteroids in COVID-19 came from the RECOVERY trial on dexamethasone, the only controlled, open-label trial conducted on 2104 patients assigned to receive dexamethasone and 4321 to receive usual care, which showed the most significant 28-day mortality benefit with low dose dexamethasone (6 mg per day oral or intravenous for 10 days) [22]. The RECOVERY trial showed an impressive mortality reduction among the sickest COVID-19 patients on invasive mechanical ventilation and among patients in oxygen therapy (with or without mechanical ventilation). In addition, COVID-19 patients on dexamethasone had a statistically significant reduction of length of hospital stay and an earlier likelihood of discharge. No benefit was observed in mild-to-moderate COVID-19 patients requiring no oxygen. However, more studies are still necessary to substantiate conclusive benefit with corticosteroid use in COVID-19 [22].
As regard hydroxychloroquine in COVID-19 pandemic, this drug has been widely used to reduce inflammation. In fact, an in vitro antiviral effect has been demonstrated on SARS-Cov-2, with chloroquine concentration of 0.36 mg/L that decreased viral load by 50% in a cell model [23]. However, to date, the administration of hydroxychloroquine in COVID-19 patients has been decreased due to its side effects and uncertain clinical benefits and all ongoing clinical trials with hydroxychloroquine used different dosing regimens, resulting in various concentrations [24]. Recently, Kannan and colleagues proposed a multiscale non-invasive model (Quasi-3D-based numerical formulation) to predict gastric and intestinal damage secondary to the use of hydroxychloroquine; this tool could be helpful in predicting the drug toxicity and optimizing the dosing regimen of hydroxychloroquine in COVID-19 patients [25]. Moreover, since the use of functional respiratory tests has been evaluated as a potential vehicle of SARS-Cov-2 infection, Kannan and colleagues provided a computational spirometry basal techniques (Quasi-3D model) that could offer fast and reliable information about bronchial caliber and morphology with a non-invasive approach to predict the lung health in COVID-19 patients [26].
The present findings suggested that some hospital units designed for monitoring and treating respiratory patients whose illness is at a level of severity that is intermediate between that which requires ICU facilities and that which can be managed on a conventional ward may have the potential to modify survival also in COVID-19 patients particularly in the present phase of a more skilled clinical management of the pandemic. However, further larger studies are still necessary to verify that the modified therapeutic approaches could have changed clinical outcomes in these patients.",Respir Res
PMC7809551,Telerehabilitation in response to constrained physical distance: an opportunity to rethink neurorehabilitative routines,"The amount of training and its reiteration over time are key factors driving a favorable outcome of neurorehabilitative treatments [1, 2]. However, keeping a proper dosage and the repetition sustained in the course of time is demanding for all actors of neurorehabilitation. On the one side, healthcare providers must face overscheduling despite a limited availability of equipped spaces and specialized professionals; on the other side, families have to re-organize their daily routines planning travels to rehab facilities, and thus covering high costs in terms of money and time of caregivers [3, 4]. A key challenge in neurorehabilitation practice is to ensure a timely access to cure and its continuity, removing all hindering factors. Among them, constrained physical distancing is one of the most detrimental, since it may affect most of the neurorehabilitative procedures, spanning from the clinician/patient contact to the joint attendance of treatment spaces.
In this perspective, we will examine how the constrained physical distancing affects the prosecution of traditional neurorehabilitation programs, hurdling the continuity of rehabilitative pathways. We will propose that telerehabilitation could represent a valuable solution to sustain neurorehabilitative continuity of cure by overcoming social isolation barriers. Previous findings indicated that telerehabilitation may have a positive impact on a range of primary and secondary neurological outcomes [1, 5, 6] despite the large heterogeneity of interventional parameters and protocol design [5]. Here, our scope is not to ascertain the efficacy of telerehabilitation, but rather to highlight its main advantages and to propose a series of suggestions aimed at maximizing its efficacy and sustainability, in light of modern technology.
In summary, constrained social distance as the one experienced during 2020 pandemic could be seen as an opportunity to rethink current neurorehabilitative routines, envisioning mixed procedures in which face-to-face sessions are integrated and combined with telerehabilitation.
Neurorehabilitation is endowed with a peculiar social vocation. Indeed, its activities are grounded on the interaction across patients, caregivers and a multidisciplinary rehabilitative team, and usually take place in spaces hosting multiple patients who can potentially interact with each other. This is why physical distancing constraints severely affect common neurorehabilitative procedures. Exemplars are the consequences of the physical distancing measures combined with changes in healthcare services regulation following the recent COVID-19 pandemic outbreak, as also indicated by several national guidelines[7]. First, most of in-patients treatments have been confined to patient’s room, which is intrinsically not conceived for hosting rehabilitation treatment; second, the clinical activities requiring an internal flow (e.g. movement between floors or to reach gym) have been suspended, as well as all the out-patients treatments or those delivered at home by therapists; third, meeting activities and clinical interviews with patient’s familiars are currently conducted only by phone or email. As a consequence of such radical measures, rehabilitation programs have been reduced, pursuing only short-term and primary goals, and the activities of the rehabilitative team have been limited to those strictly necessary. Noteworthy, beyond physical distancing measures, also changes in healthcare services access regulation are negatively affecting the access to rehabilitative services during the current pandemic.
Beyond pandemic condition, physical distancing constraints are daily experienced by immunocompromised individuals undergoing neurorehabilitation, e.g. people with aggressive forms of multiple sclerosis undergoing hematopoietic stem cell transplantation [8, 9], or frail neurological patients suffering from multimorbidity. Constrained distancing limits rehabilitative options also for patients with infectious disease requiring contact isolation [10]; also in these cases, the access to common spaces (e.g. gym, swimming pools) is restricted, and rehabilitative procedures are bounded to patient’s room.
Outside the infectious prevention, physical distancing is a condition experienced also by people living in war zones, incarcerated [11], refugees [12], and, most widely, persons that live in remote areas of the world [13], especially in developing countries [14]. In such cases, the negative impact of distancing and isolation may be exacerbated by the difficulties in transports intrinsic to neurological disability [14].
The interplay between neurological disability and social isolation is worth a discussion. Indeed, disability by itself is an independent factor promoting social isolation for patients [15, 16] and caregivers [17]. Thus, all the physical distancing factors discussed above may favor the establishment of a vicious circle in which a poor continuity of cure, limiting the rehabilitative outcome, ends up in feeding physical distancing itself (see Fig. 1).
In this realm, adapting to physical distancing scenarios represents an imperative challenge for neurorehabilitation, whose settings and procedures need to be re-organized to guarantee the achievement of treatment objectives even in the absence of physical closeness among rehabilitation actors. Such solutions may spark the advantages far beyond the mere mitigation of pandemic effects, removing barriers that affect daily neurorehabilitative practice, and thus promoting its sustainability.
Aside to the above-mentioned strenghts, telerehabilitation presents some weaknesses (see Peretti et al. [41]). The first limitation is the absence of in-person session monitoring, potentially impacting on the verification of safety of procedures. Any solution allowing for an an online and remote monitoring of the patient’s performance (webcams or sensors), the involvement and education of caregivers, and when possible the periodical alternation with in-person sessions, would temperate this criticality. The second issue concerns the heterogeneous evidence in terms of procedures, outcomes and effectiveness, narrowing a broader applicability. A recent metanalysis conducted by Laver and coworkers [42] showed that, despite the increasing number of studies testing the efficacy of telerehabilitation in patients with stroke, it is hard to reach conclusions on its effectiveness due to the considerable variability across studies in terms of interventions and outcome measures. However, since several studies comparing telerehabilitation and in-person treatment did not found outcomes significantly different between groups, the authors suggest that at least in stroke, telerehabilitation efficacy would be not inferior to that of traditional rehabilitation, with estimated effect sizes in favour of telerehabilitation ranging from 0.48 [− 1.36, 2.32] for balance to 1.23 [− 2.17,4.64] for upper-limb motor function [42]. Future research would benefit from the adoption of standardized procedures and outcome measures, which would in turn enable the comparison across studies and the delivery of more robust recommendations for telerehabilitative practice. For this purpose, the routinary adoption of telerehabilitative procedures during current pandemic would represent an unique opportunity to collect robust data on telerehabilitation, to conduct a rigorous investigation of its cost-effectiveness, and to reach solid results on its feasibility and efficacy.
Since advanced telerehabilitation is associated with an enhanced use of technologies as VR and sensors, it is worth to mention also the benefits and disadvntages specifically linked to their adoption. When dealing with technologically advanced procedures, a further limitation regards the low acceptance by people with poor confidence with digital technology. This issue, potentially involving both patients and providers, may be counteracted by a preliminary training and by implementing easily affordable procedures. Of note, scarce confidence with digital technology would likely reduce in the next decades, when digital natives will progressively represent an even larger slice of the overall population.
The main advantages and weaknesses of advanced telerehabilitation, as well as the measures aimed at counteracting limitations, are summarized in Table 1.
With the exception of few procedures where physical contact between patients and therapists is essential, such as manipulative treatments, most of common neurological impairments may take advantage of telerehabilitation, whose procedures need to be tuned to patient’s own impairments and rehabilitation objectives.
In the realm of stroke-related disability, upper-extremities motor training represents one of the most suitable scopes for telerehabilitation[1, 6]. Here, goal-oriented approaches have proven effective in inducing motor improvements similar to those produced by traditional in-clinic rehabilitation. Besides upper-limbs motor domain, also balance and gait symptoms due to stroke may benefit from telerehabilitative treatment [43]. However, the implementation of domicilary setting for walking training is more challenging due to the limited space and to safety concerns. In this regard, the use of computer screens or projectors as viewing devices in place of immersive visors, and more generally the selection of wireless devices could prevent the risk of falls during training procedures [44].
The design of stroke telerehabilitative procedures should take into account the presence of associated symptoms potentially affecting patient’s adherence to treatment. Among them, spasticity — affecting about one-third of patients with stroke[45] might support the choice of customized and easy-to-handle haptic devices, as well as the adoption of sensors compatible with spastic hypertonia (e.g. sensorized gloves should be avoided). Moving to the visual domain, when symptoms like hemianopsia or unilateral spatial neglect concur, the design of stimuli and their administration need to be adapted to patient’s own visual skills [46].
Among neurodegenerative movement disorders, Parkinson’s disease (PD) is the one in which telerehabilitation is most adopted. In patients with PD, the remote delivery of motor tasks associated to visual, auditory or haptic feedbacks may be effective to improve postural stability and walking skills [47, 48]. Here, safety recommendations similar to those indicated above for gait training in stroke patients should be embraced. Interestingly, the potential application of telerehabilitation in PD goes beyond the training of gait-related abilities, encompassing the possibility to target upper-limb motricity [24] or phonological skills [49]. Noteworthy, people with PD undergoing Levodopa pharmacological treatment should be instructed to perform training only during the ON state to limit the negative impact of motor fluctuation on telerehabilitative sessions [50].
Moving to younger subjects, telerehabilitation is facilitated by the higher degree of confidence with technology. This would be the case of people with MS. Consistently with the heterogeneous clinical manifestations of MS, here telerehabilitation can target multiple motor fields, such as balance [51], gait [52], fatiguability [53], as well as cognitive skills like executive functions [54], verbal fluency and memory [55] (see also Di Tella et al. for a systematic review [56]).
Finally, in the realm of pediatric population, the remote administration of rehabilitative treatments may take advantage from the possibility to enrich sessions with gamificated features. This aspect jointly with the instrinsic benefit of acting in a home-based setting might be exploited in children with cerebral palsy, administering motivating task-oriented exercises able to improve upper limbs motor function [22, 30, 57].
Despite its encouraging potentialities, the administration of telerehabilitation may present relevant challenges in patients suffering from cognitive disturbances [25], where understanding of procedures may be impaired, and then adherence to treatment suboptimal.
Another instance where the adoption of telerehabilitation should be cautiously considered concerns patients with poor confidence or aversion toward technology. Such conditions more frequent in elderly people may be mitigated by a proper preliminary training, and by the choice of an easy-to-use setup.
Finally, patient eligibility has to deal with neurological symptoms severity or possible comorbidities. For instance, verbal impairments impeding a proper communication with cure providers, as well as the occurrence of relevant cardiovascular comorbidities requiring continuous and supervised monitoring during active exercises could contraindicate the participation in telerehabilitation.
Most of evidence on neurological telerehabilitation effectiveness come from randomized-controlled studies where task-oriented approaches have been remotely applied in stroke patients with upper-limb motor impairment [6, 20, 42]. It is worth to note that task-oriented methods may be also fruitfully applied to other brain injuries [58] and neurodegenerative conditions [59].
Task-oriented approach consists in administering goal-directed tasks targeting various motor control features, spanning from movement speed to range of motion (see Cramer et al. [18] for an exemplar repertoire of exercises). Despite traditionally targeting upper limbs [6, 20], goal-oriented remote approaches have been recently adopted in the balance and gait rehabilitation field, where the introduction of low-cost infra-red camera and portable balance boards allow to deliver home-based training to people with MS [51], Parkinson’s disease [60] and stroke [43].
As a general rule of thumb, task-oriented exercises should meet the following criteria: (1) being challenging and meaningful, (2) addressing relevant and multiple impairments, (3) enhancing specific motor abilities through overload, (4) being endowed with goal-directedness in movement organization. Here, the major driver of task-specific self-confidence is represented by the successful performance accomplishment (see Winstein et al. [61]). Associated gamification features and feedbacks delivery may emphasize this latter factor, ultimately boosting task-oriented effectiveness [20].
Despite being groupable among task-oriented approaches, Action Observation Treatment (AOT) deserves a special consideration due to its methodological peculiarities, making it a paradigmatic framework for telerehabilitation. AOT is based on the notion that the observation of an action, followed by its imagination and executional attempt, is able to promote neuroplasticity processes underlying motor functional improvement [62]. Its efficacy has been demonstrated in a wide range of neurological disorders, such as stroke [63], Parkinson’s disease [64], multiple sclerosis [65] and cerebral palsy [30].
Being grounded on the delivery of visual stimuli depicting actions to be trained, AOT is endowed with a special vocation for remote administration. Indeed, AOT has been recently opened to telerehabilitation, especially in pediatric population [22, 30, 57]. Nuara et al. [22] applied a home-based, peer-to-peer AOT to 20 children with cerebral palsy (CP) with upper-limb impairment. During AOT remote sessions, participants had to observe and then imitate a wizard performing dexterity-demanding magic tricks. Kinematics were monitored via a markerless infrared system, and reinforcing feedbacks were provided upon the use of the impaired hand. Subsequently, a peer-to-peer live video-session to practice the same exercises took place. Following treatment, an improvement in hand motor abilities was found. Of note, peer-to-peer difference in hand motor ability was correlated to the amount of improvement, indicating that it is preferable for a child to observe a leading peer with higher motor skills. Beyond proving the feasibility of telerehabilitative approach for AOT, this study showed that in a “dual rehabilitation model”, patients could simultaneously act as “beneficiaries” and “providers” within the motor rehabilitation process.
Scaling up the remote and peer-to-peer approach for dual rehabilitation, one could envision the realization of a wide network of patients undergoing interactive and remote AOT. Here, each user could in turn improve his skills by interacting with a more capable peer, or act as a trainer towards a more impaired individual. Beyond promoting a greater motor resonance [22, 66, 67], the interplay across patients experiencing the same symptoms would favour beneficial social instances, like reciprocal encouragement and other friendly exchanges. Besides the high sustainability, the peer-to-peer approach could be easily extended to other neurological conditions in which AOT has proven effective, opening technologically advanced telerehabilitation to novel, social-enriched scenarios.
Cognitive rehabilitation includes a wide group of interventions aimed at consolidating or recovering previously acquired patterns of behavior, or at establishing new cognitive abilities compensating for impaired neurological systems [68]. Here, adopting telerehabilitation would ease the achievement of key factors of cognitive treatment efficacy, such as training intensivity, prolongation over time and engagement, ultimately empowering patient’s ability to transfer cognitive skills from virtual to real world [69]. Studies demonstrating the feasibility and effectiveness of cognitive rehabilitation have been mostly conducted on people suffering from neurodegenerative diseases (see Cotelli et al. [25] for a recent systematic review). However, there are also evidences that remote administration of cognitive rehabilitation can ameliorate the cognitive outcome of post-surgical patients with brain tumors [70], as well as of people with stroke [71] and multiple sclerosis [72].
Recent approaches in cognitive telerehabilitation encompass the use of interactive applications pursuing learning and education as primary objectives (i.e. serious games). Combining a challenging and rewarding nature with affordable costs, serious games can be intensively administered in the familiar environment of patient’s own home. Their adoption showed promising results in improving cognitive symptoms in Alzheimer disease [73], stroke [74] and cerebral palsy [75]. However, their diffusion is restricted because of the poor customization and the limited theorethical ground driving their development. For this reason, a growing effort is ongoing to tailor serious games to the clinical features of people with specific cognitive impairments [69].
Besides the administration of active treatments, neurological telerehabilitation should incorporate complementary health services for the achievement of disease-specific priorities able to affect long-term outcomes [6, 20, 76]. Among them, the education of patients about relevant aspects of their own disease may be crucial for health-status awareness, for secondary prevention [6, 20], and for the adoption of proper life-styles aimed at improving quality of life [77]. This possibility has been recently exploited for patients with stroke, where daily “education pills” have been embedded in the telerehabilitative path to optimize functional status, boost motivation and prevent secondary cerebrovascular events [20]. Such an educational approach could be extended also to neurodegenerative conditions, where life-style and dietary measures may potentially impact on disease progression and quality of life [78, 79].
The ideal rehabilitation setting should combine the highest portability and smartness on the patient side, with the highest efficiency on the healthcare provider side. For simplicity, from here on, we will refer to these sides as patient and therapist, respectively.
The main elements comprising the patient-setting are: a computer connected to internet, devices for audio–visual presentation, and wearable sensors interfacing with the computer for tracking the patient's performance.
Concerning hardware, current solutions maximize the portability and lightness of a tele-rehabilitative setup. Indeed, workstations with a Local Area Network (LAN) connection can be easily replaced to date by portable devices (laptops, tablets, or even smartphones) continuously connected to wireless networks. Although well-fitting with the notion of home-based telerehabilitation, such solutions would allow a full-portability of the telerehabilitation setup, making patients capable to adhere to treatment at any time and any place.
While the above-mentioned devices allow the presentation of multimedia content, several rehabilitative practices adopted virtual reality (VR) to recreate realistic and three-dimensional environments in which patients may bodily operate. Among VR techniques, fully immersive VR is based on a completely computer-generated environment built to evoke the perception to be physically present in a virtual world. Here, the viewing medium is generally represented by a head-mounted visor. Conversely, in mixed reality (MR), real and virtual objects coexist, interacting in a mixed environment. Closer to the real-world scenario, augmented reality (AR) enhances the sensory experience of the real environment introducing computer-generated elements, encompassing the adoption of common devices like smartphones or tablets as viewing media (see Table 2 for a summary of features and administration modalities of main VR technologies). Noteworthy, the different degrees of immersion and physical interaction [80, 81], as well as viewing devices, need to be chosen according to patient’s specific features and rehabilitative aims. For example, in cognitive rehabilitation, the VR system has to be designed to ensure a comfortable and familiar virtual experience [82]. Mixed reality would best fit in this case, since patient perception to attend procedures at his/her own home might boost the compliance to sessions, avoiding the dispersion of attentive resources, reducing anxiety and ultimately favoring treatment outcome. Especially, but not exclusively, in cognitively impaired patients, preliminary-assisted training aimed at verifying the comprehension of the task and the tolerability to the procedure, is advised thus ensuring users' comfort with the VR technology.
VR technologies have been fruitfully applied to several neurological conditions, including stroke [83–86], Parkinson’s disease [50, 87], multiple sclerosis [51, 88] and cerebral palsy [89, 90], showing an overall satisfactory profile of feasibility and efficacy [91]. Modern VR-based systems (e.g. headsets integrated with haptic, auditory and visual feedbacks) allow the administration of a multi-modal, fully immersive stimulation, giving to the patient the vivid perception to be physically present in the virtual environment. Sometimes, VR users may experience symptoms of motion sickness (commonly referred as “VR sickness” or “cybersickness”), including dizziness, fatigue, disorientation and nausea. Several preventive measures have been proposed to mitigate such side effects, like providing multimodal stimulation, using dynamic adjustment of depth of field, increase the fidelity of virtual scenarios with sinchronous and multimodal stimuli (see Chang et al. [92] for a review). Novel all-in-one VR solutions merging the computer and the viewing device within a wireless headset, may include optical tracking systems and advanced visual adjustments to prevent the insurgence of dizziness and motion sickness, thus making VR technology applicable for a larger number of patients.
In a recent metanalysis, Howard [91] identified three major factors linked to the efficacy of VR-based neurorehabilitation. The first one—namely “increased excitement”— regards the patient attitude to be engaged during the treatment procedures. Boosting attention and motivation, such a positive reaction may be favored by the adoption of novel immersive devices, the delivery of rewarding feedbacks and specific “gamification” features [93, 94]. The second one is the “increased physical fidelity”, i.e. the ability to transpose into the “real-life” tasks performed during the session. In this regard, mixed-reality-based systems could sustain a realistic perception of the environment by fostering a natural performance on behalf of patients. The third factor is the “increased cognitive fidelity”, that is the capacity of VR-based treatments to ground psychological processes in scenarios whose complexity resembles everyday life [95, 96].
Beyond informing the patient, the ideal telerehabilitation setup should inform about the patient. Direct monitoring of patient performance is fundamental to verify the adherence to treatment, to ensure safety, and to monitor recovery trajectory. While the first two aspects can be fully achieved by means of teleconference systems, the recovery trajectory needs to be objectively quantified estimating subtle changes in patient’s performance by integrating specific monitoring devices in the rehabilitation system.
Portable mechatronic devices (i.e. haptic joysticks) represent one of the earlier and cost-effective solutions for upper-limb telerehabilitation. They can apply forces and measure hand position, thus indirectly quantifying the user performance [97]. However, these devices allow only few types of movement, hindering the possibility to evaluate fine motor actions like grasping or finger apposition [98]. To overcome these limitations, systems based on sensorized gloves have been developed and tested in neurological patients [89, 99]. Despite the promising results of their adoption in hand motor training protocols [89, 99], the potential dependence on caregivers for the wearing may represent a barrier for their use. Moreover, the exclusive monitoring of the hand does not permit the evaluation of concomitant postural attitudes of more proximal segments of the upper limb, as well as of the trunk [100]. In turn, Inertial Measurement Units (IMUs) systems are able to reconstruct accurately complex and multi-segmentary body postures also in outdoor environments. Nevertheless, these systems are often difficult to wear by neurological patients without assistance. The maximal independence of the patient could be ensured by optical marker-less solutions (e.g. portable infrared camera sensors), which however are mainly suited to track large movements [101]
Concerning trunk and lower limbs kinematic evaluation, beyond IMUs, simpler wearable step counters (i.e. podometers) may provide information about gait parameters like walking speed, cadence, double support and stride with a reliability comparable to the gold standard for gait analysis [102, 103]. In addition, even smartphones can acquire useful objective data about gait and balance, being equipped with accelerometers and gyroscopes to detect body parameters, such as falls, postural sway, gait performance, and balance stability [104, 105].
In summary, the choice of the appropriate sensor should be based on patient’s neurological impairment, the primary outcome, the possibilities of assistance from the caregivers, and costs affordability. Moreover, to favor the detailing of patient’s clinical picture, multiple and complementary types of sensors could be simultaneously adopted.
Once the patient-setting has been designed, an equally relevant part to take care of is the therapist-setting, i.e. the architecture enabling the home-based setup to download information relevant to the treatment delivery, and to upload data concerning the patient performance. Ideally, an online platform should be accessible 24/7 by both patients and clinicians, with secure accounts adhering to privacy international rules. The former can start a new session at their convenience, having stimuli and procedure automatically downloaded according to clinical prescription and to their own rehabilitative history. The latter, in turn, can access the system either to monitor online the patient performance (e.g. during the first home-based session or after relevant treatment change), or to review offline the same performance in light of the whole medical history.
Beyond facing security issues, the bidirectional data transfer between the patient- and therapist-settings should keep into account the possibility of connectional malfunctions, thus accounting for proper buffering and/or offline data storage strategies.
The use of sensors presents three main cascade advantages. The first is the online monitoring of patient’s performance allowing clinicians and therapists to provide within-session feedbacks to patients or caregivers. Even if a simple webcam would be enough to detect large anomalies in behavioral performance of the patients, sensors could instantly signal subtle anomalies relative to previous history and/or to normative data.
A second advantage is the possibility to deliver online feedbacks aimed at encouraging appropriate patient’s behavior[22], or conversely at discouraging unsuitable ones; in this regard, the adoption of strategies integrating sensors and virtual reality (e.g. the online visual amplification of patient’s errors) may boost the learning process [80], biasing patient’s behavior toward the correct one.
Last but not least, the therapist-platform can be embedded with signal processing tools capable to identify relevant features about individual patient performance and history, and to compare them against data from other patients matched for clinical conditions. In addition, to provide relevant insights on the long-term dynamics of patient’s performance, this approach would pave the way to digital phenotyping [106], and the subsequent implementation of machine-learning models aimed to predict functional outcomes. Such information would ultimately support choices and adjustments by the clinicians, thus maximizing the beneficial effects of the whole rehabilitative pathway.
Thanks to modern technology, an exclusive telerehabilitation represents the only valuable and scalable solution in case of constrained and persistent social distance requirements, making patients act in virtual scenarios while remotely interacting with clinicians.
The lesson taught by COVID-19 pandemic, however, could partially apply also to daily neurorehabilitation routines, so to relieve the care burden around neurological patients and their management. Indeed, while face-to-face therapeutic interactions represent an irreplaceable element in the relationship between patients and healthcare providers, telerehabilitative sessions could act as the missing pieces of the puzzle leading to an optimal continuity of cure.
In such a “mixed” model of neurorehabilitative care, hospital-based procedures (e.g. post-acute protocols, clinical-neurophysiological evaluations, intensive training, etc.) might be used mainly to forge the scaffold of the rehabilitative program, while telerehabilitation could be prevalent in the long-term consolidation of functional progresses [107]. The development of this model requires the synergistic involvement of clinicians, therapists, engineers, developers along with caregivers and patients to promote the overall sustainability and effectiveness of the rehabilitative pathway.",J Neurol
PMC7809553,Circulating Von Willebrand factor and high molecular weight multimers as markers of endothelial injury predict COVID-19 in-hospital mortality,"Coronavirus disease 2019 (COVID-19) is a respiratory disease caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) characterized by an intense inflammatory syndrome associated with a coagulopathy and has been described as an endothelial disease [1, 2]. Increased d-dimer has been proved to be the most relevant biomarker of the COVID-19-associated coagulopathy [3]. Indeed, a high d-dimer level at the time of patients admission has been reported to be associated with the COVID-19 diagnostic likelihood [4], disease severity, risk of intensive care unit (ICU) referral and mortality [5, 6]. Moreover, we recently proposed that in COVID-19, d-dimer levels reflect pulmonary microvascular thrombosis at the origin of right ventricle dysfunction [7]. Autopsy case series confirmed the hypothesis that both endothelial inflammation and microvascular thrombosis are prominent in the pulmonary, renal and intestinal vasculature. This microthrombotic process has been described as closely related to endothelial lesions characterized by endotheliitis [8], abnormal angiogenesis in lungs [9] and also an increase in circulating endothelial cells (CECs) in COVID-19 patients [4, 10]. This endothelial injury is probably the result of a combination of SARS-CoV-2 direct entry in endothelial cells (ECs) [8], the subsequent prothrombotic phenotype of ECs and the surrounding tissue collateral damage secondary to cytokine release and complement-system activation [11, 12]. In line, we recently described an association between plasma angiopoietin-2 (Ang2) levels at admission and COVID-19 patients referral to the ICU [13]. However, the precise pathogenesis of endothelial injury and its deleterious consequences in COVID-19 are still elusive and a better understanding of these processes could help physicians, especially in the ICU, to determine the appropriate therapeutic strategies for preventing and treating coagulopathy associated with endothelial damage.
The objective of the present study was to assess to what extent endothelial activation biomarkers measured at admission were predictive of in-hospital mortality in a large cohort of 208 adult COVID-19 patients.
We performed a bi-centric cross-sectional study of adult (≥ 18-years old) COVID-19 hospitalized and ambulatory patients in two French hospitals (European Georges Pompidou Hospital and Cochin-Hotel Dieu Hospital, Paris, France) between March 13 and June 26, 2020. The study was performed in accordance with the Declaration of Helsinki and a written consent form was signed by all patients included or their trusted relatives at the time of enrollment (SARCODO 2020-A01048-31A, NCT04624997). All included patients, hospitalized or not, presented a confirmed diagnosis of COVID-19, using a reverse transcriptase–polymerase chain reaction (RT-PCR) assay on nasopharyngeal swab samples (Allplex™ 2019-nCoV Assay, Seegene, Seoul, South Korea) as previously described [14]. Data were automatically analyzed using Seegene viewer software.
Patients were classified according to World Health Organization guidance (WHO) as non-critical (median oxygen requirement 3 l/min; WHO score range 4–7) or critical (requiring mechanical ventilation, WHO score range 8–9) in the first 48 h following admission for clinically suspected COVID-19. Outpatients were COVID-19 patients who met no hospitalization criteria and returned home immediately after RT-PCR testing for COVID-19 diagnosis. None of the outpatients required supplemental oxygen, were later hospitalized or died in the month following COVID-19 diagnosis. Finally, we also included 29 non-COVID-19 non-hospitalized individuals who served as controls. These patients had an initial clinical suspicion of COVID-19, but with mild clinical presentation and a negative RT-PCR result.
Patient characteristics including age, sex, comorbidities, medical history and treatment at admission were recorded. The primary outcome was COVID-19 in-hospital mortality.
Routine laboratory tests and sampling for an extensive panel of endothelial activation biomarkers were all performed at hospital admission i.e. in the first 48 h following the admission for suspected COVID-19. Venous blood was collected from patients and controls and processed according to standard laboratory techniques. Routine laboratory tests were plasma creatinine, C-reactive protein (CRP) and high-sensitivity cardiac troponin I (Hs-cTnI) conducted on a DXI analyzer (Beckman Coulter, Brea, CA). Regarding coagulation assays and endothelial biomarker measurements, blood was collected in 0.129 M trisodium citrate tubes (9NC BD Vacutainer, Plymouth, UK). Platelet-poor plasma (PPP) was obtained after centrifugation twice at 2500×g for 15 min and stored at − 80 °C until analysis. Measurement of d-dimer was performed using the Vidas d-dimers® assay (Biomérieux, Marcy-Etoile, France) according to the manufacturer’s instruction. The plasma concentrations of soluble E-selectin (sE-sel), soluble endoglin (sEng), angiopoietin-1 (Ang1), Ang2 and vascular cell adhesion protein 1 (VCAM-1) were quantified in PPP using a Human Magnetic Luminex Assay (R&D Systems, Minneapolis, MN). Data were assessed with the Bio-Plex 200 using the Bio-Plex Manager 5.0 software (Bio-Rad, Marnes-la-Coquette, France). Soluble thrombomodulin (sTM, DTHBD0, R&D Systems) and soluble endothelial protein C receptor (sEPCR, 00264, Diagnostica Stago, Asnières, France) were measured using ELISAs on plasma samples according to the manufacturer’s recommendations.
CECs were isolated and counted by immunomagnetic separation using anti-CD146 monoclonal-antibody-coated beads and marking reagent acridin orange as previously described [4].
Von Willebrand factor antigen (VWF:Ag) and activity (VWF:Rco) used (STA Liatest, Diagnostica Stago) and a latex immunoturbidimetric assay (vWF:Rco; Diagnostica Stago), respectively, on a STA-R® Max coagulometer (Diagnostica Stago). The VWF multimers pattern was evaluated by a semi-automated assay: the Hydragel 5 von Willebrand multimers kit, on the Hydrasis 2 Scan instrumentation (Sebia, Lisses, France) [15, 16]. All samples were defrozen in a water bath at 37 °C for 5 min, were treated with the appropriate sample diluent and incubated for 20 min at 45 °C. The dilution ratio was adapted to adjust all patients’ samples to 100% VWF:Ag. The treated plasma samples were loaded onto Hydragel 5 von Willebrand multimers gels (5 µl/well) for migration by agarose gel electrophoresis. Direct immunofixation by anti-VWF antibodies and visualization by peroxidase-labeled antibodies revealed the multimeric profile. According to a standard VWF multimers evaluation [17], the relative proportions of low- (≤ 5-mers, LMWM), intermediate- (6- to 10-mers, IMWM), and high-molecular-weight multimers (> 10-mers, HMWM) of VWF were determined using densitometry analysis on a Hydrasis 2 Scan. Multimers pattern curves were displayed on the Sebia Phoresis software. For each patient, LMWM, IMWM and HMWM were either expressed as a proportion (expressed in percentage) of each patient’s total multimers or as a ratio between patient’s and healthy volunteers’ pooled plasma.
Continuous data were expressed as median (interquartile range (IQR)] and categorical data as proportions. In the univariate analysis, patients were compared according to COVID-19 status (non-COVID-19 vs COVID-19) and COVID-19 severity (non-critical vs critical) using the Mann–Whitney test and Fisher’s exact test for continuous and categorical variables, respectively. The association between levels of endothelial activation biomarkers and COVID-19 severity was assessed using the Kruskal–Wallis and Cochran–Armitage tests for trends for continuous and categorical variables (multiple groups), respectively. In order to estimate the ability of VWF:Ag to predict in-hospital mortality, we used receiver operator characteristics (ROC) analysis. We estimated the area under the curve (AUC) and its 95% confidence interval (CI) and selected the optimal cutoff that illustrated the prognostic ability of VWF:Ag.
In the multivariate analysis, we assessed the association between VWF:Ag and in-hospital mortality using the logistic regression model adjusted for age, body mass index (BMI), d-dimer and CRP levels.
For the survival analysis among patients hospitalized for COVID19, the start of the study was triggered by the diagnosis of SARS-CoV-2 infection. The end of the study was defined either by patient’s death during their hospitalization or by discharge alive from the hospital. We used the Kaplan–Meier curve to estimate the survival function from diagnosis to in-hospital death according to the optimal cutoff of VWF:Ag. Survival curves were compared using the log-rank test. We used the Cox proportional hazard (PH) model adjusted for age, BMI, d-dimer and CRP levels to investigate the relationships between the increase in VWF:Ag (over the calculated cut-off value) and in-hospital mortality.
All analyses were two-sided and a p-value of < 0.05 was considered to be statistically significant. Statistical analysis was performed using R studio software including R version 3.6.3 (RStudio, PBC, Boston, MA).
Between March 13 and June 26, 2020, a total of 208 COVID-19 adult patients comprising 23 outpatients and 185 hospitalized patients were included in this study. Among hospitalized patients at admission, 89 (48.1%) suffering from critical forms of COVID-19 were under mechanical ventilation (MV) in the ICU, whereas 96 (51.9%) were hospitalized in medical wards. Among the patients included, 129 (62.0%) were male. The non-COVID-19 control group comprised 17 (58.6%) females and 12 (41.4%) males. The median age was 39 (IQR 32.0–46.0) in the non-COVID-19 group and 62 (50.0–72.0) in COVID-19 patients. Patients were significantly older (p < 0.001) and included a higher proportion of males (p < 0.001) than non-COVID-19 patients (Table 1). Compared with the non-COVID-19 group, cardiovascular risk factors were more frequent in COVID-19 patients, especially in those who were hospitalized. Indeed, 105 (50.5%) COVID-19 patients suffered from hypertension, while obesity, hyperlipidemia and diabetes were found in approximately one third of them. Concerning hospitalized COVID-19 patients, critical and non-critical patients did not significantly differ for most clinical and biological characteristics; however, critical patients had a higher median BMI (28.1, IQR 26.0–33.7) than non-critical patients (24.4, 23.2–28.5, p < 0.001). Furthermore, critical patients had significantly higher d-dimer, Hs-cTnI and CRP levels (p < 0.001 for each) than non-critical patients.
First, CECs were significantly increased in critical (median, 32.0, IQR 17.0–55.5) COVID-19 patients compared with non-critical patients (15.0, 9.00–28.50, p < 0.001) (Fig. 1a, Table 2). In contrast, Ang1, sEng and sEPCR levels were not significantly different between COVID-19 and non-COVID-19 patients (Fig. 1b–d). Compared to the non-COVID-19 group, levels of sVCAM-1 were increased significantly in non-critical and critical COVID-19 patients without no significant difference between these two groups (critical: median 2935 ng/ml IQR 1830–5646, non-critical: 2272 ng/ml, 1068–4239, p = 0.77) (Fig. 1e). Levels of sE-sel (critical: median 42879 pg/ml, IQR 32136–65398, non-critical: 22453 pg/ml, 17873–28643, p < 0.0001), sTM (critical: median 636 pg/ml, IQR 499–871, non-critical: 343 pg/ml, 298–412, p < 0.0001), Ang2 (critical: median 5360 pg/ml, IQR 4244–9776, non-critical: 2022 pg/ml, 1363–2663, p < 0.0001), were significantly increased only in critical COVID-19 patients. In outpatients and non-critical COVID-19 patients in medical wards, circulating levels of these endothelial biomarkers circulating levels did not significantly differ from non-COVID-19 patients. (Fig. 1f–h).
In contrast to the abovementioned biomarkers, VWF:Ag levels scaled along with COVID-19 severity. Levels of VWF:Ag levels were significantly higher in all COVID-19 patients (median 367%, IQR 250–487) compared with non-COVID-19 patients (113%, 91–152, p < 0.0001). Furthermore, VWF:Ag levels were significantly higher in critical patients (median 507%, IQR 428–596) in contrast to non-critical patients (288%, 230–350, p < 0.0001) and were significantly higher in non-critical patients (288%, 230–350) in contrast to COVID-19 outpatients (144%, 133–198, p = 0.007, Fig. 1i). In terms of the association of endothelial markers and usual parameters of severity, VWF:Ag levels were the parameter most significantly associated with d-dimer levels (r = 0.794 p < 0.0001), CRP (r = 0.585 p < 0.001) and troponin I (r = 0.550 p < 0.0001). As expected, levels of VWF:Ag were strongly correlated with those of VWF:Rco (r = 0.944, p < 0.001, data not shown).
Following the observation that increased VWF:Ag in COVID-19 patients mirrored clinical severity, we next explored VWF involvement in COVID-19, performing VWF multimer analysis in both randomly generated subgroups of 40 critical and 37 non-critical included patients. No significant difference was observed in IMWM, while a significant decreased in LMWM was observed (Fig. 2a, b). Strikingly, VWF HMWM (ratio) were significantly increased in critical patients (median 1.18, IQR 1.04–1.39) compared to non-critical patients (0.96, 0.86–1.09, p < 0.001, Fig. 2c, d), in line with the decreased LMWM.
Subsequently, we further investigated the association between the levels of endothelial biomarkers at admission and in-hospital mortality. First, we performed a univariate logistic regression model for all endothelial biomarkers measured. In decreasing order, variations in levels of HMWM (ratio) (odds ratio, OR 116, 95% CI 10.2–1943, p < 0.001), HMWM (%) (OR 1.11, 95% CI 1.00–1.24, p = 0.048), vWF:Ag (OR 1.01, 95% CI 1.01–1.02, p < 0.001) and sTM (OR 1.01, 95% CI 1.01–1.01, p < 0.001) were the most significantly associated with in-hospital mortality (Table 2). In order to evaluate the respective discriminatory ability between survivors and non survivors of those four biomarkers, we generated ROC curves. Among generated ROC curves in hospitalized patients, VWF:Ag (AUC 0.92, 95% CI 0.88–0.96) proved to be the best predictive parameter followed by sTM (0.91, 95% CI 0.87–0.95), HMWM (as a ratio vs normal plasma: 0.77, 95% CI 0.64–0.90, as a percentage 0.64, 95% CI 0.49–0.79) (Fig. 3). Therefore, we used the ROC curve of VWF:Ag to estimate a cut-off value to predict in-hospital mortality. A VWF:Ag level at 423% provided an optimal sensitivity–specificity balance with an acceptable sensitivity of 95.1% (95% CI 88.0–99.1) associated with an excellent negative predictive value of 98.7% (95% CI 95.1–99.8) to predict in-hospital mortality.
Indeed, in a univariable analysis model a VWF:Ag level over 423% at admission was significantly associated with higher in-hospital mortality (OR 89.7 95% CI 25.9–567.4, p < 0.001). This association remained significant in a multivariable analysis model adjusted on age, BMI, d-dimer and CRP (OR 25.6, 95% CI 5.6–198.2, p < 0.001) (Table 3).
This ability of the vWF:Ag cut-off to predict in-hospital mortality was additionally validated in a Kaplan–Meier estimator (p < 0.001, Fig. 4) and a Cox proportional hazard analysis adjusted for age, BMI, d-dimer and CRP (Hazard ratio, HR 9.46, 95% CI 1.99–44.9, p = 0.005, Fig. 5).
In this study, we demonstrated that markers of endothelial injury in COVID-19 patients were related to severity of patients at admission and to in-hospital mortality. To our knowledge, this study is the first one to examine an extensive panel of endothelial circulating biomarkers, including the assessment of circulating endothelial cells, soluble markers and VWF multimers patterns in such a range of COVID-19 severities, from mildly symptomatic outpatients to critically ill patients, in a cohort of this scale and a non-COVID-19 control group. The best predictive marker of in-hospital mortality was found to be VWF:Ag, which makes relevant its evaluation in daily practice during COVID-19 hospitalization.
First of all, we confirmed that an endothelial dysfunction occurs in COVID-19, in particular in severe forms. Previously, our team demonstrated an association between Ang2 levels at admission and ICU referral [13]. Moreover, Goshua et al. showed that sTM levels measured in critical COVID-19 patients were increased and were a good predictor of in-hospital mortality [18]. Recently, Cugno et al. reported increased levels of sTM and sE-sel in severe COVID-19 patients without establishing their relationship to in-hospital mortality [19]. In the present study, we found an increase in several specific biomarkers of EC injury in COVID-19 patients compared with non-COVID-19 individuals, the most striking differences being observed in VWF:Ag. Notably, we identified two distinctive profiles of biomarkers according to clinical severity. Indeed, Ang2, sE-sel and sTM were elevated only in critical patients, whereas only VWF:Ag increased accordingly to disease severity. Von Willebrand factor, which mediates platelet adhesion and aggregation through its binding to platelet GPIX-Ib receptor, is contained in endothelial Weibel-Palade bodies (WBPs), mainly in the form of large multimers [20]. Inflammatory cytokines, in particular interleukin 1 and tumor necrosis factor α, were shown to trigger endothelium activation which results notably into the release of endothelial WBPs content and therefore VWF by exocytosis [21]. As expected, in our cohort, VWF:Ag levels correlated with inflammatory markers such as CRP. To date, the only therapy which has demonstrated clinical proofs on in-hospital mortality in COVID-19 is steroids, reducing deaths by approximately one-third among critically-ill patients [22]. In addition to well-known systemic anti-inflammatory effects, steroids exert various direct effects on EC. Indeed, steroids inhibit endothelial phenotype induced by inflammation [23–25] and improve endothelial barrier integrity through upregulation of junctional proteins such as occludin, claudin-5, and VE-cadherin [26]. Thus, steroids could decrease excessive endothelium activation and subsequent VWF release which could explain, at least partly, their clinical beneficial in COVID-19. Future studies need to appreciate endothelial lesion markers, in particular VWF, as prognostic marker during steroids treatment. However, in the present study, VWF:Ag remained independently associated with in-hospital mortality after adjustment for inflammatory biomarkers, which supports the hypothesis of additional causes of VWF secretion by ECs. Indeed, endothelium is emerging as a key target organ of SARS-CoV-2 infection. Dissociation between markers of activation, such as sE-sel, and VWF:Ag in critical and non-critical patients could reflect the overwhelming synthesis and release of VWF in pulmonary vasculature due to a combination of inflammation, direct viral destruction of ECs, and also lung tissue hypoxia [27].
In order to deepen the characterization of VWF involvement in COVID-19, we reported increased HMWM in critical compared with non-critical patients. Following an initial endothelial lesion caused by multiple factors, an increase in HMWM of VWF could promote local microthrombosis which itself promotes additional ECs lesion in a vicious cycle. Indeed, under physiological conditions, newly secreted VWF multimers are rapidly cleaved into smaller, less reactive multimers by the metalloproteinase ADAMTS13 during VWF secretion from ECs [28]. ADAMTS13 acquired deficiency also known as thrombotic thrombocytopenic purpura (TTP), is a life-threatening condition well known to induce an accumulation of large VWF multimers which binds spontaneously to platelets, resulting in diffuse microthrombosis [29]. In a small case series, Escher et al. reported normal ADAMTS13 activity in severe COVID-19 patients [30], whereas Rovas et al. found a minor decrease in ADAMTS13 in critically-ill patients but in no way comparable to the nearly total deficiency associated with TTP [31]. Taken together, our results suggest a massive release of unprocessed VWF from activated ECs that may overwhelm the enzymatic capacity of ADAMTS13 rather than a true ADAMTS13 deficiency. In COVID-19, this link between VWF and pulmonary microthrombosis requires further confirmation. A way to highlight this link could be measuring VWF:Ag at multiple time points during the hospitalization of severe COVID-19 patients and evaluate its correlation with advanced respiratory monitoring parameters established to mirror the pulmonary microcirculation dysfunction such as pulmonary physiological dead space and its sub-components airway dead-space and alveolar dead-space [32, 33].
Regarding clinical practice, in light of our finding that VWF:Ag levels at the time of COVID-19 patients’ aggravation (approximated in this study by hospitalization) might predict in-hospital mortality, we recommend including systematic VWF:Ag measurement into the monitoring strategy of all COVID-19 patients. In addition, it will be very important to investigate VWF:Ag follow-up, which could provide additional prognostic information both in the critical care and in the non-critical care settings. This strategy should be all the easier to set up, given that VWF:Ag is a common analysis in hematology laboratory in most healthcare centers worldwide [34].
Furthermore, establishing a well-validated VWF:Ag cut-off could help in identifying patients who might benefit the most from adjunction of antiplatelet therapies to standard of care. Indeed, VWF and, in particular, HMWM, is an essential component in platelet aggregation. Manne et al. and Hottz et al. both highlighted platelet hyperactivity in COVID-19–associated pathophysiology [35, 36]. Aspirin could present a way to hinder microthrombosis in COVID-19 and therefore to stop the vicious cycle of endothelial lesion described above. In the pre-COVID-19 era, several single-center retrospective observational cohort studies assessed a possible association between pre-hospital anti-platelet agent (the vast majority of which is aspirin) therapy and mortality in sepsis or acute respiratory distress syndrome (ARDS). Patients admitted with community-acquired pneumonia on anti-platelet therapy have a lower admission rate to the ICU and shorter hospital stay [37]. In a general population of ICU admissions, patients with pre-admission antiplatelet therapy had a decreased risk of developing ARDS [38, 39] and multi-organ failure [40]. Furthermore, in ICU patients with septic shock or ARDS being treated with antiplatelet drugs, several studies reported a reduction in mortality rate [41–43]. In COVID-19, Chow et al. recently showed in a retrospective observational cohort study of adult patients admitted with COVID-19 that patients who received aspirin within 24 h of admission or seven days prior to admission displayed a decreased risk of MV, ICU admission and in-hospital mortality with no differences in major bleeding or overt thrombosis between aspirin users and aspirin non-users [44]. Aspirin therefore appears to be a promising treatment in COVID-19, although it should be further evaluated in prospective clinical trials. Another attractive approach to hamper excessive VWF large multimers binding to platelets and the ensuing microthrombosis could be the use of novel TTP treatments caplacizumab [45] or anfibatide [46], both of which inhibit the binding of platelets to the VWF at the GPIX-Ib receptor.
Limitation of our study include the absence of iterative biomarker measurement over time to provide a more accurate picture of endothelial dysfunction during COVID-19 evolution.
In conclusion, our study provides new insights confirming that COVID-19 is a microvascular disease, in particular for critical forms of COVID-19. Inflammation and SARS-CoV-2 activates and/or directly injure ECs. In our cohort, circulating VWF levels were highly correlated with clinical severity and were the best endothelial marker to predict in-hospital mortality. Beyond its involvement as a biomarker, VWF and HMWM as thrombosis actors emphasize the link between microvascular thrombosis and endothelial injury during COVID-19. Measurement of VWF:Ag could therefore represent a quick, easy, and non-invasive way to point out the most severe form of COVID-19 but also assess treatments efficiency during follow-up.",Angiogenesis
PMC7809554,The COVID-19 pandemic and the 2020 US presidential election,"News of a novel coronavirus made global headlines beginning in January 2020. On January 9, 2020, the World Health Organization announced a coronavirus-type pneumonia outbreak in Wuhan, China. The US Centers for Disease Control and Prevention began screening at three major US airports on January 20, and the first US coronavirus case was confirmed the following day. On January 23, China made the unprecedented move of quarantining Wuhan, a city of 11 million people. The white House announced on January 31 a travel ban on foreign nationals who had traveled to China within the past 14 days. The first US death from the disease occurred on February 29 in Washington State.5
The WHO declared a pandemic on March 11. That same day the US National Basketball Association suspended all games, and the actor Tom Hanks and his wife Rita Wilson announced they had tested positive for the virus in Australia. Trump declared a national emergency on March 13, unlocking up to $50 billion dollars in federal funding to combat the spread of the disease, the same day on which several states announced school closures. On March 19, California became the first state to issue a “stay-at-home” order, with exceptions for work and shopping for essential needs. On March 26, Trump signed into law the CARES Act, which provided $2 trillion in aid to businesses, hospitals, and local governments.
While no country was unaffected, the COVID-19 pandemic hit the USA particularly hard. The US COVID-19 death toll passed the grim mark of 100,000 on May 28; by September 22, 200,000 American lives had been lost. Measured on a per capita basis, only Brazil, Spain, and Mexico have recorded higher death rates among large countries.6 Along with lost lives, the uncontrolled spread of COVID-19 in the USA exerted a profound economic impact. Increasing numbers of cases caused changes in consumer behavior, with large drops in consumption of services (Baker et al. 2020; Chetty et al. 2020) leading to an unprecedented increase in unemployment (Chetty et al. 2020; Coibion et al. 2020). The economic downturn coincided with changing political attitudes about the role of government, with Rees-Jones et al. (2020a) finding deaths and infections associated with increased support for expanding the US safety net.
In sharp contrast to most world leaders and to his opponent Joe Biden, Trump sought to downplay the threat of the virus, with limited political success. He began this tactic early in the crisis, and never veered from it. On February 10, Trump claimed, “a lot of people think that [coronavirus] goes away in April with the heat...” On February 26, as US cases began to appear, he said, “when you have 15 people, and the 15 within a couple of days is going to be down to close to zero, that’s a pretty good job we’ve done.” Again, on April 3, he remarked, “It is going to go away. It is going away.” He continued making similar comments throughout the summer, and in his first remarks after contracting the virus himself in October, he declared, “It’s going to disappear. It is disappearing.”7 The tactic did little to help his standing with the electorate. According to Gallup, Trump’s approval rating fell from a 2020 high of 49% on March 22 to 38% on June 30.8 Polls showed nearly 60% of Americans disapproved of Trump’s response to the pandemic, with very little variation in the 5 months leading up to the election.9
There are several reasons to believe that the pandemic and the Trump administration’s response were detrimental to Trump’s reelection prospects. The strong disapproval of the president’s handling of the virus suggests that a majority of the public blamed the administration for its failure to curtail its spread. Most importantly, voters likely associate rising local cases and deaths with an increasing threat to the health and safety of themselves and their loved ones. In this context, we might expect that the greater the local exposure to risk, the more likely voters are to punish the president by voting for the challenger. Another channel through which COVID-19 may have lead to diminished Trump support is economic. Despite a big rebound in economic growth in the third quarter of 2020, the unemployment rate remains well above the historical average. Ominously, rising case numbers in the lead-up to the election portended another wave of hospitalizations and deaths—and the prospect of more localized lockdowns, business closures, and a double-dip recession. Both retrospective and prospective voting frameworks suggest that voters are likely to hold the president accountable for the toll of the virus. For these reasons, we examine whether more severe local outbreaks are associated with weaker support for Trump in 2020, compared to the 2016 presidential election.
There is, however, a counter-argument to be made. A possible interpretation of Trump’s strategy in responding to the pandemic is that it was in line with the preferences of his core constituents. Survey data reveal a striking difference in attitudes toward the pandemic between Democratic and Republican voters. According to Gallup, only 25% of Republican respondents are “worried about getting the coronavirus,” whereas this percentage climbs to almost 80% among Democratic respondents.10 Similarly, about 60% of Republican respondents are “ready to return to normal activities right now,” whereas a mere 3% of Democratic respondents are ready to resume a normal lifestyle. We see similar differences for questions related to practicing social distancing, wearing masks, and avoiding large crowds. While ideology influences attitudes toward the pandemic in other countries as well, the differences between Democratic and Republican voters in the USA are uniquely large. In short, given the polarization of US politics, voters seem to be experiencing the very same event in very different ways based on their partisan identities. If this is the case, even a global pandemic responsible for hundreds of thousands of deaths may not meaningfully reduce support for Trump, especially among his base.
Our analysis relies on known COVID-19 cases and deaths, recorded at the county-level. We use the COVID-19 incidence data compiled by the Center for Systems Science and Engineering at Johns Hopkins University. The data and data sources at the state and county levels can be accessed here: https://github.com/CSSEGISandData/COVID-19. The cumulative totals of COVID-19 cases and deaths correspond to October 22, 2020. In our sample, the mean for the cumulative number of COVID-19 cases per 10,000 is 247 (std. dev. 157), while the cumulative number of COVID-19 deaths per 100,000 is 53 (std. dev. 56). Figure 1 and Appendix Fig. 4 illustrate the distribution of cases and deaths in the USA, respectively.

We also gather data on the following COVID-19 policies: stay-at-home orders, mandatory face mask policies, day care closures, freezes on evictions, and mandated quarantine for individuals arriving from another state. Data on policy duration are drawn from Raifman et al. (2020). See our discussion paper for more details about these policies (Baccini et al. 2020).
We draw social distancing data from Google’s COVID-19 Community Mobility Reports. This data set captures visits to a location relative to a baseline day using data from users who have enabled “location history” in their Google account. The baseline day is the median value for the 5-week period from January 3 to February 6, 2020. We rely on workplace as the location of interest as of April 1, 2020, i.e., the midpoint of the first COVID-19 wave. We also rely on mobility change as of August 1st as a robustness check, i.e., the midpoint of the second wave.11
We merge variables capturing COVID-19 incidence by county with data on county-level election results from Dave Leip’s Atlas of US Presidential Elections.12 We compute the difference of vote shares of Trump between the 2020 and 2016 US presidential elections. Specifically, we compute shares dividing the total number of votes for Trump by the total number of votes in each county.
Table 1 provides summary statistics, and Fig. 2 illustrates changes in voting share from 2016 to 2020. The map shows that Trump’s support fell in parts of the Rust Belt and the Sun Belt in 2020 compared with the 2016 presidential election.13
We rely on the County Business Patterns (CBP) to compute the share of employment in meat-processing factories. Of note, there are jobs in this industry for about 52% of counties. The CBP provides annual data for establishments with paid employees within the USA. This data set provides annual employment data at the county-level for the week of March 12 and annual payroll data. Note that the CBP does not include employment for most establishments with government employees and the following NAICS industries: crop and animal production; rail transportation; Postal Service; pension, health, welfare, and vacation funds; trusts, estates, and agency accounts; office of notaries; private households; and public administration. See https://www.census.gov/programs-surveys/cbp/about.html for more details.
Last, we get monthly unemployment rates at the county-level from the US Bureau of Labor Statistics’ Local Area Unemployment Statistics. In our sample, the mean change in the unemployment rate from August 2019 to August 2020 was an increase of 2.87.14
We rely on four occupational indexes as control variables: (1) exposure to disease or infection, (2) physical proximity, (3) essential worker designation, and (4) remote work. The first three indexes were built in Beland et al. (2020), while the remote work index comes from Dingel and Neiman (2020). These indexes serve as covariates in our analysis since they have been shown to be related to the severity of job losses in the USA and could be related to voting behavior and COVID-19 incidence.
As stated in our PAP, we first rely on the following model:
1\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\Delta} Y_{c} = \alpha + \beta \mathrm{COVID Incidence}_{c} + X^{\prime}_{c} \gamma + \theta_{s} + \varepsilon_{c}, $$\end{document}ΔYc=α+βCOVIDIncidencec+Xc′γ+𝜃s+εc,where Yc is the differential in Trump’s vote share in 2020 and 2016 for county c. COVIDIncidencec is the cumulative number of confirmed COVID-19 cases per 10,000 inhabitants or COVID-19 deaths per 100,000 inhabitants as of October 22, 2020.15 We report standard errors clustered at the state-level.
We include in the model Xc, which is a vector of county-level variables. We include the following demographic and socioeconomic variables: population, share of female population, share of foreign-born population, share of population with a college degree, share of non-Hispanic Black population, share of non-Hispanic white population, share of population by age group (9 dummies), social mobility index, and four occupational indexes. Moreover, we compute employment changes due to the pandemic at the county-level by taking the unemployment rate as of September 2020 minus the unemployment rate as of September 2019.16 The inclusion of these variables is key to our identification assumption that no omitted variables are related to COVID-19 incidence and the change in voting behavior from the 2016 to the 2020 presidential election. Finally, 𝜃s represents state fixed effects. This set of fixed effects allows us to further control for county-level characteristics that are common to counties within the same state.
Our estimation is thus at the county-level and we effectively test whether counties with relatively more COVID-19 cases or deaths differentially voted for the Trump in 2020 compared with the previous presidential election. We use this model instead of a model relating COVID-19 incidence to vote share in 2020 alone to better capture trends in voting behavior. In other words, we compare how voting behavior changed pre- and post-COVID-19 rather than simply analyzing voting behavior post-COVID-19. We believe this is crucial in this context given the increasing political polarization in the USA. Moreover, we think that the inclusion of state fixed effects and controlling for social distancing and a large set of demographic variables helps account for differential (changes in) behavior and preferences across counties. This is also crucial because a growing literature has shown, for instance, that individuals identifying as Republicans are less likely to comply with social distancing orders than those identifying as Democrats (e.g., Allcott et al. 2020; Gollwitzer et al.2020).
We complement the reduced form analysis with an instrumental variable approach. The concern we attempt to address is that COVID-19 cases and COVID-19 deaths do not occur at random, but rather they correlate with individuals’ behavior, which may be different between those who vote for the Democratic Party and those who vote for the Republican Party. For instance, it may be that voters living in “red” (i.e., Republican-leaning) counties are less likely to observe social distancing or to wear masks. If this is the case, this type of behavior would be likely to increase the number of COVID-19 cases (and in turn COVID-19 deaths) and we would observe a larger share of votes for Trump than for Biden in the same counties. While we control for social distancing in the previous analysis, we may have missed some other confounders in our analysis.
To attempt to achieve exogenous variation of COVID-19 cases and deaths at the county-level, we instrument COVID-19 cases and deaths with the share of employment in meat-processing factories in each county. More specifically, we use the average number of workers in the NAICS industry code 3116, “Animal Slaughtering and Processing,” in each county between 2012 and 2015, i.e., before Trump’s presidency. We divide this number by the average number of total workers in each country during the same time frame, i.e., 2012–2015. Data come from the CBP and measure raw employment.
The rationale for the instrument is that there is evidence of meat-processing plants becoming COVID-19 hotbeds due to their cold, humid environment and difficulties with workplace physical distancing.17 According to a CDC report on July 10, among 23 states reporting COVID-19 outbreaks in meat and poultry facilities, 16,233 cases in 239 facilities occurred, including 86 (0.5%) COVID-19-related deaths.18 Based on cases reported by Johns Hopkins University, as of May 6, counties containing or within 15 miles of one or more meatpacking plants reported 373 COVID-19 cases per 10,000 residents.19 That is roughly double the US average of 199 cases per 100,000 in all counties with reported cases.20 The severity of the incidence of COVID-19 cases in meat-processing facilities prompted research on how to control the spread of the virus in these plants.21
Armed with this instrument, we estimate:
2\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \left\{\begin{array}{l} \text{COVID}_{c} = \rho + \phi \cdot \text{MEAT}_{c} + X^{\prime}_{c} \psi + \theta_{s} + \nu_{c} \\ {\Delta} Y_{c} = \alpha + \delta \hat{\text{COVID}}_{c} + X^{\prime}_{c} \gamma + \theta_{s} + \varepsilon_{c}, \end{array}\right.  $$\end{document}COVIDc=ρ+ϕ⋅MEATc+Xc′ψ+𝜃s+νcΔYc=α+δCOVID^c+Xc′γ+𝜃s+εc,where MEATc is the share of workers in meat-processing plants. We run a first stage in which we regress this variable on the cumulative number of COVID-19 cases per 10,000 inhabitants or deaths per 100,000 inhabitants at the county level, including all controls and state fixed effects as in Eq. 1. Then we plug in the predicted values of this first stage and estimate the second stage of the 2SLS.
For our instrument to be valid two conditions have to hold. First, our instrument has to be a strong predictor of the number of COVID-19 cases and deaths. Figure 3 illustrates the relationship between the cumulative number of COVID-19 cases and the share of employment in meat-processing factories since the beginning of the pandemic for the (1) top 1% of counties with the highest share of employment in meat-processing factories, (2) top 5% of counties with the highest share of employment in meat-processing factories, (3) counties with at least one job in meat-processing factories, and (4) counties without any jobs in meat-processing factories.

This figure provides direct evidence that counties with a higher share of employment in meat-processing factories had a higher incidence of COVID-19 during the entire pandemic. COVID-19 case (and death) incidence is much larger for counties with a relatively high share of employment in meat-processing factories and much smaller for counties with no employment or positive employment share. This result suggests our first stage is strong and that the relationship between the share of employment in meat-processing factories and COVID-19 incidence is non-linear.
Note also that the raw correlation between COVID-19 cases and deaths and our instrument is 0.3 and 0.1, respectively. The correlation between COVID-19 cases and deaths and our instrument conditional on controls and state fixed effect is much higher, i.e., above 0.5 for cases and 0.3 for deaths.
Second, the identifying variance is the industrial composition of each county, specifically the presence of meat-processing factories. In order for our instrument to allow a causal interpretation, employment in meat-processing factories must only affect the change in voting behavior from 2016 to 2020 through its effect on COVID-19 cases and deaths, i.e., the exogeneity assumption. While there is no test to assess the validity of this assumption, we discuss other possible channels through which our instrument can affect the outcome variable and explain how we account for these channels. While we control for a host of variables that could potentially affect the exclusion restriction, we discuss here two main possible violations of the exogeneity assumption.
First, we control for the share of manufacturing employment. We do so because it may be that counties with a large share of workers in manufacturing voted against Trump in 2020 due to job losses for which he was now held accountable as the incumbent president. It may also be that trade unions were more actively campaigning against Trump in 2020 than they were in 2016, since he was the incumbent Republican president. In an effort to isolate the effect of our instrument on COVID-19 cases, we also include the share of workers in food manufacturing, i.e., NAICS industry code 311, to which “Animal Slaughtering and Processing” belongs. Including this variable implies that every possible violation of the exclusion restriction has to be specific to the meat-processing industry.
In the same spirit, we are concern that Trump policies—both those related and those unrelated to trade—did not specifically affect meat packaging industry. We thus include the China trade shock variable, which captures the vulnerability of US manufacturing counties to foreign competition especially from China.22Autor et al. (2020) show that the China trade shock increased Trump’s vote in 2016 and, in the same vein, it could have decreased his electoral support in 2020 as the incumbent president.
Second, it may be that Trump’s trade policies have negatively affected meat sales, and in turn this could have led to a loss of support among workers in this industry and in surrounding communities. Kim and Margalit (2021) provide evidence of that. For addressing this concern, we include variables capturing the potential impact of Chinese tariffs and US tariffs on the workforce in each county.23
Note also that the correlation between our instrument and the share of manufacturing employment and share of employment in food manufacturing is 0.3 and 0.4 respectively, whereas the correlation between our instrument and the other controls is never higher than 0.1.24
In Appendix Table 8, we provide empirical evidence that COVID-19 incidence is significantly related to votes for Trump in 2016 and 2020. We then provide evidence that COVID-19 incidence in our models is not successfully predicting changes in voting behavior for previous presidential elections. The variables of interest are the cumulative number of COVID-19 cases per 10,000 (columns 1–3) and COVID-19 deaths per 100,000 (columns 4–6). In panel A (B), the dependent variable is the vote share for Trump in the 2020 (2016) presidential election, whereas the dependent variable in panel C is the change in votes for Trump from 2012 to 2016. Columns 1 and 4 include only state fixed effects and our demographic controls, while columns 2 and 3 sequentially add socioeconomic controls and our social distancing indicator.
The estimates in panels A and B are positive and significant, suggesting that counties with more Trump’s supporters had larger numbers of COVID-19 cases. The fact that both estimates are positive and significant for both the 2016 and the 2020 presidential elections suggest that this model is misspecified and that a naïve estimation would conclude that COVID-19 incidence helped Trump during the 2020 presidential election.25 In contrast, the estimates are imprecisely estimated and statistically insignificant in all columns in panel C, suggesting that using the differential in voting is more appropriate than using the vote share for the current elections.
We also provide placebo evidence that our IV method leads to null findings for previous presidential elections. The estimates are presented in panels D, E, and F. The dependent variables are respectively the differential in vote share for the Republican Party for the elections in 2016 and 2012 (panel D), in 2012 and 2008 (panel E), and in 2008 and 2004 (panel F). The point estimates for COVID-19 cases are all statistically insignificant and much smaller than our 2SLS estimates for 2016–2020. These results provide evidence that our empirical models are properly specified.
In this section, we estimate the effect of COVID-19 incidence on voting behavior using OLS and 2SLS. We focus on COVID-19 cases in the main analysis. We note again that our analysis and choice of control variables were fully detailed in our pre-analysis plan. Table 2 contains OLS estimates of Eq. 1 (columns 1–3). The sample size is 2689 observations (i.e., counties).26 The dependent variable is the differential in vote for Donald Trump in 2020 and 2016. A positive value indicates that Trump received more votes in 2020 than in 2016. We report standard errors clustered at the state-level. The variables of interest are the cumulative numbers of COVID-19 cases per 100,000 inhabitants.

What clearly emerges is that COVID-19 cases are negatively related to votes for Trump during the 2020 presidential election in comparison to the 2016 election. In column 1, we include state fixed effects and our set of demographic and socioeconomic controls. We find that a county with 100 more COVID cases per 10,000 people (as compared to others in the same state) reduced its Trump vote share from 2016 to 2020 by an additional 0.12 percentage points on average. The point estimate is statistically significant at about the 10% level.
In column 2, we add to the model our indicator of social distancing, i.e., time spent at workplaces in April 2020. Column 3 is our most extensive model specification. We saturate our model with all the previous controls and state fixed effects. In addition, we add to the model the unemployment change from before to during COVID-19. The magnitude of the estimates and statistical significance remain the same.
In column 4, we add to the model a quadratic term of COVID-19 cases. The quadratic term of COVID-19 cases is positive and statistically significant at the 5% level, but very small in magnitude (6.10e-08). In contrast, the magnitude and sign of the coefficient of our variable of interest, cumulative COVID-19 cases per 10,000, remain the same. This result suggests that the negative effect of additional COVID-19 cases on Trump’s 2020 vote share becomes slightly smaller as the number of cases increases.
Of note, the coefficient of unemployment change (August 2019 to August 2020) is small and statistically insignificant.27 Our results thus suggest that job losses during the pandemic are not significantly related to voting behavior and that increases in the unemployment rate does not seem to be a major factor behind the negative effect of COVID-19 on the share of votes for Trump. A possible explanation is that job losses are triggered by policies, e.g., lockdowns, implemented by the states, which Trump opposed or at the very least for which Trump cannot be held directly responsible.
The coefficients for some of the other control variables are worth discussing (not shown for space consideration). We find that the share of women is strongly negatively correlated with the change in vote share for Trump. Similarly, Trump seems to have lost vote share in counties with a high share of adults aged 25–54.
Our OLS results provide suggestive evidence that the pandemic affected the 2020 presidential election. The main concern with our OLS estimates is that omitted variables could be related to both COVID-19 incidence and differential voting behavior in the 2016 and 2020 presidential elections. We now turn to our instrumental variable strategy.
In Table 2 (columns 5–7), we present the first stage (panel A) and the two-stage estimates (panel B) of specification (2) in which we instrument COVID-19 incidence in the first stage by the share of employment in meat-processing factories. We control for our usual set of fixed effects and control variables. As shown in Fig. 3, we find that the share of employment in meat-processing factories is strongly positively correlated with COVID-19 incidence. The coefficient is always significant and the F-statistics indicate no concern of a weak instrument.
Our second-stage estimates are presented in the bottom panel (columns 4–6). We find that counties with more COVID-19 cases substantially decreased their vote share for Trump in 2020. The 2SLS estimates are larger than the OLS estimates and suggest that a county with 100 more COVID cases per 10,000 people (as compared to others in the same state) reduced its Trump vote share from 2016 to 2020 by an additional 1.2 percentage point on average.28 The point estimates are statistically significant at the 1% level and robust to the inclusion of our large set of controls and the share of manufacturing employment as well as the share of employment in food manufacturing.
So far, our analysis has underscored an important finding: the COVID-19 pandemic costs Trump votes. But is this effect large enough to have changed the outcome of the 2020 presidential election? To answer this question, we conduct a simple counterfactual exercise to determine the magnitude of the effect by exploring how the composition of votes in a number of closely contested states would have differed if there had been fewer COVID-19 cases. The computation of the counterfactual is based on the coefficient estimate in column 1 of Table 2. For each county, we compute the fraction of total votes that Trump would have received if the number of COVID-19 cases had been X% smaller as − 0.0012 ×COVIDc × X% – i.e., the point estimate of the effect of COVIDc on Trump’s vote share from the OLS estimates, the size of each county’s measured COVID-19 cases, and the scaling factor X%. We next multiply this product by the number of total votes in a county to calculate the number of additional votes that Trump would have received in the counterfactual scenario. We then aggregate these county-level votes into state totals. To allow for the margin of error in our counterfactual calculations, we use the lower and upper bounds of our estimate (i.e., 0.0012), using the 90% confidence interval. We report these bounds in parenthesis.

Table 3 presents the results of this counterfactual analysis. Column 1 shows the actual vote margin in favor of Biden in the 2020 election for a set of closely contested states. The three subsequent columns show counterfactual outcomes had COVID-19 cases been 5% or 10% or 20% fewer. Since we find that the COVID incidence decreased Trump’s vote share, the counterfactual analyses for fewer COVID-19 cases correspondingly increase Trump’s counterfactual vote totals. The results in Table 3 show that, ceteris paribus, Trump would have won Michigan in a counterfactual scenario with 20% fewer cases. Trump would have won Pennsylvania with 10% fewer COVID-19 cases. He would have won Arizona, Georgia, and Wisconsin, with 5% fewer COVID-19 cases. Under this last counterfactual, Trump would have been reelected. Even if we consider the lower bound calculations, which are very conservative, Trump would have kept the presidency with 21% fewer cases.

We now check whether our results are robust to the use of COVID-19 deaths instead of cases. Table 6 shows our estimates. We do not find any evidence that COVID-19 deaths are related to changes in voting behavior from the 2016 to the 2020 presidential election with our OLS model. The estimates are all statistically insignificant. For our 2SLS estimates, our first stage is weaker than for cases, with F-statistics ranging from 2 in the less parsimonious model to 6 in our model with the full set of controls. The 2SLS estimates are all negative and of similar magnitude as our 2SLS estimates for cases, but more imprecise with only the estimate in column 6 being statistically significant at conventional levels.

The fact that our 2SLS estimates are of about the same magnitude for cases and deaths suggests that our conclusions are similar when using deaths instead of cases. Nonetheless, two differences are worth mentioning. First, our instrumental variable is only weakly related to COVID-19 deaths.33 The probability that a COVID-19 infection results in death rises dramatically with age, and we expect that this and other factors such as healthcare coverage may contribute to the divergence in estimated effects. Second, it is plausible that voters are less aware or less likely to know someone who has died of COVID-19 than to know someone who has tested positive for COVID-19.
One of the defining outcomes of the 2020 presidential election was the record-high turnout. Both presidential candidates would had won any previous elections, given their number of votes at the national-level. We use differences in total votes between the 2016 and 2020 presidential elections as a rough proxy of turnout. We run the same model specification as in Eqs. 1 and 2. We show the results in Table 7.

We find no evidence that COVID-19 cases affected voters’ mobilization in the OLS estimates.34 On the contrary, there is some evidence that the incidence of COVID-19 boosts turnout in the 2SLS. These conflicting results on the effect of the pandemic on mobilization are also found in previous studies that explore this topic in different electoral contexts (Giommoni and Loumeau 2020; Fernández-Navia et al. 2020).35
We provide many robustness checks for our 2SLS results in Baccini et al. (2020). For instance, we add to the models well-known predictors of voting behavior or COVID-19 incidence. We show that our results are robust to controlling for the China shock variable (Autor et al. (2020)) and two variables capturing Chinese tariffs and protection by US tariffs at the county-level from Kim and Margalit (2021). The rationale for including these variables has been explained in the previous section.
We also show that our estimates are robust to the inclusion of weather controls such as precipitation and air pollution (i.e., PM2.5 and precipitation for the first months of the pandemic),36 the share of employment in nursing care facilities,37 county-to-county (in and out) migration, and the duration (in days) of the following statewide non-pharmaceutical interventions: stay-at-home orders, mandatory face mask policies, day care closures, freezes on evictions, and mandated quarantine for out-of-state individuals.38 Overall, the inclusion of one or all of these control variables has no effect on the magnitude and significance of our 2SLS estimates.
We also check whether our OLS and 2SLS point estimates vary if we change the date for the moment in which we calculate the cumulative number of COVID-19 cases. As stated in our pre-analysis plan, we rely on October 22nd for our main analysis. In a set of robustness checks, we instead rely on July 1st, August 1st, September 1st, and August 1st. The estimates for the OLS are all larger and more significant than for our baseline, i.e., cases as of October 22nd, suggesting that we are very conservative in estimating the relationship between COVID-19 cases and the differential in votes for Trump. For the 2SLS, the point estimates all range from − 0.011 to − 0.013 and are statistically significant at the 1% level. Similarly, changing the start period to April or May, i.e., excluding cases that occurred early on in the pandemic, has no impact on our conclusions.
Last, we show that our conclusions are robust to using a different geographical level for the analysis. In Baccini et al. (2020), we replicate our main analysis using commuting zones as our unit of analysis. Commuting zones are significantly larger than counties, which provides the advantage that the distribution of employment in the meat-processing industry is less limited geographically, since many commuting zones have at least one meat-processing factory.39
This paper explores the effect of the COVID-19 pandemic on the 2020 US presidential election using both a reduced form and IV approach. Our key finding is that COVID-19 cases decreased electoral support for Trump. A simple counterfactual exercise shows that, ceteris paribus, if COVID-19 cases had been 5 percent lower, Trump would have been reelected. We find that the negative impact of COVID-19 incidence on Trump’s support is stronger (1) in states without a stay-at-home order, (2) in states that Trump won in the 2016 presidential elections, (3) in swing states, and (4) in urban counties. We find no evidence that worsening economic conditions reduced electoral support for Trump. The 2SLS estimates show evidence that COVID-19 cases affect positively voters’ mobilization, helping Biden win the presidency.
At least two explanations are consistent with these findings. First, voters may have electorally sanctioned Trump for how he handled the pandemic, which was at odds with most major countries, and widely criticized. This explanation is consistent with a retrospective voting approach (Fiorina 1981; Fearon 1999; Norpoth 2001), in which voters sanction incumbents for their handling of negative shocks. Second, some voters may have switched from Trump to Biden due to changes in preferences triggered by the pandemic and the recession. In particular, a severe public health threat and major economic losses may have shifted preferences in favor of an expansion of the social safety net, including healthcare and unemployment insurance programs (Rees-Jones et al. 2020b). Since the Democratic Party is more likely to champion these policies, Biden benefited from this switch in voters’ preferences. This explanation is in line with studies claiming that political preferences are shaped by personal experience. If it is true that these changes in preferences are long lasting (Giuliano and Spilimbergo 2014), the Democratic Party may be able to capitalize electorally in future elections.
Our empirical analysis is unable to tease out which of these two channels is operative; this remains an important task for future research. Future studies should also explore how turnout, which was quite high for the 2020 presidential election but for which granular data is not yet available, influenced the results reported in this paper. Finally, when individual-level survey data become available, it will be important to explore how voter heterogeneity in race, age, and other characteristics conditions voters’ responses to the pandemic.",J Popul Econ
PMC7809555,Umsetzung eines digitalen Semesters Augenheilkunde während der COVID-19-Pandemie,"Die bisherige Lehre der Augenheilkunde fand bis einschließlich des Wintersemesters 2019/20 im 5. und 6. Semester des Humanmedizinstudiums an der Universität Mainz statt.
Im 5. Semester fanden im „Untersuchungskurs der Augenheilkunde“ eine Vorlesungsreihe und ein praktischer Untersuchungskurs mit jeweils 9 Terminen statt. Die Vorlesungen orientierten sich an Funktionen bzw. zugehörigen Untersuchungstechniken und vermittelten propädeutische Grundlagen und theoretische Kenntnisse von ophthalmologischen Untersuchungstechniken anhand beispielhafter Erkrankungen. Diese konnten im Kleingruppenunterricht mit Feedback durch einen ärztlichen Tutor im praktischen Untersuchungskurs aneinander eingeübt werden. Im Kleingruppenunterricht gab es zudem die Gelegenheit, Verständnisprobleme zu Physiologie, Untersuchungen und beispielhaften Erkrankungen zu klären. An digitalen Inhalten standen lediglich die Vorlesungsfolien sowie ein Skript zu Untersuchungstechniken zur Verfügung.
Die Prüfung fand als „objective structured clinical examination“ (OSCE) am Ende des Semesters zu den Inhalten und Untersuchungstechniken von Vorlesung und Kleingruppenunterricht statt.
Im 6. Semester wurden im „Praktikum der Augenheilkunde“ eine Vorlesungsreihe mit 10 Videopodcasts sowie 3 Praktikumstage in der Augenklinik angeboten. Die Vorlesungsreihe orientierte sich an den Organabschnitten des Auges (Lid, Hornhaut, Linse usw.) und den jeweils wichtigsten Erkrankungen dieser. Die Praktikumstage konnten entweder während der vorlesungsfreien Zeit als Blockpraktikum (insgesamt 9 Zeitstunden umfassend) mit eigenständiger Anamnese und Untersuchung von Patienten an der Spaltlampe, Operationshospitation und einem mikrochirurgischen Naht-Wetlab absolviert werden oder während der Vorlesungszeit mit 3 Terminen inklusive eigenständiger Anamnese und Untersuchung von Patienten an der Spaltlampe sowie Sprechstunden- und Operationshospitationen [7]. Das „Mainzer eLearning Augenheilkunde“ stand als digitale Lernressource zur Verfügung mit aktuellen Vorlesungsfolien, beispielhaft beschriebenen Patientenverläufen und Übungsfragen. Links zu externen Lernmaterialien ergänzten das Angebot [8].
Die Prüfung fand im Rahmen einer Präsenz-E-Klausur (Bearbeitung der Klausur am PC in PC-Pool) mit 30 MC-Fragen zu den Inhalten von Vorlesung und Praktikum am Ende des Semesters statt.
Die Vorlesungsreihen beider Kursteile wurden als wöchentliche Videopodcasts mit Folien zur Präsentation der Inhalte mit erklärender Audiospur konzipiert. Hierbei wurden die bisherigen Vorlesungspräsentationen vollständig überarbeitet. Die Strukturierung anhand von Untersuchungen (5. Semester) bzw. Organstrukturen (6. Semester) wurden beibehalten, wie in Tab. 2 dargestellt.
Weiterhin wurde die Gestaltung vereinheitlicht und die Vorlesungsreihen zu wichtigen Inhalten der jeweiligen Themen ausgearbeitet. Die Sprachspur wurde von 2 Dozentinnen (5. Semester) bzw. 1 Dozentin (6. Semester) aufgezeichnet. Die Vorlesungsvideopodcasts wurden wöchentlich als Anker für die jeweils zugeordneten ergänzenden Lernmaterialien auf Moodle veröffentlicht (Abb. 1).
Als digitale Alternative für den Untersuchungskurs der Augenheilkunde in Kleingruppen wurden Untersuchungsvideos zu essenziellen ophthalmologischen Untersuchungstechniken erstellt: Prüfung des Visus, Messung und Palpation des Augeninnendrucks (Video 1), Konfrontationsperimetrie, Augenmotilitätsprüfung, Prüfung der Pupillomotorik, Untersuchungen bei Verdacht auf Schielen, Brückner-Test, Ektropionieren. Hierbei wurde ein detailliertes Drehbuch von 2 Autoren verfasst und in einem Review-Verfahren nochmals überarbeitet, um eine didaktische Wertigkeit und Nachvollziehbarkeit zu gewährleisten.
Die selbstständige Einübung der Untersuchungen wurde durch ein Online-Tutorium in Kleingruppen unterstützt (Tab. 3). Diese Tutorien wurden mittels Video-Conferencing-Software (z. B. Microsoft Teams [Microsoft Corporation, Redmond, CA, USA]) umgesetzt.
Die Prüfung erfolgte durch die Mentoren in Kleingruppen im Rahmen eines einzelnen Präsenztermins im Juli 2020, bei welchem verbliebene Fragen zu Untersuchungstechniken geklärt wurden und im unmittelbaren Anschluss ein OSCE durchgeführt wurde.
Um den Studierenden Symptome, Zeichen und Krankheitsgeschichten von ophthalmologischen Patienten/-innen näherzubringen, richteten wir 2 Formate ein, in welchen diese zur Sprache kamen. Die Tab. 4 stellt die jeweiligen Inhalte und Abläufe dar.
Im „Live-Patientenzimmer“ wurden 2 Patienten mit unterschiedlichen Krankheitsbildern etwa 30 studentischen Teilnehmenden über einen Live-Stream vorgestellt. Das durchführende Team bestand aus mehreren Ärztinnen und Ärzten. Von diesen betreuten jeweils 2 eine Veranstaltung, jeweils einer für Patientenuntersuchung und einer für unmittelbare Betreuung der Studierenden und technische Umsetzung. Mittels Webcam, Mikrofon und Spaltlampenkameraspion wurde die Veranstaltung übertragen. Die Studierenden wurden über einen Live-Chat eingebunden und konnten selbst Fragen stellen (Abb. 2).
Die Patienten waren stationäre Patienten der Augenklinik, welche sich nach einem Aufklärungsgespräch am Vortag über die Veranstaltung und den Rahmen des Datenschutzes schriftlich einverstanden erklären mussten. Die Einwilligung konnte zu jedem Zeitpunkt vor, während oder nach der Lehrveranstaltung zurückgezogen werden. Die Veranstaltungen wurden im Sommersemester 2020 nicht aufgezeichnet und die Studierenden über das Verbot einer Aufzeichnung bei jeder Veranstaltung informiert. Der Datenschutzbeauftragte der Universitätsmedizin Mainz erteilte für das Sommersemester 2020 eine Sondergenehmigung für die Conferencing-Software Microsoft Teams (Microsoft Corporation, Redmond, CA, USA), welche für die Übertragung der Veranstaltung genutzt wurde. Nach Ablauf des Semesters wurde eine datenschutzkonforme Open-Source Alternative für Veranstaltungsformate mit sensiblen Daten geschaffen („Big blue button“, https://bigbluebutton.org/ [BigBlueButton Inc., Open-Source-Software]).
Die „Anamnesevideos“ stellten ein weiteres Format mit echten Patientinnen und Patienten dar. Thematisch wurde jeweils einem Vorlesungsvideopodcast ein Anamnesevideo zugeordnet.
Die Operationsvideos wurden ebenfalls thematisch passend zu den Vorlesungsvideopodcast veröffentlicht.
Als weiteren verpflichtenden Bestandteil des digitalen Unterrichtskonzeptes wurden 7 ophthalmologische Warnsymptome identifiziert:Schmerzen nach Traumaschmerzhafter Visusverlust beim jungen Menschenschmerzhafter Visusverlust beim älteren Menschenschmerzloser Visusverlustneue PtoseRußregen/Blitze/Vorhangsehenrotes Auge
Diese Warnsymptome wurden in Form von interaktiven Patientenfällen („red flags“ der Augenheilkunde) über Moodle zur Verfügung gestellt (Abb. 3). Die Patientenfälle wurden aufgrund ihrer Leitsymptomorientierung den Vorlesungsvideopodcasts nicht spezifisch zugeordnet und parallel veröffentlicht.
Die Klausur fand wie zuvor als E‑Klausur statt, jedoch im Rahmen eines Kohortensystems mit reduzierter gleichzeitiger Teilnehmerzahl, ausreichender Desinfektion und Belüftung der Räumlichkeiten zwischen den einzelnen Prüfungsgruppen.
Es wurden insgesamt ab 24.03.2020 über 6 Wochen 88 Freistellungstage auf 8 Ärztinnen und Ärzte verteilt. Zwei von 8 Ärzten waren durchgehend freigestellt. Die technischen Rahmenbedingungen für einen pünktlichen Start des digitalen Semesters wurden in den ersten 4 Wochen mit 70/88 Freistellungstagen geschaffen. Die letzten beiden Wochen (ab 20.04.) befanden sich bereits in der Vorlesungszeit; 18/88 Freistellungstagen wurden hier genutzt, um die neuen Kursformate durch eingearbeitete Tutoren zu leiten und einen technisch einwandfreien Ablauf zu gewährleisten sowie aufkommende Probleme zu bearbeiten. Semesterbegleitend wurden neben der Patientenversorgung noch einzelne Inhalte finalisiert (z. B. Einsprechen von Vorlesungspodcasts).
Materialien, welche benötigt wurden, sind in Tab. 5 aufgeführt. Diese mussten nur teilweise angeschafft werden, da beispielsweise Kamera und Studiobeleuchtung aus unserer Fotoabteilung entliehen werden konnten.
Abgesehen von einem sicheren Umgang mit einer Office-Suite und ausreichender technischer Versiertheit, um sich in neue, gut dokumentierte Software einzuarbeiten, war kein spezielles „Know-how“ notwendig. Basale HTML-Kenntnisse (Wissen um die grundlegende Struktur von HTML-Code und Websites sind ausreichend) können helfen, die Optik und Funktionalität von browserbasierten eLearning-Inhalten (z. B. interaktive Patientenfälle) zu optimieren.
Für die Konzeption und Umsetzung von Skripten für Untersuchungsvideos und interaktive Patientenfälle sind Erfahrung im Dreh von Lehrvideos und Kenntnisse von Key-feature-Fragenerstellung sinnvoll, welche im Team vorhanden waren.
Es nahmen 64 Studierende im 5. Fachsemester (Untersuchungskurs der Augenheilkunde) sowie 180 Studierende im 6. Fachsemester (Praktikum der Augenheilkunde) an der Evaluation nach Teilnahme an der digitalen Lehre im Juli 2020 teil.
Die Studierenden wurden aufgefordert, nach Abschluss des OSCEs bzw. der Klausur einen Online-Evaluationsbogen auszufüllen, welcher in Zusammenarbeit mit dem Zentrum für Qualitätssicherung und -entwicklung (ZQ) der Johannes-Gutenberg-Universität Mainz gestaltet wurde. Auf diesem wurden zur digitalen Lehre, den einzelnen Bestandteilen des Lehrkonzeptes sowie zur gesamten Veranstaltung Schulnoten vergeben und auf Likert-Skalen Aussagen zur Veranstaltung und der Einschätzung des individuellen Interesses an der Augenheilkunde bewertet. Weiterhin konnten Freitextantworten verfasst werden. Das ZQ wertete die Fragebögen anschließend aus.
Zum Vergleich zu vorigen Semestern wurden vorangegangene allgemeine Evaluationen herangezogen. Diese werden vom Studiendekanat jedes Semesters durchgeführt, wobei Studierende der jeweiligen Kurse zur Teilnahme per Online-Evaluation aufgefordert waren.
Es wurden 64 Evaluationsbögen ausgewertet. Für die jeweiligen Bewertungen konnten zwischen n = 57 und n = 64 Fragebögen einbezogen werden.
Übergreifend wurde der digitale Unterricht der Augenklinik für den Untersuchungskurs Augenheilkunde im 5. Semester im Mittel mit einer Schulnote von 1,58 ± 0,75 (MW ± SD; 1 = sehr gut, 6 = ungenügend) bewertet (n = 64). Die Abb. 4 stellt die Ergebnisse der Evaluation im 5. Fachsemester dar. Die mittlere Länge der Videopodcasts des 5. Semesters betrug 27 min.
Der digitale Unterricht der Augenklinik für das Praktikum Augenheilkunde im 6. Semester wurde im Mittel mit einer Schulnote von 2,18 ± 1,07 (MW ± SD; 1 = sehr gut, 6 = ungenügend) bewertet (n = 170). Die Abb. 5 stellt die Ergebnisse der Evaluation im 6. Fachsemester dar. Die mittlere Länge der Videopodcasts des 6. Semesters betrug 15 min.
Die Ergebnisse der allgemeinen Evaluationen vom Sommersemester 2019 und Wintersemester 2019/20 sind Ergebnissen unserer speziellen Evaluation in Tab. 6 gegenübergestellt.
Die Erfordernisse einer kompetenzbasierten, modernen Lehre mit Erwerb von praktischen Fertigkeiten inklusive von Kommunikations‑, Handlungs- und Managementkompetenzen stellen der Nationale Kompetenzbasierte Lernzielkatalog Medizin (NKLM) sowie der Lernzielkatalog Augenheilkunde [4, 9]. Auch in Krisenzeiten darf die Zielsetzung der medizinischen Ausbildung nicht in Vergessenheit geraten, da sonst der Erwerb von Schlüsselkompetenzen ganzen Ärztegenerationen vorenthalten wird.
Der Präsenzunterricht in der Medizin ist unersetzlich. Ohne eine persönliche Anleitung und Supervision beim Kompetenzerwerb bleiben die Etablierung einer angemessenen Arzt-Patienten-Kommunikation, angemessenes Verhalten und korrekt vorgenommene Untersuchungstechniken lediglich „try and error“, mit hoher Gefahr von Qualitätseinbußen, insbesondere bei praktischen Tätigkeiten.
Die Rahmenbedingungen der COVID-19-Pandemie verlangten jedoch genau dies und nötigten uns, so viel des Prozesses des Kompetenzerwerbs wie möglich auf mediale, möglichst auch interaktive Elemente auszulagern. Wir achteten hierbei insbesondere auf hohe Qualität (z. B. gute Erkennbarkeit von Untersuchungstechniken in den Videomaterialien) und wertvollen didaktischen Aufbau (z. B. formative Feedbackelemente in den interaktiven Patientenfällen).
Wir erwarteten aufgrund dieses Spannungsfeldes in unserer Evaluation übergreifend trotz intensiver Anstrengungen eine eher negative Entwicklung der Veranstaltungsbewertung. Ausgesprochen erfreulich ist für uns daher insbesondere, dass der Untersuchungskurs Augenheilkunde (5. Semester) ausgezeichnete Rückmeldungen erhielt. Es wurde in Freitextantworten zwar das Fehlen von regelmäßigen Präsenzuntersuchungskursen kritisiert, die Vorbereitung auf Präsenzwiederholungsstunde und OSCE mittels Untersuchungsvideos und Online-Tutorensprechstunde aber deutlich gelobt. Das verbesserte Abschneiden gegenüber den Vorsemestern ist aus unserer Sicht am ehesten durch vollständig aktualisierte und optimierte Vorlesungsinhalte und das neue Angebot der Untersuchungsvideos zu erklären.
Herauszustellen ist aus unserer Sicht außerdem, dass wider unsere Erwartungen das Einüben der Untersuchungstechniken an Kommilitonen, Mitbewohnern oder Partnern im eigenen Haushalt überwiegend als hilfreich für das eigene Lernen angesehen wurde. Dies war lediglich als Notlösung konzipiert, aufgrund des positiven Feedbacks werden wir den Studierenden diesen Schritt im Kompetenzerwerb jedoch auch in kommenden Semestern weiterhin empfehlen.
Das Praktikum der Augenheilkunde konnte sich in seinen Bewertungen in etwa auf dem Niveau des Vorsemesters halten und wurde ebenfalls positiv bewertet. Die Praktikumsmodule (Live-Patientenzimmer, Anamnesevideos, Operationsvideos und interaktive Patientenfälle) wurden sogar durchgehend sehr gut bis gut bewertet.
Das im Verhältnis eher schlechte Abschneiden der Vorlesungspodcasts im 6. Semester sehen wir in der Dauer dieser begründet. Am Beginn des Sommersemesters erhielten die Fakultäten die didaktische Empfehlung, Vorlesungspodcasts auf maximal 15–20 min zu beschränken, da dies etwa der potenziellen Aufmerksamkeitsspanne von Zuhörern entspräche. Für das 5. Semester wurde diese Zeit mit durchschnittlich 27 min Vorlesungspodcastdauer überschritten, in der Evaluation allerdings als ideale Dauer zurückgemeldet.
Die Vorlesungspodcasts des 6. Semesters hielten sich an den Vorschlag mit ca. 15 min. Die Evaluation zeigt, dass die längeren Podcasts deutlich besser angenommen wurden. Wir gehen davon aus, dass Studierende sich das Podcastformat dank Pausierbarkeit individuell eingeteilt haben, weshalb die eigentliche Dauer auch über 20 min hinaus keine Problematik darstellte. Bei Einhaltung einer Maximaldauer von 20 min besteht eine Zwickmühle zwischen umfassender Darstellung eines Themengebietes und dessen didaktischer Aufarbeitung. Aufgrund unserer Erfahrungen ist für einen Vorlesungspodcast daher die Zeitmarke von ca. 30 min als sehr sinnvoll anzusehen.
Auf Basis der positiven Evaluation und Erfahrungen mit den digitalen Unterrichtsinhalten planen wir diese, auch nach dem Ende Corona-bedingter Beschränkungen als ergänzende Angebote zum Präsenzunterricht beizubehalten. Die einzige Ausnahme bilden die Online-Tutorien im 5. Semester, da diese wieder durch einen regelmäßigeren Untersuchungskurs (9 Termine wie im bisherigen Unterrichtskonzept) ersetzt würden. Auch Flipped-classroom-Situationen werden so ermöglicht, in welchen Lerninhalte von den Lernenden zu Hause erarbeitet werden und im Unterricht die Anwendung dieser in den Fokus gerückt wird [2, 3, 5].
Die Erstellung eines umfangreichen digitalen Angebotes erfordert Zeit und Geld. Diese Investition sehen wir jedoch auch unabhängig von der Pandemie als geboten an, da das Ziel von Kompetenzerwerb – wie im NKLM gefordert – unserer Erfahrungen nach durch diese unterstützt werden kann und von den Studierenden positiv angenommen wird. Die Umsetzung wird heutzutage durch eine Vielzahl an einsteigerfreundlichen Softwares unterstützt. So sind auch komplexere mediale und interaktive Inhalte durch die Lehrenden umsetzbar.
Das laufende Wintersemester 2020/21 wird an der Universitätsmedizin Mainz als hybrides Semester gestaltet. Aufgrund der sehr positiven Bewertungen der digitalen Lehrinhalte behielten wir diese als Ergänzung bei, um eine zeitgemäße digitale Lehre zu ermöglichen, welche sich in ihren Vorzügen mit denen der Präsenzlehre ergänzt. Feedback und Kritik der Studierenden zu den Lehrveranstaltungen werden aufgegriffen und die Lehrangebote entsprechend verbessert. Weiterhin werden die neuen Angebote mit bisherigen inhaltlich besser verknüpft. Außerdem planen wir, die Abdeckung des Lernzielkatalogs Augenheilkunde durch unsere digitalen Angebote zu überprüfen. Nach durchgeführter Optimierung planen wir voraussichtlich für das Sommersemester 2021 erneut eine umfangreiche Evaluation.
Die Möglichkeiten digitaler Lernmaterialien sind umfangreich, und ein fast ausschließlich digitales Semester konnte durchgeführt werden.Besonders der Erwerb praktischer Kompetenzen kann nur teilweise digital realisiert werden.Eine Kombination aus digitaler Lehre und ausgewählten Präsenzkursen kann die Vorzüge der Formate kombinieren.",Ophthalmologe
